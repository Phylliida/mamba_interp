{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMc-Y6T7HWxg"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Main_Demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W53l8_poHWxh"
   },
   "source": [
    "# Mamba Visualizations\n",
    "\n",
    "Various mamba visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8eCT4qsHWxl",
    "outputId": "bd17767e-7742-4f0c-82a9-53ef6e6b2738"
   },
   "outputs": [],
   "source": [
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# comment this out if you get errors\n",
    "#%matplotlib ipymplf\n",
    "# do pip install nodejs-bin\n",
    "# install node.js\n",
    "# follow these instructions https://stackoverflow.com/a/56416229\n",
    "# this gives u nice hover stuff\n",
    "# not needed, if you get an error feel free to comment it out\n",
    "#pio.renderers.default = \"colab\"\n",
    "#pio.renderers.default = \"notebook_connected\"\n",
    "#print(f\"Using renderer: {pio.renderers.default}\")\n",
    "# Import stuff\n",
    "import torch\n",
    "from functools import partial\n",
    "import transformer_lens.utils as utils\n",
    "import plotly.express as px\n",
    "torch.set_grad_enabled(False)\n",
    "device = utils.get_device()\n",
    "# from neel nanda's examples\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mamba\n",
    "import mamba\n",
    "from importlib import reload\n",
    "reload(mamba)\n",
    "model = mamba.HookedMamba.from_pretrained(\"state-spaces/mamba-370m\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Polygon\n",
    "from  IPython.display import display\n",
    "from einops import rearrange, repeat, einsum\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import IPython\n",
    "\n",
    "# test\n",
    "\n",
    "\n",
    "import mplcursors\n",
    "import colorsys\n",
    "\n",
    "FONT_SIZE = 60\n",
    "prompt_full = 'Then, Shelby and Emma had a lot of fun at the school. Shelby gave a apple to'\n",
    "prompt_tokens_full = model.to_tokens(prompt_full)\n",
    "logits_full, activations_full = model.run_with_cache(prompt_tokens_full)\n",
    "token_labels_full = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(prompt_tokens_full[0]))]\n",
    "\n",
    "# [V,D]\n",
    "embed = model.embedding.weight\n",
    "V,D = embed.size()\n",
    "\n",
    "# [V]\n",
    "embed_sizes = torch.linalg.norm(embed, ord=2, dim=1)\n",
    "# no divide by zero\n",
    "embed_sizes[embed_sizes==0] = 1.0\n",
    "# [V,D]\n",
    "normalized_embed = embed / embed_sizes.view(V,1)\n",
    "\n",
    "def tok_to_str(tok):\n",
    "    if type(tok) is torch.tensor:\n",
    "        tok = tok.item()\n",
    "    return model.to_str_tokens(torch.tensor([tok]))[0]\n",
    "\n",
    "#                       [K,D]    D is model.cfg.D, K is number of vecs we are comparing\n",
    "def find_closest_embeds(vecs):\n",
    "    if len(vecs.size()) == 1:\n",
    "        vecs = vecs.view(1,D)\n",
    "    K,D = vecs.size()\n",
    "    \n",
    "    # [K,1]\n",
    "    vecs_norm = torch.linalg.norm(vecs, ord=2,dim=1, keepdim=True)\n",
    "    # no divide by zero\n",
    "    vecs_norm[vecs_norm==0] = 1.0\n",
    "    # [K,D]          [K,D]    [K,1]\n",
    "    normalized_vecs = vecs / vecs_norm\n",
    "\n",
    "    # [V,K]         [V,D]            [D,K]\n",
    "    dot_prods = normalized_embed @ normalized_vecs.T\n",
    "\n",
    "    # [V,K]\n",
    "    sorted_closest = torch.argsort(-dot_prods, dim=0)\n",
    "\n",
    "    #       [K,V]              [K,V]\n",
    "    return sorted_closest.T, dot_prods.T\n",
    "\n",
    "if not 'diff_mag_lookup' in globals():\n",
    "    global diff_mag_lookup\n",
    "    diff_mag_lookup = None\n",
    "\n",
    "# K is number of inputs, each of size D\n",
    "#                          [K,D]\n",
    "def compare_to_differences(vecs, top_to_keep=2):\n",
    "    batch_size = 200\n",
    "    lookup_batch_size = 40 # needs to be smaller\n",
    "\n",
    "    if len(vecs.size()) == 1: # expand to K dim\n",
    "        vecs = vecs.view(1,D)\n",
    "    if len(vecs.size()) == 3: # remove batch dim\n",
    "        if vecs.size()[0] > 1: raise Exception(f\"only works for batch size = 1, you have input size {vecs.size()}\")\n",
    "        vecs = vecs[0]\n",
    "\n",
    "    # normalize input\n",
    "    norms = torch.linalg.norm(vecs, ord=2, dim=1, keepdim=True)\n",
    "    norms[norms==0] = 1 # don't divide by 0\n",
    "    vecs = vecs / norms\n",
    "    \n",
    "    K,D = vecs.size()\n",
    "    \n",
    "    top_scores = torch.zeros([K,0], device=model.cfg.device)\n",
    "    top_indices = torch.zeros([K,0,2], device=model.cfg.device, dtype=torch.int64)\n",
    "    \n",
    "    arangeK = torch.arange(K, device=model.cfg.device)\n",
    "\n",
    "\n",
    "    # We will do an optimization here\n",
    "    # assume x is normalized\n",
    "    # (x dot (a-b))/norm(a-b)\n",
    "    # = (x dot a - x dot b)/norm(a-b)\n",
    "\n",
    "    # thus we only need all x dot embed (small and ez)\n",
    "    # and a [V,V] lookup of all the norms of a-b\n",
    "    # that lookup is big, but not too big (~10GB of memory)\n",
    "\n",
    "    global diff_mag_lookup\n",
    "    if diff_mag_lookup is None:\n",
    "        diff_mag_lookup = torch.zeros([V,V], device=model.cfg.device)\n",
    "        print(\"computing diff mag lookup\")\n",
    "        for batch_start in tqdm.tqdm(list(range(0, V, lookup_batch_size))):\n",
    "            batch_end = min(batch_start+lookup_batch_size, V)\n",
    "            cur_batch_size = batch_end-batch_start\n",
    "            a        = embed[batch_start:batch_end]\n",
    "            b        = embed\n",
    "            # uses this trick https://stackoverflow.com/questions/53442069/how-to-vectorize-the-following-python-code/53442187#53442187\n",
    "            # because it copies the 1 axes until they match the other dim, this has the effect of:\n",
    "            # res[i,j] is a[i] - b[j]\n",
    "            # [batch_size, V, D]\n",
    "            diffs              = a.view(cur_batch_size,1,D)-b.view(1,V,D)\n",
    "            # [batch_size, V]\n",
    "            norms = torch.linalg.norm(diffs, ord=2, dim=2)\n",
    "            norms[norms==0.0] = 1.0 # no divide by zero!\n",
    "            diff_mag_lookup[batch_start:batch_end,:] = norms\n",
    "    # K,V       [K,D]   [V,D]\n",
    "    dot_prods = vecs @ embed.T\n",
    "\n",
    "    for batch_start in tqdm.tqdm(list(range(0, V, batch_size))):   \n",
    "        batch_end = min(batch_start+batch_size, V)\n",
    "        cur_batch_size = batch_end-batch_start\n",
    "        # [K, batch, V]   \n",
    "        x_dot_a_minus_b = dot_prods[:,batch_start:batch_end].view(K, cur_batch_size, 1) - dot_prods[:].view(K, 1, V)\n",
    "        # [K, batch, V]                 [batch, V]\n",
    "        x_dot_a_minus_b /= diff_mag_lookup[batch_start:batch_end,:].view(1, cur_batch_size, V)\n",
    "        \n",
    "        # [K,batch*V] where [k,i*V+j] = = vecs[k].dot(normalize(a[i] - b[j]))\n",
    "        res2 = x_dot_a_minus_b.flatten(start_dim=1)\n",
    "        # get top_to_keep for each k\n",
    "        # [K,top_to_keep]\n",
    "        scores, inds = torch.topk(-res2, dim=1, k=top_to_keep)\n",
    "    \n",
    "        # decode those into tuple indices\n",
    "        # [K,top_to_keep]\n",
    "        i                = inds // V + batch_start # + batch_start is because of how a is formed\n",
    "        # [K,top_to_keep]\n",
    "        j                = inds % V\n",
    "    \n",
    "        # I can't figure out how to do this and only index the right stuff\n",
    "        # this way is inefficient but it's a small number of things so whatever\n",
    "        # this gives us an array of size [K,top_to_keep] that has the scores of the top elements\n",
    "        #scores = res2[:,top_k][arangeK, arangeK]\n",
    "    \n",
    "        # turn into (i, j) tuples\n",
    "        # [K,top_to_keep,2]\n",
    "        indices = rearrange(torch.stack([j,i]), 'data k n_keep -> k n_keep data')\n",
    "    \n",
    "        # append to existing ones\n",
    "        # [K,top_to_keep*2] (might also just be [K,top_to_keep] if first iter)\n",
    "        top_scores = torch.concatenate([top_scores, scores], dim=1)\n",
    "        # [K,top_to_keep*2,2] (might also just be [K,top_to_keep,2] if first iter)\n",
    "        top_indices = torch.concatenate([top_indices, indices], dim=1)\n",
    "        \n",
    "        # cut off so we only have top_k\n",
    "        # [K,top_to_keep]\n",
    "        top_k = torch.argsort(-top_scores, dim=1)[:,:top_to_keep]\n",
    "        # [K,top_to_keep] \n",
    "        top_scores = top_scores[:,top_k][arangeK, arangeK]\n",
    "        # [K,top_to_keep,2]\n",
    "        top_indices = top_indices[:,top_k][arangeK, arangeK]\n",
    "        \n",
    "    #     [K,top_to_keep,2]   [K,top_to_keep]\n",
    "    return top_indices,        top_scores\n",
    "\n",
    "                                                        \n",
    "    \n",
    "    '''\n",
    "        a        = embed[batch_start:batch_end]\n",
    "        b        = embed\n",
    "        # uses this trick https://stackoverflow.com/questions/53442069/how-to-vectorize-the-following-python-code/53442187#53442187\n",
    "        # because it copies the 1 axes until they match the other dim, this has the effect of:\n",
    "        # res[i,j] is a[i] - b[j]\n",
    "        \n",
    "        # [batch_size, V, D]\n",
    "        diffs              = a.view(batch_size,1,D)-b.view(1,V,D)\n",
    "        norms = torch.linalg.norm(diffs, ord=2, dim=2, keepdim=True)\n",
    "        norms[norms==0] = 1.0 # no divide by zero (this happens when a vec is subtracted by itself)\n",
    "        diffs   = diffs / norms\n",
    "    \n",
    "        # now we need to dot each one by vec\n",
    "        # this does\n",
    "        # res[k,i,j] = vecs[k].dot(normalize(a[i] - b[j]))\n",
    "        # [K,batch,V]\n",
    "        res = einsum(diffs, vecs, \"batch V D, K D -> K batch V\")\n",
    "    \n",
    "        # [K,batch*V] where [k,i*V+j] = = vecs[k].dot(normalize(a[i] - b[j]))\n",
    "        res2 = res.flatten(start_dim=1)\n",
    "    \n",
    "        # get top_to_keep for each k\n",
    "        # [K,top_to_keep]\n",
    "        top_k = torch.argsort(-res2, dim=1)[:,:top_to_keep]\n",
    "    \n",
    "        # decode those into tuple indices\n",
    "        # [K,top_to_keep]\n",
    "        i                = top_k // V + batch_start # + batch_start is because of how a is formed\n",
    "        # [K,top_to_keep]\n",
    "        j                = top_k % V\n",
    "    \n",
    "        # I can't figure out how to do this and only index the right stuff\n",
    "        # this way is inefficient but it's a small number of things so whatever\n",
    "        # this gives us an array of size [K,top_to_keep] that has the scores of the top elements\n",
    "        scores = res2[:,top_k][arangeK, arangeK]\n",
    "    \n",
    "        # turn into (i, j) tuples\n",
    "        # [K,top_to_keep,2]\n",
    "        indices = rearrange(torch.stack([i,j]), 'data k n_keep -> k n_keep data')\n",
    "    \n",
    "        # append to existing ones\n",
    "        # [K,top_to_keep*2] (might also just be [K,top_to_keep] if first iter)\n",
    "        top_scores = torch.concatenate([top_scores, scores], dim=1)\n",
    "        # [K,top_to_keep*2,2] (might also just be [K,top_to_keep,2] if first iter)\n",
    "        top_indices = torch.concatenate([top_indices, indices], dim=1)\n",
    "    \n",
    "        # cut off so we only have top_k\n",
    "        # [K,top_to_keep]\n",
    "        top_k = torch.argsort(-top_scores, dim=1)[:,:top_to_keep]\n",
    "        # [K,top_to_keep] \n",
    "        top_scores = top_scores[:,top_k][arangeK, arangeK]\n",
    "        # [K,top_to_keep,2]\n",
    "        top_indices = top_indices[:,top_k][arangeK, arangeK]\n",
    "\n",
    "    #     [K,top_to_keep,2]   [K,top_to_keep]\n",
    "    return top_indices,        top_scores\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "def make_logit_image(prs, min_pr, max_pr, words, width, height, cmap):\n",
    "    cmap = matplotlib.colormaps.get_cmap(cmap)\n",
    "    \n",
    "    img = Image.new('RGBA', (width, height), (0, 0, 0, 0))\n",
    "     \n",
    "    I1 = ImageDraw.Draw(img)\n",
    "\n",
    "    def map_pr_to_color(pr):\n",
    "        return cmap((pr-min_pr)/(max_pr-min_pr))\n",
    "    \n",
    "    cell_width = width/float(len(words[0]))\n",
    "    cell_height = height/float(len(words))\n",
    "    fonts = dict([(i, ImageFont.truetype('Roboto-Regular.ttf', i)) for i in range(1, FONT_SIZE+1)])\n",
    "    for y, word_list in enumerate(words):\n",
    "        for x, word in enumerate(word_list):\n",
    "            top_left_x = cell_width*x\n",
    "            top_left_y = cell_height*y\n",
    "            color = map_pr_to_color(prs[y][x])\n",
    "            r,g,b = color[0], color[1], color[2]\n",
    "            I1.rectangle((top_left_x, top_left_y, top_left_x+cell_width, top_left_y+cell_height), fill=(int(r*255), int(g*255), int(b*255),255))\n",
    "    for y, word_list in enumerate(words):\n",
    "        for x, word in enumerate(word_list):\n",
    "            top_left_x = cell_width*x\n",
    "            top_left_y = cell_height*y\n",
    "            if word.strip() == \"\": continue\n",
    "            font_size = FONT_SIZE\n",
    "            while True:\n",
    "                tl, tt, tr, tb = I1.textbbox(xy=(0,0), text=word, font=fonts[font_size])\n",
    "                word_width = tr-tl\n",
    "                word_height = tb-tt\n",
    "                if word_width >= cell_width:\n",
    "                    font_size -= 1\n",
    "                else:\n",
    "                    break\n",
    "            # we want center of word to be at center of cell\n",
    "            # by default, center of word is at\n",
    "            center_of_word_x = top_left_x + word_width/2.0\n",
    "            # we need some offset s.t. center is at middle of cell:\n",
    "            # offset_x + center_of_word_x = top_left_x + cell_width/2.0\n",
    "            # so\n",
    "            offset_x = top_left_x + cell_width/2.0 - center_of_word_x\n",
    "            if offset_x > 0:\n",
    "                offset_x  -= 4 # fixing for space padding\n",
    "            #                202         32        -100.0      204.8\n",
    "            #print(word, word_width, word_height, offset_x, cell_width)\n",
    "            x_pos = top_left_x + offset_x\n",
    "\n",
    "            # same for y\n",
    "            center_of_word_y = top_left_y + word_height/2.0\n",
    "            offset_y = top_left_y + cell_height/2.0 - center_of_word_y\n",
    "            if offset_y > 0:\n",
    "                offset_y  -= 4 # fixing for space padding\n",
    "            \n",
    "            y_pos = top_left_y + offset_y# + cell_height//2\n",
    "            color = map_pr_to_color(prs[y][x])\n",
    "            r,g,b = color[0], color[1], color[2]\n",
    "            h, s, v = colorsys.rgb_to_hsv(r,g,b)\n",
    "            r, g, b = colorsys.hsv_to_rgb(h+0.5, 1.0-s, v)\n",
    "            \n",
    "            I1.text((x_pos, y_pos), word, fill=(0,0,0,255), font=fonts[font_size])\n",
    "    \n",
    "    return img\n",
    "\n",
    "def display_logit_lens(title, colorbar_label, token_labels, prs, words, width, height, cmap='Purples', logits=False):\n",
    "    \n",
    "    prompt_len = len(prs[0])\n",
    "\n",
    "    if logits:\n",
    "        flattened = torch.tensor(prs).flatten()\n",
    "        min_val, max_val = torch.min(flattened).item(), torch.max(flattened).item()\n",
    "        print(\"min logit\", min_val)\n",
    "        print(\"max logit\", max_val)\n",
    "    else:\n",
    "        min_val, max_val = 0.0, 1.0\n",
    "    \n",
    "    img = make_logit_image(min_pr=min_val, max_pr=max_val, prs=prs, words=words, width=width, height=height, cmap=cmap)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    cbar_ax = ax.pcolor(torch.tensor([[min_val,max_val]]), cmap=cmap)\n",
    "    cbar = fig.colorbar(cbar_ax)\n",
    "    cbar.set_label(colorbar_label)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    plt.title(title)\n",
    "    \n",
    "    x_bin_size = width/float(prompt_len)\n",
    "    x_locs = [i*x_bin_size+x_bin_size//2 for i in range(len(token_labels))]\n",
    "    x_labels = token_labels\n",
    "    plt.xticks(x_locs, x_labels)\n",
    "    ax.tick_params(axis=\"x\", bottom=True, top=True, labelbottom=True, labeltop=True)\n",
    "    plt.setp([tick.label1 for tick in ax.xaxis.get_major_ticks()], rotation=45, ha=\"right\", va=\"center\", rotation_mode=\"anchor\")\n",
    "    plt.setp([tick.label2 for tick in ax.xaxis.get_major_ticks()], rotation=45, ha=\"left\", va=\"center\",rotation_mode=\"anchor\")\n",
    "    \n",
    "    ax.set_ylabel(\"Layer\") \n",
    "    ax.tick_params(axis=\"y\", left=True, right=True, labelleft=True, labelright=True)\n",
    "    y_bin_size = height/float(model.cfg.n_layers)\n",
    "    y_locs = [i*y_bin_size+y_bin_size//2 for i in range(model.cfg.n_layers)]\n",
    "    y_labels = [f'{i+1}' for i in range(model.cfg.n_layers)]\n",
    "    plt.yticks(y_locs, y_labels)\n",
    "    \n",
    "    plt.savefig('out.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def view_logit_lens_wrapper(label, token_labels, prompt_tokens, values_iter, lens, norm, clip_first_two):\n",
    "    prompt_toks = prompt_tokens\n",
    "    if len(prompt_tokens.size()) == 2: # batch\n",
    "        prompt_toks = prompt_tokens[0]\n",
    "    sims = []\n",
    "    strs = []\n",
    "    for values in values_iter:\n",
    "        # [B,L,D]\n",
    "        values = values.clone()\n",
    "        if len(values.size()) == 2: # add batch dim if none\n",
    "            values = values.view(1, values.size()[0], values.size()[1])\n",
    "        if norm:\n",
    "            # [B,L,D]\n",
    "            values   = model.norm(values)\n",
    "\n",
    "        if lens == DIFFERENCE_LENS:\n",
    "            # [L,1,2]     [L,1]                                    [L,D]\n",
    "            top_indices, top_scores      = compare_to_differences(values[0],top_to_keep=1)\n",
    "            L,V = values[0].size()\n",
    "            layer_words = []\n",
    "            for l in range(L):\n",
    "                sim = top_scores[l,0].item()\n",
    "                toks = top_indices[l,0]\n",
    "                token_str_a = model.to_str_tokens(torch.tensor([toks[0].item()]))[0]\n",
    "                token_str_b = model.to_str_tokens(torch.tensor([toks[1].item()]))[0]\n",
    "                res_str = \"[\" + token_str_a + \" - \" + token_str_b + \"]\"\n",
    "                layer_words.append((res_str, sim))\n",
    "            sims.append([sim for (tok, sim) in layer_words])\n",
    "            strs.append([tok for (tok, sim) in layer_words])\n",
    "            print(f\"layer {len(sims)}, layer_words {layer_words}\")\n",
    "            \n",
    "        elif lens == COSINE_LENS:\n",
    "            # [L,V]  [L,V]                       [L,D]\n",
    "            closest, res_sims = find_closest_embeds(values[0])\n",
    "            \n",
    "            top_toks = closest[:,0]\n",
    "            layer_words = []\n",
    "            for l, top_tok in enumerate(top_toks):\n",
    "                sim = res_sims[l,top_tok].item()\n",
    "                token_str = model.to_str_tokens(torch.tensor([top_tok.item()]))[0]\n",
    "                layer_words.append((token_str, sim))\n",
    "            sims.append([sim for (tok, sim) in layer_words])\n",
    "            strs.append([tok for (tok, sim) in layer_words])\n",
    "\n",
    "        elif lens in [LM_HEAD_LENS, LM_HEAD_LOGIT_LENS,LM_HEAD_LOG_LOGIT_LENS]:\n",
    "            # [B,L,V]\n",
    "            layer_logits = model.lm_head(values)\n",
    "    \n",
    "            # [B,L,V]             [B,L,V]\n",
    "            prs = torch.softmax(layer_logits, dim=2)\n",
    "            # [B,L,V]             [B,L,V]\n",
    "            top_n = torch.argsort(-layer_logits, dim=2)\n",
    "    \n",
    "            layer_words = []\n",
    "            B,L,V = top_n.size()\n",
    "            for l in range(L):\n",
    "                # [1]\n",
    "                top_tok = top_n[0,l,0]\n",
    "                token_str = model.to_str_tokens(torch.tensor([top_tok.item()]))[0]\n",
    "                # [1]\n",
    "                if lens == LM_HEAD_LENS:\n",
    "                    pr = prs[0,l,top_tok].item()\n",
    "                elif lens == LM_HEAD_LOGIT_LENS:\n",
    "                    pr = layer_logits[0,l,top_tok].item()\n",
    "                elif lens == LM_HEAD_LOG_LOGIT_LENS:\n",
    "                    pr = torch.sign(layer_logits[0,l,top_tok])*torch.log(torch.abs(layer_logits[0,l,top_tok]))\n",
    "                    pr = pr.item()\n",
    "                layer_words.append((token_str, pr))\n",
    "            sims.append([pr for (tok, pr) in layer_words])\n",
    "            strs.append([tok for (tok, pr) in layer_words])\n",
    "\n",
    "    if clip_first_two:\n",
    "        sims = [s[2:] for s in sims]\n",
    "        strs = [s[2:] for s in strs]\n",
    "        labels = token_labels[2:]\n",
    "    else:\n",
    "        labels = token_labels\n",
    "    \n",
    "    width = 2048*2\n",
    "    height = 2048*2\n",
    "\n",
    "    withOrWithout = {True: 'with', False: 'without'}[norm]\n",
    "    colorbar_label = {LM_HEAD_LENS: 'pr', \n",
    "                      COSINE_LENS: 'Cosine similarity', \n",
    "                      LM_HEAD_LOGIT_LENS: 'logit',\n",
    "                      LM_HEAD_LOG_LOGIT_LENS: 'log(logit)',\n",
    "                      DIFFERENCE_LENS: 'Cosine similarity (to a difference between two embedding vectors)'}[lens]\n",
    "    using_logits = lens in [LM_HEAD_LOGIT_LENS, LM_HEAD_LOG_LOGIT_LENS]\n",
    "    display_logit_lens(title=f'{lens} Logit Lens {withOrWithout} norm for {label}', logits=using_logits, colorbar_label=colorbar_label, token_labels=labels, prs=sims, words=strs, width=width, height=height)\n",
    "    \n",
    "\n",
    "def view_logit_lens(token_labels, prompt_tokens, norm, lens, n, clip_first_two, **kwargs):\n",
    "   def values_func_iter():\n",
    "        for layer in range(model.cfg.n_layers):\n",
    "            yield activations_full[f'blocks.{layer}.hook_resid_post']\n",
    "   view_logit_lens_wrapper(label='resid post', norm=norm, lens=lens, token_labels=token_labels, prompt_tokens=prompt_tokens, clip_first_two=clip_first_two, values_iter=values_func_iter())\n",
    "\n",
    "def view_logit_lens_resid_pre(token_labels, prompt_tokens, norm, lens, n, clip_first_two, **kwargs):\n",
    "   def values_func_iter():\n",
    "        for layer in range(model.cfg.n_layers):\n",
    "            yield activations_full[f'blocks.{layer}.hook_resid_pre']\n",
    "   view_logit_lens_wrapper(label='resid pre', norm=norm, lens=lens, token_labels=token_labels, prompt_tokens=prompt_tokens, clip_first_two=clip_first_two, values_iter=values_func_iter())\n",
    "\n",
    "\n",
    "def h_values_func_iter(token_labels, n, do_D=True, do_skip=True):\n",
    "    L = len(token_labels)\n",
    "    E,N = model.cfg.E, model.cfg.N\n",
    "    for layer_i in range(model.cfg.n_layers):\n",
    "        layer = model.blocks[layer_i]\n",
    "        all_h = torch.zeros([L,E], device=model.cfg.device)\n",
    "        for l in range(L):\n",
    "            #  [E]                                           [B,E,N][0,:,n]\n",
    "            all_h[l] = activations_full[f'blocks.{layer_i}.hook_h.{l}'][0,:,n]\n",
    "        if do_D:\n",
    "            # [B,L,E]\n",
    "            x    = activations_full[f'blocks.{layer_i}.hook_ssm_input']\n",
    "            # [L,E]        [L,E]  [L,E]      [1,E]\n",
    "            ssm_output = all_h + x[0,:]*layer.W_D.view(1,E)\n",
    "        else:\n",
    "            ssm_output = all_h\n",
    "\n",
    "        if do_skip:\n",
    "            # [B,L,E]\n",
    "            skip = activations_full[f'blocks.{layer_i}.hook_skip_proj']\n",
    "            # [L,E]        [L,E]                [L,E]\n",
    "            model_out   = ssm_output * F.silu (skip[0,:])\n",
    "        else:\n",
    "            model_out   = ssm_output\n",
    "        # [L,D]             [E->D]   [L,E]\n",
    "        proj_out   = layer.out_proj(model_out)\n",
    "        yield proj_out\n",
    "\n",
    "def view_h_lens(token_labels, prompt_tokens, norm, lens, n, clip_first_two, skip, D, **kwargs):\n",
    "    withOrWithout = {True: 'with', False: 'without'}\n",
    "    d_str = withOrWithout[D] + \" D\"\n",
    "    skip_str = withOrWithout[skip] + \" skip\"\n",
    "    c_str = withOrWithout[C] + \" C\"\n",
    "    view_logit_lens_wrapper(label=f'h[{n}] {d_str}, {skip_str}', norm=norm, lens=lens, token_labels=token_labels, prompt_tokens=prompt_tokens, clip_first_two=clip_first_two,\n",
    "                            values_iter=h_values_func_iter(n=n, do_D=D, do_skip=skip, token_labels=token_labels))\n",
    "\n",
    "def h_resid_values_func_iter(token_labels, n, do_D=True, do_skip=True, do_C=True):\n",
    "    L = len(token_labels)\n",
    "    E,N = model.cfg.E, model.cfg.N\n",
    "    # [L,D]\n",
    "    resid = activations_full[f'hook_embed'][0]\n",
    "    for layer_i in range(model.cfg.n_layers):\n",
    "        layer = model.blocks[layer_i]\n",
    "        all_h = torch.zeros([L,E], device=model.cfg.device)\n",
    "        for l in range(L):\n",
    "            #  [E]                                           [B,E,N][0,:,n]\n",
    "            all_h[l] = activations_full[f'blocks.{layer_i}.hook_h.{l}'][0,:,n]\n",
    "        if do_C:\n",
    "            # [B,L,N]\n",
    "            C = activations_full[f'blocks.{layer_i}.hook_C']\n",
    "            # [L]\n",
    "            C_n = C[0,:,n]\n",
    "            # expand C_n to be same size as all_h\n",
    "            # [L,E]   [L,E]   [L,1]\n",
    "            all_h   = all_h * C_n.view(L,1)\n",
    "        \n",
    "        if do_D:\n",
    "            # [B,L,E]\n",
    "            x    = activations_full[f'blocks.{layer_i}.hook_ssm_input']\n",
    "            # [L,E]        [L,E]  [L,E]      [1,E]\n",
    "            ssm_output = all_h + x[0,:]*layer.W_D.view(1,E)\n",
    "        else:\n",
    "            ssm_output = all_h\n",
    "\n",
    "        if do_skip:\n",
    "            # [B,L,E]\n",
    "            skip = activations_full[f'blocks.{layer_i}.hook_skip_proj']\n",
    "            # [L,E]        [L,E]                [L,E]\n",
    "            model_out   = ssm_output * F.silu (skip[0,:])\n",
    "        else:\n",
    "            model_out   = ssm_output\n",
    "        \n",
    "        # [L,D]             [E->D]   [L,E]\n",
    "        proj_out   = layer.out_proj(model_out)\n",
    "        resid += proj_out\n",
    "        yield resid\n",
    "\n",
    "\n",
    "def view_h_resid_lens(token_labels, prompt_tokens, norm, lens, n, clip_first_two, skip, D, C):\n",
    "    withOrWithout = {True: 'with', False: 'without'}\n",
    "    d_str = withOrWithout[D] + \" D\"\n",
    "    skip_str = withOrWithout[skip] + \" skip\"\n",
    "    c_str = withOrWithout[C] + \" C\"\n",
    "    view_logit_lens_wrapper(label=f'h[{n}] contributions to resid {d_str}, {skip_str}, {c_str}', norm=norm, lens=lens, token_labels=token_labels, prompt_tokens=prompt_tokens, clip_first_two=clip_first_two,\n",
    "                            values_iter=h_resid_values_func_iter(n=n, do_D=D, do_skip=skip, do_C=C, token_labels=token_labels))\n",
    "\n",
    "\n",
    "def top_n_outputs(token_labels, prompt_tokens, n, lens=None, norm=None, clip_first_two=None):\n",
    "    # [B,L,V]\n",
    "    logits = activations_full[f'hook_logits']\n",
    "    top_n = torch.argsort(-logits, dim=2)\n",
    "    # [B,L,V]\n",
    "    prs = torch.softmax(logits, dim=2)\n",
    "    L = len(token_labels)\n",
    "    all_strs = []\n",
    "    all_prs = []\n",
    "    if n == 0:\n",
    "        print(\"need n to be > 0\")\n",
    "        return\n",
    "    for i in range(n):\n",
    "        out_strs = []\n",
    "        out_prs = []\n",
    "        for l in range(L):\n",
    "            top_tok = top_n[0,l,i]\n",
    "            top_pr = prs[0,l,top_tok]\n",
    "            out_strs.append(tok_to_str(top_tok.item()))\n",
    "            out_prs.append(top_pr.item())\n",
    "        all_strs.append(out_strs)\n",
    "        all_prs.append(out_prs)\n",
    "    \n",
    "    width = 2048*2\n",
    "    height = 2048*2\n",
    "    \n",
    "    display_logit_lens(title=f'Top {n} output tokens', logits=False, colorbar_label='pr', token_labels=token_labels, prs=all_prs, words=all_strs, width=width, height=height)\n",
    "\n",
    "def show_C_full(token_labels, n, **kwargs):\n",
    "    L = len(token_labels)\n",
    "    E,N = model.cfg.E, model.cfg.N\n",
    "    all_C = torch.zeros([model.cfg.n_layers, L], device=model.cfg.device)\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        # [L]                [B,L,N][0,:,n]\n",
    "        C = activations_full[f'blocks.{layer}.hook_C'][0,:,n]\n",
    "        all_C[layer,:] = C\n",
    "    \n",
    "    imshow(all_C, x=token_labels, xaxis=\"Position\", yaxis=\"Layer\", title=f\"C for n={n}\")\n",
    "    \n",
    "options_full = dict([\n",
    "    ('logit_lens resid_post', partial(view_logit_lens, token_labels=token_labels_full, prompt_tokens=prompt_tokens_full)),\n",
    "    ('logit_lens resid_pre', partial(view_logit_lens_resid_pre, token_labels=token_labels_full, prompt_tokens=prompt_tokens_full)),\n",
    "    (\"h_logit_lens\", partial(view_h_lens, token_labels=token_labels_full, prompt_tokens=prompt_tokens_full)),\n",
    "    (\"h fake logit_lens\", partial(view_h_resid_lens, token_labels=token_labels_full, prompt_tokens=prompt_tokens_full)),\n",
    "    (\"top n outputs\", partial(top_n_outputs, token_labels=token_labels_full, prompt_tokens=prompt_tokens_full)),\n",
    "    (\"C\", partial(show_C_full, token_labels=token_labels_full)),\n",
    "])\n",
    "\n",
    "def visualize_full(option, norm, lens, n, clip_first_two, skip, D, C):\n",
    "    norm = norm == 'True'\n",
    "    clip_first_two = clip_first_two == 'True'\n",
    "    skip = skip == 'True'\n",
    "    D = D == 'True'\n",
    "    C = C == 'True'\n",
    "    n = int(n)\n",
    "    options_full[option](norm=norm, lens=lens, n=n, clip_first_two=clip_first_two, skip=skip, D=D, C=C)\n",
    "\n",
    "COSINE_LENS = 'Cosine similarity'\n",
    "LM_HEAD_LENS = 'lm_head'\n",
    "LM_HEAD_LOGIT_LENS = 'lm_head logits'\n",
    "LM_HEAD_LOG_LOGIT_LENS = 'lm_head log logits'\n",
    "DIFFERENCE_LENS = 'Cosine similarity of differences'\n",
    "\n",
    "text_options_full = list(options_full.keys())\n",
    "interact(visualize_full, option=text_options_full, norm=['False', 'True'], lens=[COSINE_LENS, LM_HEAD_LENS,LM_HEAD_LOGIT_LENS,LM_HEAD_LOG_LOGIT_LENS, DIFFERENCE_LENS],n=[str(n) for n in range(model.cfg.N)], clip_first_two=['False', 'True'], skip=['True', 'False'], D=['True', 'False'], C=['True', 'False'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "#emb, dists = find_closest_embeds(model.norm.weight.view(1, -1))\n",
    "#dists[0,emb[0,0]], emb, dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[24856, 32781],\n",
       "          [31870, 32781],\n",
       "          [24856, 36271],\n",
       "          [27542, 32781]],\n",
       " \n",
       "         [[18687,  8529],\n",
       "          [18687, 31077],\n",
       "          [39355, 39601],\n",
       "          [25295,  8529]],\n",
       " \n",
       "         [[ 7773, 17958],\n",
       "          [20186, 17958],\n",
       "          [20186, 37282],\n",
       "          [ 3864, 17958]]], device='cuda:0'),\n",
       " tensor([[0.1779, 0.1740, 0.1734, 0.1733],\n",
       "         [0.1890, 0.1885, 0.1846, 0.1813],\n",
       "         [0.1767, 0.1750, 0.1720, 0.1715]], device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.randn([3, model.cfg.D], device=model.cfg.device)\n",
    "res1, res2 = compare_to_differences(v, 4)\n",
    "res1, res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1890, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizeVec(a):\n",
    "    n = torch.linalg.norm(a, ord=2)\n",
    "    if n == 0: n = 1\n",
    "    return a/n\n",
    "normalizeVec(v[1]).dot(normalizeVec(embed[18687]-embed[8529]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  282, 38327], device='cuda:0'), tensor(0.1291, device='cuda:0'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "top_indices[1,5], top_scores[1,5]\n",
    "\n",
    "\n",
    "\n",
    "#top_kf = torch.stack([torch.arange(K,device=model.cfg.device).view(K,1).expand((K,top_to_keep)), top_k])\n",
    "#top_kf = rearrange(top_kf, 'pairs k n_keep -> k n_keep pairs')\n",
    "\n",
    "#top_k[top_kf[:,:,0], top_kf[:,:,1]]\n",
    "\n",
    "#res2[:,top_k[:]][1],res2[0,top_k[0]]\n",
    "#res2[4,6*V+2], vecs[4].dot(normalizeVec(a[6]-b[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1291, device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizeVec(a):\n",
    "    n = torch.linalg.norm(a, ord=2)\n",
    "    if n == 0: n = 1\n",
    "    return a/n\n",
    "vecs[1].dot(normalizeVec(embed[282]-embed[38327]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer-wise visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237edd29e09f43eebf700ae4a9099db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='layer', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize(layer, option)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "import time\n",
    "\n",
    "prompt = 'Then, Shelby and Emma had a lot of fun at the school. Shelby gave a apple to'\n",
    "prompt_tokens = model.to_tokens(prompt)\n",
    "logits, activations = model.run_with_cache(prompt_tokens)\n",
    "token_labels = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(prompt_tokens[0]))]\n",
    "task = 'IOI task'\n",
    "\n",
    "def show_delta_1(layer, token_labels):\n",
    "    imshow(activations[f'blocks.{layer}.hook_delta_1'][0].T, x=token_labels, xaxis=\"Position\", yaxis=\"D_delta\", title=f\"WDelta1(x)[pos, D_delta] for each stream for layer {layer}\")\n",
    "\n",
    "def show_delta(layer, token_labels):\n",
    "    imshow(activations[f'blocks.{layer}.hook_delta'][0].T, x=token_labels, xaxis=\"Position\", yaxis=\"E\", title=f\"Deltas[Position, E] for each stream for layer {layer}\")\n",
    "    \n",
    "def show_delta_clipped(layer, token_labels):\n",
    "    imshow(activations[f'blocks.{layer}.hook_delta'][0].T[:,2:], x=token_labels[2:], xaxis=\"Position\", yaxis=\"E\", title=f\"Deltas[2:][Position, E] for each stream for layer {layer}\")\n",
    "    \n",
    "def show_A(layer):\n",
    "    # [E,N]\n",
    "    A = -torch.exp(model.blocks[layer].A_log)\n",
    "    CHUNK_SIZE = model.cfg.N*8\n",
    "    for chunk_start in range(0, model.cfg.E, CHUNK_SIZE):\n",
    "        imshow(A[chunk_start:chunk_start+CHUNK_SIZE].T, x=[str(x) for x in range(chunk_start, chunk_start+CHUNK_SIZE)],xaxis=\"E\", yaxis=\"N\", title=f\"A[E,N] for layer {layer} (A=-exp(A_log), A_log is learned param)\")\n",
    "    \n",
    "def show_exp_A(layer):\n",
    "    # note, these will all be < 1 because of the way A is computed via A = -exp(A_log)\n",
    "    # [E,N]\n",
    "    A = torch.exp(-torch.exp(model.blocks[layer].A_log))\n",
    "    CHUNK_SIZE = model.cfg.N*8\n",
    "    for chunk_start in range(0, model.cfg.E, CHUNK_SIZE):\n",
    "        imshow(A[chunk_start:chunk_start+CHUNK_SIZE].T, x=[str(x) for x in range(chunk_start, chunk_start+CHUNK_SIZE)],xaxis=\"E\", yaxis=\"N\", title=f\"exp(A)[E,N] for layer {layer} (A=-exp(A_log), A_log is learned param)\")\n",
    "    \n",
    "def show_h(layer, token_labels):\n",
    "    L = len(token_labels)\n",
    "    E,N = model.cfg.E, model.cfg.N\n",
    "    all_h = torch.zeros([L,E,N])\n",
    "    for l in range(L):\n",
    "        all_h[l] = activations[f'blocks.{layer}.hook_h.{l}'][0]\n",
    "    for n in range(N):\n",
    "        imshow(all_h[:,:,n].T, x=token_labels, xaxis=\"Position\", yaxis=\"E\", title=f\"h for layer {layer} with n={n}\")\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def show_C(layer, token_labels):\n",
    "    L = len(token_labels)\n",
    "    E,N = model.cfg.E, model.cfg.N\n",
    "    # [L,N]                [B,L,N][0]\n",
    "    C = activations[f'blocks.{layer}.hook_C'][0]\n",
    "    imshow(C.T, x=token_labels, xaxis=\"Position\", yaxis=\"N\", title=f\"C for layer {layer}\")\n",
    "    \n",
    "options = dict([\n",
    "    ('delta_1', partial(show_delta_1, token_labels=token_labels)),\n",
    "    ('delta', partial(show_delta, token_labels=token_labels)),\n",
    "    ('delta_clipped', partial(show_delta_clipped, token_labels=token_labels)),\n",
    "    ('A', show_A),\n",
    "    ('exp(A)', show_exp_A),\n",
    "    ('h', partial(show_h, token_labels=token_labels)),\n",
    "    ('C', partial(show_C, token_labels=token_labels)),\n",
    "])\n",
    "\n",
    "def visualize(layer, option):\n",
    "    options[option](layer)\n",
    "\n",
    "    \n",
    "text_options = list(options.keys())\n",
    "interact(visualize, layer=range(model.cfg.n_layers), option=text_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream-wise visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed20ed3f2eb41c1911744e305ccfe38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='e', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize(e, option)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "prompt_e = 'Then, Shelby and Emma had a lot of fun at the school. Shelby gave a apple to'\n",
    "prompt_tokens_e = model.to_tokens(prompt_e)\n",
    "logits_e, activations_e = model.run_with_cache(prompt_tokens_e)\n",
    "token_labels_e = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(prompt_tokens_e[0]))]\n",
    "\n",
    "def show_delta_e(e, token_labels_e):\n",
    "    L = len(token_labels_e)\n",
    "    delta_e = torch.zeros([L,model.cfg.n_layers])\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        # [B,L,E]\n",
    "        delta   =    activations[f'blocks.{layer}.hook_delta']\n",
    "        #                      [L]\n",
    "        delta_e[:,layer] = delta[0,:,e]\n",
    "    imshow(delta_e.T, x=token_labels_e, xaxis=\"Position\", yaxis=\"Layer\", title=f\"Deltas[Position,e] for stream {e} on the IOI Task\")\n",
    "\n",
    "def show_delta_e_clipped(e, token_labels_e):\n",
    "    L = len(token_labels_e)\n",
    "    delta_e = torch.zeros([L-2,model.cfg.n_layers])\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        # [B,L,E]\n",
    "        delta   =    activations[f'blocks.{layer}.hook_delta']\n",
    "        #                      [L]\n",
    "        delta_e[:,layer] = delta[0,2:,e]\n",
    "    imshow(delta_e.T, x=token_labels_e[2:], xaxis=\"Position\", yaxis=\"Layer\", title=f\"Deltas[2:][Position,e] for stream {e} on the IOI Task\")\n",
    "\n",
    "def show_A_e(e):\n",
    "    A_e = torch.zeros([model.cfg.N, model.cfg.n_layers])\n",
    "    \n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        # [E,N]\n",
    "        A = -torch.exp(model.blocks[layer].A_log)\n",
    "        A_e[:,layer] = A[e]\n",
    "    imshow(A_e, xaxis=\"Layer\", yaxis=\"N\", title=f\"A for stream {e} (A=-exp(A_log)[N], A_log is learned param)\")\n",
    "    \n",
    "def show_exp_A_e(e):\n",
    "    exp_A_e = torch.zeros([model.cfg.N, model.cfg.n_layers])\n",
    "    \n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        # [E,N]\n",
    "        A = -torch.exp(model.blocks[layer].A_log)\n",
    "        exp_A_e[:,layer] = torch.exp(A[e])\n",
    "    imshow(exp_A_e, xaxis=\"Layer\", yaxis=\"N\", title=f\"exp(A)[N] for stream {e} (A=-exp(A_log), A_log is learned param)\")\n",
    "    \n",
    "    \n",
    "options_e = dict([\n",
    "    ('delta', partial(show_delta_e, token_labels_e=token_labels_e)),\n",
    "    ('delta_clipped', partial(show_delta_e_clipped, token_labels_e=token_labels_e)),\n",
    "    ('A', show_A_e),\n",
    "    ('exp(A)', show_exp_A_e),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "def visualize(e, option):\n",
    "    options_e[option](e)\n",
    "text_options_e = list(options_e.keys())\n",
    "interact(visualize, e=range(model.cfg.E), option=text_options_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer-wise and Stream-wise visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac725bdb8b7a4b7fbb3b297b94a5c411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='layer', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize(layer, e, option)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "prompt_l_e = 'Then, Shelby and Emma had a lot of fun at the school. Shelby gave a apple to'\n",
    "prompt_tokens_l_e = model.to_tokens(prompt_l_e)\n",
    "logits_l_e, activations_l_e = model.run_with_cache(prompt_tokens_l_e)\n",
    "token_labels_l_e = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(prompt_tokens_l_e[0]))]\n",
    "\n",
    "\n",
    "def show_x(layer,e, token_labels_l_e):\n",
    "    L = len(token_labels_l_e)\n",
    "    all_x = torch.zeros([L])\n",
    "    for l in range(L):                         # [B,L,E]\n",
    "        all_x[l]   =    activations[f'blocks.{layer}.hook_ssm_input'][0,l,e]\n",
    "    imshow(all_x.view(1,L), x=token_labels_l_e,xaxis=\"Tokens\", yaxis=\"N\", title=f\"x for layer {layer} and stream {e}\")\n",
    "\n",
    "    \n",
    "def show_h(layer,e, token_labels_l_e):\n",
    "    L = len(token_labels_l_e)\n",
    "    all_h = torch.zeros([model.cfg.N,L])\n",
    "    for l in range(L):\n",
    "        all_h[:,l]   =    activations[f'blocks.{layer}.hook_h.{l}'][0][e]\n",
    "    imshow(all_h, x=token_labels_l_e,xaxis=\"Tokens\", yaxis=\"N\", title=f\"h for layer {layer} and stream {e}\")\n",
    "\n",
    "def show_y(layer,e, token_labels_l_e):\n",
    "    L = len(token_labels_l_e)\n",
    "    all_y = torch.zeros([L])\n",
    "    for l in range(L):                         # [B,L,E]\n",
    "        all_y[l]   =    activations[f'blocks.{layer}.hook_ssm_input'][0,l,e]\n",
    "    imshow(all_y.view(1,L), x=token_labels_l_e,xaxis=\"Tokens\", yaxis=\"N\", title=f\"y for layer {layer} and stream {e}\")\n",
    "\n",
    "options_l_e = dict([\n",
    "    ('x', partial(show_x, token_labels_l_e=token_labels_l_e)),\n",
    "    ('h', partial(show_h, token_labels_l_e=token_labels_l_e)),\n",
    "    ('y', partial(show_y, token_labels_l_e=token_labels_l_e)),\n",
    "])\n",
    "\n",
    "def visualize(layer, e, option):\n",
    "    options_l_e[option](layer=layer, e=e)\n",
    "text_options_l_e = list(options_l_e.keys())\n",
    "interact(visualize, layer=range(model.cfg.n_layers), e=range(model.cfg.E), option=text_options_l_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181a96d2a60b4184a9a1b424468c880d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='patching_type', options=('h', 'resid_pre'), value='h'), Output()),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.choose_patching_type(patching_type)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d6bdd5583447eb9e0a7c9a9d78e25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run Patching', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# modified from neel nanda's examples\n",
    "\n",
    "import tqdm\n",
    "from functools import partial\n",
    "from jaxtyping import Float\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, Button\n",
    "\n",
    "prompt_uncorrupted = 'Then, Shelby and Emma had a lot of fun at the school. Shelby gave a apple to'\n",
    "prompt_uncorrupted_tokens = model.to_tokens(prompt_uncorrupted)\n",
    "prompt_corrupted = 'Then, Shelby and Emma had a lot of fun at the school. Emma gave a apple to'\n",
    "prompt_corrupted_tokens = model.to_tokens(prompt_corrupted)\n",
    "uncorrupted_answer = ' Emma' # note the space in front is important\n",
    "corrupted_answer = ' Shelby'\n",
    "\n",
    "# logits should be [B,L,V] \n",
    "def uncorrupted_logit_minus_corrupted_logit(logits, uncorrupted_answer, corrupted_answer):\n",
    "    uncorrupted_index = model.to_single_token(uncorrupted_answer)\n",
    "    corrupted_index = model.to_single_token(corrupted_answer)\n",
    "    return logits[0, -1, uncorrupted_index] - logits[0, -1, corrupted_index]\n",
    "\n",
    "corrupted_logits, corrupted_activations = model.run_with_cache(prompt_corrupted_tokens)\n",
    "corrupted_diff = uncorrupted_logit_minus_corrupted_logit(logits=corrupted_logits, uncorrupted_answer=uncorrupted_answer, corrupted_answer=corrupted_answer)\n",
    "\n",
    "uncorrupted_logits = model(prompt_uncorrupted_tokens)\n",
    "uncorrupted_diff = uncorrupted_logit_minus_corrupted_logit(logits=uncorrupted_logits, uncorrupted_answer=uncorrupted_answer, corrupted_answer=corrupted_answer)\n",
    "\n",
    "# We make a tensor to store the results for each patching run. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
    "L = len(prompt_uncorrupted_tokens[0])\n",
    "if len(prompt_corrupted_tokens[0]) != len(prompt_uncorrupted_tokens[0]):\n",
    "    raise Exception(\"Prompts are not the same length\") # feel free to comment this out, you can patch for different sized prompts its just a lil sus\n",
    "\n",
    "# diff is logit of uncorrupted_answer - logit of corrupted_answer\n",
    "# we expect corrupted_diff to have a negative value (as corrupted should put high pr on corrupted_answer)\n",
    "# we expect uncorrupted to have a positive value (as uncorrupted should put high pr on uncorrupted_answer)\n",
    "# thus we can treat these as (rough) min and max possible values\n",
    "min_value = corrupted_diff\n",
    "max_value = uncorrupted_diff\n",
    "\n",
    "# make token labels that describe the patch\n",
    "corrupted_str_tokens = model.to_str_tokens(prompt_corrupted_tokens)\n",
    "uncorrupted_str_tokens = model.to_str_tokens(prompt_uncorrupted_tokens)\n",
    "token_labels = []\n",
    "for index, (corrupted_token, uncorrupted_token) in enumerate(zip(corrupted_str_tokens, uncorrupted_str_tokens)):\n",
    "    if corrupted_token == uncorrupted_token:\n",
    "        token_labels.append(f\"{corrupted_token}_{index}\")\n",
    "    else:\n",
    "        token_labels.append(f\"{uncorrupted_token}->{corrupted_token}_{index}\")\n",
    "\n",
    "def run_patching(patching_hook_name_func, patching_hook_func):\n",
    "    global patching_result # if you want to access it once this is done running\n",
    "    patching_result = torch.zeros((model.cfg.n_layers, L), device=model.cfg.device)\n",
    "    patching_result[layer, position] = normalized_patched_diff\n",
    "    for layer in tqdm.tqdm(range(model.cfg.n_layers)):\n",
    "        for position in range(L):\n",
    "            patching_hook_name = patching_hook_name_func(layer=layer, position=position)\n",
    "            patching_hook = partial(patching_hook_func, layer=layer, position=position)\n",
    "            patched_logits = model.run_with_hooks(prompt_uncorrupted_tokens, fwd_hooks=[\n",
    "                (patching_hook_name, )\n",
    "            ])\n",
    "            patched_diff = uncorrupted_logit_minus_corrupted_logit(patched_logits, uncorrupted_answer=uncorrupted_answer, corrupted_answer=corrupted_answer).detach()\n",
    "    \n",
    "            # normalize it so 0 means min_value (so 0 means that it is acting like the corrupted model)\n",
    "            # and 1 means max_value (so 1 means that it is acting like the uncorrupted model)\n",
    "            normalized_patched_diff = (patched_diff-min_value)/(max_value-min_value)\n",
    "    \n",
    "    imshow(patching_result, x=token_labels, xaxis=\"Position\", yaxis=\"Layer\", title=\"Normalized Logit Difference After Patching inputs to layers (resid_pre), on the IOI Task\")\n",
    "\n",
    "\n",
    "# 'blocks.{layer}.resid_pre' is the inputs to the layer\n",
    "def resid_pre_patching_hook(\n",
    "    resid_pre: Float[torch.Tensor, \"B L D\"],\n",
    "    hook: HookPoint,\n",
    "    position: int,\n",
    "    layer: int # we don't care about this\n",
    ") -> Float[torch.Tensor, \"B L D\"]:\n",
    "    # only intervene on the specific pos\n",
    "    corrupted_resid_pre = corrupted_activations[hook.name]\n",
    "    resid_pre[:, position, :] = corrupted_resid_pre[:, position, :]\n",
    "    return resid_pre\n",
    "\n",
    "# 'blocks.{layer}.h.{pos}' is the recurrent state of that layer after processing tokens at and before pos position\n",
    "def h_patching_hook(\n",
    "    h: Float[torch.Tensor, \"B E N\"],\n",
    "    hook: HookPoint,\n",
    "    position: int,\n",
    "    layer: int\n",
    ") -> Float[torch.Tensor, \"B E N\"]:\n",
    "    return corrupted_activations[hook.name]\n",
    "\n",
    "patching_types = {\n",
    "    'resid_pre': (lambda layer, pos: f'blocks.{layer}.hook_resid_pre', resid_pre_patching_hook),\n",
    "    'h': (lambda layer, pos: f'blocks.{layer}.hook_h.{pos}', h_patching_hook)\n",
    "}\n",
    "\n",
    "patching_types_keys = sorted(list(patching_types.keys()))\n",
    "global patching_type\n",
    "patching_type = patching_types_keys[0]\n",
    "\n",
    "def choose_patching_type(patching_type):\n",
    "    globals()['patching_type'] = patching_type\n",
    "\n",
    "display(interact(choose_patching_type, patching_type=patching_types_keys))\n",
    "\n",
    "def do_patching(arg):\n",
    "    global patching_type\n",
    "    print(f\"henlo {patching_type}\")\n",
    "\n",
    "patching_button = Button(description = 'Run Patching')\n",
    "patching_button.on_click(do_patching)\n",
    "display(patching_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Position: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "<|endoftext|>_0",
          "Then_1",
          ",_2",
          " Shelby_3",
          " and_4",
          " Emma_5",
          " had_6",
          " a_7",
          " lot_8",
          " of_9",
          " fun_10",
          " at_11",
          " the_12",
          " school_13",
          "._14",
          " Shelby-> Emma_15",
          " gave_16",
          " a_17",
          " apple_18",
          " to_19"
         ],
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ]
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Normalized Logit Difference After Patching inputs to layers, on the IOI Task"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          -1,
          6
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Position"
         },
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          -1,
          4
         ],
         "title": {
          "text": "Layer"
         }
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"2ed68e34-3fbb-4137-b8e4-bc6687802f7c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2ed68e34-3fbb-4137-b8e4-bc6687802f7c\")) {                    Plotly.newPlot(                        \"2ed68e34-3fbb-4137-b8e4-bc6687802f7c\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"Then_1\",\",_2\",\" Shelby_3\",\" and_4\",\" Emma_5\",\" had_6\",\" a_7\",\" lot_8\",\" of_9\",\" fun_10\",\" at_11\",\" the_12\",\" school_13\",\"._14\",\" Shelby-\\u003e Emma_15\",\" gave_16\",\" a_17\",\" apple_18\",\" to_19\"],\"z\":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Position: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Normalized Logit Difference After Patching inputs to layers, on the IOI Task\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2ed68e34-3fbb-4137-b8e4-bc6687802f7c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.2002\n",
      "19.2005\n",
      "19.2006\n",
      "19.2007\n",
      "19.2010\n",
      "19.2013\n",
      "19.2016\n",
      "19.2019\n",
      "19.2020\n",
      "19.2021\n",
      "19.2022\n",
      "19.2023\n",
      "19.2024\n",
      "19.2026\n",
      "19.2030\n",
      "19.2031\n",
      "19.2033\n",
      "19.2034\n",
      "19.2036\n",
      "19.2040\n",
      "19.2044\n",
      "19.2045\n",
      "19.2046\n",
      "20\n",
      "20.11\n",
      "20.17\n",
      "20.18\n",
      "20.19\n",
      "20.22\n",
      "20.34\n",
      "20.50\n",
      "20.59\n",
      "20.60\n",
      "20.62\n",
      "20.64\n",
      "20.70\n",
      "20.77\n",
      "20.82\n",
      "20.96\n",
      "20.99\n",
      "20.102\n",
      "20.104\n",
      "20.127\n",
      "20.128\n",
      "20.129\n",
      "20.136\n",
      "20.153\n",
      "20.154\n",
      "20.162\n",
      "20.176\n",
      "20.185\n",
      "20.186\n",
      "20.191\n",
      "20.200\n",
      "20.210\n",
      "20.211\n",
      "20.217\n",
      "20.222\n",
      "20.225\n",
      "20.226\n",
      "20.232\n",
      "20.237\n",
      "20.239\n",
      "20.256\n",
      "20.266\n",
      "20.280\n",
      "20.287\n",
      "20.288\n",
      "20.290\n",
      "20.292\n",
      "20.293\n",
      "20.297\n",
      "20.314\n",
      "20.315\n",
      "20.317\n",
      "20.320\n",
      "20.326\n",
      "20.345\n",
      "20.347\n",
      "20.355\n",
      "20.360\n",
      "20.363\n",
      "20.367\n",
      "20.369\n",
      "20.382\n",
      "20.383\n",
      "20.426\n",
      "20.433\n",
      "20.435\n",
      "20.436\n",
      "20.437\n",
      "20.455\n",
      "20.459\n",
      "20.465\n",
      "20.469\n",
      "20.477\n",
      "20.485\n",
      "20.491\n",
      "20.493\n",
      "20.512\n",
      "20.515\n",
      "20.516\n",
      "20.522\n",
      "20.526\n",
      "20.527\n",
      "20.534\n",
      "20.535\n",
      "20.544\n",
      "20.547\n",
      "20.550\n",
      "20.556\n",
      "20.558\n",
      "20.566\n",
      "20.572\n",
      "20.573\n",
      "20.574\n",
      "20.575\n",
      "20.577\n",
      "20.580\n",
      "20.587\n",
      "20.593\n",
      "20.599\n",
      "20.607\n",
      "20.609\n",
      "20.624\n",
      "20.626\n",
      "20.629\n",
      "20.635\n",
      "20.637\n",
      "20.652\n",
      "20.654\n",
      "20.662\n",
      "20.666\n",
      "20.670\n",
      "20.673\n",
      "20.677\n",
      "20.679\n",
      "20.685\n",
      "20.687\n",
      "20.691\n",
      "20.693\n",
      "20.694\n",
      "20.699\n",
      "20.700\n",
      "20.719\n",
      "20.728\n",
      "20.738\n",
      "20.746\n",
      "20.747\n",
      "20.751\n",
      "20.758\n",
      "20.760\n",
      "20.761\n",
      "20.772\n",
      "20.775\n",
      "20.776\n",
      "20.777\n",
      "20.778\n",
      "20.783\n",
      "20.791\n",
      "20.796\n",
      "20.802\n",
      "20.819\n",
      "20.832\n",
      "20.835\n",
      "20.842\n",
      "20.847\n",
      "20.851\n",
      "20.854\n",
      "20.855\n",
      "20.858\n",
      "20.865\n",
      "20.868\n",
      "20.872\n",
      "20.879\n",
      "20.885\n",
      "20.890\n",
      "20.900\n",
      "20.903\n",
      "20.907\n",
      "20.908\n",
      "20.930\n",
      "20.942\n",
      "20.944\n",
      "20.949\n",
      "20.956\n",
      "20.957\n",
      "20.961\n",
      "20.962\n",
      "20.970\n",
      "20.971\n",
      "20.974\n",
      "20.977\n",
      "20.987\n",
      "20.991\n",
      "20.999\n",
      "20.1003\n",
      "20.1007\n",
      "20.1012\n",
      "20.1014\n",
      "20.1015\n",
      "20.1016\n",
      "20.1019\n",
      "20.1020\n",
      "20.1023\n",
      "20.1030\n",
      "20.1032\n",
      "20.1034\n",
      "20.1038\n",
      "20.1040\n",
      "20.1045\n",
      "20.1050\n",
      "20.1056\n",
      "20.1065\n",
      "20.1066\n",
      "20.1073\n",
      "20.1082\n",
      "20.1086\n",
      "20.1089\n",
      "20.1100\n",
      "20.1110\n",
      "20.1116\n",
      "20.1128\n",
      "20.1130\n",
      "20.1138\n",
      "20.1139\n",
      "20.1143\n",
      "20.1144\n",
      "20.1145\n",
      "20.1153\n",
      "20.1158\n",
      "20.1160\n",
      "20.1162\n",
      "20.1164\n",
      "20.1166\n",
      "20.1170\n",
      "20.1172\n",
      "20.1176\n",
      "20.1180\n",
      "20.1182\n",
      "20.1186\n",
      "20.1194\n",
      "20.1198\n",
      "20.1202\n",
      "20.1204\n",
      "20.1208\n",
      "20.1211\n",
      "20.1229\n",
      "20.1234\n",
      "20.1238\n",
      "20.1240\n",
      "20.1255\n",
      "20.1286\n",
      "20.1289\n",
      "20.1296\n",
      "20.1297\n",
      "20.1310\n",
      "20.1316\n",
      "20.1317\n",
      "20.1319\n",
      "20.1322\n",
      "20.1325\n",
      "20.1334\n",
      "20.1342\n",
      "20.1353\n",
      "20.1357\n",
      "20.1367\n",
      "20.1369\n",
      "20.1389\n",
      "20.1398\n",
      "20.1399\n",
      "20.1400\n",
      "20.1402\n",
      "20.1408\n",
      "20.1413\n",
      "20.1414\n",
      "20.1422\n",
      "20.1430\n",
      "20.1439\n",
      "20.1446\n",
      "20.1480\n",
      "20.1484\n",
      "20.1491\n",
      "20.1493\n",
      "20.1498\n",
      "20.1503\n",
      "20.1505\n",
      "20.1509\n",
      "20.1510\n",
      "20.1515\n",
      "20.1516\n",
      "20.1526\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m all_h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mN,L])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(L):\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mall_h\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m   \u001b[38;5;241m=\u001b[39m    activations[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.hook_h.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][e]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39mabs(all_h)\u001b[38;5;241m>\u001b[39mEPS):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Visualize the results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "0.1\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "0.10\n",
      "0.11\n",
      "0.13\n",
      "0.15\n",
      "0.16\n",
      "0.18\n",
      "0.19\n",
      "0.20\n",
      "0.21\n",
      "0.22\n",
      "0.24\n",
      "0.25\n",
      "0.26\n",
      "0.27\n",
      "0.28\n",
      "0.29\n",
      "0.30\n",
      "0.31\n",
      "0.32\n",
      "0.33\n",
      "0.34\n",
      "0.35\n",
      "0.36\n",
      "0.37\n",
      "0.38\n",
      "0.39\n",
      "0.40\n",
      "0.41\n",
      "0.42\n",
      "0.44\n",
      "0.45\n",
      "0.46\n",
      "0.47\n",
      "0.49\n",
      "0.50\n",
      "0.51\n",
      "0.52\n",
      "0.53\n",
      "0.54\n",
      "0.55\n",
      "0.56\n",
      "0.57\n",
      "0.58\n",
      "0.59\n",
      "0.60\n",
      "0.61\n",
      "0.63\n",
      "0.64\n",
      "0.65\n",
      "0.66\n",
      "0.67\n",
      "0.68\n",
      "0.69\n",
      "0.70\n",
      "0.71\n",
      "0.72\n",
      "0.73\n",
      "0.74\n",
      "0.75\n",
      "0.76\n",
      "0.79\n",
      "0.81\n",
      "0.82\n",
      "0.83\n",
      "0.84\n",
      "0.85\n",
      "0.86\n",
      "0.87\n",
      "0.88\n",
      "0.89\n",
      "0.90\n",
      "0.91\n",
      "0.92\n",
      "0.93\n",
      "0.95\n",
      "0.96\n",
      "0.97\n",
      "0.98\n",
      "0.100\n",
      "0.101\n",
      "0.102\n",
      "0.103\n",
      "0.104\n",
      "0.105\n",
      "0.106\n",
      "0.107\n",
      "0.109\n",
      "0.110\n",
      "0.111\n",
      "0.112\n",
      "0.113\n",
      "0.114\n",
      "0.115\n",
      "0.116\n",
      "0.117\n",
      "0.118\n",
      "0.119\n",
      "0.120\n",
      "0.121\n",
      "0.122\n",
      "0.123\n",
      "0.125\n",
      "0.126\n",
      "0.127\n",
      "0.128\n",
      "0.129\n",
      "0.130\n",
      "0.131\n",
      "0.132\n",
      "0.133\n",
      "0.134\n",
      "0.135\n",
      "0.136\n",
      "0.137\n",
      "0.138\n",
      "0.139\n",
      "0.140\n",
      "0.141\n",
      "0.142\n",
      "0.143\n",
      "0.144\n",
      "0.146\n",
      "0.147\n",
      "0.148\n",
      "0.149\n",
      "0.151\n",
      "0.152\n",
      "0.153\n",
      "0.154\n",
      "0.155\n",
      "0.156\n",
      "0.157\n",
      "0.158\n",
      "0.160\n",
      "0.161\n",
      "0.162\n",
      "0.163\n",
      "0.164\n",
      "0.165\n",
      "0.166\n",
      "0.167\n",
      "0.168\n",
      "0.169\n",
      "0.170\n",
      "0.171\n",
      "0.172\n",
      "0.173\n",
      "0.174\n",
      "0.175\n",
      "0.176\n",
      "0.179\n",
      "0.180\n",
      "0.181\n",
      "0.182\n",
      "0.184\n",
      "0.185\n",
      "0.186\n",
      "0.187\n",
      "0.188\n",
      "0.189\n",
      "0.190\n",
      "0.191\n",
      "0.192\n",
      "0.193\n",
      "0.194\n",
      "0.195\n",
      "0.196\n",
      "0.198\n",
      "0.199\n",
      "0.200\n",
      "0.202\n",
      "0.204\n",
      "0.205\n",
      "0.208\n",
      "0.209\n",
      "0.210\n",
      "0.212\n",
      "0.214\n",
      "0.215\n",
      "0.216\n",
      "0.217\n",
      "0.218\n",
      "0.219\n",
      "0.221\n",
      "0.222\n",
      "0.223\n",
      "0.224\n",
      "0.225\n",
      "0.226\n",
      "0.227\n",
      "0.228\n",
      "0.229\n",
      "0.230\n",
      "0.231\n",
      "0.235\n",
      "0.237\n",
      "0.238\n",
      "0.239\n",
      "0.240\n",
      "0.242\n",
      "0.243\n",
      "0.244\n",
      "0.245\n",
      "0.246\n",
      "0.247\n",
      "0.248\n",
      "0.249\n",
      "0.250\n",
      "0.251\n",
      "0.252\n",
      "0.253\n",
      "0.254\n",
      "0.255\n",
      "0.256\n",
      "0.258\n",
      "0.259\n",
      "0.260\n",
      "0.261\n",
      "0.262\n",
      "0.264\n",
      "0.265\n",
      "0.266\n",
      "0.267\n",
      "0.268\n",
      "0.269\n",
      "0.270\n",
      "0.271\n",
      "0.272\n",
      "0.273\n",
      "0.274\n",
      "0.275\n",
      "0.276\n",
      "0.277\n",
      "0.278\n",
      "0.279\n",
      "0.280\n",
      "0.282\n",
      "0.283\n",
      "0.284\n",
      "0.286\n",
      "0.287\n",
      "0.288\n",
      "0.289\n",
      "0.290\n",
      "0.291\n",
      "0.292\n",
      "0.293\n",
      "0.294\n",
      "0.296\n",
      "0.297\n",
      "0.298\n",
      "0.299\n",
      "0.300\n",
      "0.301\n",
      "0.302\n",
      "0.303\n",
      "0.304\n",
      "0.305\n",
      "0.306\n",
      "0.307\n",
      "0.308\n",
      "0.309\n",
      "0.310\n",
      "0.311\n",
      "0.312\n",
      "0.313\n",
      "0.314\n",
      "0.315\n",
      "0.316\n",
      "0.317\n",
      "0.319\n",
      "0.320\n",
      "0.321\n",
      "0.322\n",
      "0.323\n",
      "0.324\n",
      "0.325\n",
      "0.326\n",
      "0.327\n",
      "0.328\n",
      "0.330\n",
      "0.331\n",
      "0.332\n",
      "0.333\n",
      "0.335\n",
      "0.336\n",
      "0.337\n",
      "0.338\n",
      "0.339\n",
      "0.340\n",
      "0.342\n",
      "0.344\n",
      "0.345\n",
      "0.346\n",
      "0.347\n",
      "0.348\n",
      "0.351\n",
      "0.352\n",
      "0.353\n",
      "0.354\n",
      "0.355\n",
      "0.356\n",
      "0.357\n",
      "0.358\n",
      "0.359\n",
      "0.360\n",
      "0.362\n",
      "0.364\n",
      "0.365\n",
      "0.366\n",
      "0.367\n",
      "0.368\n",
      "0.370\n",
      "0.371\n",
      "0.372\n",
      "0.373\n",
      "0.374\n",
      "0.375\n",
      "0.376\n",
      "0.379\n",
      "0.380\n",
      "0.381\n",
      "0.382\n",
      "0.383\n",
      "0.384\n",
      "0.385\n",
      "0.386\n",
      "0.387\n",
      "0.388\n",
      "0.389\n",
      "0.391\n",
      "0.392\n",
      "0.393\n",
      "0.394\n",
      "0.395\n",
      "0.397\n",
      "0.398\n",
      "0.399\n",
      "0.400\n",
      "0.401\n",
      "0.402\n",
      "0.403\n",
      "0.404\n",
      "0.406\n",
      "0.408\n",
      "0.409\n",
      "0.410\n",
      "0.411\n",
      "0.412\n",
      "0.414\n",
      "0.415\n",
      "0.416\n",
      "0.418\n",
      "0.419\n",
      "0.420\n",
      "0.421\n",
      "0.422\n",
      "0.423\n",
      "0.425\n",
      "0.426\n",
      "0.427\n",
      "0.428\n",
      "0.432\n",
      "0.433\n",
      "0.434\n",
      "0.435\n",
      "0.437\n",
      "0.438\n",
      "0.439\n",
      "0.440\n",
      "0.441\n",
      "0.442\n",
      "0.443\n",
      "0.444\n",
      "0.445\n",
      "0.447\n",
      "0.449\n",
      "0.450\n",
      "0.453\n",
      "0.455\n",
      "0.456\n",
      "0.459\n",
      "0.460\n",
      "0.461\n",
      "0.462\n",
      "0.463\n",
      "0.464\n",
      "0.465\n",
      "0.466\n",
      "0.467\n",
      "0.468\n",
      "0.469\n",
      "0.470\n",
      "0.471\n",
      "0.472\n",
      "0.473\n",
      "0.474\n",
      "0.475\n",
      "0.477\n",
      "0.478\n",
      "0.479\n",
      "0.480\n",
      "0.481\n",
      "0.482\n",
      "0.483\n",
      "0.484\n",
      "0.485\n",
      "0.486\n",
      "0.488\n",
      "0.489\n",
      "0.492\n",
      "0.493\n",
      "0.494\n",
      "0.495\n",
      "0.496\n",
      "0.497\n",
      "0.498\n",
      "0.499\n",
      "0.501\n",
      "0.502\n",
      "0.503\n",
      "0.504\n",
      "0.506\n",
      "0.507\n",
      "0.508\n",
      "0.509\n",
      "0.510\n",
      "0.511\n",
      "0.512\n",
      "0.513\n",
      "0.514\n",
      "0.516\n",
      "0.517\n",
      "0.518\n",
      "0.519\n",
      "0.520\n",
      "0.522\n",
      "0.523\n",
      "0.524\n",
      "0.525\n",
      "0.526\n",
      "0.527\n",
      "0.529\n",
      "0.531\n",
      "0.533\n",
      "0.534\n",
      "0.535\n",
      "0.536\n",
      "0.538\n",
      "0.539\n",
      "0.540\n",
      "0.541\n",
      "0.542\n",
      "0.544\n",
      "0.545\n",
      "0.546\n",
      "0.547\n",
      "0.548\n",
      "0.549\n",
      "0.550\n",
      "0.551\n",
      "0.553\n",
      "0.554\n",
      "0.556\n",
      "0.557\n",
      "0.559\n",
      "0.562\n",
      "0.563\n",
      "0.564\n",
      "0.565\n",
      "0.566\n",
      "0.567\n",
      "0.569\n",
      "0.570\n",
      "0.571\n",
      "0.573\n",
      "0.574\n",
      "0.575\n",
      "0.576\n",
      "0.578\n",
      "0.579\n",
      "0.580\n",
      "0.581\n",
      "0.582\n",
      "0.584\n",
      "0.585\n",
      "0.586\n",
      "0.588\n",
      "0.589\n",
      "0.590\n",
      "0.591\n",
      "0.592\n",
      "0.593\n",
      "0.594\n",
      "0.595\n",
      "0.596\n",
      "0.597\n",
      "0.598\n",
      "0.599\n",
      "0.600\n",
      "0.602\n",
      "0.603\n",
      "0.605\n",
      "0.606\n",
      "0.607\n",
      "0.608\n",
      "0.609\n",
      "0.610\n",
      "0.611\n",
      "0.612\n",
      "0.614\n",
      "0.616\n",
      "0.617\n",
      "0.620\n",
      "0.621\n",
      "0.622\n",
      "0.623\n",
      "0.624\n",
      "0.626\n",
      "0.627\n",
      "0.628\n",
      "0.629\n",
      "0.631\n",
      "0.632\n",
      "0.634\n",
      "0.635\n",
      "0.636\n",
      "0.637\n",
      "0.638\n",
      "0.639\n",
      "0.640\n",
      "0.642\n",
      "0.643\n",
      "0.644\n",
      "0.645\n",
      "0.646\n",
      "0.647\n",
      "0.648\n",
      "0.649\n",
      "0.650\n",
      "0.651\n",
      "0.652\n",
      "0.653\n",
      "0.654\n",
      "0.656\n",
      "0.658\n",
      "0.659\n",
      "0.660\n",
      "0.661\n",
      "0.663\n",
      "0.664\n",
      "0.665\n",
      "0.666\n",
      "0.667\n",
      "0.670\n",
      "0.671\n",
      "0.672\n",
      "0.673\n",
      "0.674\n",
      "0.675\n",
      "0.676\n",
      "0.677\n",
      "0.678\n",
      "0.679\n",
      "0.680\n",
      "0.681\n",
      "0.682\n",
      "0.683\n",
      "0.684\n",
      "0.685\n",
      "0.686\n",
      "0.687\n",
      "0.688\n",
      "0.689\n",
      "0.690\n",
      "0.691\n",
      "0.692\n",
      "0.694\n",
      "0.695\n",
      "0.696\n",
      "0.697\n",
      "0.698\n",
      "0.699\n",
      "0.700\n",
      "0.702\n",
      "0.703\n",
      "0.704\n",
      "0.705\n",
      "0.706\n",
      "0.707\n",
      "0.711\n",
      "0.712\n",
      "0.713\n",
      "0.714\n",
      "0.715\n",
      "0.716\n",
      "0.717\n",
      "0.718\n",
      "0.719\n",
      "0.720\n",
      "0.721\n",
      "0.723\n",
      "0.724\n",
      "0.725\n",
      "0.726\n",
      "0.727\n",
      "0.728\n",
      "0.729\n",
      "0.730\n",
      "0.731\n",
      "0.732\n",
      "0.733\n",
      "0.734\n",
      "0.735\n",
      "0.736\n",
      "0.737\n",
      "0.738\n",
      "0.739\n",
      "0.742\n",
      "0.743\n",
      "0.744\n",
      "0.745\n",
      "0.746\n",
      "0.747\n",
      "0.748\n",
      "0.749\n",
      "0.750\n",
      "0.751\n",
      "0.752\n",
      "0.753\n",
      "0.754\n",
      "0.755\n",
      "0.756\n",
      "0.757\n",
      "0.758\n",
      "0.759\n",
      "0.760\n",
      "0.761\n",
      "0.762\n",
      "0.763\n",
      "0.764\n",
      "0.765\n",
      "0.766\n",
      "0.767\n",
      "0.769\n",
      "0.770\n",
      "0.771\n",
      "0.772\n",
      "0.774\n",
      "0.775\n",
      "0.776\n",
      "0.777\n",
      "0.778\n",
      "0.780\n",
      "0.781\n",
      "0.782\n",
      "0.783\n",
      "0.784\n",
      "0.785\n",
      "0.786\n",
      "0.787\n",
      "0.789\n",
      "0.790\n",
      "0.791\n",
      "0.792\n",
      "0.793\n",
      "0.794\n",
      "0.795\n",
      "0.796\n",
      "0.798\n",
      "0.799\n",
      "0.800\n",
      "0.801\n",
      "0.802\n",
      "0.803\n",
      "0.804\n",
      "0.805\n",
      "0.806\n",
      "0.807\n",
      "0.808\n",
      "0.809\n",
      "0.812\n",
      "0.813\n",
      "0.814\n",
      "0.815\n",
      "0.816\n",
      "0.817\n",
      "0.818\n",
      "0.819\n",
      "0.820\n",
      "0.821\n",
      "0.822\n",
      "0.823\n",
      "0.824\n",
      "0.826\n",
      "0.827\n",
      "0.828\n",
      "0.829\n",
      "0.830\n",
      "0.832\n",
      "0.835\n",
      "0.836\n",
      "0.837\n",
      "0.838\n",
      "0.839\n",
      "0.840\n",
      "0.842\n",
      "0.843\n",
      "0.844\n",
      "0.845\n",
      "0.846\n",
      "0.848\n",
      "0.850\n",
      "0.852\n",
      "0.853\n",
      "0.854\n",
      "0.855\n",
      "0.856\n",
      "0.858\n",
      "0.860\n",
      "0.861\n",
      "0.862\n",
      "0.863\n",
      "0.864\n",
      "0.865\n",
      "0.866\n",
      "0.867\n",
      "0.868\n",
      "0.869\n",
      "0.870\n",
      "0.871\n",
      "0.872\n",
      "0.873\n",
      "0.874\n",
      "0.875\n",
      "0.876\n",
      "0.877\n",
      "0.880\n",
      "0.881\n",
      "0.882\n",
      "0.883\n",
      "0.884\n",
      "0.885\n",
      "0.886\n",
      "0.887\n",
      "0.888\n",
      "0.889\n",
      "0.890\n",
      "0.891\n",
      "0.893\n",
      "0.894\n",
      "0.895\n",
      "0.896\n",
      "0.897\n",
      "0.898\n",
      "0.899\n",
      "0.900\n",
      "0.901\n",
      "0.902\n",
      "0.903\n",
      "0.904\n",
      "0.905\n",
      "0.906\n",
      "0.908\n",
      "0.909\n",
      "0.911\n",
      "0.912\n",
      "0.913\n",
      "0.914\n",
      "0.915\n",
      "0.916\n",
      "0.917\n",
      "0.919\n",
      "0.920\n",
      "0.921\n",
      "0.922\n",
      "0.923\n",
      "0.924\n",
      "0.925\n",
      "0.926\n",
      "0.927\n",
      "0.929\n",
      "0.930\n",
      "0.931\n",
      "0.932\n",
      "0.933\n",
      "0.934\n",
      "0.935\n",
      "0.936\n",
      "0.937\n",
      "0.938\n",
      "0.940\n",
      "0.941\n",
      "0.942\n",
      "0.943\n",
      "0.945\n",
      "0.946\n",
      "0.947\n",
      "0.948\n",
      "0.949\n",
      "0.950\n",
      "0.951\n",
      "0.952\n",
      "0.954\n",
      "0.955\n",
      "0.956\n",
      "0.957\n",
      "0.958\n",
      "0.960\n",
      "0.961\n",
      "0.962\n",
      "0.963\n",
      "0.965\n",
      "0.966\n",
      "0.967\n",
      "0.969\n",
      "0.970\n",
      "0.971\n",
      "0.972\n",
      "0.973\n",
      "0.974\n",
      "0.975\n",
      "0.977\n",
      "0.978\n",
      "0.979\n",
      "0.980\n",
      "0.981\n",
      "0.982\n",
      "0.983\n",
      "0.984\n",
      "0.985\n",
      "0.986\n",
      "0.989\n",
      "0.990\n",
      "0.992\n",
      "0.993\n",
      "0.994\n",
      "0.996\n",
      "0.997\n",
      "0.998\n",
      "0.999\n",
      "0.1000\n",
      "0.1001\n",
      "0.1002\n",
      "0.1003\n",
      "0.1004\n",
      "0.1005\n",
      "0.1006\n",
      "0.1007\n",
      "0.1009\n",
      "0.1010\n",
      "0.1011\n",
      "0.1012\n",
      "0.1013\n",
      "0.1014\n",
      "0.1015\n",
      "0.1016\n",
      "0.1017\n",
      "0.1018\n",
      "0.1019\n",
      "0.1020\n",
      "0.1021\n",
      "0.1022\n",
      "0.1023\n",
      "0.1025\n",
      "0.1026\n",
      "0.1027\n",
      "0.1028\n",
      "0.1030\n",
      "0.1032\n",
      "0.1033\n",
      "0.1035\n",
      "0.1036\n",
      "0.1037\n",
      "0.1038\n",
      "0.1039\n",
      "0.1040\n",
      "0.1041\n",
      "0.1042\n",
      "0.1043\n",
      "0.1044\n",
      "0.1045\n",
      "0.1048\n",
      "0.1049\n",
      "0.1051\n",
      "0.1052\n",
      "0.1053\n",
      "0.1054\n",
      "0.1055\n",
      "0.1056\n",
      "0.1057\n",
      "0.1058\n",
      "0.1059\n",
      "0.1060\n",
      "0.1061\n",
      "0.1062\n",
      "0.1063\n",
      "0.1064\n",
      "0.1065\n",
      "0.1066\n",
      "0.1067\n",
      "0.1068\n",
      "0.1069\n",
      "0.1070\n",
      "0.1071\n",
      "0.1072\n",
      "0.1073\n",
      "0.1075\n",
      "0.1076\n",
      "0.1077\n",
      "0.1078\n",
      "0.1080\n",
      "0.1082\n",
      "0.1083\n",
      "0.1084\n",
      "0.1085\n",
      "0.1086\n",
      "0.1087\n",
      "0.1088\n",
      "0.1090\n",
      "0.1091\n",
      "0.1092\n",
      "0.1093\n",
      "0.1094\n",
      "0.1095\n",
      "0.1096\n",
      "0.1097\n",
      "0.1098\n",
      "0.1099\n",
      "0.1100\n",
      "0.1101\n",
      "0.1102\n",
      "0.1103\n",
      "0.1104\n",
      "0.1105\n",
      "0.1107\n",
      "0.1108\n",
      "0.1109\n",
      "0.1110\n",
      "0.1112\n",
      "0.1113\n",
      "0.1114\n",
      "0.1115\n",
      "0.1116\n",
      "0.1117\n",
      "0.1118\n",
      "0.1119\n",
      "0.1120\n",
      "0.1121\n",
      "0.1122\n",
      "0.1123\n",
      "0.1124\n",
      "0.1125\n",
      "0.1126\n",
      "0.1127\n",
      "0.1129\n",
      "0.1130\n",
      "0.1131\n",
      "0.1132\n",
      "0.1133\n",
      "0.1134\n",
      "0.1135\n",
      "0.1136\n",
      "0.1137\n",
      "0.1138\n",
      "0.1139\n",
      "0.1140\n",
      "0.1141\n",
      "0.1142\n",
      "0.1143\n",
      "0.1145\n",
      "0.1146\n",
      "0.1147\n",
      "0.1148\n",
      "0.1149\n",
      "0.1151\n",
      "0.1152\n",
      "0.1155\n",
      "0.1156\n",
      "0.1157\n",
      "0.1158\n",
      "0.1159\n",
      "0.1161\n",
      "0.1162\n",
      "0.1163\n",
      "0.1165\n",
      "0.1167\n",
      "0.1168\n",
      "0.1169\n",
      "0.1170\n",
      "0.1171\n",
      "0.1172\n",
      "0.1173\n",
      "0.1174\n",
      "0.1175\n",
      "0.1176\n",
      "0.1177\n",
      "0.1178\n",
      "0.1180\n",
      "0.1181\n",
      "0.1182\n",
      "0.1183\n",
      "0.1184\n",
      "0.1185\n",
      "0.1186\n",
      "0.1187\n",
      "0.1188\n",
      "0.1189\n",
      "0.1190\n",
      "0.1191\n",
      "0.1192\n",
      "0.1193\n",
      "0.1194\n",
      "0.1195\n",
      "0.1196\n",
      "0.1197\n",
      "0.1198\n",
      "0.1199\n",
      "0.1200\n",
      "0.1201\n",
      "0.1202\n",
      "0.1203\n",
      "0.1205\n",
      "0.1206\n",
      "0.1207\n",
      "0.1208\n",
      "0.1210\n",
      "0.1211\n",
      "0.1212\n",
      "0.1213\n",
      "0.1214\n",
      "0.1215\n",
      "0.1219\n",
      "0.1220\n",
      "0.1221\n",
      "0.1222\n",
      "0.1223\n",
      "0.1225\n",
      "0.1226\n",
      "0.1229\n",
      "0.1230\n",
      "0.1231\n",
      "0.1232\n",
      "0.1233\n",
      "0.1234\n",
      "0.1235\n",
      "0.1236\n",
      "0.1237\n",
      "0.1238\n",
      "0.1239\n",
      "0.1240\n",
      "0.1241\n",
      "0.1242\n",
      "0.1243\n",
      "0.1245\n",
      "0.1247\n",
      "0.1248\n",
      "0.1249\n",
      "0.1250\n",
      "0.1252\n",
      "0.1253\n",
      "0.1254\n",
      "0.1255\n",
      "0.1256\n",
      "0.1258\n",
      "0.1259\n",
      "0.1260\n",
      "0.1261\n",
      "0.1262\n",
      "0.1263\n",
      "0.1264\n",
      "0.1265\n",
      "0.1266\n",
      "0.1267\n",
      "0.1268\n",
      "0.1269\n",
      "0.1270\n",
      "0.1271\n",
      "0.1272\n",
      "0.1273\n",
      "0.1275\n",
      "0.1276\n",
      "0.1277\n",
      "0.1278\n",
      "0.1280\n",
      "0.1281\n",
      "0.1283\n",
      "0.1285\n",
      "0.1286\n",
      "0.1287\n",
      "0.1288\n",
      "0.1289\n",
      "0.1291\n",
      "0.1292\n",
      "0.1293\n",
      "0.1295\n",
      "0.1297\n",
      "0.1298\n",
      "0.1299\n",
      "0.1300\n",
      "0.1301\n",
      "0.1303\n",
      "0.1306\n",
      "0.1307\n",
      "0.1308\n",
      "0.1309\n",
      "0.1310\n",
      "0.1311\n",
      "0.1312\n",
      "0.1314\n",
      "0.1316\n",
      "0.1317\n",
      "0.1318\n",
      "0.1319\n",
      "0.1321\n",
      "0.1322\n",
      "0.1323\n",
      "0.1324\n",
      "0.1325\n",
      "0.1326\n",
      "0.1328\n",
      "0.1329\n",
      "0.1330\n",
      "0.1331\n",
      "0.1333\n",
      "0.1334\n",
      "0.1335\n",
      "0.1336\n",
      "0.1337\n",
      "0.1338\n",
      "0.1339\n",
      "0.1340\n",
      "0.1341\n",
      "0.1342\n",
      "0.1343\n",
      "0.1344\n",
      "0.1345\n",
      "0.1346\n",
      "0.1347\n",
      "0.1348\n",
      "0.1349\n",
      "0.1350\n",
      "0.1351\n",
      "0.1352\n",
      "0.1353\n",
      "0.1354\n",
      "0.1355\n",
      "0.1356\n",
      "0.1357\n",
      "0.1358\n",
      "0.1359\n",
      "0.1362\n",
      "0.1364\n",
      "0.1365\n",
      "0.1366\n",
      "0.1368\n",
      "0.1369\n",
      "0.1370\n",
      "0.1371\n",
      "0.1372\n",
      "0.1373\n",
      "0.1374\n",
      "0.1375\n",
      "0.1376\n",
      "0.1377\n",
      "0.1378\n",
      "0.1379\n",
      "0.1380\n",
      "0.1381\n",
      "0.1382\n",
      "0.1383\n",
      "0.1385\n",
      "0.1386\n",
      "0.1387\n",
      "0.1388\n",
      "0.1390\n",
      "0.1391\n",
      "0.1392\n",
      "0.1393\n",
      "0.1394\n",
      "0.1395\n",
      "0.1396\n",
      "0.1397\n",
      "0.1398\n",
      "0.1399\n",
      "0.1400\n",
      "0.1402\n",
      "0.1403\n",
      "0.1404\n",
      "0.1406\n",
      "0.1407\n",
      "0.1408\n",
      "0.1409\n",
      "0.1410\n",
      "0.1411\n",
      "0.1413\n",
      "0.1414\n",
      "0.1416\n",
      "0.1417\n",
      "0.1418\n",
      "0.1419\n",
      "0.1420\n",
      "0.1421\n",
      "0.1423\n",
      "0.1424\n",
      "0.1425\n",
      "0.1426\n",
      "0.1427\n",
      "0.1429\n",
      "0.1430\n",
      "0.1431\n",
      "0.1432\n",
      "0.1433\n",
      "0.1434\n",
      "0.1435\n",
      "0.1436\n",
      "0.1437\n",
      "0.1438\n",
      "0.1440\n",
      "0.1441\n",
      "0.1443\n",
      "0.1444\n",
      "0.1445\n",
      "0.1446\n",
      "0.1447\n",
      "0.1448\n",
      "0.1449\n",
      "0.1450\n",
      "0.1451\n",
      "0.1452\n",
      "0.1453\n",
      "0.1456\n",
      "0.1457\n",
      "0.1458\n",
      "0.1459\n",
      "0.1460\n",
      "0.1461\n",
      "0.1462\n",
      "0.1463\n",
      "0.1464\n",
      "0.1465\n",
      "0.1467\n",
      "0.1468\n",
      "0.1469\n",
      "0.1470\n",
      "0.1472\n",
      "0.1474\n",
      "0.1475\n",
      "0.1476\n",
      "0.1477\n",
      "0.1478\n",
      "0.1479\n",
      "0.1480\n",
      "0.1481\n",
      "0.1482\n",
      "0.1483\n",
      "0.1484\n",
      "0.1485\n",
      "0.1486\n",
      "0.1487\n",
      "0.1488\n",
      "0.1489\n",
      "0.1490\n",
      "0.1491\n",
      "0.1493\n",
      "0.1494\n",
      "0.1495\n",
      "0.1496\n",
      "0.1497\n",
      "0.1498\n",
      "0.1499\n",
      "0.1500\n",
      "0.1501\n",
      "0.1502\n",
      "0.1503\n",
      "0.1505\n",
      "0.1506\n",
      "0.1507\n",
      "0.1508\n",
      "0.1509\n",
      "0.1510\n",
      "0.1511\n",
      "0.1512\n",
      "0.1513\n",
      "0.1514\n",
      "0.1515\n",
      "0.1516\n",
      "0.1517\n",
      "0.1518\n",
      "0.1519\n",
      "0.1520\n",
      "0.1521\n",
      "0.1522\n",
      "0.1523\n",
      "0.1524\n",
      "0.1525\n",
      "0.1526\n",
      "0.1527\n",
      "0.1528\n",
      "0.1529\n",
      "0.1530\n",
      "0.1532\n",
      "0.1533\n",
      "0.1534\n",
      "0.1535\n",
      "0.1536\n",
      "0.1537\n",
      "0.1538\n",
      "0.1539\n",
      "0.1540\n",
      "0.1542\n",
      "0.1543\n",
      "0.1544\n",
      "0.1545\n",
      "0.1547\n",
      "0.1548\n",
      "0.1550\n",
      "0.1551\n",
      "0.1553\n",
      "0.1555\n",
      "0.1556\n",
      "0.1557\n",
      "0.1558\n",
      "0.1559\n",
      "0.1560\n",
      "0.1561\n",
      "0.1562\n",
      "0.1563\n",
      "0.1564\n",
      "0.1565\n",
      "0.1566\n",
      "0.1568\n",
      "0.1569\n",
      "0.1571\n",
      "0.1572\n",
      "0.1573\n",
      "0.1574\n",
      "0.1576\n",
      "0.1577\n",
      "0.1578\n",
      "0.1579\n",
      "0.1581\n",
      "0.1583\n",
      "0.1584\n",
      "0.1585\n",
      "0.1586\n",
      "0.1587\n",
      "0.1588\n",
      "0.1589\n",
      "0.1590\n",
      "0.1591\n",
      "0.1592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1595\n",
      "0.1596\n",
      "0.1598\n",
      "0.1599\n",
      "0.1600\n",
      "0.1601\n",
      "0.1602\n",
      "0.1604\n",
      "0.1605\n",
      "0.1606\n",
      "0.1607\n",
      "0.1608\n",
      "0.1609\n",
      "0.1610\n",
      "0.1611\n",
      "0.1612\n",
      "0.1613\n",
      "0.1614\n",
      "0.1615\n",
      "0.1616\n",
      "0.1618\n",
      "0.1621\n",
      "0.1622\n",
      "0.1623\n",
      "0.1624\n",
      "0.1625\n",
      "0.1627\n",
      "0.1629\n",
      "0.1630\n",
      "0.1631\n",
      "0.1632\n",
      "0.1634\n",
      "0.1635\n",
      "0.1636\n",
      "0.1637\n",
      "0.1638\n",
      "0.1639\n",
      "0.1640\n",
      "0.1641\n",
      "0.1642\n",
      "0.1643\n",
      "0.1644\n",
      "0.1645\n",
      "0.1646\n",
      "0.1647\n",
      "0.1649\n",
      "0.1650\n",
      "0.1651\n",
      "0.1652\n",
      "0.1654\n",
      "0.1655\n",
      "0.1656\n",
      "0.1657\n",
      "0.1658\n",
      "0.1659\n",
      "0.1660\n",
      "0.1662\n",
      "0.1663\n",
      "0.1664\n",
      "0.1665\n",
      "0.1666\n",
      "0.1667\n",
      "0.1668\n",
      "0.1669\n",
      "0.1670\n",
      "0.1672\n",
      "0.1673\n",
      "0.1674\n",
      "0.1675\n",
      "0.1677\n",
      "0.1679\n",
      "0.1680\n",
      "0.1681\n",
      "0.1682\n",
      "0.1683\n",
      "0.1685\n",
      "0.1686\n",
      "0.1687\n",
      "0.1688\n",
      "0.1689\n",
      "0.1691\n",
      "0.1693\n",
      "0.1694\n",
      "0.1695\n",
      "0.1696\n",
      "0.1697\n",
      "0.1698\n",
      "0.1699\n",
      "0.1700\n",
      "0.1702\n",
      "0.1703\n",
      "0.1704\n",
      "0.1705\n",
      "0.1707\n",
      "0.1708\n",
      "0.1710\n",
      "0.1711\n",
      "0.1712\n",
      "0.1713\n",
      "0.1714\n",
      "0.1715\n",
      "0.1716\n",
      "0.1717\n",
      "0.1719\n",
      "0.1720\n",
      "0.1721\n",
      "0.1722\n",
      "0.1723\n",
      "0.1725\n",
      "0.1726\n",
      "0.1728\n",
      "0.1729\n",
      "0.1730\n",
      "0.1731\n",
      "0.1732\n",
      "0.1733\n",
      "0.1734\n",
      "0.1735\n",
      "0.1736\n",
      "0.1737\n",
      "0.1738\n",
      "0.1739\n",
      "0.1741\n",
      "0.1742\n",
      "0.1743\n",
      "0.1744\n",
      "0.1745\n",
      "0.1746\n",
      "0.1747\n",
      "0.1748\n",
      "0.1749\n",
      "0.1750\n",
      "0.1751\n",
      "0.1752\n",
      "0.1753\n",
      "0.1754\n",
      "0.1755\n",
      "0.1756\n",
      "0.1757\n",
      "0.1758\n",
      "0.1759\n",
      "0.1760\n",
      "0.1762\n",
      "0.1763\n",
      "0.1764\n",
      "0.1765\n",
      "0.1766\n",
      "0.1767\n",
      "0.1768\n",
      "0.1769\n",
      "0.1770\n",
      "0.1771\n",
      "0.1772\n",
      "0.1773\n",
      "0.1775\n",
      "0.1776\n",
      "0.1777\n",
      "0.1778\n",
      "0.1779\n",
      "0.1782\n",
      "0.1783\n",
      "0.1785\n",
      "0.1786\n",
      "0.1787\n",
      "0.1788\n",
      "0.1789\n",
      "0.1790\n",
      "0.1791\n",
      "0.1792\n",
      "0.1793\n",
      "0.1794\n",
      "0.1796\n",
      "0.1797\n",
      "0.1798\n",
      "0.1799\n",
      "0.1800\n",
      "0.1801\n",
      "0.1803\n",
      "0.1804\n",
      "0.1807\n",
      "0.1808\n",
      "0.1809\n",
      "0.1810\n",
      "0.1811\n",
      "0.1812\n",
      "0.1813\n",
      "0.1815\n",
      "0.1816\n",
      "0.1817\n",
      "0.1818\n",
      "0.1819\n",
      "0.1821\n",
      "0.1822\n",
      "0.1823\n",
      "0.1824\n",
      "0.1825\n",
      "0.1826\n",
      "0.1827\n",
      "0.1828\n",
      "0.1829\n",
      "0.1830\n",
      "0.1831\n",
      "0.1832\n",
      "0.1834\n",
      "0.1835\n",
      "0.1836\n",
      "0.1838\n",
      "0.1839\n",
      "0.1840\n",
      "0.1841\n",
      "0.1842\n",
      "0.1843\n",
      "0.1844\n",
      "0.1845\n",
      "0.1846\n",
      "0.1848\n",
      "0.1850\n",
      "0.1851\n",
      "0.1852\n",
      "0.1853\n",
      "0.1854\n",
      "0.1855\n",
      "0.1856\n",
      "0.1857\n",
      "0.1858\n",
      "0.1859\n",
      "0.1860\n",
      "0.1861\n",
      "0.1863\n",
      "0.1864\n",
      "0.1865\n",
      "0.1866\n",
      "0.1867\n",
      "0.1868\n",
      "0.1869\n",
      "0.1870\n",
      "0.1872\n",
      "0.1873\n",
      "0.1875\n",
      "0.1876\n",
      "0.1877\n",
      "0.1878\n",
      "0.1879\n",
      "0.1880\n",
      "0.1881\n",
      "0.1883\n",
      "0.1884\n",
      "0.1886\n",
      "0.1887\n",
      "0.1888\n",
      "0.1889\n",
      "0.1890\n",
      "0.1891\n",
      "0.1892\n",
      "0.1893\n",
      "0.1894\n",
      "0.1895\n",
      "0.1896\n",
      "0.1897\n",
      "0.1898\n",
      "0.1899\n",
      "0.1900\n",
      "0.1901\n",
      "0.1902\n",
      "0.1903\n",
      "0.1904\n",
      "0.1905\n",
      "0.1906\n",
      "0.1908\n",
      "0.1909\n",
      "0.1910\n",
      "0.1911\n",
      "0.1912\n",
      "0.1913\n",
      "0.1915\n",
      "0.1916\n",
      "0.1917\n",
      "0.1918\n",
      "0.1919\n",
      "0.1920\n",
      "0.1921\n",
      "0.1923\n",
      "0.1924\n",
      "0.1925\n",
      "0.1926\n",
      "0.1927\n",
      "0.1928\n",
      "0.1929\n",
      "0.1930\n",
      "0.1931\n",
      "0.1932\n",
      "0.1934\n",
      "0.1935\n",
      "0.1937\n",
      "0.1938\n",
      "0.1940\n",
      "0.1941\n",
      "0.1942\n",
      "0.1943\n",
      "0.1944\n",
      "0.1945\n",
      "0.1946\n",
      "0.1947\n",
      "0.1948\n",
      "0.1949\n",
      "0.1950\n",
      "0.1951\n",
      "0.1953\n",
      "0.1954\n",
      "0.1955\n",
      "0.1957\n",
      "0.1958\n",
      "0.1959\n",
      "0.1960\n",
      "0.1961\n",
      "0.1962\n",
      "0.1963\n",
      "0.1965\n",
      "0.1967\n",
      "0.1968\n",
      "0.1969\n",
      "0.1970\n",
      "0.1971\n",
      "0.1972\n",
      "0.1973\n",
      "0.1974\n",
      "0.1976\n",
      "0.1977\n",
      "0.1978\n",
      "0.1979\n",
      "0.1980\n",
      "0.1981\n",
      "0.1982\n",
      "0.1983\n",
      "0.1984\n",
      "0.1985\n",
      "0.1986\n",
      "0.1987\n",
      "0.1988\n",
      "0.1989\n",
      "0.1990\n",
      "0.1991\n",
      "0.1993\n",
      "0.1994\n",
      "0.1995\n",
      "0.1996\n",
      "0.1997\n",
      "0.2000\n",
      "0.2001\n",
      "0.2002\n",
      "0.2003\n",
      "0.2004\n",
      "0.2005\n",
      "0.2006\n",
      "0.2007\n",
      "0.2008\n",
      "0.2009\n",
      "0.2010\n",
      "0.2011\n",
      "0.2012\n",
      "0.2013\n",
      "0.2015\n",
      "0.2016\n",
      "0.2018\n",
      "0.2019\n",
      "0.2021\n",
      "0.2022\n",
      "0.2023\n",
      "0.2024\n",
      "0.2025\n",
      "0.2026\n",
      "0.2027\n",
      "0.2028\n",
      "0.2029\n",
      "0.2030\n",
      "0.2031\n",
      "0.2032\n",
      "0.2033\n",
      "0.2034\n",
      "0.2035\n",
      "0.2036\n",
      "0.2040\n",
      "0.2041\n",
      "0.2042\n",
      "0.2043\n",
      "0.2044\n",
      "0.2046\n",
      "0.2047\n",
      "1\n",
      "1.11\n",
      "1.44\n",
      "1.59\n",
      "1.65\n",
      "1.129\n",
      "1.135\n",
      "1.162\n",
      "1.183\n",
      "1.205\n",
      "1.214\n",
      "1.216\n",
      "1.217\n",
      "1.235\n",
      "1.237\n",
      "1.241\n",
      "1.251\n",
      "1.253\n",
      "1.265\n",
      "1.271\n",
      "1.273\n",
      "1.276\n",
      "1.281\n",
      "1.290\n",
      "1.292\n",
      "1.293\n",
      "1.298\n",
      "1.302\n",
      "1.330\n",
      "1.333\n",
      "1.360\n",
      "1.365\n",
      "1.370\n",
      "1.374\n",
      "1.391\n",
      "1.394\n",
      "1.407\n",
      "1.409\n",
      "1.415\n",
      "1.435\n",
      "1.442\n",
      "1.443\n",
      "1.444\n",
      "1.451\n",
      "1.462\n",
      "1.463\n",
      "1.464\n",
      "1.467\n",
      "1.475\n",
      "1.476\n",
      "1.496\n",
      "1.505\n",
      "1.510\n",
      "1.514\n",
      "1.537\n",
      "1.538\n",
      "1.540\n",
      "1.553\n",
      "1.572\n",
      "1.586\n",
      "1.595\n",
      "1.598\n",
      "1.601\n",
      "1.610\n",
      "1.613\n",
      "1.621\n",
      "1.624\n",
      "1.626\n",
      "1.648\n",
      "1.651\n",
      "1.658\n",
      "1.663\n",
      "1.665\n",
      "1.675\n",
      "1.702\n",
      "1.726\n",
      "1.737\n",
      "1.738\n",
      "1.750\n",
      "1.753\n",
      "1.767\n",
      "1.776\n",
      "1.778\n",
      "1.794\n",
      "1.795\n",
      "1.807\n",
      "1.808\n",
      "1.810\n",
      "1.824\n",
      "1.825\n",
      "1.832\n",
      "1.835\n",
      "1.840\n",
      "1.873\n",
      "1.903\n",
      "1.920\n",
      "1.923\n",
      "1.931\n",
      "1.941\n",
      "1.948\n",
      "1.951\n",
      "1.955\n",
      "1.957\n",
      "1.960\n",
      "1.979\n",
      "1.980\n",
      "1.983\n",
      "1.999\n",
      "1.1001\n",
      "1.1029\n",
      "1.1032\n",
      "1.1053\n",
      "1.1056\n",
      "1.1057\n",
      "1.1084\n",
      "1.1094\n",
      "1.1108\n",
      "1.1114\n",
      "1.1124\n",
      "1.1132\n",
      "1.1156\n",
      "1.1166\n",
      "1.1167\n",
      "1.1178\n",
      "1.1179\n",
      "1.1183\n",
      "1.1191\n",
      "1.1193\n",
      "1.1208\n",
      "1.1219\n",
      "1.1224\n",
      "1.1225\n",
      "1.1249\n",
      "1.1250\n",
      "1.1275\n",
      "1.1305\n",
      "1.1351\n",
      "1.1369\n",
      "1.1378\n",
      "1.1407\n",
      "1.1409\n",
      "1.1411\n",
      "1.1426\n",
      "1.1430\n",
      "1.1450\n",
      "1.1451\n",
      "1.1458\n",
      "1.1466\n",
      "1.1475\n",
      "1.1492\n",
      "1.1518\n",
      "1.1527\n",
      "1.1530\n",
      "1.1546\n",
      "1.1552\n",
      "1.1553\n",
      "1.1562\n",
      "1.1568\n",
      "1.1587\n",
      "1.1592\n",
      "1.1600\n",
      "1.1626\n",
      "1.1630\n",
      "1.1631\n",
      "1.1641\n",
      "1.1650\n",
      "1.1651\n",
      "1.1658\n",
      "1.1662\n",
      "1.1664\n",
      "1.1665\n",
      "1.1669\n",
      "1.1670\n",
      "1.1686\n",
      "1.1726\n",
      "1.1759\n",
      "1.1763\n",
      "1.1766\n",
      "1.1775\n",
      "1.1785\n",
      "1.1799\n",
      "1.1805\n",
      "1.1819\n",
      "1.1843\n",
      "1.1844\n",
      "1.1845\n",
      "1.1853\n",
      "1.1862\n",
      "1.1867\n",
      "1.1887\n",
      "1.1896\n",
      "1.1899\n",
      "1.1916\n",
      "1.1938\n",
      "1.1944\n",
      "1.1949\n",
      "1.1953\n",
      "1.1955\n",
      "1.1963\n",
      "1.1971\n",
      "1.1989\n",
      "1.2001\n",
      "1.2012\n",
      "1.2015\n",
      "1.2016\n",
      "1.2033\n",
      "1.2041\n",
      "2\n",
      "2.4\n",
      "2.24\n",
      "2.26\n",
      "2.31\n",
      "2.52\n",
      "2.57\n",
      "2.59\n",
      "2.66\n",
      "2.70\n",
      "2.86\n",
      "2.89\n",
      "2.117\n",
      "2.127\n",
      "2.145\n",
      "2.150\n",
      "2.161\n",
      "2.163\n",
      "2.196\n",
      "2.199\n",
      "2.201\n",
      "2.202\n",
      "2.207\n",
      "2.210\n",
      "2.211\n",
      "2.213\n",
      "2.221\n",
      "2.228\n",
      "2.231\n",
      "2.233\n",
      "2.253\n",
      "2.255\n",
      "2.258\n",
      "2.259\n",
      "2.277\n",
      "2.285\n",
      "2.295\n",
      "2.296\n",
      "2.298\n",
      "2.300\n",
      "2.328\n",
      "2.333\n",
      "2.337\n",
      "2.361\n",
      "2.384\n",
      "2.388\n",
      "2.398\n",
      "2.401\n",
      "2.418\n",
      "2.439\n",
      "2.452\n",
      "2.457\n",
      "2.460\n",
      "2.462\n",
      "2.466\n",
      "2.468\n",
      "2.469\n",
      "2.472\n",
      "2.480\n",
      "2.493\n",
      "2.532\n",
      "2.533\n",
      "2.545\n",
      "2.550\n",
      "2.563\n",
      "2.564\n",
      "2.565\n",
      "2.566\n",
      "2.567\n",
      "2.568\n",
      "2.573\n",
      "2.574\n",
      "2.594\n",
      "2.598\n",
      "2.601\n",
      "2.605\n",
      "2.612\n",
      "2.667\n",
      "2.677\n",
      "2.678\n",
      "2.679\n",
      "2.687\n",
      "2.691\n",
      "2.692\n",
      "2.696\n",
      "2.712\n",
      "2.719\n",
      "2.742\n",
      "2.743\n",
      "2.745\n",
      "2.755\n",
      "2.764\n",
      "2.766\n",
      "2.767\n",
      "2.768\n",
      "2.773\n",
      "2.783\n",
      "2.784\n",
      "2.787\n",
      "2.810\n",
      "2.822\n",
      "2.825\n",
      "2.829\n",
      "2.834\n",
      "2.835\n",
      "2.838\n",
      "2.840\n",
      "2.851\n",
      "2.864\n",
      "2.865\n",
      "2.868\n",
      "2.877\n",
      "2.892\n",
      "2.894\n",
      "2.896\n",
      "2.899\n",
      "2.903\n",
      "2.916\n",
      "2.929\n",
      "2.931\n",
      "2.945\n",
      "2.955\n",
      "2.972\n",
      "2.980\n",
      "2.997\n",
      "2.999\n",
      "2.1004\n",
      "2.1007\n",
      "2.1016\n",
      "2.1028\n",
      "2.1034\n",
      "2.1040\n",
      "2.1056\n",
      "2.1069\n",
      "2.1079\n",
      "2.1086\n",
      "2.1094\n",
      "2.1100\n",
      "2.1103\n",
      "2.1105\n",
      "2.1112\n",
      "2.1119\n",
      "2.1126\n",
      "2.1131\n",
      "2.1133\n",
      "2.1153\n",
      "2.1182\n",
      "2.1186\n",
      "2.1199\n",
      "2.1206\n",
      "2.1210\n",
      "2.1221\n",
      "2.1229\n",
      "2.1243\n",
      "2.1245\n",
      "2.1247\n",
      "2.1257\n",
      "2.1262\n",
      "2.1263\n",
      "2.1286\n",
      "2.1294\n",
      "2.1295\n",
      "2.1299\n",
      "2.1303\n",
      "2.1311\n",
      "2.1316\n",
      "2.1321\n",
      "2.1327\n",
      "2.1333\n",
      "2.1341\n",
      "2.1342\n",
      "2.1346\n",
      "2.1349\n",
      "2.1356\n",
      "2.1360\n",
      "2.1361\n",
      "2.1381\n",
      "2.1382\n",
      "2.1389\n",
      "2.1410\n",
      "2.1413\n",
      "2.1417\n",
      "2.1428\n",
      "2.1431\n",
      "2.1433\n",
      "2.1443\n",
      "2.1456\n",
      "2.1467\n",
      "2.1476\n",
      "2.1480\n",
      "2.1482\n",
      "2.1489\n",
      "2.1490\n",
      "2.1495\n",
      "2.1498\n",
      "2.1502\n",
      "2.1505\n",
      "2.1512\n",
      "2.1523\n",
      "2.1528\n",
      "2.1530\n",
      "2.1531\n",
      "2.1536\n",
      "2.1546\n",
      "2.1548\n",
      "2.1549\n",
      "2.1550\n",
      "2.1559\n",
      "2.1563\n",
      "2.1566\n",
      "2.1570\n",
      "2.1585\n",
      "2.1586\n",
      "2.1603\n",
      "2.1604\n",
      "2.1609\n",
      "2.1611\n",
      "2.1616\n",
      "2.1619\n",
      "2.1628\n",
      "2.1635\n",
      "2.1641\n",
      "2.1659\n",
      "2.1675\n",
      "2.1682\n",
      "2.1684\n",
      "2.1689\n",
      "2.1697\n",
      "2.1698\n",
      "2.1701\n",
      "2.1707\n",
      "2.1723\n",
      "2.1729\n",
      "2.1751\n",
      "2.1753\n",
      "2.1762\n",
      "2.1763\n",
      "2.1792\n",
      "2.1795\n",
      "2.1807\n",
      "2.1818\n",
      "2.1819\n",
      "2.1825\n",
      "2.1834\n",
      "2.1838\n",
      "2.1845\n",
      "2.1852\n",
      "2.1853\n",
      "2.1856\n",
      "2.1875\n",
      "2.1885\n",
      "2.1892\n",
      "2.1897\n",
      "2.1903\n",
      "2.1935\n",
      "2.1939\n",
      "2.1950\n",
      "2.1954\n",
      "2.1965\n",
      "2.1980\n",
      "2.1985\n",
      "2.1989\n",
      "2.1993\n",
      "2.1995\n",
      "2.1996\n",
      "2.1999\n",
      "2.2001\n",
      "2.2004\n",
      "2.2010\n",
      "2.2011\n",
      "2.2015\n",
      "2.2020\n",
      "2.2036\n",
      "2.2042\n",
      "2.2047\n",
      "3\n",
      "3.10\n",
      "3.219\n",
      "3.358\n",
      "3.426\n",
      "3.467\n",
      "3.485\n",
      "3.536\n",
      "3.665\n",
      "3.698\n",
      "3.796\n",
      "3.875\n",
      "3.998\n",
      "3.1004\n",
      "3.1025\n",
      "3.1122\n",
      "3.1263\n",
      "3.1339\n",
      "3.1437\n",
      "3.1497\n",
      "3.1783\n",
      "3.2001\n",
      "4\n",
      "4.2\n",
      "4.15\n",
      "4.22\n",
      "4.32\n",
      "4.49\n",
      "4.69\n",
      "4.74\n",
      "4.75\n",
      "4.79\n",
      "4.84\n",
      "4.88\n",
      "4.90\n",
      "4.100\n",
      "4.103\n",
      "4.110\n",
      "4.119\n",
      "4.136\n",
      "4.140\n",
      "4.142\n",
      "4.171\n",
      "4.199\n",
      "4.204\n",
      "4.205\n",
      "4.213\n",
      "4.267\n",
      "4.270\n",
      "4.276\n",
      "4.295\n",
      "4.300\n",
      "4.304\n",
      "4.306\n",
      "4.310\n",
      "4.318\n",
      "4.331\n",
      "4.342\n",
      "4.343\n",
      "4.352\n",
      "4.366\n",
      "4.381\n",
      "4.387\n",
      "4.401\n",
      "4.406\n",
      "4.414\n",
      "4.426\n",
      "4.432\n",
      "4.434\n",
      "4.438\n",
      "4.443\n",
      "4.445\n",
      "4.450\n",
      "4.469\n",
      "4.495\n",
      "4.497\n",
      "4.499\n",
      "4.505\n",
      "4.511\n",
      "4.514\n",
      "4.518\n",
      "4.520\n",
      "4.527\n",
      "4.538\n",
      "4.540\n",
      "4.569\n",
      "4.597\n",
      "4.610\n",
      "4.621\n",
      "4.627\n",
      "4.633\n",
      "4.635\n",
      "4.644\n",
      "4.651\n",
      "4.658\n",
      "4.660\n",
      "4.687\n",
      "4.689\n",
      "4.691\n",
      "4.708\n",
      "4.730\n",
      "4.764\n",
      "4.765\n",
      "4.777\n",
      "4.782\n",
      "4.797\n",
      "4.803\n",
      "4.807\n",
      "4.813\n",
      "4.849\n",
      "4.862\n",
      "4.881\n",
      "4.882\n",
      "4.883\n",
      "4.885\n",
      "4.886\n",
      "4.887\n",
      "4.891\n",
      "4.892\n",
      "4.901\n",
      "4.904\n",
      "4.916\n",
      "4.917\n",
      "4.919\n",
      "4.923\n",
      "4.925\n",
      "4.935\n",
      "4.938\n",
      "4.952\n",
      "4.955\n",
      "4.961\n",
      "4.974\n",
      "4.982\n",
      "4.1002\n",
      "4.1030\n",
      "4.1033\n",
      "4.1040\n",
      "4.1044\n",
      "4.1059\n",
      "4.1068\n",
      "4.1069\n",
      "4.1071\n",
      "4.1076\n",
      "4.1080\n",
      "4.1087\n",
      "4.1100\n",
      "4.1101\n",
      "4.1127\n",
      "4.1130\n",
      "4.1160\n",
      "4.1162\n",
      "4.1179\n",
      "4.1182\n",
      "4.1186\n",
      "4.1207\n",
      "4.1214\n",
      "4.1220\n",
      "4.1226\n",
      "4.1238\n",
      "4.1248\n",
      "4.1259\n",
      "4.1261\n",
      "4.1277\n",
      "4.1280\n",
      "4.1307\n",
      "4.1313\n",
      "4.1317\n",
      "4.1321\n",
      "4.1338\n",
      "4.1353\n",
      "4.1355\n",
      "4.1356\n",
      "4.1361\n",
      "4.1363\n",
      "4.1372\n",
      "4.1377\n",
      "4.1379\n",
      "4.1381\n",
      "4.1382\n",
      "4.1383\n",
      "4.1386\n",
      "4.1404\n",
      "4.1405\n",
      "4.1408\n",
      "4.1411\n",
      "4.1412\n",
      "4.1418\n",
      "4.1419\n",
      "4.1421\n",
      "4.1427\n",
      "4.1446\n",
      "4.1455\n",
      "4.1456\n",
      "4.1457\n",
      "4.1469\n",
      "4.1481\n",
      "4.1496\n",
      "4.1497\n",
      "4.1512\n",
      "4.1513\n",
      "4.1526\n",
      "4.1536\n",
      "4.1540\n",
      "4.1549\n",
      "4.1554\n",
      "4.1555\n",
      "4.1558\n",
      "4.1562\n",
      "4.1565\n",
      "4.1566\n",
      "4.1573\n",
      "4.1581\n",
      "4.1584\n",
      "4.1586\n",
      "4.1600\n",
      "4.1602\n",
      "4.1605\n",
      "4.1619\n",
      "4.1629\n",
      "4.1632\n",
      "4.1650\n",
      "4.1654\n",
      "4.1658\n",
      "4.1669\n",
      "4.1678\n",
      "4.1692\n",
      "4.1693\n",
      "4.1703\n",
      "4.1717\n",
      "4.1719\n",
      "4.1726\n",
      "4.1728\n",
      "4.1742\n",
      "4.1743\n",
      "4.1771\n",
      "4.1787\n",
      "4.1789\n",
      "4.1791\n",
      "4.1793\n",
      "4.1794\n",
      "4.1799\n",
      "4.1813\n",
      "4.1827\n",
      "4.1839\n",
      "4.1848\n",
      "4.1852\n",
      "4.1866\n",
      "4.1882\n",
      "4.1897\n",
      "4.1899\n",
      "4.1908\n",
      "4.1914\n",
      "4.1931\n",
      "4.1936\n",
      "4.1945\n",
      "4.1950\n",
      "4.1957\n",
      "4.1969\n",
      "4.1989\n",
      "4.1991\n",
      "4.2003\n",
      "4.2004\n",
      "4.2008\n",
      "4.2018\n",
      "4.2021\n",
      "4.2022\n",
      "4.2024\n",
      "4.2025\n",
      "5\n",
      "5.53\n",
      "5.73\n",
      "5.122\n",
      "5.131\n",
      "5.196\n",
      "5.281\n",
      "5.301\n",
      "5.325\n",
      "5.335\n",
      "5.361\n",
      "5.499\n",
      "5.513\n",
      "5.582\n",
      "5.607\n",
      "5.620\n",
      "5.705\n",
      "5.720\n",
      "5.838\n",
      "5.847\n",
      "5.888\n",
      "5.982\n",
      "5.1017\n",
      "5.1035\n",
      "5.1115\n",
      "5.1116\n",
      "5.1151\n",
      "5.1163\n",
      "5.1220\n",
      "5.1250\n",
      "5.1255\n",
      "5.1258\n",
      "5.1262\n",
      "5.1383\n",
      "5.1465\n",
      "5.1498\n",
      "5.1530\n",
      "5.1580\n",
      "5.1618\n",
      "5.1665\n",
      "5.1675\n",
      "5.1696\n",
      "5.1755\n",
      "5.1795\n",
      "5.1973\n",
      "5.2017\n",
      "5.2032\n",
      "6\n",
      "6.43\n",
      "6.83\n",
      "6.103\n",
      "6.129\n",
      "6.143\n",
      "6.158\n",
      "6.177\n",
      "6.188\n",
      "6.193\n",
      "6.200\n",
      "6.209\n",
      "6.244\n",
      "6.264\n",
      "6.296\n",
      "6.306\n",
      "6.329\n",
      "6.345\n",
      "6.358\n",
      "6.361\n",
      "6.372\n",
      "6.383\n",
      "6.395\n",
      "6.414\n",
      "6.424\n",
      "6.426\n",
      "6.432\n",
      "6.479\n",
      "6.498\n",
      "6.499\n",
      "6.502\n",
      "6.529\n",
      "6.547\n",
      "6.552\n",
      "6.573\n",
      "6.586\n",
      "6.587\n",
      "6.592\n",
      "6.603\n",
      "6.612\n",
      "6.616\n",
      "6.622\n",
      "6.651\n",
      "6.691\n",
      "6.713\n",
      "6.755\n",
      "6.762\n",
      "6.771\n",
      "6.786\n",
      "6.817\n",
      "6.825\n",
      "6.827\n",
      "6.834\n",
      "6.859\n",
      "6.860\n",
      "6.883\n",
      "6.884\n",
      "6.896\n",
      "6.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.977\n",
      "6.978\n",
      "6.980\n",
      "6.986\n",
      "6.1002\n",
      "6.1003\n",
      "6.1007\n",
      "6.1010\n",
      "6.1014\n",
      "6.1021\n",
      "6.1032\n",
      "6.1033\n",
      "6.1049\n",
      "6.1051\n",
      "6.1053\n",
      "6.1061\n",
      "6.1068\n",
      "6.1070\n",
      "6.1082\n",
      "6.1093\n",
      "6.1112\n",
      "6.1120\n",
      "6.1123\n",
      "6.1147\n",
      "6.1155\n",
      "6.1167\n",
      "6.1171\n",
      "6.1174\n",
      "6.1177\n",
      "6.1179\n",
      "6.1225\n",
      "6.1234\n",
      "6.1257\n",
      "6.1290\n",
      "6.1371\n",
      "6.1380\n",
      "6.1407\n",
      "6.1414\n",
      "6.1426\n",
      "6.1430\n",
      "6.1433\n",
      "6.1436\n",
      "6.1439\n",
      "6.1455\n",
      "6.1460\n",
      "6.1478\n",
      "6.1485\n",
      "6.1491\n",
      "6.1495\n",
      "6.1501\n",
      "6.1512\n",
      "6.1513\n",
      "6.1548\n",
      "6.1551\n",
      "6.1582\n",
      "6.1594\n",
      "6.1619\n",
      "6.1623\n",
      "6.1628\n",
      "6.1631\n",
      "6.1638\n",
      "6.1714\n",
      "6.1723\n",
      "6.1731\n",
      "6.1733\n",
      "6.1745\n",
      "6.1769\n",
      "6.1773\n",
      "6.1777\n",
      "6.1829\n",
      "6.1833\n",
      "6.1834\n",
      "6.1837\n",
      "6.1842\n",
      "6.1859\n",
      "6.1861\n",
      "6.1872\n",
      "6.1900\n",
      "6.1922\n",
      "6.1939\n",
      "6.1940\n",
      "6.1948\n",
      "6.1965\n",
      "6.1981\n",
      "6.1985\n",
      "6.2024\n",
      "6.2033\n",
      "7\n",
      "7.13\n",
      "7.15\n",
      "7.59\n",
      "7.67\n",
      "7.77\n",
      "7.82\n",
      "7.97\n",
      "7.116\n",
      "7.139\n",
      "7.187\n",
      "7.206\n",
      "7.221\n",
      "7.250\n",
      "7.264\n",
      "7.297\n",
      "7.302\n",
      "7.318\n",
      "7.344\n",
      "7.350\n",
      "7.358\n",
      "7.361\n",
      "7.381\n",
      "7.403\n",
      "7.414\n",
      "7.439\n",
      "7.503\n",
      "7.549\n",
      "7.557\n",
      "7.560\n",
      "7.575\n",
      "7.583\n",
      "7.586\n",
      "7.614\n",
      "7.630\n",
      "7.673\n",
      "7.700\n",
      "7.763\n",
      "7.777\n",
      "7.785\n",
      "7.788\n",
      "7.815\n",
      "7.832\n",
      "7.833\n",
      "7.862\n",
      "7.885\n",
      "7.899\n",
      "7.902\n",
      "7.928\n",
      "7.936\n",
      "7.938\n",
      "7.970\n",
      "7.983\n",
      "7.1006\n",
      "7.1019\n",
      "7.1026\n",
      "7.1043\n",
      "7.1050\n",
      "7.1067\n",
      "7.1078\n",
      "7.1088\n",
      "7.1119\n",
      "7.1124\n",
      "7.1135\n",
      "7.1164\n",
      "7.1173\n",
      "7.1177\n",
      "7.1181\n",
      "7.1184\n",
      "7.1216\n",
      "7.1264\n",
      "7.1266\n",
      "7.1278\n",
      "7.1287\n",
      "7.1289\n",
      "7.1297\n",
      "7.1300\n",
      "7.1344\n",
      "7.1393\n",
      "7.1414\n",
      "7.1428\n",
      "7.1442\n",
      "7.1455\n",
      "7.1462\n",
      "7.1474\n",
      "7.1506\n",
      "7.1511\n",
      "7.1516\n",
      "7.1523\n",
      "7.1531\n",
      "7.1584\n",
      "7.1592\n",
      "7.1608\n",
      "7.1663\n",
      "7.1669\n",
      "7.1689\n",
      "7.1717\n",
      "7.1723\n",
      "7.1733\n",
      "7.1768\n",
      "7.1789\n",
      "7.1812\n",
      "7.1815\n",
      "7.1868\n",
      "7.1873\n",
      "7.1876\n",
      "7.1888\n",
      "7.1898\n",
      "7.1907\n",
      "7.1929\n",
      "7.1932\n",
      "7.1946\n",
      "7.1948\n",
      "7.1962\n",
      "7.1966\n",
      "7.2006\n",
      "7.2013\n",
      "7.2019\n",
      "7.2020\n",
      "7.2027\n",
      "7.2029\n",
      "7.2031\n",
      "8\n",
      "8.20\n",
      "8.31\n",
      "8.33\n",
      "8.36\n",
      "8.64\n",
      "8.67\n",
      "8.79\n",
      "8.81\n",
      "8.99\n",
      "8.109\n",
      "8.117\n",
      "8.137\n",
      "8.138\n",
      "8.140\n",
      "8.159\n",
      "8.165\n",
      "8.177\n",
      "8.179\n",
      "8.198\n",
      "8.219\n",
      "8.222\n",
      "8.223\n",
      "8.234\n",
      "8.259\n",
      "8.260\n",
      "8.264\n",
      "8.288\n",
      "8.290\n",
      "8.325\n",
      "8.343\n",
      "8.350\n",
      "8.357\n",
      "8.366\n",
      "8.370\n",
      "8.417\n",
      "8.458\n",
      "8.461\n",
      "8.464\n",
      "8.469\n",
      "8.472\n",
      "8.485\n",
      "8.540\n",
      "8.560\n",
      "8.574\n",
      "8.606\n",
      "8.608\n",
      "8.616\n",
      "8.629\n",
      "8.635\n",
      "8.645\n",
      "8.646\n",
      "8.654\n",
      "8.664\n",
      "8.675\n",
      "8.691\n",
      "8.712\n",
      "8.726\n",
      "8.745\n",
      "8.749\n",
      "8.763\n",
      "8.785\n",
      "8.806\n",
      "8.811\n",
      "8.822\n",
      "8.838\n",
      "8.847\n",
      "8.854\n",
      "8.866\n",
      "8.875\n",
      "8.881\n",
      "8.883\n",
      "8.901\n",
      "8.920\n",
      "8.937\n",
      "8.941\n",
      "8.942\n",
      "8.962\n",
      "8.983\n",
      "8.991\n",
      "8.995\n",
      "8.998\n",
      "8.1009\n",
      "8.1036\n",
      "8.1037\n",
      "8.1047\n",
      "8.1051\n",
      "8.1064\n",
      "8.1069\n",
      "8.1076\n",
      "8.1088\n",
      "8.1105\n",
      "8.1165\n",
      "8.1185\n",
      "8.1190\n",
      "8.1216\n",
      "8.1217\n",
      "8.1235\n",
      "8.1237\n",
      "8.1239\n",
      "8.1270\n",
      "8.1286\n",
      "8.1316\n",
      "8.1331\n",
      "8.1352\n",
      "8.1354\n",
      "8.1363\n",
      "8.1389\n",
      "8.1390\n",
      "8.1394\n",
      "8.1458\n",
      "8.1460\n",
      "8.1477\n",
      "8.1510\n",
      "8.1521\n",
      "8.1527\n",
      "8.1532\n",
      "8.1536\n",
      "8.1543\n",
      "8.1568\n",
      "8.1588\n",
      "8.1592\n",
      "8.1595\n",
      "8.1610\n",
      "8.1617\n",
      "8.1626\n",
      "8.1635\n",
      "8.1639\n",
      "8.1641\n",
      "8.1660\n",
      "8.1663\n",
      "8.1664\n",
      "8.1676\n",
      "8.1688\n",
      "8.1695\n",
      "8.1705\n",
      "8.1707\n",
      "8.1715\n",
      "8.1734\n",
      "8.1760\n",
      "8.1767\n",
      "8.1769\n",
      "8.1788\n",
      "8.1803\n",
      "8.1805\n",
      "8.1807\n",
      "8.1844\n",
      "8.1846\n",
      "8.1849\n",
      "8.1858\n",
      "8.1867\n",
      "8.1885\n",
      "8.1888\n",
      "8.1922\n",
      "8.1931\n",
      "8.1954\n",
      "8.1977\n",
      "8.1995\n",
      "8.2001\n",
      "8.2025\n",
      "8.2034\n",
      "8.2044\n",
      "9\n",
      "9.13\n",
      "9.14\n",
      "9.29\n",
      "9.34\n",
      "9.63\n",
      "9.69\n",
      "9.87\n",
      "9.106\n",
      "9.111\n",
      "9.141\n",
      "9.152\n",
      "9.153\n",
      "9.178\n",
      "9.180\n",
      "9.204\n",
      "9.205\n",
      "9.211\n",
      "9.247\n",
      "9.253\n",
      "9.292\n",
      "9.301\n",
      "9.314\n",
      "9.315\n",
      "9.319\n",
      "9.333\n",
      "9.334\n",
      "9.344\n",
      "9.359\n",
      "9.364\n",
      "9.369\n",
      "9.373\n",
      "9.422\n",
      "9.427\n",
      "9.444\n",
      "9.449\n",
      "9.458\n",
      "9.474\n",
      "9.498\n",
      "9.512\n",
      "9.569\n",
      "9.571\n",
      "9.577\n",
      "9.579\n",
      "9.580\n",
      "9.586\n",
      "9.594\n",
      "9.605\n",
      "9.627\n",
      "9.633\n",
      "9.649\n",
      "9.671\n",
      "9.695\n",
      "9.707\n",
      "9.731\n",
      "9.776\n",
      "9.777\n",
      "9.800\n",
      "9.843\n",
      "9.862\n",
      "9.864\n",
      "9.891\n",
      "9.892\n",
      "9.916\n",
      "9.923\n",
      "9.926\n",
      "9.935\n",
      "9.939\n",
      "9.942\n",
      "9.949\n",
      "9.955\n",
      "9.961\n",
      "9.989\n",
      "9.1007\n",
      "9.1010\n",
      "9.1011\n",
      "9.1012\n",
      "9.1015\n",
      "9.1019\n",
      "9.1025\n",
      "9.1038\n",
      "9.1049\n",
      "9.1055\n",
      "9.1060\n",
      "9.1086\n",
      "9.1087\n",
      "9.1104\n",
      "9.1115\n",
      "9.1118\n",
      "9.1119\n",
      "9.1121\n",
      "9.1129\n",
      "9.1133\n",
      "9.1136\n",
      "9.1140\n",
      "9.1142\n",
      "9.1167\n",
      "9.1179\n",
      "9.1197\n",
      "9.1211\n",
      "9.1220\n",
      "9.1241\n",
      "9.1265\n",
      "9.1274\n",
      "9.1348\n",
      "9.1354\n",
      "9.1356\n",
      "9.1375\n",
      "9.1393\n",
      "9.1395\n",
      "9.1401\n",
      "9.1409\n",
      "9.1414\n",
      "9.1418\n",
      "9.1424\n",
      "9.1430\n",
      "9.1451\n",
      "9.1452\n",
      "9.1456\n",
      "9.1463\n",
      "9.1469\n",
      "9.1485\n",
      "9.1490\n",
      "9.1502\n",
      "9.1510\n",
      "9.1512\n",
      "9.1570\n",
      "9.1574\n",
      "9.1598\n",
      "9.1609\n",
      "9.1613\n",
      "9.1652\n",
      "9.1667\n",
      "9.1686\n",
      "9.1693\n",
      "9.1707\n",
      "9.1720\n",
      "9.1759\n",
      "9.1771\n",
      "9.1772\n",
      "9.1783\n",
      "9.1791\n",
      "9.1797\n",
      "9.1808\n",
      "9.1832\n",
      "9.1837\n",
      "9.1844\n",
      "9.1861\n",
      "9.1866\n",
      "9.1883\n",
      "9.1944\n",
      "9.1947\n",
      "9.1948\n",
      "9.1973\n",
      "9.1977\n",
      "9.1979\n",
      "9.1992\n",
      "9.1996\n",
      "9.2047\n",
      "10\n",
      "10.2\n",
      "10.8\n",
      "10.11\n",
      "10.16\n",
      "10.21\n",
      "10.27\n",
      "10.29\n",
      "10.32\n",
      "10.35\n",
      "10.62\n",
      "10.74\n",
      "10.75\n",
      "10.76\n",
      "10.78\n",
      "10.79\n",
      "10.87\n",
      "10.95\n",
      "10.106\n",
      "10.107\n",
      "10.112\n",
      "10.128\n",
      "10.130\n",
      "10.139\n",
      "10.155\n",
      "10.158\n",
      "10.162\n",
      "10.170\n",
      "10.175\n",
      "10.184\n",
      "10.188\n",
      "10.190\n",
      "10.196\n",
      "10.199\n",
      "10.203\n",
      "10.210\n",
      "10.213\n",
      "10.214\n",
      "10.215\n",
      "10.218\n",
      "10.223\n",
      "10.233\n",
      "10.236\n",
      "10.239\n",
      "10.241\n",
      "10.243\n",
      "10.247\n",
      "10.250\n",
      "10.254\n",
      "10.255\n",
      "10.257\n",
      "10.258\n",
      "10.262\n",
      "10.269\n",
      "10.279\n",
      "10.281\n",
      "10.300\n",
      "10.301\n",
      "10.309\n",
      "10.316\n",
      "10.327\n",
      "10.337\n",
      "10.348\n",
      "10.351\n",
      "10.353\n",
      "10.357\n",
      "10.361\n",
      "10.366\n",
      "10.385\n",
      "10.397\n",
      "10.400\n",
      "10.401\n",
      "10.407\n",
      "10.413\n",
      "10.416\n",
      "10.420\n",
      "10.433\n",
      "10.454\n",
      "10.468\n",
      "10.470\n",
      "10.475\n",
      "10.479\n",
      "10.485\n",
      "10.493\n",
      "10.496\n",
      "10.497\n",
      "10.505\n",
      "10.514\n",
      "10.520\n",
      "10.526\n",
      "10.533\n",
      "10.541\n",
      "10.542\n",
      "10.554\n",
      "10.557\n",
      "10.569\n",
      "10.581\n",
      "10.590\n",
      "10.618\n",
      "10.624\n",
      "10.640\n",
      "10.642\n",
      "10.643\n",
      "10.656\n",
      "10.657\n",
      "10.659\n",
      "10.661\n",
      "10.662\n",
      "10.667\n",
      "10.669\n",
      "10.671\n",
      "10.677\n",
      "10.679\n",
      "10.687\n",
      "10.695\n",
      "10.697\n",
      "10.700\n",
      "10.701\n",
      "10.706\n",
      "10.711\n",
      "10.712\n",
      "10.739\n",
      "10.743\n",
      "10.744\n",
      "10.755\n",
      "10.763\n",
      "10.811\n",
      "10.818\n",
      "10.826\n",
      "10.827\n",
      "10.840\n",
      "10.844\n",
      "10.853\n",
      "10.862\n",
      "10.866\n",
      "10.873\n",
      "10.876\n",
      "10.898\n",
      "10.911\n",
      "10.921\n",
      "10.938\n",
      "10.940\n",
      "10.942\n",
      "10.944\n",
      "10.952\n",
      "10.953\n",
      "10.957\n",
      "10.962\n",
      "10.973\n",
      "10.975\n",
      "10.976\n",
      "10.1003\n",
      "10.1004\n",
      "10.1005\n",
      "10.1017\n",
      "10.1019\n",
      "10.1026\n",
      "10.1031\n",
      "10.1036\n",
      "10.1039\n",
      "10.1047\n",
      "10.1057\n",
      "10.1063\n",
      "10.1091\n",
      "10.1092\n",
      "10.1109\n",
      "10.1119\n",
      "10.1136\n",
      "10.1137\n",
      "10.1140\n",
      "10.1143\n",
      "10.1159\n",
      "10.1161\n",
      "10.1168\n",
      "10.1175\n",
      "10.1178\n",
      "10.1182\n",
      "10.1183\n",
      "10.1200\n",
      "10.1205\n",
      "10.1206\n",
      "10.1208\n",
      "10.1218\n",
      "10.1223\n",
      "10.1228\n",
      "10.1232\n",
      "10.1236\n",
      "10.1249\n",
      "10.1266\n",
      "10.1277\n",
      "10.1282\n",
      "10.1285\n",
      "10.1294\n",
      "10.1298\n",
      "10.1299\n",
      "10.1302\n",
      "10.1310\n",
      "10.1318\n",
      "10.1320\n",
      "10.1322\n",
      "10.1325\n",
      "10.1339\n",
      "10.1356\n",
      "10.1360\n",
      "10.1365\n",
      "10.1368\n",
      "10.1369\n",
      "10.1375\n",
      "10.1378\n",
      "10.1379\n",
      "10.1393\n",
      "10.1413\n",
      "10.1415\n",
      "10.1429\n",
      "10.1434\n",
      "10.1437\n",
      "10.1445\n",
      "10.1454\n",
      "10.1456\n",
      "10.1466\n",
      "10.1475\n",
      "10.1480\n",
      "10.1486\n",
      "10.1492\n",
      "10.1504\n",
      "10.1505\n",
      "10.1510\n",
      "10.1513\n",
      "10.1518\n",
      "10.1530\n",
      "10.1536\n",
      "10.1544\n",
      "10.1549\n",
      "10.1559\n",
      "10.1565\n",
      "10.1571\n",
      "10.1579\n",
      "10.1580\n",
      "10.1583\n",
      "10.1585\n",
      "10.1594\n",
      "10.1596\n",
      "10.1605\n",
      "10.1608\n",
      "10.1613\n",
      "10.1615\n",
      "10.1624\n",
      "10.1647\n",
      "10.1656\n",
      "10.1663\n",
      "10.1673\n",
      "10.1680\n",
      "10.1685\n",
      "10.1689\n",
      "10.1693\n",
      "10.1697\n",
      "10.1699\n",
      "10.1705\n",
      "10.1709\n",
      "10.1715\n",
      "10.1717\n",
      "10.1721\n",
      "10.1723\n",
      "10.1727\n",
      "10.1731\n",
      "10.1737\n",
      "10.1753\n",
      "10.1757\n",
      "10.1770\n",
      "10.1784\n",
      "10.1785\n",
      "10.1791\n",
      "10.1796\n",
      "10.1800\n",
      "10.1818\n",
      "10.1823\n",
      "10.1824\n",
      "10.1834\n",
      "10.1835\n",
      "10.1842\n",
      "10.1849\n",
      "10.1863\n",
      "10.1873\n",
      "10.1875\n",
      "10.1885\n",
      "10.1887\n",
      "10.1898\n",
      "10.1908\n",
      "10.1909\n",
      "10.1913\n",
      "10.1915\n",
      "10.1926\n",
      "10.1943\n",
      "10.1947\n",
      "10.1957\n",
      "10.1962\n",
      "10.1970\n",
      "10.1977\n",
      "10.1997\n",
      "10.2008\n",
      "10.2018\n",
      "11\n",
      "11.1\n",
      "11.3\n",
      "11.23\n",
      "11.28\n",
      "11.30\n",
      "11.52\n",
      "11.79\n",
      "11.81\n",
      "11.94\n",
      "11.98\n",
      "11.102\n",
      "11.103\n",
      "11.112\n",
      "11.119\n",
      "11.124\n",
      "11.137\n",
      "11.139\n",
      "11.157\n",
      "11.175\n",
      "11.178\n",
      "11.180\n",
      "11.187\n",
      "11.189\n",
      "11.194\n",
      "11.197\n",
      "11.201\n",
      "11.202\n",
      "11.212\n",
      "11.213\n",
      "11.219\n",
      "11.229\n",
      "11.238\n",
      "11.253\n",
      "11.266\n",
      "11.275\n",
      "11.284\n",
      "11.299\n",
      "11.307\n",
      "11.313\n",
      "11.329\n",
      "11.333\n",
      "11.339\n",
      "11.343\n",
      "11.344\n",
      "11.345\n",
      "11.357\n",
      "11.361\n",
      "11.369\n",
      "11.370\n",
      "11.375\n",
      "11.377\n",
      "11.388\n",
      "11.398\n",
      "11.404\n",
      "11.418\n",
      "11.426\n",
      "11.427\n",
      "11.432\n",
      "11.439\n",
      "11.440\n",
      "11.452\n",
      "11.465\n",
      "11.468\n",
      "11.472\n",
      "11.481\n",
      "11.484\n",
      "11.488\n",
      "11.502\n",
      "11.542\n",
      "11.565\n",
      "11.566\n",
      "11.567\n",
      "11.575\n",
      "11.580\n",
      "11.584\n",
      "11.603\n",
      "11.604\n",
      "11.610\n",
      "11.634\n",
      "11.652\n",
      "11.655\n",
      "11.659\n",
      "11.661\n",
      "11.662\n",
      "11.666\n",
      "11.670\n",
      "11.685\n",
      "11.704\n",
      "11.713\n",
      "11.721\n",
      "11.726\n",
      "11.734\n",
      "11.738\n",
      "11.743\n",
      "11.744\n",
      "11.748\n",
      "11.796\n",
      "11.798\n",
      "11.820\n",
      "11.822\n",
      "11.823\n",
      "11.828\n",
      "11.837\n",
      "11.850\n",
      "11.853\n",
      "11.858\n",
      "11.883\n",
      "11.890\n",
      "11.898\n",
      "11.908\n",
      "11.916\n",
      "11.920\n",
      "11.922\n",
      "11.931\n",
      "11.936\n",
      "11.954\n",
      "11.968\n",
      "11.977\n",
      "11.997\n",
      "11.1011\n",
      "11.1012\n",
      "11.1025\n",
      "11.1031\n",
      "11.1036\n",
      "11.1047\n",
      "11.1056\n",
      "11.1058\n",
      "11.1066\n",
      "11.1089\n",
      "11.1100\n",
      "11.1105\n",
      "11.1111\n",
      "11.1113\n",
      "11.1126\n",
      "11.1137\n",
      "11.1148\n",
      "11.1154\n",
      "11.1157\n",
      "11.1166\n",
      "11.1174\n",
      "11.1175\n",
      "11.1178\n",
      "11.1186\n",
      "11.1193\n",
      "11.1203\n",
      "11.1220\n",
      "11.1231\n",
      "11.1262\n",
      "11.1267\n",
      "11.1275\n",
      "11.1288\n",
      "11.1290\n",
      "11.1301\n",
      "11.1303\n",
      "11.1305\n",
      "11.1306\n",
      "11.1313\n",
      "11.1317\n",
      "11.1355\n",
      "11.1358\n",
      "11.1363\n",
      "11.1365\n",
      "11.1366\n",
      "11.1368\n",
      "11.1371\n",
      "11.1374\n",
      "11.1380\n",
      "11.1422\n",
      "11.1440\n",
      "11.1446\n",
      "11.1450\n",
      "11.1451\n",
      "11.1463\n",
      "11.1476\n",
      "11.1479\n",
      "11.1481\n",
      "11.1482\n",
      "11.1483\n",
      "11.1485\n",
      "11.1506\n",
      "11.1508\n",
      "11.1511\n",
      "11.1517\n",
      "11.1525\n",
      "11.1531\n",
      "11.1534\n",
      "11.1557\n",
      "11.1570\n",
      "11.1578\n",
      "11.1581\n",
      "11.1590\n",
      "11.1596\n",
      "11.1600\n",
      "11.1617\n",
      "11.1629\n",
      "11.1634\n",
      "11.1647\n",
      "11.1649\n",
      "11.1653\n",
      "11.1655\n",
      "11.1658\n",
      "11.1671\n",
      "11.1675\n",
      "11.1676\n",
      "11.1708\n",
      "11.1730\n",
      "11.1737\n",
      "11.1738\n",
      "11.1747\n",
      "11.1753\n",
      "11.1764\n",
      "11.1781\n",
      "11.1791\n",
      "11.1792\n",
      "11.1797\n",
      "11.1799\n",
      "11.1807\n",
      "11.1812\n",
      "11.1814\n",
      "11.1817\n",
      "11.1819\n",
      "11.1858\n",
      "11.1865\n",
      "11.1868\n",
      "11.1903\n",
      "11.1908\n",
      "11.1909\n",
      "11.1911\n",
      "11.1915\n",
      "11.1929\n",
      "11.1945\n",
      "11.1975\n",
      "11.1982\n",
      "11.2002\n",
      "11.2004\n",
      "11.2007\n",
      "11.2011\n",
      "11.2021\n",
      "11.2030\n",
      "11.2031\n",
      "12\n",
      "12.3\n",
      "12.9\n",
      "12.10\n",
      "12.13\n",
      "12.14\n",
      "12.15\n",
      "12.18\n",
      "12.23\n",
      "12.45\n",
      "12.49\n",
      "12.50\n",
      "12.52\n",
      "12.54\n",
      "12.60\n",
      "12.84\n",
      "12.90\n",
      "12.93\n",
      "12.94\n",
      "12.97\n",
      "12.98\n",
      "12.100\n",
      "12.101\n",
      "12.105\n",
      "12.107\n",
      "12.108\n",
      "12.120\n",
      "12.132\n",
      "12.138\n",
      "12.141\n",
      "12.142\n",
      "12.146\n",
      "12.149\n",
      "12.150\n",
      "12.152\n",
      "12.157\n",
      "12.162\n",
      "12.165\n",
      "12.166\n",
      "12.169\n",
      "12.170\n",
      "12.171\n",
      "12.173\n",
      "12.174\n",
      "12.186\n",
      "12.190\n",
      "12.191\n",
      "12.193\n",
      "12.205\n",
      "12.212\n",
      "12.213\n",
      "12.229\n",
      "12.231\n",
      "12.234\n",
      "12.236\n",
      "12.243\n",
      "12.247\n",
      "12.249\n",
      "12.255\n",
      "12.259\n",
      "12.265\n",
      "12.275\n",
      "12.282\n",
      "12.285\n",
      "12.294\n",
      "12.296\n",
      "12.297\n",
      "12.300\n",
      "12.303\n",
      "12.306\n",
      "12.319\n",
      "12.320\n",
      "12.321\n",
      "12.338\n",
      "12.351\n",
      "12.361\n",
      "12.365\n",
      "12.374\n",
      "12.381\n",
      "12.386\n",
      "12.389\n",
      "12.392\n",
      "12.393\n",
      "12.394\n",
      "12.395\n",
      "12.401\n",
      "12.405\n",
      "12.410\n",
      "12.413\n",
      "12.414\n",
      "12.426\n",
      "12.429\n",
      "12.443\n",
      "12.453\n",
      "12.460\n",
      "12.463\n",
      "12.466\n",
      "12.468\n",
      "12.474\n",
      "12.482\n",
      "12.494\n",
      "12.495\n",
      "12.496\n",
      "12.501\n",
      "12.505\n",
      "12.514\n",
      "12.525\n",
      "12.527\n",
      "12.540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.558\n",
      "12.566\n",
      "12.572\n",
      "12.583\n",
      "12.585\n",
      "12.591\n",
      "12.592\n",
      "12.596\n",
      "12.603\n",
      "12.607\n",
      "12.608\n",
      "12.615\n",
      "12.629\n",
      "12.630\n",
      "12.631\n",
      "12.641\n",
      "12.646\n",
      "12.647\n",
      "12.652\n",
      "12.679\n",
      "12.681\n",
      "12.694\n",
      "12.709\n",
      "12.710\n",
      "12.713\n",
      "12.715\n",
      "12.721\n",
      "12.723\n",
      "12.724\n",
      "12.727\n",
      "12.730\n",
      "12.736\n",
      "12.739\n",
      "12.741\n",
      "12.759\n",
      "12.765\n",
      "12.768\n",
      "12.784\n",
      "12.795\n",
      "12.796\n",
      "12.797\n",
      "12.798\n",
      "12.799\n",
      "12.802\n",
      "12.804\n",
      "12.817\n",
      "12.818\n",
      "12.827\n",
      "12.831\n",
      "12.842\n",
      "12.843\n",
      "12.844\n",
      "12.857\n",
      "12.858\n",
      "12.859\n",
      "12.861\n",
      "12.867\n",
      "12.872\n",
      "12.875\n",
      "12.878\n",
      "12.885\n",
      "12.889\n",
      "12.896\n",
      "12.901\n",
      "12.902\n",
      "12.903\n",
      "12.913\n",
      "12.921\n",
      "12.929\n",
      "12.939\n",
      "12.943\n",
      "12.954\n",
      "12.957\n",
      "12.959\n",
      "12.973\n",
      "12.980\n",
      "12.983\n",
      "12.985\n",
      "12.989\n",
      "12.990\n",
      "12.1005\n",
      "12.1025\n",
      "12.1028\n",
      "12.1030\n",
      "12.1043\n",
      "12.1045\n",
      "12.1047\n",
      "12.1048\n",
      "12.1052\n",
      "12.1069\n",
      "12.1071\n",
      "12.1089\n",
      "12.1092\n",
      "12.1093\n",
      "12.1101\n",
      "12.1108\n",
      "12.1113\n",
      "12.1114\n",
      "12.1137\n",
      "12.1141\n",
      "12.1147\n",
      "12.1148\n",
      "12.1149\n",
      "12.1152\n",
      "12.1153\n",
      "12.1157\n",
      "12.1164\n",
      "12.1168\n",
      "12.1174\n",
      "12.1175\n",
      "12.1179\n",
      "12.1190\n",
      "12.1195\n",
      "12.1196\n",
      "12.1202\n",
      "12.1203\n",
      "12.1207\n",
      "12.1211\n",
      "12.1214\n",
      "12.1221\n",
      "12.1226\n",
      "12.1227\n",
      "12.1231\n",
      "12.1239\n",
      "12.1249\n",
      "12.1251\n",
      "12.1260\n",
      "12.1269\n",
      "12.1272\n",
      "12.1275\n",
      "12.1312\n",
      "12.1329\n",
      "12.1332\n",
      "12.1334\n",
      "12.1335\n",
      "12.1357\n",
      "12.1374\n",
      "12.1375\n",
      "12.1383\n",
      "12.1385\n",
      "12.1392\n",
      "12.1401\n",
      "12.1402\n",
      "12.1410\n",
      "12.1425\n",
      "12.1427\n",
      "12.1441\n",
      "12.1444\n",
      "12.1449\n",
      "12.1454\n",
      "12.1456\n",
      "12.1462\n",
      "12.1464\n",
      "12.1474\n",
      "12.1478\n",
      "12.1499\n",
      "12.1506\n",
      "12.1516\n",
      "12.1527\n",
      "12.1530\n",
      "12.1537\n",
      "12.1549\n",
      "12.1561\n",
      "12.1571\n",
      "12.1575\n",
      "12.1587\n",
      "12.1588\n",
      "12.1598\n",
      "12.1601\n",
      "12.1604\n",
      "12.1614\n",
      "12.1620\n",
      "12.1621\n",
      "12.1627\n",
      "12.1629\n",
      "12.1632\n",
      "12.1640\n",
      "12.1644\n",
      "12.1651\n",
      "12.1663\n",
      "12.1667\n",
      "12.1681\n",
      "12.1684\n",
      "12.1688\n",
      "12.1696\n",
      "12.1699\n",
      "12.1701\n",
      "12.1703\n",
      "12.1713\n",
      "12.1728\n",
      "12.1744\n",
      "12.1750\n",
      "12.1754\n",
      "12.1762\n",
      "12.1765\n",
      "12.1767\n",
      "12.1769\n",
      "12.1770\n",
      "12.1773\n",
      "12.1776\n",
      "12.1778\n",
      "12.1781\n",
      "12.1788\n",
      "12.1792\n",
      "12.1797\n",
      "12.1799\n",
      "12.1808\n",
      "12.1831\n",
      "12.1845\n",
      "12.1849\n",
      "12.1852\n",
      "12.1854\n",
      "12.1871\n",
      "12.1875\n",
      "12.1878\n",
      "12.1880\n",
      "12.1882\n",
      "12.1890\n",
      "12.1895\n",
      "12.1896\n",
      "12.1902\n",
      "12.1903\n",
      "12.1909\n",
      "12.1910\n",
      "12.1911\n",
      "12.1915\n",
      "12.1918\n",
      "12.1919\n",
      "12.1925\n",
      "12.1935\n",
      "12.1938\n",
      "12.1957\n",
      "12.1960\n",
      "12.1963\n",
      "12.1972\n",
      "12.1973\n",
      "12.1974\n",
      "12.1989\n",
      "12.1998\n",
      "12.2003\n",
      "12.2006\n",
      "12.2007\n",
      "12.2010\n",
      "12.2018\n",
      "12.2020\n",
      "12.2025\n",
      "12.2037\n",
      "12.2046\n",
      "13\n",
      "13.1\n",
      "13.45\n",
      "13.61\n",
      "13.78\n",
      "13.80\n",
      "13.83\n",
      "13.96\n",
      "13.111\n",
      "13.116\n",
      "13.117\n",
      "13.118\n",
      "13.120\n",
      "13.132\n",
      "13.135\n",
      "13.136\n",
      "13.139\n",
      "13.149\n",
      "13.150\n",
      "13.158\n",
      "13.161\n",
      "13.172\n",
      "13.174\n",
      "13.189\n",
      "13.190\n",
      "13.201\n",
      "13.202\n",
      "13.206\n",
      "13.210\n",
      "13.221\n",
      "13.224\n",
      "13.229\n",
      "13.240\n",
      "13.243\n",
      "13.275\n",
      "13.281\n",
      "13.289\n",
      "13.296\n",
      "13.297\n",
      "13.302\n",
      "13.305\n",
      "13.307\n",
      "13.308\n",
      "13.310\n",
      "13.312\n",
      "13.324\n",
      "13.326\n",
      "13.334\n",
      "13.336\n",
      "13.338\n",
      "13.347\n",
      "13.348\n",
      "13.349\n",
      "13.350\n",
      "13.354\n",
      "13.356\n",
      "13.364\n",
      "13.377\n",
      "13.386\n",
      "13.387\n",
      "13.390\n",
      "13.399\n",
      "13.402\n",
      "13.406\n",
      "13.411\n",
      "13.454\n",
      "13.457\n",
      "13.458\n",
      "13.459\n",
      "13.460\n",
      "13.468\n",
      "13.489\n",
      "13.509\n",
      "13.512\n",
      "13.524\n",
      "13.533\n",
      "13.544\n",
      "13.545\n",
      "13.553\n",
      "13.555\n",
      "13.560\n",
      "13.562\n",
      "13.564\n",
      "13.568\n",
      "13.581\n",
      "13.586\n",
      "13.592\n",
      "13.603\n",
      "13.614\n",
      "13.615\n",
      "13.632\n",
      "13.635\n",
      "13.640\n",
      "13.644\n",
      "13.646\n",
      "13.648\n",
      "13.656\n",
      "13.659\n",
      "13.661\n",
      "13.677\n",
      "13.682\n",
      "13.691\n",
      "13.720\n",
      "13.726\n",
      "13.733\n",
      "13.734\n",
      "13.736\n",
      "13.743\n",
      "13.746\n",
      "13.770\n",
      "13.778\n",
      "13.788\n",
      "13.789\n",
      "13.800\n",
      "13.818\n",
      "13.822\n",
      "13.828\n",
      "13.829\n",
      "13.850\n",
      "13.854\n",
      "13.858\n",
      "13.859\n",
      "13.861\n",
      "13.862\n",
      "13.874\n",
      "13.888\n",
      "13.895\n",
      "13.899\n",
      "13.910\n",
      "13.915\n",
      "13.919\n",
      "13.928\n",
      "13.932\n",
      "13.938\n",
      "13.951\n",
      "13.958\n",
      "13.960\n",
      "13.963\n",
      "13.970\n",
      "13.978\n",
      "13.980\n",
      "13.991\n",
      "13.994\n",
      "13.999\n",
      "13.1011\n",
      "13.1016\n",
      "13.1024\n",
      "13.1028\n",
      "13.1032\n",
      "13.1036\n",
      "13.1039\n",
      "13.1046\n",
      "13.1049\n",
      "13.1088\n",
      "13.1108\n",
      "13.1120\n",
      "13.1131\n",
      "13.1134\n",
      "13.1138\n",
      "13.1141\n",
      "13.1143\n",
      "13.1148\n",
      "13.1152\n",
      "13.1159\n",
      "13.1166\n",
      "13.1178\n",
      "13.1180\n",
      "13.1194\n",
      "13.1204\n",
      "13.1208\n",
      "13.1213\n",
      "13.1221\n",
      "13.1228\n",
      "13.1230\n",
      "13.1235\n",
      "13.1241\n",
      "13.1248\n",
      "13.1251\n",
      "13.1261\n",
      "13.1270\n",
      "13.1275\n",
      "13.1311\n",
      "13.1317\n",
      "13.1327\n",
      "13.1335\n",
      "13.1336\n",
      "13.1356\n",
      "13.1359\n",
      "13.1361\n",
      "13.1374\n",
      "13.1379\n",
      "13.1382\n",
      "13.1394\n",
      "13.1404\n",
      "13.1405\n",
      "13.1414\n",
      "13.1417\n",
      "13.1428\n",
      "13.1432\n",
      "13.1434\n",
      "13.1451\n",
      "13.1452\n",
      "13.1468\n",
      "13.1477\n",
      "13.1491\n",
      "13.1528\n",
      "13.1529\n",
      "13.1530\n",
      "13.1537\n",
      "13.1539\n",
      "13.1540\n",
      "13.1547\n",
      "13.1573\n",
      "13.1585\n",
      "13.1586\n",
      "13.1596\n",
      "13.1604\n",
      "13.1613\n",
      "13.1614\n",
      "13.1615\n",
      "13.1631\n",
      "13.1659\n",
      "13.1664\n",
      "13.1669\n",
      "13.1673\n",
      "13.1674\n",
      "13.1675\n",
      "13.1676\n",
      "13.1683\n",
      "13.1691\n",
      "13.1703\n",
      "13.1708\n",
      "13.1710\n",
      "13.1726\n",
      "13.1728\n",
      "13.1732\n",
      "13.1733\n",
      "13.1736\n",
      "13.1741\n",
      "13.1754\n",
      "13.1758\n",
      "13.1761\n",
      "13.1762\n",
      "13.1770\n",
      "13.1772\n",
      "13.1773\n",
      "13.1782\n",
      "13.1792\n",
      "13.1793\n",
      "13.1799\n",
      "13.1807\n",
      "13.1818\n",
      "13.1825\n",
      "13.1827\n",
      "13.1837\n",
      "13.1844\n",
      "13.1851\n",
      "13.1852\n",
      "13.1857\n",
      "13.1859\n",
      "13.1873\n",
      "13.1879\n",
      "13.1880\n",
      "13.1885\n",
      "13.1912\n",
      "13.1914\n",
      "13.1920\n",
      "13.1931\n",
      "13.1933\n",
      "13.1934\n",
      "13.1936\n",
      "13.1938\n",
      "13.1941\n",
      "13.1954\n",
      "13.1957\n",
      "13.1967\n",
      "13.1972\n",
      "13.1989\n",
      "13.2004\n",
      "13.2014\n",
      "13.2017\n",
      "13.2030\n",
      "13.2041\n",
      "13.2047\n",
      "14\n",
      "14.1\n",
      "14.2\n",
      "14.3\n",
      "14.12\n",
      "14.13\n",
      "14.16\n",
      "14.20\n",
      "14.28\n",
      "14.50\n",
      "14.54\n",
      "14.70\n",
      "14.81\n",
      "14.89\n",
      "14.90\n",
      "14.92\n",
      "14.96\n",
      "14.111\n",
      "14.116\n",
      "14.117\n",
      "14.118\n",
      "14.130\n",
      "14.137\n",
      "14.148\n",
      "14.154\n",
      "14.180\n",
      "14.182\n",
      "14.197\n",
      "14.230\n",
      "14.237\n",
      "14.246\n",
      "14.247\n",
      "14.249\n",
      "14.251\n",
      "14.253\n",
      "14.255\n",
      "14.262\n",
      "14.271\n",
      "14.308\n",
      "14.313\n",
      "14.321\n",
      "14.322\n",
      "14.335\n",
      "14.337\n",
      "14.343\n",
      "14.347\n",
      "14.360\n",
      "14.366\n",
      "14.367\n",
      "14.370\n",
      "14.373\n",
      "14.374\n",
      "14.383\n",
      "14.393\n",
      "14.400\n",
      "14.419\n",
      "14.429\n",
      "14.436\n",
      "14.438\n",
      "14.443\n",
      "14.444\n",
      "14.456\n",
      "14.461\n",
      "14.471\n",
      "14.487\n",
      "14.488\n",
      "14.491\n",
      "14.499\n",
      "14.505\n",
      "14.516\n",
      "14.526\n",
      "14.549\n",
      "14.550\n",
      "14.551\n",
      "14.556\n",
      "14.563\n",
      "14.569\n",
      "14.581\n",
      "14.594\n",
      "14.599\n",
      "14.600\n",
      "14.615\n",
      "14.620\n",
      "14.626\n",
      "14.641\n",
      "14.643\n",
      "14.648\n",
      "14.650\n",
      "14.656\n",
      "14.661\n",
      "14.663\n",
      "14.664\n",
      "14.669\n",
      "14.673\n",
      "14.674\n",
      "14.687\n",
      "14.688\n",
      "14.694\n",
      "14.708\n",
      "14.718\n",
      "14.719\n",
      "14.746\n",
      "14.752\n",
      "14.753\n",
      "14.755\n",
      "14.758\n",
      "14.769\n",
      "14.772\n",
      "14.786\n",
      "14.792\n",
      "14.799\n",
      "14.812\n",
      "14.817\n",
      "14.820\n",
      "14.839\n",
      "14.840\n",
      "14.845\n",
      "14.846\n",
      "14.851\n",
      "14.853\n",
      "14.862\n",
      "14.866\n",
      "14.870\n",
      "14.877\n",
      "14.880\n",
      "14.881\n",
      "14.887\n",
      "14.898\n",
      "14.913\n",
      "14.918\n",
      "14.919\n",
      "14.921\n",
      "14.927\n",
      "14.938\n",
      "14.944\n",
      "14.954\n",
      "14.959\n",
      "14.964\n",
      "14.978\n",
      "14.992\n",
      "14.1009\n",
      "14.1013\n",
      "14.1017\n",
      "14.1018\n",
      "14.1019\n",
      "14.1023\n",
      "14.1032\n",
      "14.1034\n",
      "14.1038\n",
      "14.1044\n",
      "14.1053\n",
      "14.1055\n",
      "14.1056\n",
      "14.1067\n",
      "14.1083\n",
      "14.1086\n",
      "14.1091\n",
      "14.1101\n",
      "14.1102\n",
      "14.1105\n",
      "14.1111\n",
      "14.1112\n",
      "14.1122\n",
      "14.1133\n",
      "14.1135\n",
      "14.1139\n",
      "14.1143\n",
      "14.1144\n",
      "14.1155\n",
      "14.1165\n",
      "14.1178\n",
      "14.1181\n",
      "14.1186\n",
      "14.1187\n",
      "14.1193\n",
      "14.1194\n",
      "14.1206\n",
      "14.1220\n",
      "14.1230\n",
      "14.1250\n",
      "14.1262\n",
      "14.1278\n",
      "14.1279\n",
      "14.1295\n",
      "14.1296\n",
      "14.1298\n",
      "14.1299\n",
      "14.1314\n",
      "14.1315\n",
      "14.1321\n",
      "14.1332\n",
      "14.1334\n",
      "14.1335\n",
      "14.1349\n",
      "14.1361\n",
      "14.1363\n",
      "14.1370\n",
      "14.1375\n",
      "14.1380\n",
      "14.1383\n",
      "14.1386\n",
      "14.1391\n",
      "14.1395\n",
      "14.1396\n",
      "14.1405\n",
      "14.1407\n",
      "14.1409\n",
      "14.1412\n",
      "14.1413\n",
      "14.1420\n",
      "14.1440\n",
      "14.1446\n",
      "14.1453\n",
      "14.1457\n",
      "14.1468\n",
      "14.1475\n",
      "14.1478\n",
      "14.1483\n",
      "14.1490\n",
      "14.1494\n",
      "14.1495\n",
      "14.1498\n",
      "14.1503\n",
      "14.1504\n",
      "14.1511\n",
      "14.1522\n",
      "14.1523\n",
      "14.1524\n",
      "14.1525\n",
      "14.1528\n",
      "14.1543\n",
      "14.1560\n",
      "14.1585\n",
      "14.1597\n",
      "14.1599\n",
      "14.1605\n",
      "14.1613\n",
      "14.1615\n",
      "14.1616\n",
      "14.1622\n",
      "14.1627\n",
      "14.1634\n",
      "14.1667\n",
      "14.1668\n",
      "14.1670\n",
      "14.1671\n",
      "14.1673\n",
      "14.1676\n",
      "14.1683\n",
      "14.1685\n",
      "14.1687\n",
      "14.1694\n",
      "14.1702\n",
      "14.1703\n",
      "14.1708\n",
      "14.1741\n",
      "14.1742\n",
      "14.1756\n",
      "14.1768\n",
      "14.1780\n",
      "14.1798\n",
      "14.1800\n",
      "14.1805\n",
      "14.1809\n",
      "14.1810\n",
      "14.1811\n",
      "14.1812\n",
      "14.1813\n",
      "14.1821\n",
      "14.1823\n",
      "14.1831\n",
      "14.1835\n",
      "14.1850\n",
      "14.1864\n",
      "14.1867\n",
      "14.1880\n",
      "14.1890\n",
      "14.1895\n",
      "14.1897\n",
      "14.1900\n",
      "14.1911\n",
      "14.1920\n",
      "14.1922\n",
      "14.1932\n",
      "14.1934\n",
      "14.1944\n",
      "14.1948\n",
      "14.1955\n",
      "14.1966\n",
      "14.1973\n",
      "14.1976\n",
      "14.1984\n",
      "14.1985\n",
      "14.1992\n",
      "14.1994\n",
      "14.2003\n",
      "14.2007\n",
      "14.2008\n",
      "14.2016\n",
      "14.2018\n",
      "14.2031\n",
      "14.2035\n",
      "14.2037\n",
      "14.2041\n",
      "15\n",
      "15.1\n",
      "15.3\n",
      "15.9\n",
      "15.12\n",
      "15.16\n",
      "15.20\n",
      "15.23\n",
      "15.24\n",
      "15.26\n",
      "15.29\n",
      "15.33\n",
      "15.41\n",
      "15.53\n",
      "15.58\n",
      "15.59\n",
      "15.60\n",
      "15.65\n",
      "15.72\n",
      "15.79\n",
      "15.85\n",
      "15.95\n",
      "15.96\n",
      "15.97\n",
      "15.100\n",
      "15.103\n",
      "15.109\n",
      "15.122\n",
      "15.123\n",
      "15.131\n",
      "15.133\n",
      "15.147\n",
      "15.160\n",
      "15.172\n",
      "15.174\n",
      "15.175\n",
      "15.179\n",
      "15.183\n",
      "15.193\n",
      "15.197\n",
      "15.212\n",
      "15.219\n",
      "15.222\n",
      "15.223\n",
      "15.231\n",
      "15.233\n",
      "15.238\n",
      "15.253\n",
      "15.270\n",
      "15.279\n",
      "15.284\n",
      "15.286\n",
      "15.296\n",
      "15.299\n",
      "15.301\n",
      "15.303\n",
      "15.304\n",
      "15.306\n",
      "15.308\n",
      "15.309\n",
      "15.314\n",
      "15.319\n",
      "15.320\n",
      "15.328\n",
      "15.332\n",
      "15.337\n",
      "15.339\n",
      "15.341\n",
      "15.342\n",
      "15.345\n",
      "15.347\n",
      "15.348\n",
      "15.353\n",
      "15.356\n",
      "15.367\n",
      "15.377\n",
      "15.380\n",
      "15.389\n",
      "15.425\n",
      "15.430\n",
      "15.431\n",
      "15.438\n",
      "15.439\n",
      "15.440\n",
      "15.442\n",
      "15.444\n",
      "15.447\n",
      "15.450\n",
      "15.456\n",
      "15.457\n",
      "15.472\n",
      "15.473\n",
      "15.475\n",
      "15.487\n",
      "15.489\n",
      "15.495\n",
      "15.496\n",
      "15.503\n",
      "15.507\n",
      "15.515\n",
      "15.522\n",
      "15.523\n",
      "15.525\n",
      "15.530\n",
      "15.531\n",
      "15.532\n",
      "15.542\n",
      "15.544\n",
      "15.555\n",
      "15.562\n",
      "15.565\n",
      "15.582\n",
      "15.584\n",
      "15.593\n",
      "15.594\n",
      "15.602\n",
      "15.605\n",
      "15.608\n",
      "15.610\n",
      "15.612\n",
      "15.613\n",
      "15.615\n",
      "15.617\n",
      "15.622\n",
      "15.642\n",
      "15.643\n",
      "15.650\n",
      "15.651\n",
      "15.657\n",
      "15.670\n",
      "15.686\n",
      "15.694\n",
      "15.695\n",
      "15.698\n",
      "15.699\n",
      "15.702\n",
      "15.708\n",
      "15.709\n",
      "15.713\n",
      "15.714\n",
      "15.716\n",
      "15.722\n",
      "15.726\n",
      "15.727\n",
      "15.729\n",
      "15.738\n",
      "15.740\n",
      "15.747\n",
      "15.748\n",
      "15.757\n",
      "15.758\n",
      "15.767\n",
      "15.769\n",
      "15.775\n",
      "15.776\n",
      "15.778\n",
      "15.782\n",
      "15.783\n",
      "15.784\n",
      "15.786\n",
      "15.788\n",
      "15.794\n",
      "15.796\n",
      "15.798\n",
      "15.799\n",
      "15.801\n",
      "15.804\n",
      "15.808\n",
      "15.819\n",
      "15.826\n",
      "15.829\n",
      "15.837\n",
      "15.838\n",
      "15.842\n",
      "15.845\n",
      "15.850\n",
      "15.854\n",
      "15.860\n",
      "15.865\n",
      "15.866\n",
      "15.867\n",
      "15.869\n",
      "15.871\n",
      "15.878\n",
      "15.887\n",
      "15.891\n",
      "15.892\n",
      "15.894\n",
      "15.895\n",
      "15.896\n",
      "15.902\n",
      "15.908\n",
      "15.915\n",
      "15.917\n",
      "15.931\n",
      "15.935\n",
      "15.938\n",
      "15.939\n",
      "15.940\n",
      "15.941\n",
      "15.942\n",
      "15.947\n",
      "15.948\n",
      "15.950\n",
      "15.952\n",
      "15.957\n",
      "15.959\n",
      "15.962\n",
      "15.963\n",
      "15.975\n",
      "15.980\n",
      "15.981\n",
      "15.982\n",
      "15.986\n",
      "15.988\n",
      "15.990\n",
      "15.992\n",
      "15.1000\n",
      "15.1001\n",
      "15.1003\n",
      "15.1010\n",
      "15.1014\n",
      "15.1015\n",
      "15.1016\n",
      "15.1017\n",
      "15.1018\n",
      "15.1022\n",
      "15.1023\n",
      "15.1026\n",
      "15.1027\n",
      "15.1028\n",
      "15.1040\n",
      "15.1041\n",
      "15.1052\n",
      "15.1058\n",
      "15.1060\n",
      "15.1065\n",
      "15.1067\n",
      "15.1074\n",
      "15.1075\n",
      "15.1078\n",
      "15.1079\n",
      "15.1083\n",
      "15.1084\n",
      "15.1092\n",
      "15.1096\n",
      "15.1099\n",
      "15.1100\n",
      "15.1103\n",
      "15.1106\n",
      "15.1110\n",
      "15.1113\n",
      "15.1123\n",
      "15.1138\n",
      "15.1149\n",
      "15.1160\n",
      "15.1161\n",
      "15.1162\n",
      "15.1168\n",
      "15.1176\n",
      "15.1181\n",
      "15.1182\n",
      "15.1183\n",
      "15.1189\n",
      "15.1192\n",
      "15.1201\n",
      "15.1202\n",
      "15.1203\n",
      "15.1205\n",
      "15.1209\n",
      "15.1211\n",
      "15.1212\n",
      "15.1223\n",
      "15.1224\n",
      "15.1225\n",
      "15.1227\n",
      "15.1228\n",
      "15.1231\n",
      "15.1241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.1248\n",
      "15.1250\n",
      "15.1251\n",
      "15.1265\n",
      "15.1276\n",
      "15.1278\n",
      "15.1284\n",
      "15.1287\n",
      "15.1291\n",
      "15.1292\n",
      "15.1293\n",
      "15.1297\n",
      "15.1299\n",
      "15.1304\n",
      "15.1310\n",
      "15.1313\n",
      "15.1314\n",
      "15.1322\n",
      "15.1328\n",
      "15.1331\n",
      "15.1333\n",
      "15.1335\n",
      "15.1339\n",
      "15.1346\n",
      "15.1347\n",
      "15.1348\n",
      "15.1351\n",
      "15.1352\n",
      "15.1360\n",
      "15.1378\n",
      "15.1387\n",
      "15.1391\n",
      "15.1393\n",
      "15.1396\n",
      "15.1405\n",
      "15.1411\n",
      "15.1413\n",
      "15.1414\n",
      "15.1421\n",
      "15.1422\n",
      "15.1426\n",
      "15.1433\n",
      "15.1438\n",
      "15.1446\n",
      "15.1447\n",
      "15.1452\n",
      "15.1454\n",
      "15.1457\n",
      "15.1463\n",
      "15.1464\n",
      "15.1471\n",
      "15.1472\n",
      "15.1474\n",
      "15.1478\n",
      "15.1494\n",
      "15.1503\n",
      "15.1508\n",
      "15.1512\n",
      "15.1513\n",
      "15.1514\n",
      "15.1517\n",
      "15.1522\n",
      "15.1528\n",
      "15.1529\n",
      "15.1540\n",
      "15.1545\n",
      "15.1548\n",
      "15.1557\n",
      "15.1558\n",
      "15.1561\n",
      "15.1568\n",
      "15.1570\n",
      "15.1571\n",
      "15.1575\n",
      "15.1579\n",
      "15.1580\n",
      "15.1587\n",
      "15.1598\n",
      "15.1601\n",
      "15.1605\n",
      "15.1607\n",
      "15.1610\n",
      "15.1621\n",
      "15.1625\n",
      "15.1626\n",
      "15.1628\n",
      "15.1631\n",
      "15.1637\n",
      "15.1639\n",
      "15.1649\n",
      "15.1653\n",
      "15.1659\n",
      "15.1670\n",
      "15.1673\n",
      "15.1682\n",
      "15.1684\n",
      "15.1687\n",
      "15.1691\n",
      "15.1696\n",
      "15.1697\n",
      "15.1700\n",
      "15.1704\n",
      "15.1705\n",
      "15.1706\n",
      "15.1708\n",
      "15.1711\n",
      "15.1713\n",
      "15.1718\n",
      "15.1720\n",
      "15.1724\n",
      "15.1725\n",
      "15.1726\n",
      "15.1731\n",
      "15.1738\n",
      "15.1742\n",
      "15.1745\n",
      "15.1750\n",
      "15.1753\n",
      "15.1760\n",
      "15.1773\n",
      "15.1778\n",
      "15.1782\n",
      "15.1802\n",
      "15.1803\n",
      "15.1812\n",
      "15.1820\n",
      "15.1821\n",
      "15.1829\n",
      "15.1830\n",
      "15.1837\n",
      "15.1839\n",
      "15.1842\n",
      "15.1846\n",
      "15.1854\n",
      "15.1857\n",
      "15.1862\n",
      "15.1864\n",
      "15.1865\n",
      "15.1873\n",
      "15.1874\n",
      "15.1879\n",
      "15.1883\n",
      "15.1885\n",
      "15.1887\n",
      "15.1893\n",
      "15.1896\n",
      "15.1900\n",
      "15.1903\n",
      "15.1908\n",
      "15.1909\n",
      "15.1917\n",
      "15.1920\n",
      "15.1924\n",
      "15.1939\n",
      "15.1940\n",
      "15.1943\n",
      "15.1949\n",
      "15.1958\n",
      "15.1961\n",
      "15.1970\n",
      "15.1984\n",
      "15.1988\n",
      "15.1991\n",
      "15.1994\n",
      "15.1995\n",
      "15.2003\n",
      "15.2004\n",
      "15.2005\n",
      "15.2006\n",
      "15.2007\n",
      "15.2011\n",
      "15.2012\n",
      "15.2016\n",
      "15.2033\n",
      "15.2045\n",
      "16\n",
      "16.1\n",
      "16.4\n",
      "16.17\n",
      "16.25\n",
      "16.28\n",
      "16.31\n",
      "16.46\n",
      "16.54\n",
      "16.64\n",
      "16.72\n",
      "16.77\n",
      "16.78\n",
      "16.80\n",
      "16.97\n",
      "16.100\n",
      "16.103\n",
      "16.109\n",
      "16.111\n",
      "16.115\n",
      "16.118\n",
      "16.126\n",
      "16.129\n",
      "16.130\n",
      "16.135\n",
      "16.136\n",
      "16.142\n",
      "16.145\n",
      "16.148\n",
      "16.149\n",
      "16.153\n",
      "16.157\n",
      "16.159\n",
      "16.165\n",
      "16.178\n",
      "16.183\n",
      "16.186\n",
      "16.195\n",
      "16.196\n",
      "16.212\n",
      "16.218\n",
      "16.222\n",
      "16.227\n",
      "16.232\n",
      "16.248\n",
      "16.250\n",
      "16.263\n",
      "16.273\n",
      "16.278\n",
      "16.282\n",
      "16.283\n",
      "16.286\n",
      "16.287\n",
      "16.294\n",
      "16.295\n",
      "16.322\n",
      "16.324\n",
      "16.329\n",
      "16.333\n",
      "16.335\n",
      "16.348\n",
      "16.356\n",
      "16.361\n",
      "16.367\n",
      "16.369\n",
      "16.377\n",
      "16.384\n",
      "16.385\n",
      "16.395\n",
      "16.405\n",
      "16.408\n",
      "16.413\n",
      "16.418\n",
      "16.446\n",
      "16.448\n",
      "16.452\n",
      "16.454\n",
      "16.459\n",
      "16.468\n",
      "16.474\n",
      "16.491\n",
      "16.499\n",
      "16.511\n",
      "16.513\n",
      "16.516\n",
      "16.522\n",
      "16.524\n",
      "16.531\n",
      "16.534\n",
      "16.537\n",
      "16.554\n",
      "16.559\n",
      "16.561\n",
      "16.577\n",
      "16.580\n",
      "16.581\n",
      "16.588\n",
      "16.596\n",
      "16.600\n",
      "16.602\n",
      "16.604\n",
      "16.605\n",
      "16.608\n",
      "16.611\n",
      "16.620\n",
      "16.621\n",
      "16.623\n",
      "16.624\n",
      "16.628\n",
      "16.630\n",
      "16.633\n",
      "16.637\n",
      "16.638\n",
      "16.648\n",
      "16.655\n",
      "16.659\n",
      "16.661\n",
      "16.667\n",
      "16.669\n",
      "16.682\n",
      "16.687\n",
      "16.688\n",
      "16.691\n",
      "16.696\n",
      "16.699\n",
      "16.702\n",
      "16.705\n",
      "16.711\n",
      "16.714\n",
      "16.716\n",
      "16.721\n",
      "16.726\n",
      "16.727\n",
      "16.728\n",
      "16.729\n",
      "16.734\n",
      "16.735\n",
      "16.746\n",
      "16.758\n",
      "16.759\n",
      "16.762\n",
      "16.769\n",
      "16.773\n",
      "16.777\n",
      "16.779\n",
      "16.782\n",
      "16.789\n",
      "16.798\n",
      "16.802\n",
      "16.804\n",
      "16.805\n",
      "16.810\n",
      "16.814\n",
      "16.817\n",
      "16.819\n",
      "16.820\n",
      "16.831\n",
      "16.832\n",
      "16.843\n",
      "16.855\n",
      "16.857\n",
      "16.858\n",
      "16.860\n",
      "16.863\n",
      "16.869\n",
      "16.877\n",
      "16.879\n",
      "16.881\n",
      "16.895\n",
      "16.901\n",
      "16.909\n",
      "16.910\n",
      "16.924\n",
      "16.929\n",
      "16.930\n",
      "16.940\n",
      "16.946\n",
      "16.947\n",
      "16.948\n",
      "16.958\n",
      "16.965\n",
      "16.971\n",
      "16.976\n",
      "16.985\n",
      "16.990\n",
      "16.995\n",
      "16.1006\n",
      "16.1010\n",
      "16.1011\n",
      "16.1014\n",
      "16.1022\n",
      "16.1023\n",
      "16.1029\n",
      "16.1031\n",
      "16.1035\n",
      "16.1046\n",
      "16.1056\n",
      "16.1067\n",
      "16.1070\n",
      "16.1074\n",
      "16.1076\n",
      "16.1081\n",
      "16.1085\n",
      "16.1086\n",
      "16.1089\n",
      "16.1097\n",
      "16.1099\n",
      "16.1109\n",
      "16.1110\n",
      "16.1111\n",
      "16.1112\n",
      "16.1124\n",
      "16.1136\n",
      "16.1146\n",
      "16.1151\n",
      "16.1156\n",
      "16.1163\n",
      "16.1185\n",
      "16.1194\n",
      "16.1219\n",
      "16.1220\n",
      "16.1223\n",
      "16.1232\n",
      "16.1236\n",
      "16.1246\n",
      "16.1251\n",
      "16.1254\n",
      "16.1261\n",
      "16.1269\n",
      "16.1272\n",
      "16.1274\n",
      "16.1286\n",
      "16.1292\n",
      "16.1300\n",
      "16.1302\n",
      "16.1303\n",
      "16.1306\n",
      "16.1308\n",
      "16.1324\n",
      "16.1328\n",
      "16.1332\n",
      "16.1342\n",
      "16.1350\n",
      "16.1360\n",
      "16.1361\n",
      "16.1362\n",
      "16.1379\n",
      "16.1383\n",
      "16.1388\n",
      "16.1391\n",
      "16.1395\n",
      "16.1399\n",
      "16.1401\n",
      "16.1404\n",
      "16.1407\n",
      "16.1411\n",
      "16.1419\n",
      "16.1425\n",
      "16.1431\n",
      "16.1442\n",
      "16.1443\n",
      "16.1447\n",
      "16.1449\n",
      "16.1450\n",
      "16.1452\n",
      "16.1456\n",
      "16.1462\n",
      "16.1464\n",
      "16.1466\n",
      "16.1467\n",
      "16.1474\n",
      "16.1479\n",
      "16.1483\n",
      "16.1489\n",
      "16.1495\n",
      "16.1501\n",
      "16.1502\n",
      "16.1508\n",
      "16.1511\n",
      "16.1513\n",
      "16.1521\n",
      "16.1523\n",
      "16.1527\n",
      "16.1536\n",
      "16.1538\n",
      "16.1539\n",
      "16.1541\n",
      "16.1544\n",
      "16.1546\n",
      "16.1554\n",
      "16.1564\n",
      "16.1576\n",
      "16.1581\n",
      "16.1585\n",
      "16.1590\n",
      "16.1606\n",
      "16.1609\n",
      "16.1612\n",
      "16.1614\n",
      "16.1620\n",
      "16.1621\n",
      "16.1622\n",
      "16.1641\n",
      "16.1643\n",
      "16.1647\n",
      "16.1649\n",
      "16.1650\n",
      "16.1654\n",
      "16.1663\n",
      "16.1664\n",
      "16.1674\n",
      "16.1677\n",
      "16.1683\n",
      "16.1690\n",
      "16.1691\n",
      "16.1692\n",
      "16.1697\n",
      "16.1701\n",
      "16.1705\n",
      "16.1707\n",
      "16.1708\n",
      "16.1709\n",
      "16.1715\n",
      "16.1727\n",
      "16.1728\n",
      "16.1740\n",
      "16.1743\n",
      "16.1749\n",
      "16.1758\n",
      "16.1759\n",
      "16.1772\n",
      "16.1774\n",
      "16.1788\n",
      "16.1800\n",
      "16.1802\n",
      "16.1809\n",
      "16.1815\n",
      "16.1818\n",
      "16.1824\n",
      "16.1830\n",
      "16.1845\n",
      "16.1852\n",
      "16.1856\n",
      "16.1859\n",
      "16.1863\n",
      "16.1868\n",
      "16.1883\n",
      "16.1891\n",
      "16.1894\n",
      "16.1895\n",
      "16.1901\n",
      "16.1902\n",
      "16.1912\n",
      "16.1913\n",
      "16.1922\n",
      "16.1925\n",
      "16.1936\n",
      "16.1937\n",
      "16.1938\n",
      "16.1942\n",
      "16.1943\n",
      "16.1946\n",
      "16.1959\n",
      "16.1972\n",
      "16.1978\n",
      "16.1979\n",
      "16.1987\n",
      "16.1988\n",
      "16.1994\n",
      "16.1996\n",
      "16.1997\n",
      "16.2002\n",
      "16.2006\n",
      "16.2011\n",
      "16.2014\n",
      "16.2015\n",
      "16.2026\n",
      "16.2034\n",
      "16.2036\n",
      "17\n",
      "17.3\n",
      "17.4\n",
      "17.7\n",
      "17.9\n",
      "17.10\n",
      "17.13\n",
      "17.15\n",
      "17.18\n",
      "17.19\n",
      "17.21\n",
      "17.28\n",
      "17.29\n",
      "17.44\n",
      "17.48\n",
      "17.52\n",
      "17.55\n",
      "17.56\n",
      "17.63\n",
      "17.67\n",
      "17.71\n",
      "17.77\n",
      "17.79\n",
      "17.80\n",
      "17.89\n",
      "17.90\n",
      "17.91\n",
      "17.96\n",
      "17.103\n",
      "17.104\n",
      "17.105\n",
      "17.106\n",
      "17.118\n",
      "17.124\n",
      "17.129\n",
      "17.140\n",
      "17.146\n",
      "17.147\n",
      "17.152\n",
      "17.155\n",
      "17.156\n",
      "17.158\n",
      "17.160\n",
      "17.168\n",
      "17.181\n",
      "17.183\n",
      "17.184\n",
      "17.195\n",
      "17.196\n",
      "17.202\n",
      "17.204\n",
      "17.208\n",
      "17.211\n",
      "17.212\n",
      "17.214\n",
      "17.215\n",
      "17.217\n",
      "17.219\n",
      "17.222\n",
      "17.225\n",
      "17.227\n",
      "17.229\n",
      "17.236\n",
      "17.238\n",
      "17.244\n",
      "17.246\n",
      "17.257\n",
      "17.267\n",
      "17.269\n",
      "17.270\n",
      "17.272\n",
      "17.273\n",
      "17.274\n",
      "17.279\n",
      "17.281\n",
      "17.295\n",
      "17.300\n",
      "17.306\n",
      "17.310\n",
      "17.329\n",
      "17.345\n",
      "17.348\n",
      "17.349\n",
      "17.354\n",
      "17.355\n",
      "17.357\n",
      "17.365\n",
      "17.366\n",
      "17.368\n",
      "17.372\n",
      "17.379\n",
      "17.381\n",
      "17.395\n",
      "17.404\n",
      "17.413\n",
      "17.415\n",
      "17.417\n",
      "17.424\n",
      "17.425\n",
      "17.429\n",
      "17.431\n",
      "17.433\n",
      "17.443\n",
      "17.446\n",
      "17.459\n",
      "17.460\n",
      "17.464\n",
      "17.474\n",
      "17.481\n",
      "17.484\n",
      "17.485\n",
      "17.488\n",
      "17.489\n",
      "17.492\n",
      "17.493\n",
      "17.497\n",
      "17.508\n",
      "17.512\n",
      "17.513\n",
      "17.518\n",
      "17.528\n",
      "17.533\n",
      "17.541\n",
      "17.550\n",
      "17.551\n",
      "17.574\n",
      "17.579\n",
      "17.580\n",
      "17.582\n",
      "17.588\n",
      "17.591\n",
      "17.592\n",
      "17.593\n",
      "17.595\n",
      "17.597\n",
      "17.602\n",
      "17.606\n",
      "17.615\n",
      "17.616\n",
      "17.623\n",
      "17.630\n",
      "17.633\n",
      "17.635\n",
      "17.641\n",
      "17.645\n",
      "17.646\n",
      "17.653\n",
      "17.657\n",
      "17.663\n",
      "17.665\n",
      "17.673\n",
      "17.683\n",
      "17.687\n",
      "17.690\n",
      "17.694\n",
      "17.701\n",
      "17.706\n",
      "17.714\n",
      "17.715\n",
      "17.718\n",
      "17.723\n",
      "17.728\n",
      "17.733\n",
      "17.734\n",
      "17.750\n",
      "17.755\n",
      "17.762\n",
      "17.771\n",
      "17.777\n",
      "17.781\n",
      "17.783\n",
      "17.786\n",
      "17.788\n",
      "17.792\n",
      "17.796\n",
      "17.808\n",
      "17.811\n",
      "17.817\n",
      "17.819\n",
      "17.821\n",
      "17.822\n",
      "17.830\n",
      "17.832\n",
      "17.834\n",
      "17.850\n",
      "17.852\n",
      "17.858\n",
      "17.863\n",
      "17.865\n",
      "17.881\n",
      "17.886\n",
      "17.888\n",
      "17.889\n",
      "17.895\n",
      "17.900\n",
      "17.907\n",
      "17.912\n",
      "17.915\n",
      "17.926\n",
      "17.930\n",
      "17.942\n",
      "17.955\n",
      "17.957\n",
      "17.958\n",
      "17.963\n",
      "17.968\n",
      "17.975\n",
      "17.985\n",
      "17.989\n",
      "17.992\n",
      "17.993\n",
      "17.998\n",
      "17.1005\n",
      "17.1006\n",
      "17.1007\n",
      "17.1011\n",
      "17.1013\n",
      "17.1017\n",
      "17.1029\n",
      "17.1031\n",
      "17.1032\n",
      "17.1037\n",
      "17.1041\n",
      "17.1046\n",
      "17.1054\n",
      "17.1056\n",
      "17.1059\n",
      "17.1062\n",
      "17.1063\n",
      "17.1065\n",
      "17.1066\n",
      "17.1069\n",
      "17.1070\n",
      "17.1072\n",
      "17.1080\n",
      "17.1081\n",
      "17.1090\n",
      "17.1093\n",
      "17.1095\n",
      "17.1097\n",
      "17.1099\n",
      "17.1100\n",
      "17.1101\n",
      "17.1105\n",
      "17.1109\n",
      "17.1111\n",
      "17.1112\n",
      "17.1115\n",
      "17.1117\n",
      "17.1126\n",
      "17.1128\n",
      "17.1130\n",
      "17.1131\n",
      "17.1132\n",
      "17.1134\n",
      "17.1135\n",
      "17.1149\n",
      "17.1152\n",
      "17.1156\n",
      "17.1159\n",
      "17.1163\n",
      "17.1167\n",
      "17.1169\n",
      "17.1171\n",
      "17.1172\n",
      "17.1173\n",
      "17.1182\n",
      "17.1187\n",
      "17.1188\n",
      "17.1192\n",
      "17.1202\n",
      "17.1204\n",
      "17.1209\n",
      "17.1217\n",
      "17.1223\n",
      "17.1227\n",
      "17.1239\n",
      "17.1242\n",
      "17.1243\n",
      "17.1244\n",
      "17.1258\n",
      "17.1260\n",
      "17.1263\n",
      "17.1265\n",
      "17.1267\n",
      "17.1268\n",
      "17.1277\n",
      "17.1278\n",
      "17.1282\n",
      "17.1297\n",
      "17.1302\n",
      "17.1305\n",
      "17.1314\n",
      "17.1320\n",
      "17.1323\n",
      "17.1328\n",
      "17.1333\n",
      "17.1336\n",
      "17.1343\n",
      "17.1344\n",
      "17.1346\n",
      "17.1347\n",
      "17.1356\n",
      "17.1364\n",
      "17.1365\n",
      "17.1379\n",
      "17.1380\n",
      "17.1381\n",
      "17.1383\n",
      "17.1388\n",
      "17.1392\n",
      "17.1400\n",
      "17.1401\n",
      "17.1403\n",
      "17.1404\n",
      "17.1406\n",
      "17.1408\n",
      "17.1418\n",
      "17.1419\n",
      "17.1421\n",
      "17.1422\n",
      "17.1435\n",
      "17.1437\n",
      "17.1439\n",
      "17.1441\n",
      "17.1442\n",
      "17.1452\n",
      "17.1456\n",
      "17.1457\n",
      "17.1466\n",
      "17.1470\n",
      "17.1474\n",
      "17.1490\n",
      "17.1494\n",
      "17.1504\n",
      "17.1513\n",
      "17.1521\n",
      "17.1532\n",
      "17.1533\n",
      "17.1541\n",
      "17.1543\n",
      "17.1546\n",
      "17.1566\n",
      "17.1568\n",
      "17.1569\n",
      "17.1573\n",
      "17.1574\n",
      "17.1576\n",
      "17.1578\n",
      "17.1582\n",
      "17.1583\n",
      "17.1586\n",
      "17.1596\n",
      "17.1601\n",
      "17.1609\n",
      "17.1615\n",
      "17.1617\n",
      "17.1618\n",
      "17.1623\n",
      "17.1627\n",
      "17.1631\n",
      "17.1637\n",
      "17.1652\n",
      "17.1653\n",
      "17.1655\n",
      "17.1660\n",
      "17.1665\n",
      "17.1666\n",
      "17.1670\n",
      "17.1673\n",
      "17.1675\n",
      "17.1676\n",
      "17.1682\n",
      "17.1686\n",
      "17.1691\n",
      "17.1693\n",
      "17.1699\n",
      "17.1700\n",
      "17.1702\n",
      "17.1705\n",
      "17.1706\n",
      "17.1711\n",
      "17.1713\n",
      "17.1718\n",
      "17.1719\n",
      "17.1721\n",
      "17.1723\n",
      "17.1731\n",
      "17.1732\n",
      "17.1734\n",
      "17.1736\n",
      "17.1749\n",
      "17.1752\n",
      "17.1756\n",
      "17.1758\n",
      "17.1760\n",
      "17.1769\n",
      "17.1779\n",
      "17.1781\n",
      "17.1789\n",
      "17.1794\n",
      "17.1796\n",
      "17.1798\n",
      "17.1799\n",
      "17.1800\n",
      "17.1812\n",
      "17.1818\n",
      "17.1819\n",
      "17.1828\n",
      "17.1829\n",
      "17.1832\n",
      "17.1835\n",
      "17.1836\n",
      "17.1853\n",
      "17.1861\n",
      "17.1865\n",
      "17.1867\n",
      "17.1869\n",
      "17.1874\n",
      "17.1879\n",
      "17.1883\n",
      "17.1886\n",
      "17.1891\n",
      "17.1905\n",
      "17.1908\n",
      "17.1909\n",
      "17.1920\n",
      "17.1923\n",
      "17.1926\n",
      "17.1935\n",
      "17.1938\n",
      "17.1947\n",
      "17.1948\n",
      "17.1956\n",
      "17.1965\n",
      "17.1966\n",
      "17.1971\n",
      "17.1973\n",
      "17.1974\n",
      "17.1975\n",
      "17.1980\n",
      "17.1984\n",
      "17.1992\n",
      "17.1995\n",
      "17.1997\n",
      "17.1998\n",
      "17.1999\n",
      "17.2000\n",
      "17.2003\n",
      "17.2005\n",
      "17.2009\n",
      "17.2013\n",
      "17.2016\n",
      "17.2018\n",
      "17.2027\n",
      "17.2029\n",
      "17.2034\n",
      "17.2037\n",
      "17.2040\n",
      "18\n",
      "18.3\n",
      "18.5\n",
      "18.6\n",
      "18.23\n",
      "18.31\n",
      "18.32\n",
      "18.37\n",
      "18.41\n",
      "18.45\n",
      "18.47\n",
      "18.48\n",
      "18.56\n",
      "18.59\n",
      "18.63\n",
      "18.69\n",
      "18.71\n",
      "18.76\n",
      "18.77\n",
      "18.79\n",
      "18.81\n",
      "18.83\n",
      "18.95\n",
      "18.96\n",
      "18.98\n",
      "18.106\n",
      "18.109\n",
      "18.111\n",
      "18.112\n",
      "18.116\n",
      "18.117\n",
      "18.118\n",
      "18.126\n",
      "18.143\n",
      "18.147\n",
      "18.149\n",
      "18.150\n",
      "18.151\n",
      "18.157\n",
      "18.158\n",
      "18.168\n",
      "18.169\n",
      "18.171\n",
      "18.173\n",
      "18.182\n",
      "18.184\n",
      "18.187\n",
      "18.193\n",
      "18.200\n",
      "18.207\n",
      "18.211\n",
      "18.213\n",
      "18.223\n",
      "18.224\n",
      "18.229\n",
      "18.231\n",
      "18.233\n",
      "18.235\n",
      "18.236\n",
      "18.238\n",
      "18.239\n",
      "18.242\n",
      "18.243\n",
      "18.244\n",
      "18.246\n",
      "18.247\n",
      "18.251\n",
      "18.258\n",
      "18.265\n",
      "18.269\n",
      "18.271\n",
      "18.272\n",
      "18.273\n",
      "18.274\n",
      "18.275\n",
      "18.277\n",
      "18.286\n",
      "18.292\n",
      "18.294\n",
      "18.299\n",
      "18.300\n",
      "18.301\n",
      "18.302\n",
      "18.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.311\n",
      "18.315\n",
      "18.322\n",
      "18.325\n",
      "18.326\n",
      "18.327\n",
      "18.330\n",
      "18.332\n",
      "18.339\n",
      "18.342\n",
      "18.343\n",
      "18.352\n",
      "18.361\n",
      "18.363\n",
      "18.367\n",
      "18.368\n",
      "18.373\n",
      "18.375\n",
      "18.384\n",
      "18.386\n",
      "18.388\n",
      "18.395\n",
      "18.400\n",
      "18.402\n",
      "18.403\n",
      "18.409\n",
      "18.411\n",
      "18.414\n",
      "18.415\n",
      "18.418\n",
      "18.421\n",
      "18.426\n",
      "18.427\n",
      "18.436\n",
      "18.444\n",
      "18.445\n",
      "18.458\n",
      "18.459\n",
      "18.460\n",
      "18.463\n",
      "18.470\n",
      "18.473\n",
      "18.474\n",
      "18.482\n",
      "18.489\n",
      "18.491\n",
      "18.492\n",
      "18.496\n",
      "18.502\n",
      "18.505\n",
      "18.518\n",
      "18.521\n",
      "18.522\n",
      "18.524\n",
      "18.525\n",
      "18.527\n",
      "18.530\n",
      "18.533\n",
      "18.535\n",
      "18.542\n",
      "18.556\n",
      "18.557\n",
      "18.558\n",
      "18.567\n",
      "18.583\n",
      "18.584\n",
      "18.587\n",
      "18.588\n",
      "18.590\n",
      "18.595\n",
      "18.596\n",
      "18.603\n",
      "18.612\n",
      "18.615\n",
      "18.618\n",
      "18.620\n",
      "18.624\n",
      "18.626\n",
      "18.632\n",
      "18.634\n",
      "18.648\n",
      "18.655\n",
      "18.657\n",
      "18.664\n",
      "18.666\n",
      "18.669\n",
      "18.670\n",
      "18.671\n",
      "18.673\n",
      "18.675\n",
      "18.681\n",
      "18.682\n",
      "18.684\n",
      "18.691\n",
      "18.693\n",
      "18.694\n",
      "18.696\n",
      "18.708\n",
      "18.713\n",
      "18.714\n",
      "18.716\n",
      "18.724\n",
      "18.725\n",
      "18.726\n",
      "18.732\n",
      "18.740\n",
      "18.743\n",
      "18.746\n",
      "18.747\n",
      "18.754\n",
      "18.756\n",
      "18.758\n",
      "18.761\n",
      "18.764\n",
      "18.770\n",
      "18.778\n",
      "18.779\n",
      "18.781\n",
      "18.789\n",
      "18.792\n",
      "18.794\n",
      "18.795\n",
      "18.796\n",
      "18.799\n",
      "18.804\n",
      "18.805\n",
      "18.807\n",
      "18.809\n",
      "18.811\n",
      "18.816\n",
      "18.822\n",
      "18.831\n",
      "18.832\n",
      "18.833\n",
      "18.839\n",
      "18.841\n",
      "18.846\n",
      "18.850\n",
      "18.852\n",
      "18.854\n",
      "18.858\n",
      "18.864\n",
      "18.866\n",
      "18.869\n",
      "18.870\n",
      "18.875\n",
      "18.884\n",
      "18.887\n",
      "18.894\n",
      "18.901\n",
      "18.903\n",
      "18.906\n",
      "18.907\n",
      "18.911\n",
      "18.916\n",
      "18.922\n",
      "18.932\n",
      "18.934\n",
      "18.936\n",
      "18.940\n",
      "18.944\n",
      "18.947\n",
      "18.950\n",
      "18.951\n",
      "18.953\n",
      "18.955\n",
      "18.958\n",
      "18.959\n",
      "18.962\n",
      "18.967\n",
      "18.974\n",
      "18.977\n",
      "18.981\n",
      "18.988\n",
      "18.990\n",
      "18.991\n",
      "18.993\n",
      "18.1001\n",
      "18.1011\n",
      "18.1014\n",
      "18.1016\n",
      "18.1019\n",
      "18.1026\n",
      "18.1027\n",
      "18.1038\n",
      "18.1042\n",
      "18.1044\n",
      "18.1047\n",
      "18.1057\n",
      "18.1068\n",
      "18.1071\n",
      "18.1074\n",
      "18.1083\n",
      "18.1086\n",
      "18.1091\n",
      "18.1093\n",
      "18.1098\n",
      "18.1100\n",
      "18.1106\n",
      "18.1117\n",
      "18.1121\n",
      "18.1126\n",
      "18.1136\n",
      "18.1139\n",
      "18.1145\n",
      "18.1146\n",
      "18.1148\n",
      "18.1152\n",
      "18.1159\n",
      "18.1176\n",
      "18.1184\n",
      "18.1202\n",
      "18.1209\n",
      "18.1213\n",
      "18.1218\n",
      "18.1220\n",
      "18.1226\n",
      "18.1230\n",
      "18.1238\n",
      "18.1242\n",
      "18.1243\n",
      "18.1247\n",
      "18.1258\n",
      "18.1262\n",
      "18.1265\n",
      "18.1269\n",
      "18.1278\n",
      "18.1282\n",
      "18.1283\n",
      "18.1284\n",
      "18.1285\n",
      "18.1292\n",
      "18.1295\n",
      "18.1296\n",
      "18.1303\n",
      "18.1315\n",
      "18.1316\n",
      "18.1320\n",
      "18.1324\n",
      "18.1326\n",
      "18.1330\n",
      "18.1339\n",
      "18.1349\n",
      "18.1350\n",
      "18.1355\n",
      "18.1356\n",
      "18.1357\n",
      "18.1360\n",
      "18.1363\n",
      "18.1366\n",
      "18.1368\n",
      "18.1373\n",
      "18.1374\n",
      "18.1376\n",
      "18.1377\n",
      "18.1379\n",
      "18.1388\n",
      "18.1398\n",
      "18.1400\n",
      "18.1401\n",
      "18.1402\n",
      "18.1405\n",
      "18.1407\n",
      "18.1416\n",
      "18.1417\n",
      "18.1421\n",
      "18.1423\n",
      "18.1426\n",
      "18.1429\n",
      "18.1433\n",
      "18.1437\n",
      "18.1446\n",
      "18.1450\n",
      "18.1460\n",
      "18.1461\n",
      "18.1468\n",
      "18.1475\n",
      "18.1481\n",
      "18.1483\n",
      "18.1489\n",
      "18.1490\n",
      "18.1491\n",
      "18.1494\n",
      "18.1500\n",
      "18.1505\n",
      "18.1506\n",
      "18.1515\n",
      "18.1516\n",
      "18.1517\n",
      "18.1519\n",
      "18.1520\n",
      "18.1534\n",
      "18.1539\n",
      "18.1550\n",
      "18.1554\n",
      "18.1561\n",
      "18.1565\n",
      "18.1568\n",
      "18.1572\n",
      "18.1573\n",
      "18.1576\n",
      "18.1579\n",
      "18.1581\n",
      "18.1582\n",
      "18.1590\n",
      "18.1593\n",
      "18.1594\n",
      "18.1598\n",
      "18.1602\n",
      "18.1604\n",
      "18.1608\n",
      "18.1609\n",
      "18.1612\n",
      "18.1614\n",
      "18.1615\n",
      "18.1616\n",
      "18.1618\n",
      "18.1619\n",
      "18.1621\n",
      "18.1623\n",
      "18.1625\n",
      "18.1628\n",
      "18.1634\n",
      "18.1639\n",
      "18.1643\n",
      "18.1646\n",
      "18.1653\n",
      "18.1655\n",
      "18.1656\n",
      "18.1662\n",
      "18.1663\n",
      "18.1665\n",
      "18.1668\n",
      "18.1670\n",
      "18.1677\n",
      "18.1679\n",
      "18.1680\n",
      "18.1681\n",
      "18.1687\n",
      "18.1696\n",
      "18.1698\n",
      "18.1700\n",
      "18.1702\n",
      "18.1717\n",
      "18.1729\n",
      "18.1738\n",
      "18.1741\n",
      "18.1743\n",
      "18.1748\n",
      "18.1750\n",
      "18.1751\n",
      "18.1754\n",
      "18.1755\n",
      "18.1759\n",
      "18.1766\n",
      "18.1767\n",
      "18.1772\n",
      "18.1773\n",
      "18.1774\n",
      "18.1776\n",
      "18.1777\n",
      "18.1790\n",
      "18.1795\n",
      "18.1798\n",
      "18.1804\n",
      "18.1807\n",
      "18.1815\n",
      "18.1817\n",
      "18.1823\n",
      "18.1826\n",
      "18.1828\n",
      "18.1829\n",
      "18.1836\n",
      "18.1840\n",
      "18.1843\n",
      "18.1852\n",
      "18.1857\n",
      "18.1858\n",
      "18.1865\n",
      "18.1867\n",
      "18.1868\n",
      "18.1873\n",
      "18.1875\n",
      "18.1878\n",
      "18.1879\n",
      "18.1890\n",
      "18.1898\n",
      "18.1903\n",
      "18.1904\n",
      "18.1907\n",
      "18.1910\n",
      "18.1921\n",
      "18.1927\n",
      "18.1936\n",
      "18.1941\n",
      "18.1943\n",
      "18.1960\n",
      "18.1969\n",
      "18.1974\n",
      "18.1975\n",
      "18.1980\n",
      "18.1982\n",
      "18.1991\n",
      "18.1999\n",
      "18.2004\n",
      "18.2013\n",
      "18.2017\n",
      "18.2021\n",
      "18.2024\n",
      "18.2026\n",
      "18.2030\n",
      "18.2031\n",
      "18.2038\n",
      "18.2040\n",
      "18.2046\n",
      "19\n",
      "19.1\n",
      "19.2\n",
      "19.4\n",
      "19.5\n",
      "19.7\n",
      "19.8\n",
      "19.9\n",
      "19.10\n",
      "19.11\n",
      "19.12\n",
      "19.14\n",
      "19.15\n",
      "19.16\n",
      "19.18\n",
      "19.19\n",
      "19.20\n",
      "19.21\n",
      "19.26\n",
      "19.27\n",
      "19.29\n",
      "19.31\n",
      "19.32\n",
      "19.40\n",
      "19.44\n",
      "19.50\n",
      "19.52\n",
      "19.53\n",
      "19.55\n",
      "19.62\n",
      "19.63\n",
      "19.69\n",
      "19.74\n",
      "19.75\n",
      "19.76\n",
      "19.79\n",
      "19.82\n",
      "19.84\n",
      "19.86\n",
      "19.89\n",
      "19.92\n",
      "19.93\n",
      "19.94\n",
      "19.95\n",
      "19.102\n",
      "19.103\n",
      "19.104\n",
      "19.105\n",
      "19.109\n",
      "19.111\n",
      "19.112\n",
      "19.118\n",
      "19.121\n",
      "19.122\n",
      "19.123\n",
      "19.127\n",
      "19.132\n",
      "19.133\n",
      "19.135\n",
      "19.137\n",
      "19.138\n",
      "19.139\n",
      "19.140\n",
      "19.141\n",
      "19.142\n",
      "19.143\n",
      "19.157\n",
      "19.160\n",
      "19.163\n",
      "19.172\n",
      "19.175\n",
      "19.176\n",
      "19.179\n",
      "19.180\n",
      "19.181\n",
      "19.183\n",
      "19.187\n",
      "19.188\n",
      "19.191\n",
      "19.193\n",
      "19.194\n",
      "19.199\n",
      "19.201\n",
      "19.203\n",
      "19.206\n",
      "19.207\n",
      "19.208\n",
      "19.210\n",
      "19.211\n",
      "19.215\n",
      "19.216\n",
      "19.222\n",
      "19.224\n",
      "19.225\n",
      "19.226\n",
      "19.228\n",
      "19.229\n",
      "19.230\n",
      "19.231\n",
      "19.234\n",
      "19.237\n",
      "19.239\n",
      "19.240\n",
      "19.243\n",
      "19.245\n",
      "19.246\n",
      "19.248\n",
      "19.249\n",
      "19.258\n",
      "19.262\n",
      "19.264\n",
      "19.265\n",
      "19.268\n",
      "19.269\n",
      "19.272\n",
      "19.274\n",
      "19.276\n",
      "19.278\n",
      "19.280\n",
      "19.285\n",
      "19.286\n",
      "19.287\n",
      "19.289\n",
      "19.290\n",
      "19.297\n",
      "19.299\n",
      "19.302\n",
      "19.303\n",
      "19.305\n",
      "19.306\n",
      "19.310\n",
      "19.314\n",
      "19.315\n",
      "19.324\n",
      "19.326\n",
      "19.327\n",
      "19.328\n",
      "19.330\n",
      "19.332\n",
      "19.335\n",
      "19.339\n",
      "19.341\n",
      "19.344\n",
      "19.349\n",
      "19.351\n",
      "19.352\n",
      "19.355\n",
      "19.356\n",
      "19.358\n",
      "19.360\n",
      "19.361\n",
      "19.363\n",
      "19.366\n",
      "19.370\n",
      "19.372\n",
      "19.375\n",
      "19.377\n",
      "19.378\n",
      "19.391\n",
      "19.392\n",
      "19.394\n",
      "19.395\n",
      "19.398\n",
      "19.399\n",
      "19.402\n",
      "19.407\n",
      "19.408\n",
      "19.411\n",
      "19.420\n",
      "19.423\n",
      "19.424\n",
      "19.426\n",
      "19.433\n",
      "19.444\n",
      "19.448\n",
      "19.449\n",
      "19.450\n",
      "19.453\n",
      "19.454\n",
      "19.456\n",
      "19.458\n",
      "19.460\n",
      "19.462\n",
      "19.463\n",
      "19.472\n",
      "19.474\n",
      "19.475\n",
      "19.477\n",
      "19.478\n",
      "19.483\n",
      "19.486\n",
      "19.488\n",
      "19.504\n",
      "19.507\n",
      "19.509\n",
      "19.510\n",
      "19.511\n",
      "19.516\n",
      "19.518\n",
      "19.520\n",
      "19.521\n",
      "19.525\n",
      "19.527\n",
      "19.533\n",
      "19.536\n",
      "19.545\n",
      "19.548\n",
      "19.549\n",
      "19.552\n",
      "19.553\n",
      "19.557\n",
      "19.560\n",
      "19.568\n",
      "19.575\n",
      "19.576\n",
      "19.577\n",
      "19.578\n",
      "19.587\n",
      "19.591\n",
      "19.596\n",
      "19.600\n",
      "19.603\n",
      "19.606\n",
      "19.607\n",
      "19.609\n",
      "19.621\n",
      "19.622\n",
      "19.628\n",
      "19.632\n",
      "19.633\n",
      "19.635\n",
      "19.637\n",
      "19.638\n",
      "19.642\n",
      "19.648\n",
      "19.650\n",
      "19.651\n",
      "19.652\n",
      "19.654\n",
      "19.655\n",
      "19.657\n",
      "19.658\n",
      "19.659\n",
      "19.664\n",
      "19.667\n",
      "19.668\n",
      "19.672\n",
      "19.674\n",
      "19.680\n",
      "19.685\n",
      "19.687\n",
      "19.689\n",
      "19.694\n",
      "19.695\n",
      "19.696\n",
      "19.698\n",
      "19.700\n",
      "19.701\n",
      "19.710\n",
      "19.711\n",
      "19.715\n",
      "19.716\n",
      "19.718\n",
      "19.719\n",
      "19.721\n",
      "19.723\n",
      "19.726\n",
      "19.730\n",
      "19.734\n",
      "19.738\n",
      "19.757\n",
      "19.760\n",
      "19.768\n",
      "19.771\n",
      "19.774\n",
      "19.775\n",
      "19.776\n",
      "19.777\n",
      "19.784\n",
      "19.785\n",
      "19.786\n",
      "19.789\n",
      "19.794\n",
      "19.796\n",
      "19.801\n",
      "19.804\n",
      "19.809\n",
      "19.813\n",
      "19.814\n",
      "19.815\n",
      "19.819\n",
      "19.820\n",
      "19.822\n",
      "19.828\n",
      "19.829\n",
      "19.832\n",
      "19.833\n",
      "19.835\n",
      "19.838\n",
      "19.841\n",
      "19.846\n",
      "19.847\n",
      "19.851\n",
      "19.852\n",
      "19.853\n",
      "19.855\n",
      "19.856\n",
      "19.858\n",
      "19.860\n",
      "19.862\n",
      "19.865\n",
      "19.866\n",
      "19.867\n",
      "19.869\n",
      "19.879\n",
      "19.885\n",
      "19.888\n",
      "19.890\n",
      "19.892\n",
      "19.893\n",
      "19.896\n",
      "19.901\n",
      "19.903\n",
      "19.904\n",
      "19.905\n",
      "19.906\n",
      "19.908\n",
      "19.910\n",
      "19.912\n",
      "19.913\n",
      "19.921\n",
      "19.922\n",
      "19.928\n",
      "19.929\n",
      "19.930\n",
      "19.931\n",
      "19.935\n",
      "19.936\n",
      "19.937\n",
      "19.938\n",
      "19.940\n",
      "19.950\n",
      "19.957\n",
      "19.963\n",
      "19.965\n",
      "19.966\n",
      "19.967\n",
      "19.968\n",
      "19.969\n",
      "19.971\n",
      "19.982\n",
      "19.984\n",
      "19.985\n",
      "19.989\n",
      "19.993\n",
      "19.995\n",
      "19.998\n",
      "19.1005\n",
      "19.1006\n",
      "19.1007\n",
      "19.1010\n",
      "19.1011\n",
      "19.1016\n",
      "19.1017\n",
      "19.1019\n",
      "19.1023\n",
      "19.1025\n",
      "19.1031\n",
      "19.1033\n",
      "19.1036\n",
      "19.1040\n",
      "19.1042\n",
      "19.1043\n",
      "19.1053\n",
      "19.1055\n",
      "19.1061\n",
      "19.1069\n",
      "19.1071\n",
      "19.1073\n",
      "19.1075\n",
      "19.1077\n",
      "19.1078\n",
      "19.1081\n",
      "19.1084\n",
      "19.1085\n",
      "19.1088\n",
      "19.1091\n",
      "19.1096\n",
      "19.1101\n",
      "19.1102\n",
      "19.1104\n",
      "19.1107\n",
      "19.1108\n",
      "19.1110\n",
      "19.1115\n",
      "19.1123\n",
      "19.1124\n",
      "19.1135\n",
      "19.1137\n",
      "19.1140\n",
      "19.1144\n",
      "19.1145\n",
      "19.1151\n",
      "19.1153\n",
      "19.1156\n",
      "19.1161\n",
      "19.1162\n",
      "19.1163\n",
      "19.1166\n",
      "19.1168\n",
      "19.1173\n",
      "19.1175\n",
      "19.1177\n",
      "19.1195\n",
      "19.1197\n",
      "19.1198\n",
      "19.1202\n",
      "19.1203\n",
      "19.1204\n",
      "19.1205\n",
      "19.1209\n",
      "19.1210\n",
      "19.1211\n",
      "19.1214\n",
      "19.1215\n",
      "19.1219\n",
      "19.1221\n",
      "19.1222\n",
      "19.1223\n",
      "19.1227\n",
      "19.1228\n",
      "19.1230\n",
      "19.1231\n",
      "19.1235\n",
      "19.1237\n",
      "19.1239\n",
      "19.1244\n",
      "19.1251\n",
      "19.1252\n",
      "19.1253\n",
      "19.1257\n",
      "19.1260\n",
      "19.1266\n",
      "19.1269\n",
      "19.1272\n",
      "19.1273\n",
      "19.1275\n",
      "19.1277\n",
      "19.1280\n",
      "19.1282\n",
      "19.1283\n",
      "19.1285\n",
      "19.1287\n",
      "19.1293\n",
      "19.1294\n",
      "19.1298\n",
      "19.1300\n",
      "19.1302\n",
      "19.1305\n",
      "19.1307\n",
      "19.1316\n",
      "19.1318\n",
      "19.1320\n",
      "19.1323\n",
      "19.1324\n",
      "19.1325\n",
      "19.1331\n",
      "19.1332\n",
      "19.1333\n",
      "19.1336\n",
      "19.1337\n",
      "19.1338\n",
      "19.1339\n",
      "19.1341\n",
      "19.1343\n",
      "19.1344\n",
      "19.1351\n",
      "19.1352\n",
      "19.1355\n",
      "19.1356\n",
      "19.1361\n",
      "19.1366\n",
      "19.1367\n",
      "19.1368\n",
      "19.1370\n",
      "19.1372\n",
      "19.1373\n",
      "19.1377\n",
      "19.1378\n",
      "19.1379\n",
      "19.1380\n",
      "19.1385\n",
      "19.1387\n",
      "19.1389\n",
      "19.1399\n",
      "19.1402\n",
      "19.1405\n",
      "19.1406\n",
      "19.1408\n",
      "19.1417\n",
      "19.1418\n",
      "19.1420\n",
      "19.1423\n",
      "19.1425\n",
      "19.1427\n",
      "19.1430\n",
      "19.1431\n",
      "19.1442\n",
      "19.1443\n",
      "19.1444\n",
      "19.1445\n",
      "19.1446\n",
      "19.1447\n",
      "19.1448\n",
      "19.1449\n",
      "19.1454\n",
      "19.1459\n",
      "19.1460\n",
      "19.1462\n",
      "19.1469\n",
      "19.1474\n",
      "19.1478\n",
      "19.1486\n",
      "19.1490\n",
      "19.1496\n",
      "19.1498\n",
      "19.1502\n",
      "19.1503\n",
      "19.1506\n",
      "19.1509\n",
      "19.1515\n",
      "19.1518\n",
      "19.1520\n",
      "19.1522\n",
      "19.1523\n",
      "19.1525\n",
      "19.1527\n",
      "19.1529\n",
      "19.1530\n",
      "19.1532\n",
      "19.1538\n",
      "19.1539\n",
      "19.1542\n",
      "19.1543\n",
      "19.1545\n",
      "19.1546\n",
      "19.1553\n",
      "19.1561\n",
      "19.1573\n",
      "19.1574\n",
      "19.1576\n",
      "19.1577\n",
      "19.1581\n",
      "19.1586\n",
      "19.1589\n",
      "19.1592\n",
      "19.1593\n",
      "19.1598\n",
      "19.1600\n",
      "19.1602\n",
      "19.1603\n",
      "19.1609\n",
      "19.1611\n",
      "19.1613\n",
      "19.1615\n",
      "19.1620\n",
      "19.1621\n",
      "19.1622\n",
      "19.1629\n",
      "19.1630\n",
      "19.1631\n",
      "19.1633\n",
      "19.1634\n",
      "19.1635\n",
      "19.1637\n",
      "19.1638\n",
      "19.1643\n",
      "19.1647\n",
      "19.1648\n",
      "19.1654\n",
      "19.1657\n",
      "19.1658\n",
      "19.1660\n",
      "19.1662\n",
      "19.1665\n",
      "19.1666\n",
      "19.1671\n",
      "19.1674\n",
      "19.1675\n",
      "19.1676\n",
      "19.1679\n",
      "19.1684\n",
      "19.1688\n",
      "19.1689\n",
      "19.1695\n",
      "19.1696\n",
      "19.1698\n",
      "19.1700\n",
      "19.1708\n",
      "19.1715\n",
      "19.1719\n",
      "19.1720\n",
      "19.1725\n",
      "19.1730\n",
      "19.1731\n",
      "19.1733\n",
      "19.1734\n",
      "19.1737\n",
      "19.1739\n",
      "19.1740\n",
      "19.1745\n",
      "19.1746\n",
      "19.1754\n",
      "19.1755\n",
      "19.1758\n",
      "19.1761\n",
      "19.1762\n",
      "19.1770\n",
      "19.1771\n",
      "19.1774\n",
      "19.1776\n",
      "19.1783\n",
      "19.1784\n",
      "19.1787\n",
      "19.1793\n",
      "19.1794\n",
      "19.1799\n",
      "19.1800\n",
      "19.1811\n",
      "19.1812\n",
      "19.1814\n",
      "19.1815\n",
      "19.1816\n",
      "19.1822\n",
      "19.1828\n",
      "19.1830\n",
      "19.1831\n",
      "19.1836\n",
      "19.1838\n",
      "19.1841\n",
      "19.1843\n",
      "19.1844\n",
      "19.1846\n",
      "19.1848\n",
      "19.1851\n",
      "19.1852\n",
      "19.1854\n",
      "19.1856\n",
      "19.1858\n",
      "19.1859\n",
      "19.1865\n",
      "19.1866\n",
      "19.1867\n",
      "19.1870\n",
      "19.1871\n",
      "19.1872\n",
      "19.1873\n",
      "19.1878\n",
      "19.1879\n",
      "19.1884\n",
      "19.1886\n",
      "19.1890\n",
      "19.1891\n",
      "19.1894\n",
      "19.1897\n",
      "19.1898\n",
      "19.1901\n",
      "19.1904\n",
      "19.1909\n",
      "19.1911\n",
      "19.1912\n",
      "19.1915\n",
      "19.1917\n",
      "19.1919\n",
      "19.1927\n",
      "19.1928\n",
      "19.1933\n",
      "19.1934\n",
      "19.1937\n",
      "19.1939\n",
      "19.1942\n",
      "19.1943\n",
      "19.1946\n",
      "19.1949\n",
      "19.1952\n",
      "19.1954\n",
      "19.1962\n",
      "19.1963\n",
      "19.1964\n",
      "19.1966\n",
      "19.1969\n",
      "19.1970\n",
      "19.1971\n",
      "19.1979\n",
      "19.1982\n",
      "19.1984\n",
      "19.1985\n",
      "19.1988\n",
      "19.1990\n",
      "19.1992\n",
      "19.1994\n",
      "19.1995\n",
      "19.2000\n",
      "19.2001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.2002\n",
      "19.2005\n",
      "19.2006\n",
      "19.2007\n",
      "19.2010\n",
      "19.2013\n",
      "19.2016\n",
      "19.2019\n",
      "19.2020\n",
      "19.2021\n",
      "19.2022\n",
      "19.2023\n",
      "19.2024\n",
      "19.2026\n",
      "19.2030\n",
      "19.2031\n",
      "19.2033\n",
      "19.2034\n",
      "19.2036\n",
      "19.2040\n",
      "19.2044\n",
      "19.2045\n",
      "19.2046\n",
      "20\n",
      "20.11\n",
      "20.17\n",
      "20.18\n",
      "20.19\n",
      "20.22\n",
      "20.34\n",
      "20.50\n",
      "20.59\n",
      "20.60\n",
      "20.62\n",
      "20.64\n",
      "20.70\n",
      "20.77\n",
      "20.82\n",
      "20.96\n",
      "20.99\n",
      "20.102\n",
      "20.104\n",
      "20.127\n",
      "20.128\n",
      "20.129\n",
      "20.136\n",
      "20.153\n",
      "20.154\n",
      "20.162\n",
      "20.176\n",
      "20.185\n",
      "20.186\n",
      "20.191\n",
      "20.200\n",
      "20.210\n",
      "20.211\n",
      "20.217\n",
      "20.222\n",
      "20.225\n",
      "20.226\n",
      "20.232\n",
      "20.237\n",
      "20.239\n",
      "20.256\n",
      "20.266\n",
      "20.280\n",
      "20.287\n",
      "20.288\n",
      "20.290\n",
      "20.292\n",
      "20.293\n",
      "20.297\n",
      "20.314\n",
      "20.315\n",
      "20.317\n",
      "20.320\n",
      "20.326\n",
      "20.345\n",
      "20.347\n",
      "20.355\n",
      "20.360\n",
      "20.363\n",
      "20.367\n",
      "20.369\n",
      "20.382\n",
      "20.383\n",
      "20.426\n",
      "20.433\n",
      "20.435\n",
      "20.436\n",
      "20.437\n",
      "20.455\n",
      "20.459\n",
      "20.465\n",
      "20.469\n",
      "20.477\n",
      "20.485\n",
      "20.491\n",
      "20.493\n",
      "20.512\n",
      "20.515\n",
      "20.516\n",
      "20.522\n",
      "20.526\n",
      "20.527\n",
      "20.534\n",
      "20.535\n",
      "20.544\n",
      "20.547\n",
      "20.550\n",
      "20.556\n",
      "20.558\n",
      "20.566\n",
      "20.572\n",
      "20.573\n",
      "20.574\n",
      "20.575\n",
      "20.577\n",
      "20.580\n",
      "20.587\n",
      "20.593\n",
      "20.599\n",
      "20.607\n",
      "20.609\n",
      "20.624\n",
      "20.626\n",
      "20.629\n",
      "20.635\n",
      "20.637\n",
      "20.652\n",
      "20.654\n",
      "20.662\n",
      "20.666\n",
      "20.670\n",
      "20.673\n",
      "20.677\n",
      "20.679\n",
      "20.685\n",
      "20.687\n",
      "20.691\n",
      "20.693\n",
      "20.694\n",
      "20.699\n",
      "20.700\n",
      "20.719\n",
      "20.728\n",
      "20.738\n",
      "20.746\n",
      "20.747\n",
      "20.751\n",
      "20.758\n",
      "20.760\n",
      "20.761\n",
      "20.772\n",
      "20.775\n",
      "20.776\n",
      "20.777\n",
      "20.778\n",
      "20.783\n",
      "20.791\n",
      "20.796\n",
      "20.802\n",
      "20.819\n",
      "20.832\n",
      "20.835\n",
      "20.842\n",
      "20.847\n",
      "20.851\n",
      "20.854\n",
      "20.855\n",
      "20.858\n",
      "20.865\n",
      "20.868\n",
      "20.872\n",
      "20.879\n",
      "20.885\n",
      "20.890\n",
      "20.900\n",
      "20.903\n",
      "20.907\n",
      "20.908\n",
      "20.930\n",
      "20.942\n",
      "20.944\n",
      "20.949\n",
      "20.956\n",
      "20.957\n",
      "20.961\n",
      "20.962\n",
      "20.970\n",
      "20.971\n",
      "20.974\n",
      "20.977\n",
      "20.987\n",
      "20.991\n",
      "20.999\n",
      "20.1003\n",
      "20.1007\n",
      "20.1012\n",
      "20.1014\n",
      "20.1015\n",
      "20.1016\n",
      "20.1019\n",
      "20.1020\n",
      "20.1023\n",
      "20.1030\n",
      "20.1032\n",
      "20.1034\n",
      "20.1038\n",
      "20.1040\n",
      "20.1045\n",
      "20.1050\n",
      "20.1056\n",
      "20.1065\n",
      "20.1066\n",
      "20.1073\n",
      "20.1082\n",
      "20.1086\n",
      "20.1089\n",
      "20.1100\n",
      "20.1110\n",
      "20.1116\n",
      "20.1128\n",
      "20.1130\n",
      "20.1138\n",
      "20.1139\n",
      "20.1143\n",
      "20.1144\n",
      "20.1145\n",
      "20.1153\n",
      "20.1158\n",
      "20.1160\n",
      "20.1162\n",
      "20.1164\n",
      "20.1166\n",
      "20.1170\n",
      "20.1172\n",
      "20.1176\n",
      "20.1180\n",
      "20.1182\n",
      "20.1186\n",
      "20.1194\n",
      "20.1198\n",
      "20.1202\n",
      "20.1204\n",
      "20.1208\n",
      "20.1211\n",
      "20.1229\n",
      "20.1234\n",
      "20.1238\n",
      "20.1240\n",
      "20.1255\n",
      "20.1286\n",
      "20.1289\n",
      "20.1296\n",
      "20.1297\n",
      "20.1310\n",
      "20.1316\n",
      "20.1317\n",
      "20.1319\n",
      "20.1322\n",
      "20.1325\n",
      "20.1334\n",
      "20.1342\n",
      "20.1353\n",
      "20.1357\n",
      "20.1367\n",
      "20.1369\n",
      "20.1389\n",
      "20.1398\n",
      "20.1399\n",
      "20.1400\n",
      "20.1402\n",
      "20.1408\n",
      "20.1413\n",
      "20.1414\n",
      "20.1422\n",
      "20.1430\n",
      "20.1439\n",
      "20.1446\n",
      "20.1480\n",
      "20.1484\n",
      "20.1491\n",
      "20.1493\n",
      "20.1498\n",
      "20.1503\n",
      "20.1505\n",
      "20.1509\n",
      "20.1510\n",
      "20.1515\n",
      "20.1516\n",
      "20.1526\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m all_h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mN,L])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(L):\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mall_h\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m   \u001b[38;5;241m=\u001b[39m    activations[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.hook_h.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][e]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39mabs(all_h)\u001b[38;5;241m>\u001b[39mEPS):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "prompt_looking = 'Then, Shelby and Emma had a lot of fun at the school. Shelby gave a apple to'\n",
    "prompt_tokens_looking = model.to_tokens(prompt_looking)\n",
    "logits_looking, activations_looking = model.run_with_cache(prompt_tokens_looking)\n",
    "token_labels_looking = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(prompt_tokens_looking[0]))]\n",
    "L = len(token_labels_l_e)\n",
    "EPS = 0.05\n",
    "choices = []\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    print(layer)\n",
    "    for e in range(model.cfg.E):\n",
    "        all_h = torch.zeros([model.cfg.N,L])\n",
    "        for l in range(L):\n",
    "            all_h[:,l]   =    activations[f'blocks.{layer}.hook_h.{l}'][0][e]\n",
    "        if torch.any(torch.abs(all_h)>EPS):\n",
    "            print(f'{layer}.{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb812820b5094695c8a581672e17220e30dd2c15d704c018326e3cc2e1a566f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
