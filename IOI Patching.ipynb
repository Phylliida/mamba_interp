{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2150298-45a8-4a12-84ef-a4a42ccb7b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f91111ab160>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requires\n",
    "# pip install git+https://github.com/Phylliida/MambaLens.git\n",
    "    \n",
    "from mamba_lens import HookedMamba # this will take a little while to import\n",
    "import torch\n",
    "model_path = \"state-spaces/mamba-370m\"\n",
    "model = HookedMamba.from_pretrained(model_path, device='cuda')\n",
    "torch.set_grad_enabled(False)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29eba0c2-102b-4450-ad2f-7c9fce14cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to do\n",
    "# pip install -e .\n",
    "# in the root directory of this repo\n",
    "# also\n",
    "# to install graphviz:\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install graphviz xdg-utils\n",
    "\n",
    "from acdc.data.ioi import ioi_data_generator, ABC_TEMPLATES, get_all_single_name_abc_patching_formats\n",
    "from acdc.data.utils import generate_dataset\n",
    "\n",
    "num_patching_pairs = 30000\n",
    "seed = 27\n",
    "valid_seed = 28\n",
    "constrain_to_answers = True\n",
    "has_symmetric_patching = True\n",
    "\n",
    "templates = ABC_TEMPLATES\n",
    "patching_formats = list(get_all_single_name_abc_patching_formats())\n",
    "\n",
    "data = generate_dataset(model=model,\n",
    "                  data_generator=ioi_data_generator,\n",
    "                  num_patching_pairs=num_patching_pairs,\n",
    "                  seed=seed,\n",
    "                  valid_seed=valid_seed,\n",
    "                  constrain_to_answers=constrain_to_answers,\n",
    "                  has_symmetric_patching=has_symmetric_patching, \n",
    "                  varying_data_lengths=True,\n",
    "                  templates=templates,\n",
    "                  patching_formats=patching_formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6302f3-c007-4fa7-b405-f998a00a700b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{50178, 46600, 31755, 11276, 10765, 46604, 33811, 46612, 16916, 18966, 12824, 32794, 7195, 33821, 33313, 37921, 29222, 31270, 28712, 28200, 37930, 18985, 7727, 24112, 36400, 32817, 5171, 44085, 35382, 14912, 30274, 20554, 15435, 33357, 49231, 38994, 21587, 7252, 40537, 27738, 44123, 44124, 14943, 45664, 15458, 49765, 19046, 35944, 29804, 23662, 37497, 22138, 27773, 28798, 33407, 27264, 9857, 14468, 35972, 6277, 4744, 32905, 32393, 22671, 20628, 32920, 17560, 21661, 16543, 31903, 18089, 16553, 28331, 41131, 20145, 46262, 30397, 41151, 22723, 23239, 14538, 17100, 37073, 22739, 49365, 16598, 31959, 47831, 22234, 23259, 20189, 45790, 29927, 46312, 31465, 46831, 31472, 29936, 26355, 6393, 26876, 8444, 26878, 6911, 25856, 21249, 19717, 8966, 38150, 26888, 27917, 39184, 48401, 24336, 6416, 23316, 37144, 31513, 42266, 29989, 27434, 45867, 36139, 29489, 27955, 27443, 22838, 7993, 13114, 13629, 28991, 40771, 25413, 44870, 18247, 47944, 35657, 26953, 13651, 27991, 26456, 48990, 34655, 16225, 28518, 43367, 20839, 11116, 10092, 31086, 29040, 50033, 5490, 39795, 48505, 40316, 19838, 24958, 38783, 23425, 24962, 13187, 49028, 12167, 43406, 43921, 18322, 14737, 12694, 16286, 48545, 29092, 16809, 15273, 22455, 24504, 30140, 27581, 21438, 35262, 36292, 6086, 21960, 31231, 20428, 17361, 33747, 13268, 2516, 45014, 25556, 33240, 36312, 16863, 28642, 10213, 16358, 25062, 23528, 35307, 19436, 25579, 15859, 38900, 7670, 8698, 12284, 44542, 5119}\n",
      "torch.Size([120000, 20])\n"
     ]
    }
   ],
   "source": [
    "from acdc.data.ioi import good_names\n",
    "from collections import defaultdict\n",
    "name_tokens = set([model.to_single_token(\" \" + name) for name in good_names])\n",
    "print(name_tokens)\n",
    "print(data.data.size())\n",
    "name_positions = defaultdict(lambda: [])\n",
    "for i in range(data.data.size()[0]):\n",
    "    prompt_tokens = data.data[i]\n",
    "    name_pos = 0\n",
    "    for i, tok in enumerate(prompt_tokens):\n",
    "        if tok.item() in name_tokens:\n",
    "            name_positions[name_pos].append(i) # +1 because conv\n",
    "            name_pos += 1\n",
    "    if name_pos != 5: raise ValueError(f\"data point {model.to_str_tokens(data)} does not have 5 names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "969917bf-e5cc-4b9c-b12c-c16a3fa6d3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808d1465fe464f54bbad8fae1f1ae63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7f973116f490>, {0: {50178: 238, 46600: 172, 31755: 186, 46604: 184, 10765: 176, 11276: 202, 33811: 158, 46612: 210, 16916: 172, 18966: 188, 12824: 196, 32794: 202, 7195: 164, 33821: 196, 37921: 232, 33313: 226, 31270: 184, 29222: 188, 28712: 180, 18985: 180, 37930: 170, 28200: 178, 7727: 174, 24112: 186, 36400: 222, 32817: 188, 5171: 188, 44085: 176, 35382: 192, 14912: 174, 30274: 200, 20554: 180, 15435: 156, 33357: 146, 49231: 172, 38994: 214, 21587: 172, 7252: 180, 40537: 202, 27738: 212, 44123: 166, 44124: 202, 14943: 182, 45664: 118, 15458: 188, 49765: 190, 19046: 194, 35944: 226, 29804: 170, 23662: 162, 37497: 198, 22138: 168, 27773: 240, 28798: 232, 33407: 226, 27264: 218, 9857: 214, 14468: 180, 6277: 144, 35972: 214, 4744: 192, 32905: 160, 32393: 202, 22671: 218, 20628: 168, 32920: 344, 17560: 204, 5119: 138, 21661: 184, 16543: 144, 31903: 266, 18089: 186, 16553: 154, 28331: 184, 41131: 196, 20145: 186, 46262: 188, 30397: 184, 41151: 254, 22723: 186, 23239: 218, 14538: 168, 17100: 166, 37073: 184, 22739: 234, 49365: 226, 16598: 204, 47831: 210, 31959: 242, 22234: 192, 23259: 178, 20189: 208, 45790: 200, 29927: 196, 46312: 206, 31465: 166, 46831: 176, 31472: 186, 29936: 136, 26355: 198, 6393: 156, 26876: 170, 8444: 252, 26878: 236, 6911: 170, 25856: 158, 21249: 168, 19717: 188, 8966: 152, 38150: 140, 26888: 218, 27917: 200, 39184: 166, 48401: 250, 24336: 172, 6416: 228, 23316: 174, 37144: 220, 31513: 200, 42266: 152, 29989: 188, 27434: 188, 45867: 206, 36139: 274, 29489: 224, 27443: 198, 27955: 194, 22838: 186, 7993: 226, 13114: 174, 13629: 188, 28991: 164, 40771: 190, 25413: 228, 44870: 198, 18247: 164, 47944: 164, 35657: 182, 26953: 156, 13651: 174, 27991: 200, 26456: 148, 48990: 224, 34655: 182, 16225: 210, 28518: 166, 20839: 208, 43367: 184, 10092: 226, 11116: 212, 31086: 214, 29040: 208, 50033: 180, 5490: 216, 39795: 190, 48505: 174, 40316: 202, 24958: 158, 38783: 198, 19838: 192, 23425: 200, 24962: 210, 13187: 184, 49028: 162, 12167: 250, 43406: 192, 14737: 216, 18322: 150, 43921: 212, 12694: 150, 16286: 170, 48545: 174, 29092: 188, 15273: 160, 16809: 176, 22455: 130, 24504: 132, 30140: 234, 27581: 152, 21438: 164, 35262: 200, 36292: 212, 6086: 156, 21960: 146, 20428: 204, 17361: 170, 33747: 210, 2516: 188, 13268: 368, 45014: 210, 25556: 196, 33240: 172, 36312: 216, 16863: 198, 28642: 172, 10213: 186, 16358: 200, 25062: 156, 23528: 174, 35307: 212, 19436: 158, 25579: 194, 15859: 216, 38900: 182, 7670: 192, 8698: 202, 12284: 210, 44542: 172, 31231: 214}, 1: {50178: 194, 46600: 182, 31755: 184, 46604: 192, 10765: 224, 11276: 176, 33811: 186, 46612: 232, 16916: 238, 18966: 220, 12824: 182, 32794: 212, 7195: 178, 33821: 170, 37921: 176, 33313: 208, 31270: 176, 29222: 146, 28712: 182, 18985: 240, 37930: 220, 28200: 188, 7727: 168, 24112: 186, 36400: 246, 32817: 214, 5171: 192, 44085: 242, 35382: 172, 14912: 194, 30274: 150, 20554: 144, 15435: 190, 33357: 182, 49231: 168, 38994: 192, 21587: 210, 7252: 164, 40537: 160, 27738: 196, 44123: 154, 44124: 186, 14943: 178, 45664: 192, 15458: 266, 49765: 222, 19046: 222, 35944: 190, 29804: 170, 23662: 172, 37497: 164, 22138: 178, 27773: 220, 28798: 156, 33407: 172, 27264: 182, 9857: 212, 14468: 152, 6277: 192, 35972: 180, 4744: 186, 32905: 170, 32393: 234, 22671: 172, 20628: 200, 32920: 382, 17560: 164, 5119: 166, 21661: 244, 16543: 206, 31903: 198, 18089: 138, 16553: 198, 28331: 232, 41131: 186, 20145: 138, 46262: 196, 30397: 228, 41151: 206, 22723: 246, 23239: 166, 14538: 190, 17100: 200, 37073: 178, 22739: 210, 49365: 136, 16598: 148, 47831: 210, 31959: 184, 22234: 208, 23259: 162, 20189: 224, 45790: 216, 29927: 262, 46312: 218, 31465: 160, 46831: 170, 31472: 204, 29936: 158, 26355: 248, 6393: 206, 26876: 210, 8444: 172, 26878: 172, 6911: 198, 25856: 176, 21249: 188, 19717: 130, 8966: 158, 38150: 204, 26888: 168, 27917: 148, 39184: 158, 48401: 142, 24336: 184, 6416: 194, 23316: 148, 37144: 200, 31513: 202, 42266: 222, 29989: 146, 27434: 158, 45867: 158, 36139: 234, 29489: 170, 27443: 172, 27955: 210, 22838: 202, 7993: 196, 13114: 182, 13629: 186, 28991: 182, 40771: 180, 25413: 188, 44870: 198, 18247: 202, 47944: 196, 35657: 178, 26953: 186, 13651: 154, 27991: 170, 26456: 200, 48990: 126, 34655: 234, 16225: 196, 28518: 140, 20839: 184, 43367: 216, 10092: 168, 11116: 216, 31086: 216, 29040: 244, 50033: 188, 5490: 196, 39795: 190, 48505: 182, 40316: 218, 24958: 184, 38783: 198, 19838: 194, 23425: 198, 24962: 168, 13187: 220, 49028: 196, 12167: 158, 43406: 204, 14737: 200, 18322: 190, 43921: 172, 12694: 180, 16286: 182, 48545: 180, 29092: 198, 15273: 174, 16809: 178, 22455: 190, 24504: 202, 30140: 240, 27581: 178, 21438: 224, 35262: 172, 36292: 164, 6086: 210, 21960: 152, 20428: 206, 17361: 182, 33747: 170, 2516: 162, 13268: 332, 45014: 206, 25556: 166, 33240: 184, 36312: 192, 16863: 222, 28642: 200, 10213: 184, 16358: 196, 25062: 184, 23528: 174, 35307: 186, 19436: 204, 25579: 230, 15859: 186, 38900: 238, 7670: 174, 8698: 170, 12284: 222, 44542: 208, 31231: 196}, 2: {50178: 144, 46600: 180, 31755: 164, 46604: 210, 10765: 192, 11276: 210, 33811: 164, 46612: 238, 16916: 188, 18966: 222, 12824: 194, 32794: 162, 7195: 174, 33821: 182, 37921: 174, 33313: 206, 31270: 200, 29222: 134, 28712: 168, 18985: 150, 37930: 176, 28200: 208, 7727: 126, 24112: 222, 36400: 178, 32817: 222, 5171: 170, 44085: 208, 35382: 218, 14912: 192, 30274: 214, 20554: 152, 15435: 210, 33357: 144, 49231: 210, 38994: 198, 21587: 204, 7252: 158, 40537: 222, 27738: 238, 44123: 196, 44124: 232, 14943: 184, 45664: 198, 15458: 214, 49765: 194, 19046: 200, 35944: 220, 29804: 194, 23662: 198, 37497: 198, 22138: 220, 27773: 184, 28798: 166, 33407: 160, 27264: 168, 9857: 138, 14468: 208, 6277: 196, 35972: 158, 4744: 200, 32905: 218, 32393: 166, 22671: 212, 20628: 194, 32920: 372, 17560: 184, 5119: 116, 21661: 212, 16543: 190, 31903: 182, 18089: 196, 16553: 190, 28331: 170, 41131: 188, 20145: 198, 46262: 198, 30397: 190, 41151: 198, 22723: 164, 23239: 192, 14538: 188, 17100: 228, 37073: 180, 22739: 236, 49365: 160, 16598: 178, 47831: 186, 31959: 184, 22234: 196, 23259: 228, 20189: 158, 45790: 206, 29927: 216, 46312: 206, 31465: 206, 46831: 186, 31472: 222, 29936: 164, 26355: 130, 6393: 154, 26876: 194, 8444: 162, 26878: 180, 6911: 150, 25856: 152, 21249: 152, 19717: 176, 8966: 190, 38150: 182, 26888: 226, 27917: 212, 39184: 192, 48401: 152, 24336: 170, 6416: 180, 23316: 152, 37144: 168, 31513: 200, 42266: 148, 29989: 156, 27434: 220, 45867: 190, 36139: 194, 29489: 182, 27443: 218, 27955: 188, 22838: 190, 7993: 170, 13114: 164, 13629: 198, 28991: 192, 40771: 182, 25413: 258, 44870: 180, 18247: 236, 47944: 208, 35657: 198, 26953: 214, 13651: 248, 27991: 228, 26456: 214, 48990: 188, 34655: 186, 16225: 158, 28518: 158, 20839: 212, 43367: 228, 10092: 192, 11116: 166, 31086: 176, 29040: 208, 50033: 158, 5490: 198, 39795: 218, 48505: 166, 40316: 196, 24958: 210, 38783: 132, 19838: 230, 23425: 156, 24962: 210, 13187: 192, 49028: 252, 12167: 174, 43406: 226, 14737: 172, 18322: 178, 43921: 188, 12694: 192, 16286: 174, 48545: 172, 29092: 140, 15273: 210, 16809: 190, 22455: 160, 24504: 214, 30140: 154, 27581: 168, 21438: 206, 35262: 192, 36292: 178, 6086: 162, 21960: 200, 20428: 214, 17361: 202, 33747: 172, 2516: 244, 13268: 414, 45014: 174, 25556: 196, 33240: 236, 36312: 218, 16863: 140, 28642: 204, 10213: 212, 16358: 192, 25062: 206, 23528: 190, 35307: 172, 19436: 176, 25579: 168, 15859: 178, 38900: 202, 7670: 206, 8698: 212, 12284: 184, 44542: 190, 31231: 198}, 3: {50178: 238, 46600: 156, 31755: 182, 46604: 188, 10765: 196, 11276: 182, 33811: 174, 46612: 214, 16916: 218, 18966: 208, 12824: 172, 32794: 220, 7195: 162, 33821: 194, 37921: 246, 33313: 238, 31270: 172, 29222: 164, 28712: 186, 18985: 196, 37930: 180, 28200: 190, 7727: 184, 24112: 188, 36400: 226, 32817: 194, 5171: 180, 44085: 158, 35382: 202, 14912: 172, 30274: 184, 20554: 180, 15435: 148, 33357: 154, 49231: 158, 38994: 236, 21587: 200, 7252: 196, 40537: 194, 27738: 224, 44123: 154, 44124: 198, 14943: 168, 45664: 136, 15458: 222, 49765: 210, 19046: 210, 35944: 258, 29804: 176, 23662: 166, 37497: 160, 22138: 164, 27773: 270, 28798: 176, 33407: 202, 27264: 196, 9857: 216, 14468: 170, 6277: 172, 35972: 202, 4744: 216, 32905: 164, 32393: 206, 22671: 220, 20628: 176, 32920: 320, 17560: 200, 5119: 154, 21661: 174, 16543: 176, 31903: 246, 18089: 154, 16553: 158, 28331: 184, 41131: 214, 20145: 182, 46262: 210, 30397: 184, 41151: 256, 22723: 206, 23239: 212, 14538: 170, 17100: 168, 37073: 160, 22739: 228, 49365: 204, 16598: 190, 47831: 220, 31959: 218, 22234: 208, 23259: 176, 20189: 226, 45790: 194, 29927: 232, 46312: 194, 31465: 148, 46831: 174, 31472: 240, 29936: 146, 26355: 256, 6393: 146, 26876: 180, 8444: 230, 26878: 224, 6911: 176, 25856: 164, 21249: 194, 19717: 168, 8966: 146, 38150: 142, 26888: 194, 27917: 158, 39184: 148, 48401: 234, 24336: 170, 6416: 220, 23316: 176, 37144: 218, 31513: 208, 42266: 188, 29989: 168, 27434: 160, 45867: 206, 36139: 272, 29489: 208, 27443: 176, 27955: 204, 22838: 196, 7993: 246, 13114: 166, 13629: 192, 28991: 158, 40771: 204, 25413: 208, 44870: 188, 18247: 170, 47944: 164, 35657: 182, 26953: 154, 13651: 178, 27991: 200, 26456: 146, 48990: 192, 34655: 198, 16225: 222, 28518: 154, 20839: 204, 43367: 206, 10092: 216, 11116: 220, 31086: 192, 29040: 242, 50033: 182, 5490: 168, 39795: 214, 48505: 174, 40316: 196, 24958: 176, 38783: 184, 19838: 196, 23425: 178, 24962: 182, 13187: 218, 49028: 170, 12167: 224, 43406: 182, 14737: 224, 18322: 162, 43921: 170, 12694: 140, 16286: 176, 48545: 192, 29092: 172, 15273: 172, 16809: 152, 22455: 140, 24504: 150, 30140: 250, 27581: 162, 21438: 174, 35262: 208, 36292: 202, 6086: 170, 21960: 138, 20428: 206, 17361: 178, 33747: 188, 2516: 160, 13268: 340, 45014: 200, 25556: 180, 33240: 192, 36312: 180, 16863: 192, 28642: 174, 10213: 192, 16358: 200, 25062: 176, 23528: 154, 35307: 196, 19436: 176, 25579: 198, 15859: 194, 38900: 220, 7670: 188, 8698: 182, 12284: 212, 44542: 176, 31231: 228}, 4: {50178: 160, 46600: 194, 31755: 158, 46604: 180, 10765: 204, 11276: 204, 33811: 162, 46612: 240, 16916: 170, 18966: 246, 12824: 198, 32794: 164, 7195: 182, 33821: 172, 37921: 162, 33313: 220, 31270: 208, 29222: 130, 28712: 168, 18985: 172, 37930: 196, 28200: 206, 7727: 128, 24112: 204, 36400: 216, 32817: 210, 5171: 184, 44085: 232, 35382: 200, 14912: 162, 30274: 224, 20554: 150, 15435: 210, 33357: 158, 49231: 212, 38994: 212, 21587: 190, 7252: 144, 40537: 212, 27738: 236, 44123: 206, 44124: 212, 14943: 190, 45664: 208, 15458: 232, 49765: 202, 19046: 222, 35944: 198, 29804: 170, 23662: 184, 37497: 190, 22138: 220, 27773: 190, 28798: 172, 33407: 148, 27264: 190, 9857: 124, 14468: 182, 6277: 190, 35972: 166, 4744: 206, 32905: 198, 32393: 186, 22671: 208, 20628: 188, 32920: 380, 17560: 178, 5119: 108, 21661: 246, 16543: 164, 31903: 188, 18089: 180, 16553: 204, 28331: 206, 41131: 178, 20145: 168, 46262: 184, 30397: 212, 41151: 194, 22723: 202, 23239: 182, 14538: 198, 17100: 228, 37073: 192, 22739: 228, 49365: 172, 16598: 168, 47831: 188, 31959: 172, 22234: 178, 23259: 206, 20189: 162, 45790: 232, 29927: 214, 46312: 224, 31465: 214, 46831: 188, 31472: 204, 29936: 138, 26355: 160, 6393: 204, 26876: 210, 8444: 172, 26878: 158, 6911: 144, 25856: 140, 21249: 132, 19717: 154, 8966: 196, 38150: 200, 26888: 212, 27917: 198, 39184: 190, 48401: 150, 24336: 160, 6416: 176, 23316: 154, 37144: 176, 31513: 206, 42266: 142, 29989: 142, 27434: 218, 45867: 156, 36139: 210, 29489: 180, 27443: 206, 27955: 190, 22838: 210, 7993: 170, 13114: 176, 13629: 190, 28991: 182, 40771: 176, 25413: 240, 44870: 192, 18247: 214, 47944: 200, 35657: 184, 26953: 212, 13651: 194, 27991: 222, 26456: 220, 48990: 162, 34655: 202, 16225: 166, 28518: 152, 20839: 220, 43367: 194, 10092: 180, 11116: 174, 31086: 170, 29040: 220, 50033: 172, 5490: 214, 39795: 212, 48505: 154, 40316: 198, 24958: 198, 38783: 172, 19838: 204, 23425: 184, 24962: 220, 13187: 192, 49028: 226, 12167: 168, 43406: 248, 14737: 152, 18322: 206, 43921: 190, 12694: 172, 16286: 158, 48545: 154, 29092: 152, 15273: 174, 16809: 208, 22455: 184, 24504: 218, 30140: 168, 27581: 168, 21438: 206, 35262: 160, 36292: 164, 6086: 196, 21960: 202, 20428: 200, 17361: 190, 33747: 184, 2516: 250, 13268: 394, 45014: 200, 25556: 174, 33240: 220, 36312: 206, 16863: 174, 28642: 210, 10213: 218, 16358: 176, 25062: 218, 23528: 190, 35307: 184, 19436: 184, 25579: 190, 15859: 190, 38900: 242, 7670: 198, 8698: 208, 12284: 210, 44542: 196, 31231: 200}})\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "LAYER = 39\n",
    "batch_size = 40\n",
    "\n",
    "hook = f\"blocks.{LAYER}.hook_ssm_input\"\n",
    "\n",
    "name_averages = defaultdict(lambda: {})\n",
    "counts = defaultdict(lambda: {})\n",
    "\n",
    "TOTAL_AVG_NAME = \"total\"\n",
    "\n",
    "for tok in name_tokens:\n",
    "    for name_i in range(len(name_positions)):\n",
    "        name_averages[name_i][tok] = torch.zeros([model.cfg.E], device=model.cfg.device)\n",
    "        counts[name_i][tok] = 0\n",
    "\n",
    "for batch_start in tqdm(list(range(0, data.data.size()[0], batch_size))):\n",
    "    batch_end = min(data.data.size()[0], batch_start+batch_size)\n",
    "    data_batch = data.data[batch_start:batch_end]\n",
    "    logits, activations = model.run_with_cache(data_batch, names_filter=[hook], fast_ssm=True, fast_conv=True)\n",
    "    for name_i in range(len(name_positions)):\n",
    "        positions = torch.tensor(name_positions[name_i][batch_start:batch_end], device=model.cfg.device)\n",
    "        batch_name_tokens = data_batch[torch.arange(batch_end-batch_start),positions]\n",
    "        ssm_inputs = activations[hook]\n",
    "        for batch_i, name_tok in enumerate(batch_name_tokens):\n",
    "            #print(ssm_inputs[batch_i, position].size())\n",
    "            try:\n",
    "                position = positions[batch_i]+1\n",
    "                name_averages[name_i][name_tok.item()] = ssm_inputs[batch_i, position]\n",
    "                name_averages['all'][name_tok.item()] = ssm_inputs[batch_i, position]\n",
    "                #name_averages[name_i][TOTAL_AVG_NAME] += ssm_inputs[batch_i, position]\n",
    "                counts[name_i][name_tok.item()] += 1\n",
    "                #counts[name_i][TOTAL_AVG_NAME] += 1\n",
    "            except:\n",
    "                print(model.to_str_tokens([name_tok]))\n",
    "                raise\n",
    "    \n",
    "print(counts)\n",
    "for name_i in range(len(name_positions)):\n",
    "    for name_tok in list(name_averages.keys()):\n",
    "        #name_averages[name_i][name_tok] = name_averages[name_i][name_tok] / counts[name_i][name_tok]\n",
    "        pass   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cba178a-3688-4632-be14-0445f634da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "\n",
    "DO_DIFF = False\n",
    "\n",
    "model_kwargs = {\"fast_ssm\": True, \"fast_conv\": True}\n",
    "\n",
    "original_corrects = {}\n",
    "original_replaces = {}\n",
    "replace_corrects = {}\n",
    "replace_replaces = {}\n",
    "patched_corrects = {}\n",
    "patched_replaces = {}\n",
    "\n",
    "for position_1 in range(3):\n",
    "    for position_2 in range(5):\n",
    "        print(position_1, position_2)\n",
    "        original_correct = []\n",
    "        original_replace = []\n",
    "        replace_correct = []\n",
    "        replace_replace = []\n",
    "        patched_correct = []\n",
    "        patched_replace = []\n",
    "\n",
    "        original_corrects[(position_1, position_2)] = original_correct\n",
    "        original_replaces[(position_1, position_2)] = original_replace\n",
    "        replace_corrects[(position_1, position_2)] = replace_correct\n",
    "        replace_replaces[(position_1, position_2)] = replace_replace\n",
    "        patched_corrects[(position_1, position_2)] = patched_correct\n",
    "        patched_replaces[(position_1, position_2)] = patched_replace\n",
    "        \n",
    "        num_found = 0\n",
    "        while True:\n",
    "            data_i = random.choice(list(range(data.data.size()[0])))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i]\n",
    "            answer_tok = data.correct[data_i][0]\n",
    "            answer = model.to_str_tokens(answer_tok)[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            \n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                replace_vec,\n",
    "                replace_add_vec\n",
    "            ):\n",
    "                if not replace_vec is None:\n",
    "                    x[0, position] = replace_vec\n",
    "                if not replace_add_vec is None:\n",
    "                    x[0, position] += replace_add_vec\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(name_positions)):\n",
    "                position = name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            hooks = []\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                \n",
    "                name_i = position_2\n",
    "                replace_vec = name_averages[name_i][replace_tok]\n",
    "                # two ways to do it\n",
    "                # diff(name) = avg - name\n",
    "                # if we add this it should \"erase\" name\n",
    "                # if we subtract this it should \"add\" name\n",
    "                # so we can do\n",
    "                # replace_add_vec = diff(answer) - diff(replace)\n",
    "                #diff_answer = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][answer_tok]\n",
    "                #diff_replace = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][replace_tok]\n",
    "                #replace_add_vec = diff_answer - diff_replace\n",
    "                # this is (avg-a) - (avg-r) = r-a\n",
    "                # in other words the average doesn't matter for this\n",
    "                # and it's just subtract avg for a and add average for b\n",
    "                replace_add_vec = name_averages[name_i][replace_tok] - name_averages[name_i][answer_tok.item()]\n",
    "                # then we do\n",
    "                # replace_vec\n",
    "                # we have x\n",
    "                # we want y\n",
    "                # we can do\n",
    "                # x-y\n",
    "                # and apply it to y\n",
    "                #replace_diff = name_averages[name_i][TOTAL_AVG_NAME]\n",
    "        \n",
    "                if DO_DIFF:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec)))\n",
    "                else:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None)))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 100:\n",
    "                break\n",
    "    \n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a963471-2615-44aa-8be8-64f3e274530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_correct_matrix = torch.zeros([3,5])\n",
    "\n",
    "for pos1 in range(3):\n",
    "    for pos2 in range(5):\n",
    "        #original_diff = -torch.tensor(original_correct) + torch.tensor(original_replace)\n",
    "        replace_diff = -torch.tensor(replace_corrects[(pos1,pos2)]) + torch.tensor(replace_replaces[(pos1,pos2)])\n",
    "        #patched_diff = -torch.tensor(patched_correct) + torch.tensor(patched_replace)\n",
    "        \n",
    "        #print(f'original min diff {torch.min(original_diff)} max diff {torch.max(original_diff)} avg diff {torch.mean(original_diff)}')\n",
    "        #print(f'replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "        #print(f'patch min diff {torch.min(patched_diff)} max diff {torch.max(patched_diff)} avg diff {torch.mean(patched_diff)}')\n",
    "\n",
    "        n_correct_matrix[pos1, pos2] = torch.sum(replace_diff > 0)/101.0\n",
    "        #print(f'original n correct {torch.sum(original_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'replace n correct {torch.sum(replace_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'patch n correct {torch.sum(patched_diff < 0)} / {original_diff.size()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8637d98c-498d-4ad2-bd9f-1f23265ab475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "y": [
          0,
          1,
          2
         ],
         "yaxis": "y",
         "z": [
          [
           0.9900990128517151,
           0.9900990128517151,
           1,
           0.4752475321292877,
           0.4752475321292877
          ],
          [
           1,
           1,
           0.9900990128517151,
           0.603960394859314,
           0.5841584205627441
          ],
          [
           0.9801980257034302,
           1,
           0.9900990128517151,
           0.4455445408821106,
           0.3861386179924011
          ]
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "replacing"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.21209213051823417,
          0.7879078694817658
         ],
         "range": [
          -0.5,
          4.5
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          2.5,
          -0.5
         ],
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"fb9184de-aad0-4157-af14-c9db66ef9d18\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fb9184de-aad0-4157-af14-c9db66ef9d18\")) {                    Plotly.newPlot(                        \"fb9184de-aad0-4157-af14-c9db66ef9d18\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"y\":[0,1,2],\"z\":[[0.9900990128517151,0.9900990128517151,1.0,0.4752475321292877,0.4752475321292877],[1.0,1.0,0.9900990128517151,0.603960394859314,0.5841584205627441],[0.9801980257034302,1.0,0.9900990128517151,0.4455445408821106,0.3861386179924011]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"title\":{\"text\":\"replacing\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fb9184de-aad0-4157-af14-c9db66ef9d18');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# modified from neel nanda's examples\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", font_size=None, show=True, color_continuous_midpoint=0.0, fix_size=False, **kwargs):\n",
    "    import plotly.express as px\n",
    "    import transformer_lens.utils as utils\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=color_continuous_midpoint, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show()\n",
    "\n",
    "imshow(n_correct_matrix, color_continuous_midpoint=None, y=[0,1,2], title='replacing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ba32f2c-2128-463f-9979-48b48b813d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {0: {50178: 238,\n",
       "              46600: 172,\n",
       "              31755: 186,\n",
       "              46604: 184,\n",
       "              10765: 176,\n",
       "              11276: 202,\n",
       "              33811: 158,\n",
       "              46612: 210,\n",
       "              16916: 172,\n",
       "              18966: 188,\n",
       "              12824: 196,\n",
       "              32794: 202,\n",
       "              7195: 164,\n",
       "              33821: 196,\n",
       "              37921: 232,\n",
       "              33313: 226,\n",
       "              31270: 184,\n",
       "              29222: 188,\n",
       "              28712: 180,\n",
       "              18985: 180,\n",
       "              37930: 170,\n",
       "              28200: 178,\n",
       "              7727: 174,\n",
       "              24112: 186,\n",
       "              36400: 222,\n",
       "              32817: 188,\n",
       "              5171: 188,\n",
       "              44085: 176,\n",
       "              35382: 192,\n",
       "              14912: 174,\n",
       "              30274: 200,\n",
       "              20554: 180,\n",
       "              15435: 156,\n",
       "              33357: 146,\n",
       "              49231: 172,\n",
       "              38994: 214,\n",
       "              21587: 172,\n",
       "              7252: 180,\n",
       "              40537: 202,\n",
       "              27738: 212,\n",
       "              44123: 166,\n",
       "              44124: 202,\n",
       "              14943: 182,\n",
       "              45664: 118,\n",
       "              15458: 188,\n",
       "              49765: 190,\n",
       "              19046: 194,\n",
       "              35944: 226,\n",
       "              29804: 170,\n",
       "              23662: 162,\n",
       "              37497: 198,\n",
       "              22138: 168,\n",
       "              27773: 240,\n",
       "              28798: 232,\n",
       "              33407: 226,\n",
       "              27264: 218,\n",
       "              9857: 214,\n",
       "              14468: 180,\n",
       "              6277: 144,\n",
       "              35972: 214,\n",
       "              4744: 192,\n",
       "              32905: 160,\n",
       "              32393: 202,\n",
       "              22671: 218,\n",
       "              20628: 168,\n",
       "              32920: 344,\n",
       "              17560: 204,\n",
       "              5119: 138,\n",
       "              21661: 184,\n",
       "              16543: 144,\n",
       "              31903: 266,\n",
       "              18089: 186,\n",
       "              16553: 154,\n",
       "              28331: 184,\n",
       "              41131: 196,\n",
       "              20145: 186,\n",
       "              46262: 188,\n",
       "              30397: 184,\n",
       "              41151: 254,\n",
       "              22723: 186,\n",
       "              23239: 218,\n",
       "              14538: 168,\n",
       "              17100: 166,\n",
       "              37073: 184,\n",
       "              22739: 234,\n",
       "              49365: 226,\n",
       "              16598: 204,\n",
       "              47831: 210,\n",
       "              31959: 242,\n",
       "              22234: 192,\n",
       "              23259: 178,\n",
       "              20189: 208,\n",
       "              45790: 200,\n",
       "              29927: 196,\n",
       "              46312: 206,\n",
       "              31465: 166,\n",
       "              46831: 176,\n",
       "              31472: 186,\n",
       "              29936: 136,\n",
       "              26355: 198,\n",
       "              6393: 156,\n",
       "              26876: 170,\n",
       "              8444: 252,\n",
       "              26878: 236,\n",
       "              6911: 170,\n",
       "              25856: 158,\n",
       "              21249: 168,\n",
       "              19717: 188,\n",
       "              8966: 152,\n",
       "              38150: 140,\n",
       "              26888: 218,\n",
       "              27917: 200,\n",
       "              39184: 166,\n",
       "              48401: 250,\n",
       "              24336: 172,\n",
       "              6416: 228,\n",
       "              23316: 174,\n",
       "              37144: 220,\n",
       "              31513: 200,\n",
       "              42266: 152,\n",
       "              29989: 188,\n",
       "              27434: 188,\n",
       "              45867: 206,\n",
       "              36139: 274,\n",
       "              29489: 224,\n",
       "              27443: 198,\n",
       "              27955: 194,\n",
       "              22838: 186,\n",
       "              7993: 226,\n",
       "              13114: 174,\n",
       "              13629: 188,\n",
       "              28991: 164,\n",
       "              40771: 190,\n",
       "              25413: 228,\n",
       "              44870: 198,\n",
       "              18247: 164,\n",
       "              47944: 164,\n",
       "              35657: 182,\n",
       "              26953: 156,\n",
       "              13651: 174,\n",
       "              27991: 200,\n",
       "              26456: 148,\n",
       "              48990: 224,\n",
       "              34655: 182,\n",
       "              16225: 210,\n",
       "              28518: 166,\n",
       "              20839: 208,\n",
       "              43367: 184,\n",
       "              10092: 226,\n",
       "              11116: 212,\n",
       "              31086: 214,\n",
       "              29040: 208,\n",
       "              50033: 180,\n",
       "              5490: 216,\n",
       "              39795: 190,\n",
       "              48505: 174,\n",
       "              40316: 202,\n",
       "              24958: 158,\n",
       "              38783: 198,\n",
       "              19838: 192,\n",
       "              23425: 200,\n",
       "              24962: 210,\n",
       "              13187: 184,\n",
       "              49028: 162,\n",
       "              12167: 250,\n",
       "              43406: 192,\n",
       "              14737: 216,\n",
       "              18322: 150,\n",
       "              43921: 212,\n",
       "              12694: 150,\n",
       "              16286: 170,\n",
       "              48545: 174,\n",
       "              29092: 188,\n",
       "              15273: 160,\n",
       "              16809: 176,\n",
       "              22455: 130,\n",
       "              24504: 132,\n",
       "              30140: 234,\n",
       "              27581: 152,\n",
       "              21438: 164,\n",
       "              35262: 200,\n",
       "              36292: 212,\n",
       "              6086: 156,\n",
       "              21960: 146,\n",
       "              20428: 204,\n",
       "              17361: 170,\n",
       "              33747: 210,\n",
       "              2516: 188,\n",
       "              13268: 368,\n",
       "              45014: 210,\n",
       "              25556: 196,\n",
       "              33240: 172,\n",
       "              36312: 216,\n",
       "              16863: 198,\n",
       "              28642: 172,\n",
       "              10213: 186,\n",
       "              16358: 200,\n",
       "              25062: 156,\n",
       "              23528: 174,\n",
       "              35307: 212,\n",
       "              19436: 158,\n",
       "              25579: 194,\n",
       "              15859: 216,\n",
       "              38900: 182,\n",
       "              7670: 192,\n",
       "              8698: 202,\n",
       "              12284: 210,\n",
       "              44542: 172,\n",
       "              31231: 214},\n",
       "             1: {50178: 194,\n",
       "              46600: 182,\n",
       "              31755: 184,\n",
       "              46604: 192,\n",
       "              10765: 224,\n",
       "              11276: 176,\n",
       "              33811: 186,\n",
       "              46612: 232,\n",
       "              16916: 238,\n",
       "              18966: 220,\n",
       "              12824: 182,\n",
       "              32794: 212,\n",
       "              7195: 178,\n",
       "              33821: 170,\n",
       "              37921: 176,\n",
       "              33313: 208,\n",
       "              31270: 176,\n",
       "              29222: 146,\n",
       "              28712: 182,\n",
       "              18985: 240,\n",
       "              37930: 220,\n",
       "              28200: 188,\n",
       "              7727: 168,\n",
       "              24112: 186,\n",
       "              36400: 246,\n",
       "              32817: 214,\n",
       "              5171: 192,\n",
       "              44085: 242,\n",
       "              35382: 172,\n",
       "              14912: 194,\n",
       "              30274: 150,\n",
       "              20554: 144,\n",
       "              15435: 190,\n",
       "              33357: 182,\n",
       "              49231: 168,\n",
       "              38994: 192,\n",
       "              21587: 210,\n",
       "              7252: 164,\n",
       "              40537: 160,\n",
       "              27738: 196,\n",
       "              44123: 154,\n",
       "              44124: 186,\n",
       "              14943: 178,\n",
       "              45664: 192,\n",
       "              15458: 266,\n",
       "              49765: 222,\n",
       "              19046: 222,\n",
       "              35944: 190,\n",
       "              29804: 170,\n",
       "              23662: 172,\n",
       "              37497: 164,\n",
       "              22138: 178,\n",
       "              27773: 220,\n",
       "              28798: 156,\n",
       "              33407: 172,\n",
       "              27264: 182,\n",
       "              9857: 212,\n",
       "              14468: 152,\n",
       "              6277: 192,\n",
       "              35972: 180,\n",
       "              4744: 186,\n",
       "              32905: 170,\n",
       "              32393: 234,\n",
       "              22671: 172,\n",
       "              20628: 200,\n",
       "              32920: 382,\n",
       "              17560: 164,\n",
       "              5119: 166,\n",
       "              21661: 244,\n",
       "              16543: 206,\n",
       "              31903: 198,\n",
       "              18089: 138,\n",
       "              16553: 198,\n",
       "              28331: 232,\n",
       "              41131: 186,\n",
       "              20145: 138,\n",
       "              46262: 196,\n",
       "              30397: 228,\n",
       "              41151: 206,\n",
       "              22723: 246,\n",
       "              23239: 166,\n",
       "              14538: 190,\n",
       "              17100: 200,\n",
       "              37073: 178,\n",
       "              22739: 210,\n",
       "              49365: 136,\n",
       "              16598: 148,\n",
       "              47831: 210,\n",
       "              31959: 184,\n",
       "              22234: 208,\n",
       "              23259: 162,\n",
       "              20189: 224,\n",
       "              45790: 216,\n",
       "              29927: 262,\n",
       "              46312: 218,\n",
       "              31465: 160,\n",
       "              46831: 170,\n",
       "              31472: 204,\n",
       "              29936: 158,\n",
       "              26355: 248,\n",
       "              6393: 206,\n",
       "              26876: 210,\n",
       "              8444: 172,\n",
       "              26878: 172,\n",
       "              6911: 198,\n",
       "              25856: 176,\n",
       "              21249: 188,\n",
       "              19717: 130,\n",
       "              8966: 158,\n",
       "              38150: 204,\n",
       "              26888: 168,\n",
       "              27917: 148,\n",
       "              39184: 158,\n",
       "              48401: 142,\n",
       "              24336: 184,\n",
       "              6416: 194,\n",
       "              23316: 148,\n",
       "              37144: 200,\n",
       "              31513: 202,\n",
       "              42266: 222,\n",
       "              29989: 146,\n",
       "              27434: 158,\n",
       "              45867: 158,\n",
       "              36139: 234,\n",
       "              29489: 170,\n",
       "              27443: 172,\n",
       "              27955: 210,\n",
       "              22838: 202,\n",
       "              7993: 196,\n",
       "              13114: 182,\n",
       "              13629: 186,\n",
       "              28991: 182,\n",
       "              40771: 180,\n",
       "              25413: 188,\n",
       "              44870: 198,\n",
       "              18247: 202,\n",
       "              47944: 196,\n",
       "              35657: 178,\n",
       "              26953: 186,\n",
       "              13651: 154,\n",
       "              27991: 170,\n",
       "              26456: 200,\n",
       "              48990: 126,\n",
       "              34655: 234,\n",
       "              16225: 196,\n",
       "              28518: 140,\n",
       "              20839: 184,\n",
       "              43367: 216,\n",
       "              10092: 168,\n",
       "              11116: 216,\n",
       "              31086: 216,\n",
       "              29040: 244,\n",
       "              50033: 188,\n",
       "              5490: 196,\n",
       "              39795: 190,\n",
       "              48505: 182,\n",
       "              40316: 218,\n",
       "              24958: 184,\n",
       "              38783: 198,\n",
       "              19838: 194,\n",
       "              23425: 198,\n",
       "              24962: 168,\n",
       "              13187: 220,\n",
       "              49028: 196,\n",
       "              12167: 158,\n",
       "              43406: 204,\n",
       "              14737: 200,\n",
       "              18322: 190,\n",
       "              43921: 172,\n",
       "              12694: 180,\n",
       "              16286: 182,\n",
       "              48545: 180,\n",
       "              29092: 198,\n",
       "              15273: 174,\n",
       "              16809: 178,\n",
       "              22455: 190,\n",
       "              24504: 202,\n",
       "              30140: 240,\n",
       "              27581: 178,\n",
       "              21438: 224,\n",
       "              35262: 172,\n",
       "              36292: 164,\n",
       "              6086: 210,\n",
       "              21960: 152,\n",
       "              20428: 206,\n",
       "              17361: 182,\n",
       "              33747: 170,\n",
       "              2516: 162,\n",
       "              13268: 332,\n",
       "              45014: 206,\n",
       "              25556: 166,\n",
       "              33240: 184,\n",
       "              36312: 192,\n",
       "              16863: 222,\n",
       "              28642: 200,\n",
       "              10213: 184,\n",
       "              16358: 196,\n",
       "              25062: 184,\n",
       "              23528: 174,\n",
       "              35307: 186,\n",
       "              19436: 204,\n",
       "              25579: 230,\n",
       "              15859: 186,\n",
       "              38900: 238,\n",
       "              7670: 174,\n",
       "              8698: 170,\n",
       "              12284: 222,\n",
       "              44542: 208,\n",
       "              31231: 196},\n",
       "             2: {50178: 144,\n",
       "              46600: 180,\n",
       "              31755: 164,\n",
       "              46604: 210,\n",
       "              10765: 192,\n",
       "              11276: 210,\n",
       "              33811: 164,\n",
       "              46612: 238,\n",
       "              16916: 188,\n",
       "              18966: 222,\n",
       "              12824: 194,\n",
       "              32794: 162,\n",
       "              7195: 174,\n",
       "              33821: 182,\n",
       "              37921: 174,\n",
       "              33313: 206,\n",
       "              31270: 200,\n",
       "              29222: 134,\n",
       "              28712: 168,\n",
       "              18985: 150,\n",
       "              37930: 176,\n",
       "              28200: 208,\n",
       "              7727: 126,\n",
       "              24112: 222,\n",
       "              36400: 178,\n",
       "              32817: 222,\n",
       "              5171: 170,\n",
       "              44085: 208,\n",
       "              35382: 218,\n",
       "              14912: 192,\n",
       "              30274: 214,\n",
       "              20554: 152,\n",
       "              15435: 210,\n",
       "              33357: 144,\n",
       "              49231: 210,\n",
       "              38994: 198,\n",
       "              21587: 204,\n",
       "              7252: 158,\n",
       "              40537: 222,\n",
       "              27738: 238,\n",
       "              44123: 196,\n",
       "              44124: 232,\n",
       "              14943: 184,\n",
       "              45664: 198,\n",
       "              15458: 214,\n",
       "              49765: 194,\n",
       "              19046: 200,\n",
       "              35944: 220,\n",
       "              29804: 194,\n",
       "              23662: 198,\n",
       "              37497: 198,\n",
       "              22138: 220,\n",
       "              27773: 184,\n",
       "              28798: 166,\n",
       "              33407: 160,\n",
       "              27264: 168,\n",
       "              9857: 138,\n",
       "              14468: 208,\n",
       "              6277: 196,\n",
       "              35972: 158,\n",
       "              4744: 200,\n",
       "              32905: 218,\n",
       "              32393: 166,\n",
       "              22671: 212,\n",
       "              20628: 194,\n",
       "              32920: 372,\n",
       "              17560: 184,\n",
       "              5119: 116,\n",
       "              21661: 212,\n",
       "              16543: 190,\n",
       "              31903: 182,\n",
       "              18089: 196,\n",
       "              16553: 190,\n",
       "              28331: 170,\n",
       "              41131: 188,\n",
       "              20145: 198,\n",
       "              46262: 198,\n",
       "              30397: 190,\n",
       "              41151: 198,\n",
       "              22723: 164,\n",
       "              23239: 192,\n",
       "              14538: 188,\n",
       "              17100: 228,\n",
       "              37073: 180,\n",
       "              22739: 236,\n",
       "              49365: 160,\n",
       "              16598: 178,\n",
       "              47831: 186,\n",
       "              31959: 184,\n",
       "              22234: 196,\n",
       "              23259: 228,\n",
       "              20189: 158,\n",
       "              45790: 206,\n",
       "              29927: 216,\n",
       "              46312: 206,\n",
       "              31465: 206,\n",
       "              46831: 186,\n",
       "              31472: 222,\n",
       "              29936: 164,\n",
       "              26355: 130,\n",
       "              6393: 154,\n",
       "              26876: 194,\n",
       "              8444: 162,\n",
       "              26878: 180,\n",
       "              6911: 150,\n",
       "              25856: 152,\n",
       "              21249: 152,\n",
       "              19717: 176,\n",
       "              8966: 190,\n",
       "              38150: 182,\n",
       "              26888: 226,\n",
       "              27917: 212,\n",
       "              39184: 192,\n",
       "              48401: 152,\n",
       "              24336: 170,\n",
       "              6416: 180,\n",
       "              23316: 152,\n",
       "              37144: 168,\n",
       "              31513: 200,\n",
       "              42266: 148,\n",
       "              29989: 156,\n",
       "              27434: 220,\n",
       "              45867: 190,\n",
       "              36139: 194,\n",
       "              29489: 182,\n",
       "              27443: 218,\n",
       "              27955: 188,\n",
       "              22838: 190,\n",
       "              7993: 170,\n",
       "              13114: 164,\n",
       "              13629: 198,\n",
       "              28991: 192,\n",
       "              40771: 182,\n",
       "              25413: 258,\n",
       "              44870: 180,\n",
       "              18247: 236,\n",
       "              47944: 208,\n",
       "              35657: 198,\n",
       "              26953: 214,\n",
       "              13651: 248,\n",
       "              27991: 228,\n",
       "              26456: 214,\n",
       "              48990: 188,\n",
       "              34655: 186,\n",
       "              16225: 158,\n",
       "              28518: 158,\n",
       "              20839: 212,\n",
       "              43367: 228,\n",
       "              10092: 192,\n",
       "              11116: 166,\n",
       "              31086: 176,\n",
       "              29040: 208,\n",
       "              50033: 158,\n",
       "              5490: 198,\n",
       "              39795: 218,\n",
       "              48505: 166,\n",
       "              40316: 196,\n",
       "              24958: 210,\n",
       "              38783: 132,\n",
       "              19838: 230,\n",
       "              23425: 156,\n",
       "              24962: 210,\n",
       "              13187: 192,\n",
       "              49028: 252,\n",
       "              12167: 174,\n",
       "              43406: 226,\n",
       "              14737: 172,\n",
       "              18322: 178,\n",
       "              43921: 188,\n",
       "              12694: 192,\n",
       "              16286: 174,\n",
       "              48545: 172,\n",
       "              29092: 140,\n",
       "              15273: 210,\n",
       "              16809: 190,\n",
       "              22455: 160,\n",
       "              24504: 214,\n",
       "              30140: 154,\n",
       "              27581: 168,\n",
       "              21438: 206,\n",
       "              35262: 192,\n",
       "              36292: 178,\n",
       "              6086: 162,\n",
       "              21960: 200,\n",
       "              20428: 214,\n",
       "              17361: 202,\n",
       "              33747: 172,\n",
       "              2516: 244,\n",
       "              13268: 414,\n",
       "              45014: 174,\n",
       "              25556: 196,\n",
       "              33240: 236,\n",
       "              36312: 218,\n",
       "              16863: 140,\n",
       "              28642: 204,\n",
       "              10213: 212,\n",
       "              16358: 192,\n",
       "              25062: 206,\n",
       "              23528: 190,\n",
       "              35307: 172,\n",
       "              19436: 176,\n",
       "              25579: 168,\n",
       "              15859: 178,\n",
       "              38900: 202,\n",
       "              7670: 206,\n",
       "              8698: 212,\n",
       "              12284: 184,\n",
       "              44542: 190,\n",
       "              31231: 198},\n",
       "             3: {50178: 238,\n",
       "              46600: 156,\n",
       "              31755: 182,\n",
       "              46604: 188,\n",
       "              10765: 196,\n",
       "              11276: 182,\n",
       "              33811: 174,\n",
       "              46612: 214,\n",
       "              16916: 218,\n",
       "              18966: 208,\n",
       "              12824: 172,\n",
       "              32794: 220,\n",
       "              7195: 162,\n",
       "              33821: 194,\n",
       "              37921: 246,\n",
       "              33313: 238,\n",
       "              31270: 172,\n",
       "              29222: 164,\n",
       "              28712: 186,\n",
       "              18985: 196,\n",
       "              37930: 180,\n",
       "              28200: 190,\n",
       "              7727: 184,\n",
       "              24112: 188,\n",
       "              36400: 226,\n",
       "              32817: 194,\n",
       "              5171: 180,\n",
       "              44085: 158,\n",
       "              35382: 202,\n",
       "              14912: 172,\n",
       "              30274: 184,\n",
       "              20554: 180,\n",
       "              15435: 148,\n",
       "              33357: 154,\n",
       "              49231: 158,\n",
       "              38994: 236,\n",
       "              21587: 200,\n",
       "              7252: 196,\n",
       "              40537: 194,\n",
       "              27738: 224,\n",
       "              44123: 154,\n",
       "              44124: 198,\n",
       "              14943: 168,\n",
       "              45664: 136,\n",
       "              15458: 222,\n",
       "              49765: 210,\n",
       "              19046: 210,\n",
       "              35944: 258,\n",
       "              29804: 176,\n",
       "              23662: 166,\n",
       "              37497: 160,\n",
       "              22138: 164,\n",
       "              27773: 270,\n",
       "              28798: 176,\n",
       "              33407: 202,\n",
       "              27264: 196,\n",
       "              9857: 216,\n",
       "              14468: 170,\n",
       "              6277: 172,\n",
       "              35972: 202,\n",
       "              4744: 216,\n",
       "              32905: 164,\n",
       "              32393: 206,\n",
       "              22671: 220,\n",
       "              20628: 176,\n",
       "              32920: 320,\n",
       "              17560: 200,\n",
       "              5119: 154,\n",
       "              21661: 174,\n",
       "              16543: 176,\n",
       "              31903: 246,\n",
       "              18089: 154,\n",
       "              16553: 158,\n",
       "              28331: 184,\n",
       "              41131: 214,\n",
       "              20145: 182,\n",
       "              46262: 210,\n",
       "              30397: 184,\n",
       "              41151: 256,\n",
       "              22723: 206,\n",
       "              23239: 212,\n",
       "              14538: 170,\n",
       "              17100: 168,\n",
       "              37073: 160,\n",
       "              22739: 228,\n",
       "              49365: 204,\n",
       "              16598: 190,\n",
       "              47831: 220,\n",
       "              31959: 218,\n",
       "              22234: 208,\n",
       "              23259: 176,\n",
       "              20189: 226,\n",
       "              45790: 194,\n",
       "              29927: 232,\n",
       "              46312: 194,\n",
       "              31465: 148,\n",
       "              46831: 174,\n",
       "              31472: 240,\n",
       "              29936: 146,\n",
       "              26355: 256,\n",
       "              6393: 146,\n",
       "              26876: 180,\n",
       "              8444: 230,\n",
       "              26878: 224,\n",
       "              6911: 176,\n",
       "              25856: 164,\n",
       "              21249: 194,\n",
       "              19717: 168,\n",
       "              8966: 146,\n",
       "              38150: 142,\n",
       "              26888: 194,\n",
       "              27917: 158,\n",
       "              39184: 148,\n",
       "              48401: 234,\n",
       "              24336: 170,\n",
       "              6416: 220,\n",
       "              23316: 176,\n",
       "              37144: 218,\n",
       "              31513: 208,\n",
       "              42266: 188,\n",
       "              29989: 168,\n",
       "              27434: 160,\n",
       "              45867: 206,\n",
       "              36139: 272,\n",
       "              29489: 208,\n",
       "              27443: 176,\n",
       "              27955: 204,\n",
       "              22838: 196,\n",
       "              7993: 246,\n",
       "              13114: 166,\n",
       "              13629: 192,\n",
       "              28991: 158,\n",
       "              40771: 204,\n",
       "              25413: 208,\n",
       "              44870: 188,\n",
       "              18247: 170,\n",
       "              47944: 164,\n",
       "              35657: 182,\n",
       "              26953: 154,\n",
       "              13651: 178,\n",
       "              27991: 200,\n",
       "              26456: 146,\n",
       "              48990: 192,\n",
       "              34655: 198,\n",
       "              16225: 222,\n",
       "              28518: 154,\n",
       "              20839: 204,\n",
       "              43367: 206,\n",
       "              10092: 216,\n",
       "              11116: 220,\n",
       "              31086: 192,\n",
       "              29040: 242,\n",
       "              50033: 182,\n",
       "              5490: 168,\n",
       "              39795: 214,\n",
       "              48505: 174,\n",
       "              40316: 196,\n",
       "              24958: 176,\n",
       "              38783: 184,\n",
       "              19838: 196,\n",
       "              23425: 178,\n",
       "              24962: 182,\n",
       "              13187: 218,\n",
       "              49028: 170,\n",
       "              12167: 224,\n",
       "              43406: 182,\n",
       "              14737: 224,\n",
       "              18322: 162,\n",
       "              43921: 170,\n",
       "              12694: 140,\n",
       "              16286: 176,\n",
       "              48545: 192,\n",
       "              29092: 172,\n",
       "              15273: 172,\n",
       "              16809: 152,\n",
       "              22455: 140,\n",
       "              24504: 150,\n",
       "              30140: 250,\n",
       "              27581: 162,\n",
       "              21438: 174,\n",
       "              35262: 208,\n",
       "              36292: 202,\n",
       "              6086: 170,\n",
       "              21960: 138,\n",
       "              20428: 206,\n",
       "              17361: 178,\n",
       "              33747: 188,\n",
       "              2516: 160,\n",
       "              13268: 340,\n",
       "              45014: 200,\n",
       "              25556: 180,\n",
       "              33240: 192,\n",
       "              36312: 180,\n",
       "              16863: 192,\n",
       "              28642: 174,\n",
       "              10213: 192,\n",
       "              16358: 200,\n",
       "              25062: 176,\n",
       "              23528: 154,\n",
       "              35307: 196,\n",
       "              19436: 176,\n",
       "              25579: 198,\n",
       "              15859: 194,\n",
       "              38900: 220,\n",
       "              7670: 188,\n",
       "              8698: 182,\n",
       "              12284: 212,\n",
       "              44542: 176,\n",
       "              31231: 228},\n",
       "             4: {50178: 160,\n",
       "              46600: 194,\n",
       "              31755: 158,\n",
       "              46604: 180,\n",
       "              10765: 204,\n",
       "              11276: 204,\n",
       "              33811: 162,\n",
       "              46612: 240,\n",
       "              16916: 170,\n",
       "              18966: 246,\n",
       "              12824: 198,\n",
       "              32794: 164,\n",
       "              7195: 182,\n",
       "              33821: 172,\n",
       "              37921: 162,\n",
       "              33313: 220,\n",
       "              31270: 208,\n",
       "              29222: 130,\n",
       "              28712: 168,\n",
       "              18985: 172,\n",
       "              37930: 196,\n",
       "              28200: 206,\n",
       "              7727: 128,\n",
       "              24112: 204,\n",
       "              36400: 216,\n",
       "              32817: 210,\n",
       "              5171: 184,\n",
       "              44085: 232,\n",
       "              35382: 200,\n",
       "              14912: 162,\n",
       "              30274: 224,\n",
       "              20554: 150,\n",
       "              15435: 210,\n",
       "              33357: 158,\n",
       "              49231: 212,\n",
       "              38994: 212,\n",
       "              21587: 190,\n",
       "              7252: 144,\n",
       "              40537: 212,\n",
       "              27738: 236,\n",
       "              44123: 206,\n",
       "              44124: 212,\n",
       "              14943: 190,\n",
       "              45664: 208,\n",
       "              15458: 232,\n",
       "              49765: 202,\n",
       "              19046: 222,\n",
       "              35944: 198,\n",
       "              29804: 170,\n",
       "              23662: 184,\n",
       "              37497: 190,\n",
       "              22138: 220,\n",
       "              27773: 190,\n",
       "              28798: 172,\n",
       "              33407: 148,\n",
       "              27264: 190,\n",
       "              9857: 124,\n",
       "              14468: 182,\n",
       "              6277: 190,\n",
       "              35972: 166,\n",
       "              4744: 206,\n",
       "              32905: 198,\n",
       "              32393: 186,\n",
       "              22671: 208,\n",
       "              20628: 188,\n",
       "              32920: 380,\n",
       "              17560: 178,\n",
       "              5119: 108,\n",
       "              21661: 246,\n",
       "              16543: 164,\n",
       "              31903: 188,\n",
       "              18089: 180,\n",
       "              16553: 204,\n",
       "              28331: 206,\n",
       "              41131: 178,\n",
       "              20145: 168,\n",
       "              46262: 184,\n",
       "              30397: 212,\n",
       "              41151: 194,\n",
       "              22723: 202,\n",
       "              23239: 182,\n",
       "              14538: 198,\n",
       "              17100: 228,\n",
       "              37073: 192,\n",
       "              22739: 228,\n",
       "              49365: 172,\n",
       "              16598: 168,\n",
       "              47831: 188,\n",
       "              31959: 172,\n",
       "              22234: 178,\n",
       "              23259: 206,\n",
       "              20189: 162,\n",
       "              45790: 232,\n",
       "              29927: 214,\n",
       "              46312: 224,\n",
       "              31465: 214,\n",
       "              46831: 188,\n",
       "              31472: 204,\n",
       "              29936: 138,\n",
       "              26355: 160,\n",
       "              6393: 204,\n",
       "              26876: 210,\n",
       "              8444: 172,\n",
       "              26878: 158,\n",
       "              6911: 144,\n",
       "              25856: 140,\n",
       "              21249: 132,\n",
       "              19717: 154,\n",
       "              8966: 196,\n",
       "              38150: 200,\n",
       "              26888: 212,\n",
       "              27917: 198,\n",
       "              39184: 190,\n",
       "              48401: 150,\n",
       "              24336: 160,\n",
       "              6416: 176,\n",
       "              23316: 154,\n",
       "              37144: 176,\n",
       "              31513: 206,\n",
       "              42266: 142,\n",
       "              29989: 142,\n",
       "              27434: 218,\n",
       "              45867: 156,\n",
       "              36139: 210,\n",
       "              29489: 180,\n",
       "              27443: 206,\n",
       "              27955: 190,\n",
       "              22838: 210,\n",
       "              7993: 170,\n",
       "              13114: 176,\n",
       "              13629: 190,\n",
       "              28991: 182,\n",
       "              40771: 176,\n",
       "              25413: 240,\n",
       "              44870: 192,\n",
       "              18247: 214,\n",
       "              47944: 200,\n",
       "              35657: 184,\n",
       "              26953: 212,\n",
       "              13651: 194,\n",
       "              27991: 222,\n",
       "              26456: 220,\n",
       "              48990: 162,\n",
       "              34655: 202,\n",
       "              16225: 166,\n",
       "              28518: 152,\n",
       "              20839: 220,\n",
       "              43367: 194,\n",
       "              10092: 180,\n",
       "              11116: 174,\n",
       "              31086: 170,\n",
       "              29040: 220,\n",
       "              50033: 172,\n",
       "              5490: 214,\n",
       "              39795: 212,\n",
       "              48505: 154,\n",
       "              40316: 198,\n",
       "              24958: 198,\n",
       "              38783: 172,\n",
       "              19838: 204,\n",
       "              23425: 184,\n",
       "              24962: 220,\n",
       "              13187: 192,\n",
       "              49028: 226,\n",
       "              12167: 168,\n",
       "              43406: 248,\n",
       "              14737: 152,\n",
       "              18322: 206,\n",
       "              43921: 190,\n",
       "              12694: 172,\n",
       "              16286: 158,\n",
       "              48545: 154,\n",
       "              29092: 152,\n",
       "              15273: 174,\n",
       "              16809: 208,\n",
       "              22455: 184,\n",
       "              24504: 218,\n",
       "              30140: 168,\n",
       "              27581: 168,\n",
       "              21438: 206,\n",
       "              35262: 160,\n",
       "              36292: 164,\n",
       "              6086: 196,\n",
       "              21960: 202,\n",
       "              20428: 200,\n",
       "              17361: 190,\n",
       "              33747: 184,\n",
       "              2516: 250,\n",
       "              13268: 394,\n",
       "              45014: 200,\n",
       "              25556: 174,\n",
       "              33240: 220,\n",
       "              36312: 206,\n",
       "              16863: 174,\n",
       "              28642: 210,\n",
       "              10213: 218,\n",
       "              16358: 176,\n",
       "              25062: 218,\n",
       "              23528: 190,\n",
       "              35307: 184,\n",
       "              19436: 184,\n",
       "              25579: 190,\n",
       "              15859: 190,\n",
       "              38900: 242,\n",
       "              7670: 198,\n",
       "              8698: 208,\n",
       "              12284: 210,\n",
       "              44542: 196,\n",
       "              31231: 200}})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd58f192-1209-4e50-91ed-6fae7bc1b021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9901, 0.9901, 1.0000, 0.4752, 0.4752],\n",
       "        [1.0000, 1.0000, 0.9901, 0.6040, 0.5842],\n",
       "        [0.9802, 1.0000, 0.9901, 0.4455, 0.3861]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_correct_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "88a02596-53c9-4a4c-a6bf-512407cd28b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 120000/120000 [00:21<00:00, 5461.76it/s]\n",
      "100%|| 120000/120000 [00:22<00:00, 5441.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [07:02<00:00,  1.06s/it]\n",
      "100%|| 400/400 [07:02<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position 0 layer 39 acc 1.0\n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [07:04<00:00,  1.06s/it]\n",
      "100%|| 400/400 [07:02<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position 1 layer 39 acc 1.0\n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [07:03<00:00,  1.06s/it]\n",
      " 28%|                                                          | 110/400 [01:57<05:08,  1.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 148\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m#del X\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#del Y\u001b[39;00m\n\u001b[1;32m    147\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m--> 148\u001b[0m vX, vY \u001b[38;5;241m=\u001b[39m \u001b[43mget_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvdata_name_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m pY \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mpredict(vX)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# we want cosine similarity to actual embedding vectors\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m#avg_sim = cosine_similarity(pY, vY).mean().item()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[133], line 132\u001b[0m, in \u001b[0;36mget_training_data\u001b[0;34m(dat, name_positions, batch_size)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_end\u001b[38;5;241m-\u001b[39mbatch_start):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m#print(ssm_inputs[batch_i, position].size())\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     position \u001b[38;5;241m=\u001b[39m positions[batch_i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# +1 because conv\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     bX \u001b[38;5;241m=\u001b[39m \u001b[43mget_linear_classification_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(bX)\n\u001b[1;32m    134\u001b[0m     Y\u001b[38;5;241m.\u001b[39mappend(name_tokens[batch_i]\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[133], line 102\u001b[0m, in \u001b[0;36mget_linear_classification_X\u001b[0;34m(activations, layer, batch_i, position_x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_linear_classification_X\u001b[39m(activations, layer, batch_i, position_x):\n\u001b[0;32m--> 102\u001b[0m     vec \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblocks.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.hook_ssm_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43mposition_x\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (vec \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(vec, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m divTerm)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "# we want to predict the name from the representation\n",
    "# there are two ways to do this:\n",
    "# 1. Predict the probability of a rep being a name (output logits for each name)\n",
    "# 2. Output the name embedding\n",
    "# we'll start with the second one because it is more general, if that doesn't work we can try the first one\n",
    "\n",
    "\n",
    "# we're basically doing a tuned lens sorta? idk\n",
    "# lets start with not batched\n",
    "\n",
    "# okay so say we are trying to output the name embedding\n",
    "# on layer i, that could mean:\n",
    "#    predict emb after it's projected into E space (which is after norm, but before conv)\n",
    "#    predict emb after conv\n",
    "#    predict emb after conv and silu\n",
    "#    predict emb from hidden state or some other internal rep\n",
    "# the point is that we train this linear map for some specific thing, then how well it performs suggests how well that thing encodes our data,\n",
    "# so we can try it for lots of intermediate stuff\n",
    "# some of the maps won't work, that's ok\n",
    "from mamba_lens.input_dependent_hooks import clean_hooks\n",
    "import torch\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from jaxtyping import Float\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "# this is useful because sometimes if you spam ctrl-c too many times some hooks will stay around\n",
    "clean_hooks(model)\n",
    "\n",
    "# make sure we have no overlap\n",
    "#joined_data = torch.cat([data.data, data.valid_data], dim=0)\n",
    "#torch.sort(joined_data, dim=0)\n",
    "#unique = torch.unique(joined_data, dim=0)\n",
    "#torch.manual_seed(27)\n",
    "# shuffle data\n",
    "#unique = unique[torch.randperm(unique.size()[0])]\n",
    "#B = unique.size()[0]//3\n",
    "# split into train valid and test\n",
    "#dataset, vdataset, tdataset = unique[:B], unique[B:2*B], unique[2*B:3*B]\n",
    "dataset = data.data\n",
    "vdataset = data.valid_data\n",
    "\n",
    "\n",
    "\n",
    "from acdc.data.ioi import good_names\n",
    "from collections import defaultdict\n",
    "name_tokens = set([model.to_single_token(\" \" + name) for name in good_names])\n",
    "\n",
    "\n",
    "name_tok_to_class = {}\n",
    "for i, tok in enumerate(sorted(list(name_tokens))):\n",
    "    name_tok_to_class[tok] = i\n",
    "\n",
    "def get_name_positions(dat):\n",
    "    name_positions = defaultdict(lambda: [])\n",
    "    for i in tqdm(list(range(dat.size()[0]))):\n",
    "        prompt_tokens = dat[i]\n",
    "        name_pos = 0\n",
    "        for i, tok in enumerate(prompt_tokens):\n",
    "            if tok.item() in name_tokens:\n",
    "                name_positions[name_pos].append(i)\n",
    "                name_pos += 1\n",
    "        if name_pos != 5: raise ValueError(f\"data point {model.to_str_tokens(data)} does not have 5 names\")\n",
    "    return name_positions\n",
    "\n",
    "data_name_positions, vdata_name_positions = get_name_positions(dataset), get_name_positions(vdataset)\n",
    "\n",
    "model_kwargs = {\n",
    "    \"fast_ssm\": True,\n",
    "    \"fast_conv\": True,\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 300\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "B,L = dataset.size()\n",
    "\n",
    "# for each position that varies, for each other position, fit a linear model\n",
    "\n",
    "global probing_dataset_X\n",
    "probing_dataset_X = []\n",
    "def dataset_gathering_hook(\n",
    "    x: Float[torch.Tensor, \"B L D\"],\n",
    "    hook: HookPoint,\n",
    "    position: int\n",
    "):\n",
    "    global probing_dataset_X\n",
    "    probing_dataset_X.append(x[:,position,:].cpu())\n",
    "    return x\n",
    "\n",
    "layer = 39\n",
    "\n",
    "linear_models = []\n",
    "E = model.cfg.E\n",
    "divTerm = float(math.sqrt(math.sqrt(float(E))*E))\n",
    "for name_i in range(5):\n",
    "    \n",
    "    # make dataset\n",
    "    \n",
    "    def get_linear_classification_X(activations, layer, batch_i, position_x):\n",
    "        vec = activations[f'blocks.{layer}.hook_ssm_input'][batch_i,position_x].view(-1)\n",
    "        return (vec / torch.linalg.norm(vec, ord=2) / divTerm).view(1,-1).detach().cpu().numpy()\n",
    "\n",
    "    def get_linear_classification_Y(labels):\n",
    "        B = labels.size()[0]\n",
    "        Y = np.zeros([B,len(name_tokens)])\n",
    "        #Y = model.embedding.weight[input_data[:,position_y]]\n",
    "        #return Y.detach().cpu().numpy()\n",
    "        Y[:] = -1 # predict a vector with -1 for incorrect class and 1 for correct class\n",
    "        for i in range(B):\n",
    "            value = labels[i].item()\n",
    "            Y[i,name_tok_to_class[value]] = 1\n",
    "        return Y/math.sqrt(float(model.cfg.E))\n",
    "    \n",
    "    names_filter = [f'blocks.{layer}.hook_ssm_input']\n",
    "    \n",
    "    print(f\"collecting data...\")\n",
    "\n",
    "    def get_training_data(dat, name_positions, batch_size):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for batch_start in tqdm(list(range(0, dat.size()[0], batch_size))):\n",
    "            batch_end = min(batch_start + batch_size, dataset.size()[0])\n",
    "            data_batch = dat[batch_start:batch_end]\n",
    "            positions = torch.tensor(name_positions[name_i][batch_start:batch_end], device=model.cfg.device)\n",
    "            name_tokens = data_batch[torch.arange(batch_end-batch_start),positions]\n",
    "            logits, activations = model.run_with_cache(data_batch, names_filter=names_filter, **model_kwargs)\n",
    "            for batch_i in range(batch_end-batch_start):\n",
    "                #print(ssm_inputs[batch_i, position].size())\n",
    "                position = positions[batch_i] + 1 # +1 because conv\n",
    "                bX = get_linear_classification_X(activations=activations, layer=layer, batch_i=batch_i, position_x=position)\n",
    "                X.append(bX)\n",
    "                Y.append(name_tokens[batch_i].item())\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        Y = torch.tensor(Y)\n",
    "        Y = get_linear_classification_Y(labels=Y)\n",
    "        return X, Y\n",
    "\n",
    "    X, Y = get_training_data(dat=dataset, name_positions=data_name_positions, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X, Y)\n",
    "    linear_models.append(linear_model)\n",
    "    #del X\n",
    "    #del Y\n",
    "    torch.cuda.empty_cache()\n",
    "    vX, vY = get_training_data(dat=vdataset, name_positions=vdata_name_positions, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    pY = linear_model.predict(vX)\n",
    "    # we want cosine similarity to actual embedding vectors\n",
    "    #avg_sim = cosine_similarity(pY, vY).mean().item()\n",
    "    predicted_inds = np.argmax(pY, axis=1)\n",
    "    actual_inds = np.argmax(vY, axis=1)\n",
    "    acc = np.sum(predicted_inds==actual_inds)/float(predicted_inds.shape[0])\n",
    "    print(f\"position {name_i} layer {layer} acc {acc}\")\n",
    "    #outpaut_accuracies[position_i, layer, other_position] = avg_sim\n",
    "\n",
    "print(f\"these token positions vary their value: {positions_that_vary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "43e19606-dde4-49fc-840e-8cd3c035e560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "470a3314-2d8d-4337-9f01-28af455ab120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div term 304.4370214406966\n",
      "worst case mag 5.129492386402035e-10\n",
      "div term 304.4370214406966\n",
      "worst case mag 5.129643376733384e-10\n",
      "div term 304.4370214406966\n",
      "worst case mag 5.129641711398847e-10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "np.random.seed(27)\n",
    "\n",
    "class NameBasis(object):\n",
    "    def __init__(self, linear_model):\n",
    "        self.linear_model = linear_model\n",
    "        #       [C,E] [E,1] [C] [C]\n",
    "        # we have A  @  x  + b = y which is -1 for not name and 1 for name\n",
    "        # we want a V s.t.\n",
    "        #       [E,E] [E,1] [E]  [E]\n",
    "        #         V  @  x  + d =  y\n",
    "        # where V is invertible so\n",
    "        #        [E]   [E,E]    [E] [E]\n",
    "        #         x  = V^-1  @  (y - d)\n",
    "        # and\n",
    "        #          [C,E]    [E,1]     [C]\n",
    "        #        V[:C,:]  @   x   +  d[:C] =\n",
    "        #            A                 b\n",
    "        # the simplest way to do this is to set those extra bias terms to zero\n",
    "        # and those extra rows to normally distributed random values\n",
    "        # (with high pr the matrix should be invertible as long as first C aren't linearly dependent)\n",
    "        A = linear_model.coef_\n",
    "        b = linear_model.intercept_\n",
    "        C,E = A.shape\n",
    "        self.E = E\n",
    "        d = np.zeros([E])\n",
    "        d[:C] = b\n",
    "        V = np.random.randn(E,E)\n",
    "        V[:C] = A\n",
    "        # normalize rows to help it be more well behaved\n",
    "        # actually if they are normalized, the input is normalized so output values\n",
    "        # go from -1 to 1\n",
    "        # but that's too big, that means output norm is sqrt(E)\n",
    "        # what we want is norm of result is 1\n",
    "        # each row should be magnitude 1/sqrt(E)\n",
    "        # if input is also size 1/sqrt(E) then dot product gives us\n",
    "        # ((-1,1)*1/sqrt(E)*1/sqrt(E) which is (-1/E,1/E)\n",
    "        # which would give us sqrt(E*E^2) = E^3/2 which is not unit\n",
    "        # we have mag1 mag2 and dot product gives\n",
    "        # mag1*mag2\n",
    "        # and magnitude gives\n",
    "        # sqrt(E*mag1^2*mag2^2) = sqrt(E)*mag1*mag2\n",
    "        # we want this to be 1, so\n",
    "        # 1 = sqrt(E)*mag1*mag2\n",
    "        # assume mag=mag1=mag2\n",
    "        # 1 = sqrt(E)*mag^2\n",
    "        # 1/sqrt(E) = mag^2\n",
    "        # 1/sqrt(sqrt(E)) = mag\n",
    "        # lets double check that\n",
    "        # consider 111111 vector\n",
    "        # when we divide by 1/sqrt(sqrt(E)) we get lots of terms of \n",
    "        # we have two vectors each full of 1/sqrt(sqrt(E)) terms\n",
    "        # dot product will give lots of\n",
    "        # E*(1/sqrt(sqrt(E)))*(1/sqrt(sqrt(E)))\n",
    "        # E*1/sqrt(E)\n",
    "        # The magnitude of that is\n",
    "        # sqrt(E*(E^2/E)) = E\n",
    "        # not what we want\n",
    "        # okay so we have a matrix full of 1/v\n",
    "        # we dot product each row with another vector full of 1/v\n",
    "        # each entry in result is E*1/v^2\n",
    "        # So total magnitude is\n",
    "        # sqrt(E*(E^2/v^4))\n",
    "        # = sqrt(E)*E/v^2\n",
    "        # we want this to be 1\n",
    "        # thus\n",
    "        # 1 = sqrt(E)*E/v^2\n",
    "        # v^2 = sqrt(E)*E\n",
    "        # v = sqrt(sqrt(E)*E)\n",
    "        # lets double check that\n",
    "        # E*1/sqrt(sqrt(E)*E)*1/sqrt(sqrt(E)*E) is each term\n",
    "        # E*1/sqrt(E)*1/E\n",
    "        # 1/sqrt(E) is each term in the result\n",
    "        # sqrt(E*1/E) = sqrt(1) nice!\n",
    "        self.divTerm = float(math.sqrt(math.sqrt(float(E))*E))\n",
    "        print(\"div term\", self.divTerm)\n",
    "        for row in range(C,E):\n",
    "            vrow = V[row]\n",
    "            V[row] = vrow / np.linalg.norm(vrow, ord=2) / self.divTerm\n",
    "        V_inv = np.linalg.inv(V)\n",
    "        \n",
    "        self.d = torch.tensor(d, device=model.cfg.device, dtype=torch.double)\n",
    "        self.V = torch.tensor(V, device=model.cfg.device, dtype=torch.double)\n",
    "        self.V_inv = torch.tensor(V_inv, device=model.cfg.device, dtype=torch.double)\n",
    "        # test to make sure it's invertible\n",
    "        mags = []\n",
    "        for i in range(200):\n",
    "            x = torch.tensor(vX[i] / np.linalg.norm(vX[i], ord=2) / self.divTerm, device=model.cfg.device)\n",
    "            coords = self.map_to_coords(x)\n",
    "            backx = self.map_from_coords(coords)\n",
    "            mags.append(torch.linalg.norm(x-backx, dim=0, ord=2))\n",
    "        print(f\"worst case mag {torch.max(torch.tensor(mags))}\")\n",
    "    \n",
    "    def map_to_coords(self, vec):\n",
    "        vec = vec.double() / torch.linalg.norm(vec, ord=2) / self.divTerm\n",
    "        return ((self.V @ vec.view(self.E, 1))[:,0] + self.d)\n",
    "\n",
    "    def map_from_coords(self, coords):\n",
    "        return (self.V_inv @ (coords - self.d).view(self.E, 1))[:,0].float()        \n",
    "\n",
    "\n",
    "name_bases = [NameBasis(linear_model) for linear_model in linear_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8db46432-3422-47fc-9698-78ccba2ddf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 64 0.022097047994478453\n",
      "answer 64 replace 142\n",
      "now predict 142 0.0692\n",
      "orig norm 12.99548053741455 patched norm 0.03652969002723694\n",
      "now orig norm 12.99548053741455 patched norm 0.03652969002723694\n",
      "predict2 tensor([-0.0587, -0.0574, -0.0569, -0.0519, -0.0513], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05125618186332083\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 11 0.022097061885368433\n",
      "answer 11 replace 89\n",
      "now predict 89 0.0692\n",
      "orig norm 12.534335136413574 patched norm 0.055888831615448\n",
      "now orig norm 12.534335136413574 patched norm 0.055888831615448\n",
      "predict2 tensor([-0.0600, -0.0586, -0.0581, -0.0529, -0.0523], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05225413532630422\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 93 0.022097002536668964\n",
      "answer 93 replace 158\n",
      "now predict 158 0.0692\n",
      "orig norm 13.534789085388184 patched norm 0.045756228268146515\n",
      "now orig norm 13.534789085388184 patched norm 0.045756228268146515\n",
      "predict2 tensor([-0.0581, -0.0576, -0.0536, -0.0525, -0.0518], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.051837118497471676\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 19 0.022097302282511305\n",
      "answer 19 replace 206\n",
      "now predict 206 0.0692\n",
      "orig norm 12.201866149902344 patched norm 0.03150026872754097\n",
      "now orig norm 12.201866149902344 patched norm 0.03150026872754097\n",
      "predict2 tensor([-0.0582, -0.0569, -0.0564, -0.0514, -0.0508], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05079615225024685\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 58 0.022096914788549443\n",
      "answer 58 replace 208\n",
      "now predict 208 0.0692\n",
      "orig norm 13.41019344329834 patched norm 0.09869207441806793\n",
      "now orig norm 13.41019344329834 patched norm 0.09869207441806793\n",
      "predict2 tensor([-0.0610, -0.0596, -0.0591, -0.0537, -0.0531], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05307084299107048\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 7 0.02209717254580755\n",
      "answer 7 replace 186\n",
      "now predict 186 0.0692\n",
      "orig norm 12.462011337280273 patched norm 0.10216479748487473\n",
      "now orig norm 12.462011337280273 patched norm 0.10216479748487473\n",
      "predict2 tensor([-0.0611, -0.0597, -0.0591, -0.0538, -0.0531], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05310708759271408\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 35 0.022097118221772766\n",
      "answer 35 replace 29\n",
      "now predict 29 0.0692\n",
      "orig norm 12.580636978149414 patched norm 0.04933926463127136\n",
      "now orig norm 12.580636978149414 patched norm 0.04933926463127136\n",
      "predict2 tensor([-0.0597, -0.0583, -0.0578, -0.0526, -0.0520], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05200416112619839\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 122 0.02209708753847693\n",
      "answer 122 replace 50\n",
      "now predict 50 0.0692\n",
      "orig norm 12.62678050994873 patched norm 0.04884419962763786\n",
      "now orig norm 12.62678050994873 patched norm 0.04884419962763786\n",
      "predict2 tensor([-0.0596, -0.0583, -0.0578, -0.0526, -0.0520], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05198255350288887\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 172 0.022096956785928767\n",
      "answer 172 replace 8\n",
      "now predict 8 0.0692\n",
      "orig norm 13.72957706451416 patched norm 0.03637801110744476\n",
      "now orig norm 13.72957706451416 patched norm 0.03637801110744476\n",
      "predict2 tensor([-0.0587, -0.0574, -0.0569, -0.0518, -0.0512], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.051244164191360145\n",
      "10\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 77 0.022097117374185127\n",
      "answer 77 replace 18\n",
      "now predict 18 0.0692\n",
      "orig norm 13.64716625213623 patched norm 0.05106676369905472\n",
      "now orig norm 13.64716625213623 patched norm 0.05106676369905472\n",
      "predict2 tensor([-0.0598, -0.0584, -0.0579, -0.0527, -0.0521], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05207631043408074\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 7 0.02209707773069504\n",
      "answer 7 replace 84\n",
      "now predict 84 0.0692\n",
      "orig norm 12.243758201599121 patched norm 0.09266592562198639\n",
      "now orig norm 12.243758201599121 patched norm 0.09266592562198639\n",
      "predict2 tensor([-0.0609, -0.0596, -0.0590, -0.0536, -0.0530], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.053001491131641904\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 203 0.022097122486544246\n",
      "answer 203 replace 30\n",
      "now predict 30 0.0692\n",
      "orig norm 12.228135108947754 patched norm 0.059634048491716385\n",
      "now orig norm 12.228135108947754 patched norm 0.059634048491716385\n",
      "predict2 tensor([-0.0601, -0.0588, -0.0583, -0.0530, -0.0524], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05237239209410348\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 35 0.02209703145746189\n",
      "answer 35 replace 98\n",
      "now predict 98 0.0692\n",
      "orig norm 13.566959381103516 patched norm 0.07336187362670898\n",
      "now orig norm 13.566959381103516 patched norm 0.07336187362670898\n",
      "predict2 tensor([-0.0592, -0.0587, -0.0569, -0.0533, -0.0527], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05270263793999732\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 28 0.022096957527709488\n",
      "answer 28 replace 49\n",
      "now predict 49 0.0692\n",
      "orig norm 13.298748970031738 patched norm 0.030373698100447655\n",
      "now orig norm 13.298748970031738 patched norm 0.030373698100447655\n",
      "predict2 tensor([-0.0580, -0.0567, -0.0562, -0.0513, -0.0507], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.050672249665719635\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 156 0.022096854690208542\n",
      "answer 156 replace 197\n",
      "now predict 197 0.0692\n",
      "orig norm 12.739072799682617 patched norm 0.033943817019462585\n",
      "now orig norm 12.739072799682617 patched norm 0.033943817019462585\n",
      "predict2 tensor([-0.0587, -0.0585, -0.0572, -0.0516, -0.0510], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05103669504104654\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 167 0.022096872539279153\n",
      "answer 167 replace 15\n",
      "now predict 15 0.0692\n",
      "orig norm 14.231318473815918 patched norm 0.03395983204245567\n",
      "now orig norm 14.231318473815918 patched norm 0.03395983204245567\n",
      "predict2 tensor([-0.0585, -0.0572, -0.0567, -0.0516, -0.0510], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05103818430580599\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 174 0.022097271099656618\n",
      "answer 174 replace 79\n",
      "now predict 79 0.0692\n",
      "orig norm 13.145578384399414 patched norm 0.06257270276546478\n",
      "now orig norm 13.145578384399414 patched norm 0.06257270276546478\n",
      "predict2 tensor([-0.0602, -0.0589, -0.0584, -0.0531, -0.0525], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052455283824158934\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 7 0.02209707773069504\n",
      "answer 7 replace 84\n",
      "now predict 84 0.0692\n",
      "orig norm 12.243758201599121 patched norm 0.09266592562198639\n",
      "now orig norm 12.243758201599121 patched norm 0.09266592562198639\n",
      "predict2 tensor([-0.0609, -0.0596, -0.0590, -0.0536, -0.0530], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.053001491131641904\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 199 0.02209724353979084\n",
      "answer 199 replace 131\n",
      "now predict 131 0.0692\n",
      "orig norm 14.04427719116211 patched norm 0.07325658947229385\n",
      "now orig norm 14.04427719116211 patched norm 0.07325658947229385\n",
      "predict2 tensor([-0.0605, -0.0592, -0.0587, -0.0533, -0.0527], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05270057069875714\n",
      "20\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 204 0.02209683416908803\n",
      "answer 204 replace 186\n",
      "now predict 186 0.0692\n",
      "orig norm 13.081708908081055 patched norm 0.04935765638947487\n",
      "now orig norm 13.081708908081055 patched norm 0.04935765638947487\n",
      "predict2 tensor([-0.0597, -0.0583, -0.0578, -0.0526, -0.0520], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.0520049653946842\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 129 0.022097173127301556\n",
      "answer 129 replace 88\n",
      "now predict 88 0.0692\n",
      "orig norm 12.616907119750977 patched norm 0.03176454082131386\n",
      "now orig norm 12.616907119750977 patched norm 0.03176454082131386\n",
      "predict2 tensor([-0.0569, -0.0564, -0.0514, -0.0508, -0.0496], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 88 -0.04964919949805584\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 138 0.02209661489592664\n",
      "answer 138 replace 133\n",
      "now predict 133 0.0692\n",
      "orig norm 14.489544868469238 patched norm 0.09219486266374588\n",
      "now orig norm 14.489544868469238 patched norm 0.09219486266374588\n",
      "predict2 tensor([-0.0609, -0.0595, -0.0590, -0.0536, -0.0530], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05299569267880054\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 85 0.02209728887617972\n",
      "answer 85 replace 55\n",
      "now predict 55 0.0692\n",
      "orig norm 14.880778312683105 patched norm 0.10456843674182892\n",
      "now orig norm 14.880778312683105 patched norm 0.10456843674182892\n",
      "predict2 tensor([-0.0611, -0.0597, -0.0592, -0.0538, -0.0531], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05313076203024161\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 117 0.022096881701393067\n",
      "answer 117 replace 54\n",
      "now predict 54 0.0692\n",
      "orig norm 13.68354606628418 patched norm 0.047412797808647156\n",
      "now orig norm 13.68354606628418 patched norm 0.047412797808647156\n",
      "predict2 tensor([-0.0596, -0.0582, -0.0577, -0.0525, -0.0519], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05191749358699141\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 130 0.022097133278228542\n",
      "answer 130 replace 161\n",
      "now predict 161 0.0692\n",
      "orig norm 13.408074378967285 patched norm 0.07232484966516495\n",
      "now orig norm 13.408074378967285 patched norm 0.07232484966516495\n",
      "predict2 tensor([-0.0605, -0.0592, -0.0586, -0.0533, -0.0527], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05268206394268285\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 143 0.022096948874700123\n",
      "answer 143 replace 80\n",
      "now predict 80 0.0692\n",
      "orig norm 14.593806266784668 patched norm 0.039714451879262924\n",
      "now orig norm 14.593806266784668 patched norm 0.039714451879262924\n",
      "predict2 tensor([-0.0590, -0.0577, -0.0572, -0.0521, -0.0515], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.051487219957164786\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 181 0.022097252404277\n",
      "answer 181 replace 146\n",
      "now predict 146 0.0692\n",
      "orig norm 13.730018615722656 patched norm 0.03392760828137398\n",
      "now orig norm 13.730018615722656 patched norm 0.03392760828137398\n",
      "predict2 tensor([-0.0585, -0.0572, -0.0567, -0.0516, -0.0510], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.051035202596055596\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 203 0.022097129206051475\n",
      "answer 203 replace 157\n",
      "now predict 157 0.0692\n",
      "orig norm 12.650960922241211 patched norm 0.04518437385559082\n",
      "now orig norm 12.650960922241211 patched norm 0.04518437385559082\n",
      "predict2 tensor([-0.0594, -0.0581, -0.0576, -0.0524, -0.0518], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05180800825441402\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 90 0.02209716035332135\n",
      "answer 90 replace 132\n",
      "now predict 132 0.0692\n",
      "orig norm 12.449385643005371 patched norm 0.07634842395782471\n",
      "now orig norm 12.449385643005371 patched norm 0.07634842395782471\n",
      "predict2 tensor([-0.0606, -0.0593, -0.0587, -0.0534, -0.0528], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05275875139269322\n",
      "30\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 164 0.02209711816171446\n",
      "answer 164 replace 109\n",
      "now predict 109 0.0692\n",
      "orig norm 13.362958908081055 patched norm 0.07676385343074799\n",
      "now orig norm 13.362958908081055 patched norm 0.07676385343074799\n",
      "predict2 tensor([-0.0606, -0.0593, -0.0587, -0.0534, -0.0528], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05276621043586287\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 184 0.02209726268045116\n",
      "answer 184 replace 41\n",
      "now predict 41 0.0692\n",
      "orig norm 14.042174339294434 patched norm 0.032766371965408325\n",
      "now orig norm 14.042174339294434 patched norm 0.032766371965408325\n",
      "predict2 tensor([-0.0581, -0.0570, -0.0565, -0.0515, -0.0509], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05092526532802672\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 78 0.0220970946376276\n",
      "answer 78 replace 65\n",
      "now predict 65 0.0692\n",
      "orig norm 12.919561386108398 patched norm 0.061074648052453995\n",
      "now orig norm 12.919561386108398 patched norm 0.061074648052453995\n",
      "predict2 tensor([-0.0602, -0.0588, -0.0583, -0.0530, -0.0524], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05241401897184473\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 58 0.022096914788549443\n",
      "answer 58 replace 154\n",
      "now predict 154 0.0692\n",
      "orig norm 13.41019344329834 patched norm 0.09153170883655548\n",
      "now orig norm 13.41019344329834 patched norm 0.09153170883655548\n",
      "predict2 tensor([-0.0609, -0.0595, -0.0590, -0.0536, -0.0530], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052987421582723855\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 208 0.0220974488462983\n",
      "answer 208 replace 157\n",
      "now predict 157 0.0692\n",
      "orig norm 13.824738502502441 patched norm 0.06010563671588898\n",
      "now orig norm 13.824738502502441 patched norm 0.06010563671588898\n",
      "predict2 tensor([-0.0602, -0.0588, -0.0583, -0.0530, -0.0524], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052386234498816325\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 182 0.022096982220858055\n",
      "answer 182 replace 98\n",
      "now predict 98 0.0692\n",
      "orig norm 12.455857276916504 patched norm 0.046091996133327484\n",
      "now orig norm 12.455857276916504 patched norm 0.046091996133327484\n",
      "predict2 tensor([-0.0582, -0.0576, -0.0534, -0.0525, -0.0519], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05185387684773979\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 171 0.022097216756988197\n",
      "answer 171 replace 205\n",
      "now predict 205 0.0692\n",
      "orig norm 12.145123481750488 patched norm 0.05742112547159195\n",
      "now orig norm 12.145123481750488 patched norm 0.05742112547159195\n",
      "predict2 tensor([-0.0600, -0.0587, -0.0582, -0.0529, -0.0523], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052304375090267155\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 203 0.022097122486544246\n",
      "answer 203 replace 162\n",
      "now predict 162 0.0692\n",
      "orig norm 12.228135108947754 patched norm 0.07055668532848358\n",
      "now orig norm 12.228135108947754 patched norm 0.07055668532848358\n",
      "predict2 tensor([-0.0605, -0.0591, -0.0586, -0.0533, -0.0526], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052645598857378725\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 67 0.02209716230330512\n",
      "answer 67 replace 156\n",
      "now predict 156 0.0692\n",
      "orig norm 13.304838180541992 patched norm 0.040128372609615326\n",
      "now orig norm 13.304838180541992 patched norm 0.040128372609615326\n",
      "predict2 tensor([-0.0591, -0.0578, -0.0554, -0.0521, -0.0498], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 156 -0.04976425992877506\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 138 0.02209751552297022\n",
      "answer 138 replace 42\n",
      "now predict 42 0.0692\n",
      "orig norm 13.461606979370117 patched norm 0.058111656457185745\n",
      "now orig norm 13.461606979370117 patched norm 0.058111656457185745\n",
      "predict2 tensor([-0.0601, -0.0587, -0.0582, -0.0530, -0.0523], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05232614986861638\n",
      "40\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 154 0.02209739887707167\n",
      "answer 154 replace 122\n",
      "now predict 122 0.0692\n",
      "orig norm 13.490448951721191 patched norm 0.03121287375688553\n",
      "now orig norm 13.490448951721191 patched norm 0.03121287375688553\n",
      "predict2 tensor([-0.0581, -0.0568, -0.0563, -0.0514, -0.0508], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05076542038119093\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 55 0.022097140429780157\n",
      "answer 55 replace 102\n",
      "now predict 102 0.0692\n",
      "orig norm 12.857909202575684 patched norm 0.05828738957643509\n",
      "now orig norm 12.857909202575684 patched norm 0.05828738957643509\n",
      "predict2 tensor([-0.0601, -0.0587, -0.0582, -0.0530, -0.0523], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05233161388911307\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 204 0.022097266630333484\n",
      "answer 204 replace 70\n",
      "now predict 70 0.0692\n",
      "orig norm 14.028974533081055 patched norm 0.05768749490380287\n",
      "now orig norm 14.028974533081055 patched norm 0.05768749490380287\n",
      "predict2 tensor([-0.0601, -0.0587, -0.0582, -0.0529, -0.0523], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05231283338647648\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 30 0.022096982881407545\n",
      "answer 30 replace 43\n",
      "now predict 43 0.0692\n",
      "orig norm 12.72297477722168 patched norm 0.08601359277963638\n",
      "now orig norm 12.72297477722168 patched norm 0.08601359277963638\n",
      "predict2 tensor([-0.0608, -0.0594, -0.0589, -0.0536, -0.0529], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.0529136501123606\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 94 0.022097029644784244\n",
      "answer 94 replace 76\n",
      "now predict 76 0.0692\n",
      "orig norm 12.381141662597656 patched norm 0.06896551698446274\n",
      "now orig norm 12.381141662597656 patched norm 0.06896551698446274\n",
      "predict2 tensor([-0.0604, -0.0591, -0.0585, -0.0532, -0.0526], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05261118051381545\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 23 0.022097126190940133\n",
      "answer 23 replace 25\n",
      "now predict 25 0.0692\n",
      "orig norm 12.931190490722656 patched norm 0.02011324092745781\n",
      "now orig norm 12.931190490722656 patched norm 0.02011324092745781\n",
      "predict2 tensor([-0.0546, -0.0541, -0.0495, -0.0489, -0.0484], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 25 -0.04839197839190641\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 172 0.022096956785928767\n",
      "answer 172 replace 8\n",
      "now predict 8 0.0692\n",
      "orig norm 13.72957706451416 patched norm 0.03637801110744476\n",
      "now orig norm 13.72957706451416 patched norm 0.03637801110744476\n",
      "predict2 tensor([-0.0587, -0.0574, -0.0569, -0.0518, -0.0512], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.051244164191360145\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 189 0.022097338893924845\n",
      "answer 189 replace 194\n",
      "now predict 194 0.0692\n",
      "orig norm 12.927559852600098 patched norm 0.039577167481184006\n",
      "now orig norm 12.927559852600098 patched norm 0.039577167481184006\n",
      "predict2 tensor([-0.0590, -0.0577, -0.0572, -0.0521, -0.0515], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05147799921334407\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 156 0.022096854690208542\n",
      "answer 156 replace 197\n",
      "now predict 197 0.0692\n",
      "orig norm 12.739072799682617 patched norm 0.033943817019462585\n",
      "now orig norm 12.739072799682617 patched norm 0.033943817019462585\n",
      "predict2 tensor([-0.0587, -0.0585, -0.0572, -0.0516, -0.0510], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05103669504104654\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 88 0.022096916604023464\n",
      "answer 88 replace 179\n",
      "now predict 179 0.0692\n",
      "orig norm 14.253873825073242 patched norm 0.05613556504249573\n",
      "now orig norm 14.253873825073242 patched norm 0.05613556504249573\n",
      "predict2 tensor([-0.0600, -0.0587, -0.0581, -0.0529, -0.0523], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05226241059111392\n",
      "50\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 166 0.022097443798090255\n",
      "answer 166 replace 2\n",
      "now predict 2 0.0692\n",
      "orig norm 13.963031768798828 patched norm 0.06874606013298035\n",
      "now orig norm 13.963031768798828 patched norm 0.06874606013298035\n",
      "predict2 tensor([-0.0604, -0.0591, -0.0585, -0.0532, -0.0526], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052606309966966705\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 157 0.022097383606966364\n",
      "answer 157 replace 11\n",
      "now predict 11 0.0692\n",
      "orig norm 13.521185874938965 patched norm 0.08865641802549362\n",
      "now orig norm 13.521185874938965 patched norm 0.08865641802549362\n",
      "predict2 tensor([-0.0609, -0.0595, -0.0590, -0.0536, -0.0530], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052950122371299625\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 78 0.0220970946376276\n",
      "answer 78 replace 121\n",
      "now predict 121 0.0692\n",
      "orig norm 12.919561386108398 patched norm 0.05181906744837761\n",
      "now orig norm 12.919561386108398 patched norm 0.05181906744837761\n",
      "predict2 tensor([-0.0598, -0.0585, -0.0579, -0.0527, -0.0521], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05210623176401697\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 67 0.02209716230330512\n",
      "answer 67 replace 129\n",
      "now predict 129 0.0692\n",
      "orig norm 13.304838180541992 patched norm 0.05508594214916229\n",
      "now orig norm 13.304838180541992 patched norm 0.05508594214916229\n",
      "predict2 tensor([-0.0600, -0.0586, -0.0581, -0.0550, -0.0529], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 61 -0.052851586950545947\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 79 0.02209695007828158\n",
      "answer 79 replace 160\n",
      "now predict 160 0.0692\n",
      "orig norm 14.696538925170898 patched norm 0.061947230249643326\n",
      "now orig norm 14.696538925170898 patched norm 0.061947230249643326\n",
      "predict2 tensor([-0.0602, -0.0589, -0.0583, -0.0531, -0.0524], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05243831491514102\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 25 0.022097023947429198\n",
      "answer 25 replace 32\n",
      "now predict 32 0.0692\n",
      "orig norm 13.75168228149414 patched norm 0.04343061149120331\n",
      "now orig norm 13.75168228149414 patched norm 0.04343061149120331\n",
      "predict2 tensor([-0.0593, -0.0580, -0.0575, -0.0523, -0.0517], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.051713966898407814\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 10 0.022096953620362028\n",
      "answer 10 replace 127\n",
      "now predict 127 0.0692\n",
      "orig norm 12.451216697692871 patched norm 0.07700970023870468\n",
      "now orig norm 12.451216697692871 patched norm 0.07700970023870468\n",
      "predict2 tensor([-0.0606, -0.0593, -0.0587, -0.0534, -0.0528], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05277059757678147\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 4 0.02209717827233361\n",
      "answer 4 replace 161\n",
      "now predict 161 0.0692\n",
      "orig norm 12.02725601196289 patched norm 0.030353492125868797\n",
      "now orig norm 12.02725601196289 patched norm 0.030353492125868797\n",
      "predict2 tensor([-0.0580, -0.0567, -0.0562, -0.0513, -0.0507], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05066994781408166\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 124 0.02209716114406253\n",
      "answer 124 replace 82\n",
      "now predict 82 0.0692\n",
      "orig norm 13.723197937011719 patched norm 0.07640200853347778\n",
      "now orig norm 13.723197937011719 patched norm 0.07640200853347778\n",
      "predict2 tensor([-0.0606, -0.0593, -0.0587, -0.0534, -0.0528], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052759718856576966\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 130 0.022097265395764176\n",
      "answer 130 replace 77\n",
      "now predict 77 0.0692\n",
      "orig norm 12.494521141052246 patched norm 0.03938541188836098\n",
      "now orig norm 12.494521141052246 patched norm 0.03938541188836098\n",
      "predict2 tensor([-0.0590, -0.0577, -0.0572, -0.0521, -0.0515], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05146507041336437\n",
      "60\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 7 0.02209707773069504\n",
      "answer 7 replace 172\n",
      "now predict 172 0.0692\n",
      "orig norm 12.243758201599121 patched norm 0.12792421877384186\n",
      "now orig norm 12.243758201599121 patched norm 0.12792421877384186\n",
      "predict2 tensor([-0.0613, -0.0599, -0.0594, -0.0540, -0.0533], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05331451814169888\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 156 0.022097020116883637\n",
      "answer 156 replace 26\n",
      "now predict 26 0.0692\n",
      "orig norm 13.336088180541992 patched norm 0.024422327056527138\n",
      "now orig norm 13.336088180541992 patched norm 0.024422327056527138\n",
      "predict2 tensor([-0.0571, -0.0569, -0.0557, -0.0504, -0.0498], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.04982791355931928\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 139 0.022096895451247517\n",
      "answer 139 replace 4\n",
      "now predict 4 0.0692\n",
      "orig norm 13.899628639221191 patched norm 0.11667802929878235\n",
      "now orig norm 13.899628639221191 patched norm 0.11667802929878235\n",
      "predict2 tensor([-0.0612, -0.0598, -0.0593, -0.0539, -0.0532], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.053235222504281095\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 102 0.02209698598566985\n",
      "answer 102 replace 19\n",
      "now predict 19 0.0692\n",
      "orig norm 11.970561027526855 patched norm 0.043470192700624466\n",
      "now orig norm 11.970561027526855 patched norm 0.043470192700624466\n",
      "predict2 tensor([-0.0582, -0.0580, -0.0575, -0.0523, -0.0517], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05171616813934189\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 117 0.022097017321776047\n",
      "answer 117 replace 59\n",
      "now predict 59 0.0692\n",
      "orig norm 12.63362979888916 patched norm 0.08341798931360245\n",
      "now orig norm 12.63362979888916 patched norm 0.08341798931360245\n",
      "predict2 tensor([-0.0608, -0.0594, -0.0589, -0.0535, -0.0529], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.0528755790322345\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 81 0.022096987506097246\n",
      "answer 81 replace 67\n",
      "now predict 67 0.0692\n",
      "orig norm 12.737386703491211 patched norm 0.03497588634490967\n",
      "now orig norm 12.737386703491211 patched norm 0.03497588634490967\n",
      "predict2 tensor([-0.0586, -0.0573, -0.0568, -0.0517, -0.0426], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.0425540388202159\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 56 0.02209705153801919\n",
      "answer 56 replace 138\n",
      "now predict 138 0.0692\n",
      "orig norm 12.388019561767578 patched norm 0.0567227378487587\n",
      "now orig norm 12.388019561767578 patched norm 0.0567227378487587\n",
      "predict2 tensor([-0.0600, -0.0587, -0.0582, -0.0529, -0.0523], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052281810176351244\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 31 0.022097251102738302\n",
      "answer 31 replace 65\n",
      "now predict 65 0.0692\n",
      "orig norm 12.94420051574707 patched norm 0.030094437301158905\n",
      "now orig norm 12.94420051574707 patched norm 0.030094437301158905\n",
      "predict2 tensor([-0.0567, -0.0562, -0.0529, -0.0512, -0.0506], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.050640100181210665\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 122 0.02209708753847693\n",
      "answer 122 replace 50\n",
      "now predict 50 0.0692\n",
      "orig norm 12.62678050994873 patched norm 0.04884419962763786\n",
      "now orig norm 12.62678050994873 patched norm 0.04884419962763786\n",
      "predict2 tensor([-0.0596, -0.0583, -0.0578, -0.0526, -0.0520], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05198255350288887\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 68 0.022097270332568086\n",
      "answer 68 replace 164\n",
      "now predict 164 0.0692\n",
      "orig norm 12.805018424987793 patched norm 0.030746662989258766\n",
      "now orig norm 12.805018424987793 patched norm 0.030746662989258766\n",
      "predict2 tensor([-0.0577, -0.0568, -0.0563, -0.0513, -0.0507], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.050714291620101125\n",
      "70\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 157 0.022097383606966364\n",
      "answer 157 replace 11\n",
      "now predict 11 0.0692\n",
      "orig norm 13.521185874938965 patched norm 0.08865641802549362\n",
      "now orig norm 13.521185874938965 patched norm 0.08865641802549362\n",
      "predict2 tensor([-0.0609, -0.0595, -0.0590, -0.0536, -0.0530], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052950122371299625\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 205 0.022097043450408527\n",
      "answer 205 replace 106\n",
      "now predict 106 0.0692\n",
      "orig norm 13.165217399597168 patched norm 0.032922398298978806\n",
      "now orig norm 13.165217399597168 patched norm 0.032922398298978806\n",
      "predict2 tensor([-0.0583, -0.0571, -0.0566, -0.0515, -0.0509], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05094049756366106\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 176 0.02209707360119087\n",
      "answer 176 replace 131\n",
      "now predict 131 0.0692\n",
      "orig norm 13.693303108215332 patched norm 0.025049326941370964\n",
      "now orig norm 13.693303108215332 patched norm 0.025049326941370964\n",
      "predict2 tensor([-0.0571, -0.0558, -0.0554, -0.0505, -0.0499], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.049935745354438094\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 171 0.022097092554911477\n",
      "answer 171 replace 80\n",
      "now predict 80 0.0692\n",
      "orig norm 12.155314445495605 patched norm 0.09277249127626419\n",
      "now orig norm 12.155314445495605 patched norm 0.09277249127626419\n",
      "predict2 tensor([-0.0609, -0.0596, -0.0590, -0.0536, -0.0530], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05300279480958638\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 51 0.022097391187145696\n",
      "answer 51 replace 195\n",
      "now predict 195 0.0692\n",
      "orig norm 13.71535873413086 patched norm 0.043102264404296875\n",
      "now orig norm 13.71535873413086 patched norm 0.043102264404296875\n",
      "predict2 tensor([-0.0593, -0.0580, -0.0575, -0.0523, -0.0517], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05169548530130673\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 188 0.02209698483178947\n",
      "answer 188 replace 86\n",
      "now predict 86 0.0692\n",
      "orig norm 14.136275291442871 patched norm 0.03215986490249634\n",
      "now orig norm 14.136275291442871 patched norm 0.03215986490249634\n",
      "predict2 tensor([-0.0578, -0.0570, -0.0565, -0.0515, -0.0509], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.0508647201449527\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 157 0.022097035356530542\n",
      "answer 157 replace 186\n",
      "now predict 186 0.0692\n",
      "orig norm 14.471002578735352 patched norm 0.07964771240949631\n",
      "now orig norm 14.471002578735352 patched norm 0.07964771240949631\n",
      "predict2 tensor([-0.0607, -0.0593, -0.0588, -0.0535, -0.0528], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052815862835799955\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 138 0.02209751552297022\n",
      "answer 138 replace 93\n",
      "now predict 93 0.0692\n",
      "orig norm 13.461606979370117 patched norm 0.094124935567379\n",
      "now orig norm 13.461606979370117 patched norm 0.094124935567379\n",
      "predict2 tensor([-0.0609, -0.0596, -0.0590, -0.0537, -0.0530], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05301908477230368\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 24 0.0220969673615284\n",
      "answer 24 replace 71\n",
      "now predict 71 0.0692\n",
      "orig norm 13.302364349365234 patched norm 0.03646157681941986\n",
      "now orig norm 13.302364349365234 patched norm 0.03646157681941986\n",
      "predict2 tensor([-0.0574, -0.0569, -0.0519, -0.0513, -0.0507], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 71 -0.05072090678500754\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 68 0.022097270332568086\n",
      "answer 68 replace 164\n",
      "now predict 164 0.0692\n",
      "orig norm 12.805018424987793 patched norm 0.030746662989258766\n",
      "now orig norm 12.805018424987793 patched norm 0.030746662989258766\n",
      "predict2 tensor([-0.0577, -0.0568, -0.0563, -0.0513, -0.0507], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.050714291620101125\n",
      "80\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 30 0.022097028112674222\n",
      "answer 30 replace 59\n",
      "now predict 59 0.0692\n",
      "orig norm 13.800618171691895 patched norm 0.09676897525787354\n",
      "now orig norm 13.800618171691895 patched norm 0.09676897525787354\n",
      "predict2 tensor([-0.0610, -0.0596, -0.0591, -0.0537, -0.0530], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05304964647965406\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 133 0.02209707023913403\n",
      "answer 133 replace 165\n",
      "now predict 165 0.0692\n",
      "orig norm 12.532169342041016 patched norm 0.06776076555252075\n",
      "now orig norm 12.532169342041016 patched norm 0.06776076555252075\n",
      "predict2 tensor([-0.0604, -0.0590, -0.0585, -0.0532, -0.0526], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.0525840511978662\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 136 0.02209684828959453\n",
      "answer 136 replace 86\n",
      "now predict 86 0.0692\n",
      "orig norm 12.948307991027832 patched norm 0.03784038871526718\n",
      "now orig norm 12.948307991027832 patched norm 0.03784038871526718\n",
      "predict2 tensor([-0.0589, -0.0576, -0.0570, -0.0520, -0.0514], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.051355969127658184\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 122 0.02209708753847693\n",
      "answer 122 replace 50\n",
      "now predict 50 0.0692\n",
      "orig norm 12.62678050994873 patched norm 0.04884419962763786\n",
      "now orig norm 12.62678050994873 patched norm 0.04884419962763786\n",
      "predict2 tensor([-0.0596, -0.0583, -0.0578, -0.0526, -0.0520], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05198255350288887\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 41 0.02209683161380191\n",
      "answer 41 replace 125\n",
      "now predict 125 0.0692\n",
      "orig norm 13.338723182678223 patched norm 0.09443815797567368\n",
      "now orig norm 13.338723182678223 patched norm 0.09443815797567368\n",
      "predict2 tensor([-0.0610, -0.0596, -0.0590, -0.0537, -0.0530], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.053022805346907495\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 47 0.022096890923839388\n",
      "answer 47 replace 119\n",
      "now predict 119 0.0692\n",
      "orig norm 13.014554023742676 patched norm 0.0263145100325346\n",
      "now orig norm 13.014554023742676 patched norm 0.0263145100325346\n",
      "predict2 tensor([-0.0573, -0.0561, -0.0556, -0.0507, -0.0501], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05013778448768405\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 187 0.022097329586588665\n",
      "answer 187 replace 34\n",
      "now predict 34 0.0692\n",
      "orig norm 14.157035827636719 patched norm 0.08469607681035995\n",
      "now orig norm 14.157035827636719 patched norm 0.08469607681035995\n",
      "predict2 tensor([-0.0608, -0.0594, -0.0589, -0.0535, -0.0529], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05289461250638407\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 148 0.022097387580457983\n",
      "answer 148 replace 165\n",
      "now predict 165 0.0692\n",
      "orig norm 14.148893356323242 patched norm 0.06781057268381119\n",
      "now orig norm 14.148893356323242 patched norm 0.06781057268381119\n",
      "predict2 tensor([-0.0604, -0.0590, -0.0585, -0.0532, -0.0526], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052585190732766844\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 55 0.022096795604340663\n",
      "answer 55 replace 207\n",
      "now predict 207 0.0692\n",
      "orig norm 14.208223342895508 patched norm 0.04462785646319389\n",
      "now orig norm 14.208223342895508 patched norm 0.04462785646319389\n",
      "predict2 tensor([-0.0581, -0.0576, -0.0562, -0.0524, -0.0518], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05177896426900873\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 105 0.02209694022335071\n",
      "answer 105 replace 41\n",
      "now predict 41 0.0692\n",
      "orig norm 13.563377380371094 patched norm 0.07557852566242218\n",
      "now orig norm 13.563377380371094 patched norm 0.07557852566242218\n",
      "predict2 tensor([-0.0606, -0.0592, -0.0587, -0.0534, -0.0527], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05274472136630224\n",
      "90\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 143 0.02209710416948142\n",
      "answer 143 replace 205\n",
      "now predict 205 0.0692\n",
      "orig norm 13.442266464233398 patched norm 0.04499584436416626\n",
      "now orig norm 13.442266464233398 patched norm 0.04499584436416626\n",
      "predict2 tensor([-0.0586, -0.0581, -0.0576, -0.0524, -0.0518], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.0517982614409257\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 7 0.02209707773069504\n",
      "answer 7 replace 172\n",
      "now predict 172 0.0692\n",
      "orig norm 12.243758201599121 patched norm 0.12792421877384186\n",
      "now orig norm 12.243758201599121 patched norm 0.12792421877384186\n",
      "predict2 tensor([-0.0613, -0.0599, -0.0594, -0.0540, -0.0533], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05331451814169888\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 68 0.022097082361608317\n",
      "answer 68 replace 109\n",
      "now predict 109 0.0692\n",
      "orig norm 12.771722793579102 patched norm 0.07128157466650009\n",
      "now orig norm 12.771722793579102 patched norm 0.07128157466650009\n",
      "predict2 tensor([-0.0605, -0.0591, -0.0586, -0.0533, -0.0527], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052660767704046554\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 127 0.022096911028051197\n",
      "answer 127 replace 19\n",
      "now predict 19 0.0692\n",
      "orig norm 12.875789642333984 patched norm 0.06532753258943558\n",
      "now orig norm 12.875789642333984 patched norm 0.06532753258943558\n",
      "predict2 tensor([-0.0603, -0.0590, -0.0584, -0.0532, -0.0525], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05252620373427634\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 87 0.02209696442200436\n",
      "answer 87 replace 184\n",
      "now predict 184 0.0692\n",
      "orig norm 13.428627967834473 patched norm 0.042690254747867584\n",
      "now orig norm 13.428627967834473 patched norm 0.042690254747867584\n",
      "predict2 tensor([-0.0593, -0.0579, -0.0574, -0.0523, -0.0517], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05167193928132453\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 181 0.02209704527948357\n",
      "answer 181 replace 66\n",
      "now predict 66 0.0692\n",
      "orig norm 12.76126766204834 patched norm 0.05177575722336769\n",
      "now orig norm 12.76126766204834 patched norm 0.05177575722336769\n",
      "predict2 tensor([-0.0598, -0.0585, -0.0579, -0.0527, -0.0521], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05210454063807142\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 28 0.022096957527709488\n",
      "answer 28 replace 83\n",
      "now predict 83 0.0692\n",
      "orig norm 13.298748970031738 patched norm 0.03784990683197975\n",
      "now orig norm 13.298748970031738 patched norm 0.03784990683197975\n",
      "predict2 tensor([-0.0576, -0.0570, -0.0566, -0.0520, -0.0514], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05135666039879936\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 128 0.022097064495001942\n",
      "answer 128 replace 151\n",
      "now predict 151 0.0692\n",
      "orig norm 13.466296195983887 patched norm 0.04122382774949074\n",
      "now orig norm 13.466296195983887 patched norm 0.04122382774949074\n",
      "predict2 tensor([-0.0591, -0.0578, -0.0573, -0.0522, -0.0516], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.051584246165053416\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 127 0.022096911028051197\n",
      "answer 127 replace 159\n",
      "now predict 159 0.0692\n",
      "orig norm 12.875789642333984 patched norm 0.10827566683292389\n",
      "now orig norm 12.875789642333984 patched norm 0.10827566683292389\n",
      "predict2 tensor([-0.0611, -0.0598, -0.0592, -0.0538, -0.0532], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.053165223830143715\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 123 0.022097340347031633\n",
      "answer 123 replace 181\n",
      "now predict 181 0.0692\n",
      "orig norm 14.080500602722168 patched norm 0.04781460016965866\n",
      "now orig norm 14.080500602722168 patched norm 0.04781460016965866\n",
      "predict2 tensor([-0.0596, -0.0583, -0.0577, -0.0526, -0.0519], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.05193614820586108\n",
      "100\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 23 0.022097126190940133\n",
      "answer 23 replace 25\n",
      "now predict 25 0.0692\n",
      "orig norm 12.931190490722656 patched norm 0.02011324092745781\n",
      "now orig norm 12.931190490722656 patched norm 0.02011324092745781\n",
      "predict2 tensor([-0.0546, -0.0541, -0.0495, -0.0489, -0.0484], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 25 -0.04839197839190641\n",
      "tensor([-0.0221, -0.0221, -0.0221, -0.0221,  0.0221], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict 59 0.02209719174803136\n",
      "answer 59 replace 21\n",
      "now predict 21 0.0692\n",
      "orig norm 12.756818771362305 patched norm 0.0533272810280323\n",
      "now orig norm 12.756818771362305 patched norm 0.0533272810280323\n",
      "predict2 tensor([-0.0599, -0.0585, -0.0580, -0.0528, -0.0522], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "predict2 67 -0.052163670864051555\n"
     ]
    }
   ],
   "source": [
    "replace_correct = []\n",
    "replace_replace = []\n",
    "print(f\"layer {layer}\")\n",
    "for position_1, name_basis in enumerate(name_bases):\n",
    "    num_found = 0\n",
    "    while True:            \n",
    "        data_i = random.choice(list(range(10000)))\n",
    "        \n",
    "        import random\n",
    "        from functools import partial\n",
    "    \n",
    "        data_i = (data_i // 2)*2\n",
    "        patched_i = data_i + 1\n",
    "        \n",
    "        data_tokens = data.data[data_i]\n",
    "        answer_tok = data.correct[data_i][0].item()\n",
    "        answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "        replace_tok = data.correct[patched_i][0].item()\n",
    "        replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "        '''\n",
    "        others = model.to_str_tokens(data.incorrect[data_i])\n",
    "        print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "        print(\"answer\", answer)\n",
    "        print(\"other names\", others)\n",
    "        replace_name = model.to_str_tokens(answer)[0]\n",
    "        while True:\n",
    "            replace_tok = random.choice(list(name_tokens))\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            if not replace_name in [answer] + others:\n",
    "                break\n",
    "        '''\n",
    "        #print(\"got replace name\", repr(replace_name))\n",
    "        #print(\"logits before replace\")\n",
    "        last_token_pos = data.last_token_position[data_i]\n",
    "        \n",
    "        def replace_hook(\n",
    "            x,\n",
    "            hook,\n",
    "            position,\n",
    "            answer_name_tok,\n",
    "            replace_name_tok,\n",
    "            name_basis\n",
    "        ):\n",
    "            B,L,E = x.size()\n",
    "            for b in range(B):\n",
    "                vec = x[b,position]\n",
    "                coords = name_basis.map_to_coords(vec/torch.linalg.norm(vec, ord=2))\n",
    "                C = len(name_tok_to_class)\n",
    "                sorted = torch.argsort(coords[:C])\n",
    "                print(coords[sorted][-5:])\n",
    "                maxi = torch.argmax(coords[:C])\n",
    "                print(f\"predict {maxi} {coords[maxi]}\")\n",
    "                print(f\"answer {name_tok_to_class[answer_name_tok]} replace {name_tok_to_class[replace_name_tok]}\")\n",
    "                coords[name_tok_to_class[answer_name_tok]] = -0.0692\n",
    "                coords[name_tok_to_class[replace_name_tok]] = 0.0692\n",
    "                maxi = torch.argmax(coords[:C])\n",
    "                print(f\"now predict {maxi} {coords[maxi]}\")\n",
    "                patched_vec = name_basis.map_from_coords(coords)\n",
    "                print(f\"orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                patched_veco = patched_vec / torch.linalg.norm(patched_vec, ord=2) * torch.linalg.norm(vec, ord=2)\n",
    "                print(f\"now orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                coords2 = name_basis.map_to_coords(patched_vec)\n",
    "                sorted = torch.argsort(coords2[:C])\n",
    "                print(\"predict2\", coords2[sorted][-5:])\n",
    "                maxi = torch.argmax(coords2[:C])\n",
    "                print(f\"predict2 {maxi} {coords2[maxi]}\")\n",
    "                x[b,position] = patched_veco\n",
    "            return x\n",
    "        \n",
    "        answer_positions = []\n",
    "        for name_i in range(len(data_name_positions)):\n",
    "            position = data_name_positions[name_i][data_i]\n",
    "            if data_tokens[position].item() == answer_tok:\n",
    "                answer_positions.append((name_i, position))\n",
    "        \n",
    "        #print(\"answer positions\", answer_positions)\n",
    "        hooks = []\n",
    "        bad = False\n",
    "        for name_i, position in answer_positions:\n",
    "            if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                bad = True\n",
    "            \n",
    "            hooks.append((\n",
    "                f'blocks.{layer}.hook_ssm_input', \n",
    "                partial(replace_hook,\n",
    "                        position=position+1,\n",
    "                        answer_name_tok=answer_tok,\n",
    "                        replace_name_tok=replace_tok,\n",
    "                        name_basis=name_basis\n",
    "                )\n",
    "            ))\n",
    "        if bad:\n",
    "            continue\n",
    "        else:\n",
    "            num_found += 1\n",
    "        \n",
    "        #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "        #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "        #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "        #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "        #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "        if num_found % 10 == 0:\n",
    "            print(num_found)\n",
    "        logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "        #print(logits_modified.size())\n",
    "        #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "        #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "        replace_correct.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "        replace_replace.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "        #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "        #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "        #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "        #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "        #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "        if num_found > 100:\n",
    "            break\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aae9b467-00ca-41a5-b319-5d67412fd57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.292292594909668 5.980109214782715\n",
      "11.832980155944824 11.420822143554688\n",
      "2.0388691425323486 -1.5182201862335205\n",
      "9.111919403076172 6.245798110961914\n",
      "8.759381294250488 7.01724910736084\n",
      "11.328155517578125 8.289484977722168\n",
      "9.199292182922363 9.68761920928955\n",
      "12.135746002197266 8.438560485839844\n",
      "9.180728912353516 8.649641036987305\n",
      "10.156808853149414 7.379574775695801\n",
      "10.524291038513184 8.64991569519043\n",
      "8.724018096923828 7.955240249633789\n",
      "4.5647382736206055 -3.1865406036376953\n",
      "10.020065307617188 5.990218639373779\n",
      "9.88664436340332 10.900086402893066\n",
      "11.016952514648438 10.124259948730469\n",
      "9.08195972442627 10.729022979736328\n",
      "10.524291038513184 8.64991569519043\n",
      "10.972002029418945 9.637287139892578\n",
      "10.687192916870117 9.235893249511719\n",
      "11.367867469787598 9.720467567443848\n",
      "11.898422241210938 8.95764446258545\n",
      "5.688894271850586 7.332655906677246\n",
      "1.1635046005249023 0.15468621253967285\n",
      "10.471689224243164 8.442193984985352\n",
      "10.87183952331543 9.364906311035156\n",
      "9.019893646240234 7.604190826416016\n",
      "8.369454383850098 7.869716644287109\n",
      "8.962318420410156 5.547757625579834\n",
      "7.965351104736328 6.542729377746582\n",
      "7.406050682067871 4.118391036987305\n",
      "10.27177619934082 10.339862823486328\n",
      "5.927156448364258 4.316592216491699\n",
      "9.892830848693848 9.7142333984375\n",
      "9.282148361206055 6.883196830749512\n",
      "8.014092445373535 7.338183879852295\n",
      "9.677741050720215 11.90847396850586\n",
      "10.656192779541016 6.340978145599365\n",
      "11.332195281982422 9.819135665893555\n",
      "11.730380058288574 12.454326629638672\n",
      "13.231882095336914 11.331403732299805\n",
      "9.144026756286621 7.0731682777404785\n",
      "11.215670585632324 8.216924667358398\n",
      "10.575016021728516 7.570246696472168\n",
      "10.954968452453613 10.066690444946289\n",
      "9.180728912353516 8.649641036987305\n",
      "9.600513458251953 6.804722309112549\n",
      "9.88664436340332 10.900086402893066\n",
      "7.737124443054199 6.422698020935059\n",
      "7.044924736022949 9.229584693908691\n",
      "7.532392501831055 6.539206504821777\n",
      "7.137608051300049 5.703571319580078\n",
      "9.275016784667969 9.799403190612793\n",
      "12.114215850830078 8.725317001342773\n",
      "9.13656997680664 8.05966567993164\n",
      "9.786730766296387 9.741252899169922\n",
      "11.472740173339844 7.319180965423584\n",
      "5.843885898590088 4.707385063171387\n",
      "10.485712051391602 10.138962745666504\n",
      "13.678668022155762 8.629636764526367\n",
      "9.797690391540527 9.62701416015625\n",
      "9.843938827514648 10.789496421813965\n",
      "10.348573684692383 8.684566497802734\n",
      "11.628838539123535 9.652535438537598\n",
      "12.417684555053711 9.897825241088867\n",
      "9.872723579406738 8.181621551513672\n",
      "7.814011573791504 8.003792762756348\n",
      "12.135746002197266 8.438560485839844\n",
      "9.034223556518555 7.025053024291992\n",
      "7.532392501831055 6.539206504821777\n",
      "11.893741607666016 8.131321907043457\n",
      "11.763076782226562 10.196839332580566\n",
      "7.005289077758789 9.864834785461426\n",
      "10.101154327392578 9.306151390075684\n",
      "10.573576927185059 10.192205429077148\n",
      "3.136749744415283 2.7273340225219727\n",
      "9.52226448059082 9.180560111999512\n",
      "12.301972389221191 11.97080135345459\n",
      "9.034223556518555 7.025053024291992\n",
      "3.1296463012695312 1.6323657035827637\n",
      "7.067662715911865 6.903785705566406\n",
      "12.542158126831055 11.449722290039062\n",
      "12.135746002197266 8.438560485839844\n",
      "7.246221542358398 6.078848361968994\n",
      "9.037522315979004 7.140205383300781\n",
      "7.281317234039307 4.416881084442139\n",
      "10.119890213012695 9.346521377563477\n",
      "12.324901580810547 10.071224212646484\n",
      "11.949225425720215 8.599422454833984\n",
      "7.4592084884643555 5.90174674987793\n",
      "13.678668022155762 8.629636764526367\n",
      "6.385002613067627 5.341318607330322\n",
      "12.22933578491211 8.830243110656738\n",
      "10.925069808959961 7.18157958984375\n",
      "8.573979377746582 8.616127014160156\n",
      "7.7559709548950195 5.00753116607666\n",
      "9.706771850585938 11.058938980102539\n",
      "11.962288856506348 11.401345252990723\n",
      "9.72370719909668 9.464593887329102\n",
      "10.954968452453613 10.066690444946289\n",
      "10.780614852905273 5.724254608154297\n",
      "tensor(0.1485)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(replace_correct)):\n",
    "    print(replace_correct[i], replace_replace[i])\n",
    "replace_diff = -torch.tensor(replace_correct) + torch.tensor(replace_replace)\n",
    "#patched_diff = -torch.tensor(patched_correct) + torch.tensor(patched_replace)\n",
    "\n",
    "#print(f'original min diff {torch.min(original_diff)} max diff {torch.max(original_diff)} avg diff {torch.mean(original_diff)}')\n",
    "#print(f'replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "#print(f'patch min diff {torch.min(patched_diff)} max diff {torch.max(patched_diff)} avg diff {torch.mean(patched_diff)}')\n",
    "\n",
    "n_correct_matrix = torch.sum(replace_diff > 0)/101.0\n",
    "print(n_correct_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369477e-4828-477e-b16b-d882309f5184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
