{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2150298-45a8-4a12-84ef-a4a42ccb7b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fc8577db640>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requires\n",
    "# pip install git+https://github.com/Phylliida/MambaLens.git\n",
    "\n",
    "# do PCA (and projective PCA?)\n",
    "# todo: for each name look at its PCA (make a colored graph for different components?)\n",
    "# train projection from PCA space to classifier space?\n",
    "\n",
    "from mamba_lens import HookedMamba # this will take a little while to import\n",
    "import torch\n",
    "model_path = \"state-spaces/mamba-370m\"\n",
    "model = HookedMamba.from_pretrained(model_path, device='cuda')\n",
    "torch.set_grad_enabled(False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29eba0c2-102b-4450-ad2f-7c9fce14cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to do\n",
    "# pip install -e .\n",
    "# in the root directory of this repo\n",
    "# also\n",
    "# to install graphviz:\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install graphviz xdg-utils\n",
    "\n",
    "from acdc.data.ioi import ioi_data_generator, ABC_TEMPLATES, get_all_single_name_abc_patching_formats\n",
    "from acdc.data.utils import generate_dataset\n",
    "\n",
    "num_patching_pairs = 10000\n",
    "seed = 27\n",
    "valid_seed = 28\n",
    "constrain_to_answers = True\n",
    "has_symmetric_patching = True\n",
    "\n",
    "from acdc.data.ioi import BABA_TEMPLATES\n",
    "#templates = [BABA_TEMPLATES[1]]\n",
    "templates = ABC_TEMPLATES\n",
    "patching_formats = list(get_all_single_name_abc_patching_formats())\n",
    "'''\n",
    "patching_formats = [\n",
    "    'AB A B\\nAC A C', # 85, \n",
    "    #'AB A B\\nCB C B', # 66\n",
    "    #'AB B A\\nAC C A', # 74\n",
    "    #'AB B A\\nCB B C' # 85\n",
    "]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "data = generate_dataset(model=model,\n",
    "                  data_generator=ioi_data_generator,\n",
    "                  num_patching_pairs=num_patching_pairs,\n",
    "                  seed=seed,\n",
    "                  valid_seed=valid_seed,\n",
    "                  constrain_to_answers=constrain_to_answers,\n",
    "                  has_symmetric_patching=has_symmetric_patching, \n",
    "                  varying_data_lengths=True,\n",
    "                  templates=templates,\n",
    "                  patching_formats=patching_formats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6284e540-c8bd-4153-b272-1ed5f4cdd57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template: Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.82625\n",
      "template: Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.62375\n",
      "template: Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.5475\n",
      "template: Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.795\n",
      "template: Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.8775\n",
      "template: Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.61625\n",
      "template: Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.57625\n",
      "template: Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.87375\n",
      "template: Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.89375\n",
      "template: Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.6025\n",
      "template: Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.47625\n",
      "template: Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.865\n",
      "template: Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.72875\n",
      "template: Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.43375\n",
      "template: Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.295\n",
      "template: Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.665\n",
      "template: Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.7525\n",
      "template: Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.6575\n",
      "template: Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.91875\n",
      "template: Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.83375\n",
      "template: After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.785\n",
      "template: After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.46375\n",
      "template: After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.52875\n",
      "template: After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.8425\n",
      "template: When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.87875\n",
      "template: When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.55875\n",
      "template: When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.67875\n",
      "template: When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.925\n",
      "template: When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.8175\n",
      "template: When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.48\n",
      "template: When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.5875\n",
      "template: When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.90125\n",
      "template: While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.7675\n",
      "template: While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.59625\n",
      "template: While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.63375\n",
      "template: While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.79875\n",
      "template: While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.8375\n",
      "template: While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.505\n",
      "template: While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.44375\n",
      "template: While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.85\n",
      "template: After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.81875\n",
      "template: After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.51\n",
      "template: After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.49375\n",
      "template: After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.845\n",
      "template: Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.82625\n",
      "template: Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.51375\n",
      "template: Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.52375\n",
      "template: Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.84125\n",
      "template: Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.76625\n",
      "template: Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.66125\n",
      "template: Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.8925\n",
      "template: Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.86625\n",
      "template: The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.845\n",
      "template: The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.47875\n",
      "template: The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.63375\n",
      "template: The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.9075\n",
      "template: Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to\n",
      "patching format:\n",
      "AB A B\n",
      "AC A C\n",
      "accuracy: 0.8525\n",
      "template: Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to\n",
      "patching format:\n",
      "AB A B\n",
      "CB C B\n",
      "accuracy: 0.57875\n",
      "template: Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to\n",
      "patching format:\n",
      "AB B A\n",
      "AC C A\n",
      "accuracy: 0.7725\n",
      "template: Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to\n",
      "patching format:\n",
      "AB B A\n",
      "CB B C\n",
      "accuracy: 0.915\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mamba_lens.input_dependent_hooks import clean_hooks\n",
    "from acdc import accuracy_metric\n",
    "from acdc import ACDCEvalData\n",
    "from acdc import get_pad_token\n",
    "import itertools\n",
    "\n",
    "\n",
    "patching_formats = [\n",
    "    'AB A B\\nAC A C', # 85, \n",
    "    'AB A B\\nCB C B', # 66\n",
    "    'AB B A\\nAC C A', # 74\n",
    "    'AB B A\\nCB B C' # 85\n",
    "]\n",
    "\n",
    "#patching_formats = list(get_all_single_name_abc_patching_formats())\n",
    "scores = torch.zeros([len(BABA_TEMPLATES), len(patching_formats)])\n",
    "template_to_i = dict([(t,i) for (i,t) in enumerate(BABA_TEMPLATES)])\n",
    "patching_to_i = dict([(t,i) for (i,t) in enumerate(patching_formats)])\n",
    "\n",
    "\n",
    "for template, patching_format in itertools.product(BABA_TEMPLATES, patching_formats):\n",
    "        \n",
    "    data = generate_dataset(model=model,\n",
    "                      data_generator=ioi_data_generator,\n",
    "                      num_patching_pairs=num_patching_pairs,\n",
    "                      seed=seed,\n",
    "                      valid_seed=valid_seed,\n",
    "                      constrain_to_answers=constrain_to_answers,\n",
    "                      has_symmetric_patching=has_symmetric_patching, \n",
    "                      varying_data_lengths=True,\n",
    "                      templates=[template],\n",
    "                      patching_formats=[patching_format])\n",
    "    \n",
    "    clean_hooks(model)\n",
    "    def top_is_correct_metric(data: ACDCEvalData):\n",
    "        return data.patched.top_is_correct\n",
    "    #limited_layers = [0, 7, 10, 11, 16, 17, 18, 19, 23, 24, 25, 28, 33, 39, 45, 46, 47]\n",
    "    limited_layers  = [0, 7, 10, 11, 16, 17, 18, 19, 23, 24, 25, 28, 33, 39, 45, 46, 47]\n",
    "    limited_layers = list(range(model.cfg.n_layers))\n",
    "    from functools import partial\n",
    "    def wrap_run_with_hooks(model, fwd_hooks, bwd_hooks=[], **kwargs):\n",
    "        '''\n",
    "        Makes a fake object that acts like model\n",
    "        but when you call it it'll actually call run_with_hooks with the provided hooks\n",
    "        '''\n",
    "        def wrapper(input, fwd_hooks, bwd_hooks):\n",
    "            #print(f\"running model with {len(fwd_hooks)} fwd hooks and {len(bwd_hooks)} bwd hooks\")\n",
    "            return model.run_with_hooks(input, only_use_these_layers=limited_layers, fwd_hooks=fwd_hooks, bwd_hooks=bwd_hooks, **kwargs)\n",
    "        wrapper_with_hooks = partial(wrapper, fwd_hooks=fwd_hooks, bwd_hooks=bwd_hooks)\n",
    "        wrapper_with_hooks.tokenizer = model.tokenizer\n",
    "        wrapper_with_hooks.cfg = model.cfg\n",
    "        return wrapper_with_hooks\n",
    "    layers_to_patch = list(limited_layers)\n",
    "    layers_to_patch.remove(39)\n",
    "    model_wrapped = wrap_run_with_hooks(model, fwd_hooks=hooks_to_remove_token_cross_talk(layers=layers_to_patch))\n",
    "    #model_wrapped = wrap_run_with_hooks(model, fwd_hooks=[])\n",
    "    \n",
    "    top_is_correct = data.eval(model=model_wrapped, batch_size=100, metric=top_is_correct_metric)\n",
    "    accuracy = top_is_correct.sum().item()/top_is_correct.size()[0]\n",
    "    print(f\"template: {template}\")\n",
    "    print(f\"patching format:\")\n",
    "    print(patching_format)\n",
    "    print(f\"accuracy: {accuracy}\")\n",
    "    scores[template_to_i[template], patching_to_i[patching_format]] = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "226e8048-7de9-4d8d-94a8-e31b1affc4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to",
          "Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to",
          "After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to",
          "While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to",
          "While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to",
          "After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to",
          "The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to",
          "Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to"
         ],
         "xaxis": "x",
         "y": [
          "AB A B\nAC A C",
          "AB A B\nCB C B",
          "AB B A\nAC C A",
          "AB B A\nCB B C"
         ],
         "yaxis": "y",
         "z": [
          [
           0.8262500166893005,
           0.8774999976158142,
           0.893750011920929,
           0.7287499904632568,
           0.7524999976158142,
           0.7850000262260437,
           0.8787500262260437,
           0.8174999952316284,
           0.7674999833106995,
           0.8374999761581421,
           0.8187500238418579,
           0.8262500166893005,
           0.7662500143051147,
           0.8450000286102295,
           0.8525000214576721
          ],
          [
           0.6237499713897705,
           0.6162499785423279,
           0.6025000214576721,
           0.4337500035762787,
           0.6575000286102295,
           0.4637500047683716,
           0.5587499737739563,
           0.47999998927116394,
           0.5962499976158142,
           0.5049999952316284,
           0.5099999904632568,
           0.5137500166893005,
           0.6612499952316284,
           0.47874999046325684,
           0.5787500143051147
          ],
          [
           0.5475000143051147,
           0.5762500166893005,
           0.4762499928474426,
           0.29499998688697815,
           0.918749988079071,
           0.5287500023841858,
           0.6787499785423279,
           0.5874999761581421,
           0.6337500214576721,
           0.4437499940395355,
           0.4937500059604645,
           0.5237500071525574,
           0.8924999833106995,
           0.6337500214576721,
           0.7724999785423279
          ],
          [
           0.7950000166893005,
           0.8737499713897705,
           0.8650000095367432,
           0.6650000214576721,
           0.8337500095367432,
           0.8424999713897705,
           0.925000011920929,
           0.9012500047683716,
           0.7987499833106995,
           0.8500000238418579,
           0.8450000286102295,
           0.8412500023841858,
           0.8662499785423279,
           0.9075000286102295,
           0.9150000214576721
          ]
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "font": {
         "color": "black",
         "size": 7
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.049581005586592175,
          0.9504189944134078
         ],
         "range": [
          -0.5,
          14.5
         ],
         "scaleanchor": "y",
         "tickmode": "array",
         "ticktext": [
          "Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to",
          "Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to",
          "After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to",
          "While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to",
          "While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to",
          "After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to",
          "The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to",
          "Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to"
         ],
         "tickvals": [
          "Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to",
          "Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to",
          "After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to",
          "While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to",
          "While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to",
          "After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to",
          "The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to",
          "Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to"
         ],
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          3.5,
          -0.5
         ],
         "tickmode": "array",
         "ticktext": [
          "AB A B\nAC A C",
          "AB A B\nCB C B",
          "AB B A\nAC C A",
          "AB B A\nCB B C"
         ],
         "tickvals": [
          "AB A B\nAC A C",
          "AB A B\nCB C B",
          "AB B A\nAC C A",
          "AB B A\nCB B C"
         ],
         "type": "category"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"a3290536-59ca-4174-9aaa-99061b4511fa\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a3290536-59ca-4174-9aaa-99061b4511fa\")) {                    Plotly.newPlot(                        \"a3290536-59ca-4174-9aaa-99061b4511fa\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to\",\"Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to\",\"After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to\",\"While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to\",\"While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to\",\"After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to\",\"The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to\",\"Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to\"],\"y\":[\"AB A B\\nAC A C\",\"AB A B\\nCB C B\",\"AB B A\\nAC C A\",\"AB B A\\nCB B C\"],\"z\":[[0.8262500166893005,0.8774999976158142,0.893750011920929,0.7287499904632568,0.7524999976158142,0.7850000262260437,0.8787500262260437,0.8174999952316284,0.7674999833106995,0.8374999761581421,0.8187500238418579,0.8262500166893005,0.7662500143051147,0.8450000286102295,0.8525000214576721],[0.6237499713897705,0.6162499785423279,0.6025000214576721,0.4337500035762787,0.6575000286102295,0.4637500047683716,0.5587499737739563,0.47999998927116394,0.5962499976158142,0.5049999952316284,0.5099999904632568,0.5137500166893005,0.6612499952316284,0.47874999046325684,0.5787500143051147],[0.5475000143051147,0.5762500166893005,0.4762499928474426,0.29499998688697815,0.918749988079071,0.5287500023841858,0.6787499785423279,0.5874999761581421,0.6337500214576721,0.4437499940395355,0.4937500059604645,0.5237500071525574,0.8924999833106995,0.6337500214576721,0.7724999785423279],[0.7950000166893005,0.8737499713897705,0.8650000095367432,0.6650000214576721,0.8337500095367432,0.8424999713897705,0.925000011920929,0.9012500047683716,0.7987499833106995,0.8500000238418579,0.8450000286102295,0.8412500023841858,0.8662499785423279,0.9075000286102295,0.9150000214576721]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"tickmode\":\"array\",\"tickvals\":[\"Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to\",\"Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to\",\"After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to\",\"While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to\",\"While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to\",\"After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to\",\"The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to\",\"Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to\"],\"ticktext\":[\"Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to\",\"Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to\",\"After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to\",\"While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to\",\"While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to\",\"After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to\",\"The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to\",\"Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to\"]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"tickmode\":\"array\",\"tickvals\":[\"AB A B\\nAC A C\",\"AB A B\\nCB C B\",\"AB B A\\nAC C A\",\"AB B A\\nCB B C\"],\"ticktext\":[\"AB A B\\nAC A C\",\"AB A B\\nCB C B\",\"AB B A\\nAC C A\",\"AB B A\\nCB B C\"]},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"margin\":{\"t\":60},\"font\":{\"size\":7,\"color\":\"black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a3290536-59ca-4174-9aaa-99061b4511fa');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import transformer_lens.utils as utils\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", font_size=None, show=True, color_continuous_midpoint=0.0, **kwargs):\n",
    "    fig = px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=color_continuous_midpoint, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs)\n",
    "    if not font_size is None:\n",
    "        if 'x' in kwargs:\n",
    "            fig.update_layout(\n",
    "              xaxis = dict(\n",
    "                tickmode='array',\n",
    "                tickvals = kwargs['x'],\n",
    "                ticktext = kwargs['x'], \n",
    "                ),\n",
    "               font=dict(size=font_size, color=\"black\"))\n",
    "        if 'y' in kwargs:\n",
    "            fig.update_layout(\n",
    "              yaxis = dict(\n",
    "                tickmode='array',\n",
    "                tickvals = kwargs['y'],\n",
    "                ticktext = kwargs['y'], \n",
    "                ),\n",
    "               font=dict(size=font_size, color=\"black\"))\n",
    "    if show:\n",
    "        fig.show(renderer)\n",
    "    else:\n",
    "        return fig\n",
    "\n",
    "imshow(scores[:len(BABA_TEMPLATES)].T, x=BABA_TEMPLATES, y=patching_formats, font_size=7, color_continuous_midpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19a57466-f934-4acd-b912-869aa8898ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from einops import rearrange\n",
    "global storage\n",
    "storage = {}\n",
    "\n",
    "def in_proj_stofrage_hook(\n",
    "    in_proj: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    global storage\n",
    "    storage[\"in_proj\"] = in_proj\n",
    "\n",
    "def ignore_conv_crfoss_talk_hook(\n",
    "    x_conv: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint,\n",
    "    layer: int,\n",
    ") -> Float[torch.Tensor, \"B L E\"]:    \n",
    "    D_CONV = model.cfg.d_conv\n",
    "    global storage\n",
    "    conv_input = storage[\"in_proj\"]\n",
    "    B, L, E = conv_input.size()\n",
    "    conv_input = rearrange(conv_input, 'B L E -> B E L')\n",
    "    \n",
    "    ### This is identical to what the conv is doing\n",
    "    # pad zeros in front\n",
    "    # [B,E,D_CONV-1+L]\n",
    "    padded_input = torch.nn.functional.pad(conv_input, (D_CONV-1,0), mode='constant', value=0)\n",
    "    output = torch.zeros([B,E,L], device=model.cfg.device)\n",
    "    # [E,1,D_CONV]\n",
    "    conv_weight = model.blocks[layer].conv1d.weight\n",
    "    # [E]\n",
    "    conv_bias = model.blocks[layer].conv1d.bias\n",
    "    for i in range(D_CONV):\n",
    "        #                 [E]                    [B,E,L]\n",
    "        #output += conv_weight[:,0,i].view(E,1)*padded_input[:,:,i:i+L] # this is what conv is doing\n",
    "        output += conv_weight[:,0,i].view(E,1)*conv_input\n",
    "        #if i == D_CONV-1:\n",
    "        #    output += conv_weight[:,0,i].view(E,1)*conv_input\n",
    "    \n",
    "    output += conv_bias.view(E, 1)\n",
    "    \n",
    "    output = rearrange(output, 'B E L -> B L E')\n",
    "    return output\n",
    "\n",
    "\n",
    "def ssm_input_stofrage_hook(\n",
    "    ssm_input: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    global storage\n",
    "    storage[\"ssm_input\"] = ssm_input\n",
    "    return ssm_input\n",
    "\n",
    "global storage\n",
    "def B_bar_storfage_hook(\n",
    "    B_bar: Float[torch.Tensor, \"B L E N\"],\n",
    "    hook: HookPoint,\n",
    ") -> Float[torch.Tensor, \"B L E N\"]:\n",
    "    global storage\n",
    "    storage['B_bar'] = B_bar\n",
    "    return B_bar\n",
    "\n",
    "def h_no_token_crofss_talk_hook(\n",
    "    h: Float[torch.Tensor, \"B E N\"],\n",
    "    hook: HookPoint,\n",
    "    position: int,\n",
    ") -> Float[torch.Tensor, \"B E N\"]:\n",
    "    B,E,N = h.size()\n",
    "    # [B E N]\n",
    "    global storage\n",
    "    B_bar = storage['B_bar'][:,position,:,:]\n",
    "    # [B E 1]\n",
    "    x = storage['ssm_input'][:,position].view(B,E,1)\n",
    "    my_contribution = B_bar*x\n",
    "    #corrupted_\n",
    "    return B_bar*x\n",
    "\n",
    "# doesn't work, 0.2 accuracy\n",
    "def skip_ssm_hfook(\n",
    "    y: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    global ssm_input_storage\n",
    "    return ssm_input_storage[\"ssm_input\"]\n",
    "\n",
    "# 80%\n",
    "def patch_ssm_hofok(\n",
    "    y: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    y[0::2] = y[1::2]\n",
    "    return y\n",
    "\n",
    "# 85%\n",
    "def patch_h_hofok(\n",
    "    h: Float[torch.Tensor, \"B E N\"],\n",
    "    hook: HookPoint,\n",
    "    position: int,\n",
    ") -> Float[torch.Tensor, \"B E N\"]:\n",
    "    corrupted = h[1::2]\n",
    "    h[0::2] = corrupted\n",
    "    return h\n",
    "\n",
    "class EmptyObject(object):\n",
    "    pass\n",
    "\n",
    "ssm_inputs_storage = EmptyObject()\n",
    "\n",
    "\n",
    "def ssm_infput_hook(\n",
    "    ssm_input: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint,\n",
    "    layer: int,\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    ssm_inputs_storage.ssm_input = ssm_input\n",
    "    return ssm_input\n",
    "\n",
    "def C_hofok(\n",
    "    C: Float[torch.Tensor, \"B L N\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L N\"]:\n",
    "    ssm_inputs_storage.C = C\n",
    "    return C\n",
    "\n",
    "def B_bar_hofok(\n",
    "    B_bar: Float[torch.Tensor, \"B L E N\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L E N\"]:\n",
    "    ssm_inputs_storage.B_bar = B_bar\n",
    "    return B_bar\n",
    "\n",
    "def ssm_outpuft_hook(\n",
    "    ssm_output: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint,\n",
    "    layer: int,\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    # return ssm_output\n",
    "    # [B,L,E]\n",
    "    x = ssm_inputs_storage.ssm_input\n",
    "    B,L,E = x.size()\n",
    "    # [B,L,N]\n",
    "    C = ssm_inputs_storage.C\n",
    "    B,L,N = C.size()\n",
    "    # [B,L,E,N]\n",
    "    B_bar = ssm_inputs_storage.B_bar\n",
    "    output = torch.zeros((B,L,E), device=model.cfg.device)\n",
    "    for n in range(N):\n",
    "        #  [B,L,E]             [B,L,E]        [B,L,E]\n",
    "        h_contributions =   B_bar[:,:,:,n]   *   x\n",
    "        #[B,L,E]    [B,L,E]               [B,L,1]\n",
    "        output   +=  h_contributions *  C[:,:,n].view(B,L,1)\n",
    "        \n",
    "    #     [B,L,E]         [B,L,E]           [E]\n",
    "    return   output     +   x    *  model.blocks[layer].W_D\n",
    "\n",
    "def patch_layer_hook(\n",
    "    h: Float[torch.Tensor, \"B E N\"],\n",
    "    hook: HookPoint,\n",
    ") -> Float[torch.Tensor, \"B E N\"]:\n",
    "    # patch in corrupted (they come in pairs)\n",
    "    for i in range(0, h.size()[0], 2):\n",
    "        h[i] = h[i+1]\n",
    "    return h\n",
    "\n",
    "def hooks_to_remove_token_cross_talk(layers):\n",
    "    # remove conv cross talk\n",
    "    hooks = []\n",
    "    \n",
    "    for layer in layers:\n",
    "        L = data.data.size()[1]\n",
    "        hooks.append((f\"blocks.{layer}.hook_conv\", patch_layer_hook))\n",
    "        for l in range(L):\n",
    "            hooks.append((f\"blocks.{layer}.hook_h.{l}\", patch_layer_hook))\n",
    "    '''\n",
    "    for layer in layers:\n",
    "        #hooks.append((f\"blocks.{layer}.hook_in_proj\", in_proj_storage_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_conv\", partial(ignore_conv_cross_talk_hook, layer=layer)))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_conv\", patch_ssm_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_ssm_input\", ssm_input_storage_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_B_bar\", B_bar_storage_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_ssm_input\", partial(ssm_input_hook, layer=layer)))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_C\", C_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_B_bar\", B_bar_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_ssm_output\", partial(ssm_output_hook, layer=layer)))\n",
    "        \n",
    "\n",
    "        \n",
    "        #L = data.data.size()[1]\n",
    "        for l in range(L):\n",
    "            #hooks.append((f\"blocks.{layer}.hook_h.{l}\", partial(h_no_token_cross_talk_hook, position=l)))\n",
    "            #hooks.append((f\"blocks.{layer}.hook_h.{l}\", partial(patch_h_hook, position=l)))\n",
    "            hooks.append((f\"blocks.{layer}.hook_h.{l}\", partial(patch_h_hook, position=l)))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_ssm_input\", patch_h_hook))\n",
    "    '''\n",
    "    return hooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac732959-bdab-4903-8f05-97298bf467e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{50178, 46600, 31755, 46604, 10765, 11276, 33811, 46612, 16916, 18966, 12824, 32794, 7195, 33821, 37921, 33313, 31270, 29222, 28712, 18985, 37930, 28200, 7727, 24112, 36400, 32817, 5171, 44085, 35382, 14912, 30274, 20554, 15435, 33357, 49231, 38994, 21587, 7252, 40537, 27738, 44123, 44124, 14943, 45664, 15458, 49765, 19046, 35944, 29804, 23662, 37497, 22138, 27773, 28798, 33407, 27264, 9857, 14468, 6277, 35972, 4744, 32905, 32393, 22671, 20628, 32920, 17560, 5119, 21661, 16543, 31903, 18089, 16553, 28331, 41131, 20145, 46262, 30397, 41151, 22723, 23239, 14538, 17100, 37073, 22739, 49365, 16598, 47831, 31959, 22234, 23259, 20189, 45790, 29927, 46312, 31465, 46831, 31472, 29936, 26355, 6393, 26876, 8444, 26878, 6911, 25856, 21249, 19717, 8966, 38150, 26888, 27917, 39184, 48401, 24336, 6416, 23316, 37144, 31513, 42266, 29989, 27434, 45867, 36139, 29489, 27443, 27955, 22838, 7993, 13114, 13629, 28991, 40771, 25413, 44870, 18247, 47944, 35657, 26953, 13651, 27991, 26456, 48990, 34655, 16225, 28518, 20839, 43367, 10092, 11116, 31086, 29040, 50033, 5490, 39795, 48505, 40316, 24958, 38783, 19838, 23425, 24962, 13187, 49028, 12167, 43406, 14737, 18322, 43921, 12694, 16286, 48545, 29092, 15273, 16809, 22455, 24504, 30140, 27581, 21438, 35262, 36292, 6086, 21960, 20428, 17361, 33747, 2516, 13268, 45014, 25556, 33240, 36312, 16863, 28642, 10213, 16358, 25062, 23528, 35307, 19436, 25579, 15859, 38900, 7670, 8698, 12284, 44542, 31231}\n",
      "torch.Size([40000, 20])\n"
     ]
    }
   ],
   "source": [
    "from acdc.data.ioi import good_names\n",
    "from collections import defaultdict\n",
    "name_tokens = set([model.to_single_token(\" \" + name) for name in good_names])\\\n",
    "\n",
    "print(name_tokens)\n",
    "print(data.data.size())\n",
    "name_positions = defaultdict(lambda: [])\n",
    "for i in range(data.data.size()[0]):\n",
    "    prompt_tokens = data.data[i]\n",
    "    name_pos = 0\n",
    "    for i, tok in enumerate(prompt_tokens):\n",
    "        if tok.item() in name_tokens:\n",
    "            name_positions[name_pos].append(i) # +1 because conv\n",
    "            name_pos += 1\n",
    "    if name_pos != 5: raise ValueError(f\"data point {model.to_str_tokens(data)} does not have 5 names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a127f0f-b5db-415a-ab4f-7468f72dd099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "969917bf-e5cc-4b9c-b12c-c16a3fa6d3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2fafad053a434793c8118195acd55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7fc428aac790>, {0: {50178: 166, 46600: 186, 31755: 180, 46604: 212, 10765: 194, 11276: 236, 33811: 180, 46612: 224, 16916: 192, 18966: 176, 12824: 210, 32794: 170, 7195: 162, 33821: 174, 37921: 172, 33313: 206, 31270: 206, 29222: 182, 28712: 152, 18985: 190, 37930: 180, 28200: 206, 7727: 122, 24112: 196, 36400: 198, 32817: 238, 5171: 148, 44085: 210, 35382: 208, 14912: 198, 30274: 200, 20554: 148, 15435: 244, 33357: 170, 49231: 176, 38994: 182, 21587: 218, 7252: 146, 40537: 184, 27738: 224, 44123: 180, 44124: 220, 14943: 144, 45664: 194, 15458: 216, 49765: 194, 19046: 194, 35944: 204, 29804: 166, 23662: 220, 37497: 198, 22138: 216, 27773: 188, 28798: 172, 33407: 200, 27264: 162, 9857: 184, 14468: 206, 6277: 188, 35972: 164, 4744: 152, 32905: 198, 32393: 186, 22671: 172, 20628: 208, 32920: 352, 17560: 166, 5119: 134, 21661: 184, 16543: 180, 31903: 206, 18089: 184, 16553: 200, 28331: 188, 41131: 150, 20145: 204, 46262: 160, 30397: 206, 41151: 210, 22723: 198, 23239: 194, 14538: 172, 17100: 222, 37073: 172, 22739: 230, 49365: 146, 16598: 186, 47831: 196, 31959: 226, 22234: 244, 23259: 238, 20189: 178, 45790: 190, 29927: 230, 46312: 238, 31465: 170, 46831: 142, 31472: 174, 29936: 150, 26355: 142, 6393: 144, 26876: 208, 8444: 156, 26878: 192, 6911: 152, 25856: 174, 21249: 192, 19717: 196, 8966: 168, 38150: 180, 26888: 210, 27917: 188, 39184: 212, 48401: 118, 24336: 172, 6416: 178, 23316: 156, 37144: 146, 31513: 210, 42266: 184, 29989: 178, 27434: 210, 45867: 204, 36139: 228, 29489: 184, 27443: 206, 27955: 206, 22838: 178, 7993: 174, 13114: 168, 13629: 210, 28991: 182, 40771: 178, 25413: 226, 44870: 190, 18247: 230, 47944: 214, 35657: 174, 26953: 174, 13651: 236, 27991: 206, 26456: 216, 48990: 198, 34655: 176, 16225: 156, 28518: 142, 20839: 202, 43367: 250, 10092: 194, 11116: 164, 31086: 192, 29040: 204, 50033: 192, 5490: 210, 39795: 194, 48505: 162, 40316: 188, 24958: 212, 38783: 164, 19838: 208, 23425: 174, 24962: 188, 13187: 176, 49028: 210, 12167: 186, 43406: 198, 14737: 192, 18322: 164, 43921: 210, 12694: 204, 16286: 192, 48545: 202, 29092: 158, 15273: 200, 16809: 188, 22455: 132, 24504: 206, 30140: 210, 27581: 166, 21438: 196, 35262: 176, 36292: 194, 6086: 168, 21960: 198, 20428: 238, 17361: 228, 33747: 150, 2516: 246, 13268: 422, 45014: 170, 25556: 216, 33240: 222, 36312: 226, 16863: 184, 28642: 206, 10213: 184, 16358: 216, 25062: 176, 23528: 192, 35307: 218, 19436: 162, 25579: 188, 15859: 222, 38900: 138, 7670: 208, 8698: 194, 12284: 170, 44542: 184, 31231: 182}, 1: {50178: 226, 46600: 160, 31755: 178, 46604: 170, 10765: 218, 11276: 204, 33811: 172, 46612: 220, 16916: 154, 18966: 202, 12824: 208, 32794: 182, 7195: 194, 33821: 184, 37921: 184, 33313: 228, 31270: 172, 29222: 156, 28712: 166, 18985: 196, 37930: 194, 28200: 184, 7727: 182, 24112: 212, 36400: 214, 32817: 194, 5171: 200, 44085: 238, 35382: 184, 14912: 170, 30274: 186, 20554: 154, 15435: 150, 33357: 146, 49231: 224, 38994: 172, 21587: 150, 7252: 164, 40537: 218, 27738: 210, 44123: 170, 44124: 248, 14943: 226, 45664: 156, 15458: 202, 49765: 190, 19046: 218, 35944: 218, 29804: 176, 23662: 154, 37497: 204, 22138: 164, 27773: 200, 28798: 252, 33407: 190, 27264: 206, 9857: 168, 14468: 160, 6277: 152, 35972: 222, 4744: 186, 32905: 160, 32393: 224, 22671: 196, 20628: 202, 32920: 366, 17560: 178, 5119: 128, 21661: 226, 16543: 142, 31903: 230, 18089: 180, 16553: 184, 28331: 198, 41131: 184, 20145: 158, 46262: 198, 30397: 242, 41151: 216, 22723: 208, 23239: 212, 14538: 182, 17100: 192, 37073: 180, 22739: 222, 49365: 218, 16598: 128, 47831: 188, 31959: 198, 22234: 178, 23259: 164, 20189: 180, 45790: 210, 29927: 204, 46312: 204, 31465: 204, 46831: 180, 31472: 176, 29936: 118, 26355: 178, 6393: 224, 26876: 174, 8444: 190, 26878: 198, 6911: 162, 25856: 128, 21249: 158, 19717: 158, 8966: 192, 38150: 198, 26888: 204, 27917: 254, 39184: 174, 48401: 216, 24336: 178, 6416: 200, 23316: 174, 37144: 190, 31513: 194, 42266: 122, 29989: 196, 27434: 202, 45867: 170, 36139: 224, 29489: 192, 27443: 196, 27955: 190, 22838: 186, 7993: 184, 13114: 180, 13629: 198, 28991: 162, 40771: 194, 25413: 218, 44870: 198, 18247: 168, 47944: 176, 35657: 198, 26953: 190, 13651: 164, 27991: 226, 26456: 198, 48990: 170, 34655: 212, 16225: 186, 28518: 154, 20839: 194, 43367: 194, 10092: 192, 11116: 164, 31086: 218, 29040: 178, 50033: 176, 5490: 228, 39795: 156, 48505: 168, 40316: 194, 24958: 136, 38783: 180, 19838: 210, 23425: 196, 24962: 212, 13187: 198, 49028: 154, 12167: 214, 43406: 232, 14737: 212, 18322: 154, 43921: 202, 12694: 192, 16286: 156, 48545: 152, 29092: 226, 15273: 180, 16809: 204, 22455: 172, 24504: 166, 30140: 218, 27581: 178, 21438: 188, 35262: 150, 36292: 200, 6086: 172, 21960: 166, 20428: 190, 17361: 136, 33747: 182, 2516: 232, 13268: 376, 45014: 182, 25556: 194, 33240: 204, 36312: 246, 16863: 212, 28642: 208, 10213: 196, 16358: 200, 25062: 176, 23528: 206, 35307: 212, 19436: 168, 25579: 234, 15859: 200, 38900: 232, 7670: 162, 8698: 228, 12284: 246, 44542: 182, 31231: 176}, 2: {50178: 188, 46600: 186, 31755: 194, 46604: 214, 10765: 200, 11276: 160, 33811: 178, 46612: 236, 16916: 264, 18966: 214, 12824: 164, 32794: 234, 7195: 166, 33821: 190, 37921: 210, 33313: 202, 31270: 178, 29222: 156, 28712: 212, 18985: 214, 37930: 194, 28200: 174, 7727: 154, 24112: 184, 36400: 220, 32817: 206, 5171: 192, 44085: 194, 35382: 176, 14912: 194, 30274: 156, 20554: 160, 15435: 168, 33357: 172, 49231: 136, 38994: 216, 21587: 222, 7252: 182, 40537: 164, 27738: 178, 44123: 152, 44124: 156, 14943: 156, 45664: 158, 15458: 252, 49765: 216, 19046: 196, 35944: 210, 29804: 192, 23662: 170, 37497: 178, 22138: 174, 27773: 240, 28798: 152, 33407: 188, 27264: 196, 9857: 240, 14468: 162, 6277: 200, 35972: 174, 4744: 208, 32905: 184, 32393: 204, 22671: 210, 20628: 172, 32920: 388, 17560: 196, 5119: 172, 21661: 216, 16543: 216, 31903: 212, 18089: 156, 16553: 158, 28331: 200, 41131: 220, 20145: 150, 46262: 210, 30397: 168, 41151: 226, 22723: 206, 23239: 168, 14538: 184, 17100: 182, 37073: 180, 22739: 228, 49365: 156, 16598: 186, 47831: 238, 31959: 200, 22234: 212, 23259: 162, 20189: 238, 45790: 198, 29927: 258, 46312: 196, 31465: 144, 46831: 188, 31472: 230, 29936: 182, 26355: 248, 6393: 150, 26876: 188, 8444: 208, 26878: 206, 6911: 220, 25856: 192, 21249: 186, 19717: 152, 8966: 134, 38150: 168, 26888: 190, 27917: 134, 39184: 142, 48401: 180, 24336: 176, 6416: 212, 23316: 150, 37144: 216, 31513: 198, 42266: 230, 29989: 134, 27434: 154, 45867: 188, 36139: 250, 29489: 194, 27443: 178, 27955: 200, 22838: 194, 7993: 230, 13114: 172, 13629: 174, 28991: 204, 40771: 178, 25413: 224, 44870: 188, 18247: 206, 47944: 194, 35657: 182, 26953: 190, 13651: 182, 27991: 154, 26456: 156, 48990: 158, 34655: 214, 16225: 200, 28518: 162, 20839: 200, 43367: 206, 10092: 196, 11116: 250, 31086: 216, 29040: 258, 50033: 166, 5490: 168, 39795: 226, 48505: 196, 40316: 238, 24958: 196, 38783: 188, 19838: 196, 23425: 190, 24962: 172, 13187: 212, 49028: 222, 12167: 192, 43406: 168, 14737: 198, 18322: 184, 43921: 170, 12694: 164, 16286: 208, 48545: 180, 29092: 168, 15273: 164, 16809: 154, 22455: 162, 24504: 174, 30140: 218, 27581: 164, 21438: 206, 35262: 232, 36292: 174, 6086: 196, 21960: 124, 20428: 214, 17361: 204, 33747: 198, 2516: 124, 13268: 338, 45014: 236, 25556: 158, 33240: 158, 36312: 166, 16863: 178, 28642: 164, 10213: 186, 16358: 190, 25062: 176, 23528: 160, 35307: 166, 19436: 196, 25579: 196, 15859: 174, 38900: 210, 7670: 202, 8698: 164, 12284: 186, 44542: 216, 31231: 238}, 3: {50178: 188, 46600: 178, 31755: 192, 46604: 200, 10765: 204, 11276: 218, 33811: 198, 46612: 206, 16916: 192, 18966: 142, 12824: 216, 32794: 180, 7195: 188, 33821: 180, 37921: 168, 33313: 204, 31270: 194, 29222: 186, 28712: 160, 18985: 206, 37930: 204, 28200: 202, 7727: 126, 24112: 202, 36400: 170, 32817: 240, 5171: 156, 44085: 220, 35382: 190, 14912: 206, 30274: 178, 20554: 140, 15435: 188, 33357: 166, 49231: 184, 38994: 172, 21587: 202, 7252: 156, 40537: 196, 27738: 186, 44123: 160, 44124: 236, 14943: 156, 45664: 170, 15458: 202, 49765: 192, 19046: 188, 35944: 216, 29804: 198, 23662: 218, 37497: 220, 22138: 184, 27773: 176, 28798: 212, 33407: 226, 27264: 168, 9857: 208, 14468: 198, 6277: 170, 35972: 182, 4744: 146, 32905: 186, 32393: 202, 22671: 176, 20628: 218, 32920: 362, 17560: 164, 5119: 140, 21661: 182, 16543: 172, 31903: 212, 18089: 184, 16553: 194, 28331: 186, 41131: 178, 20145: 174, 46262: 168, 30397: 200, 41151: 202, 22723: 210, 23239: 206, 14538: 174, 17100: 204, 37073: 170, 22739: 238, 49365: 168, 16598: 152, 47831: 204, 31959: 232, 22234: 252, 23259: 194, 20189: 176, 45790: 188, 29927: 226, 46312: 210, 31465: 176, 46831: 158, 31472: 162, 29936: 150, 26355: 136, 6393: 150, 26876: 182, 8444: 152, 26878: 216, 6911: 162, 25856: 170, 21249: 186, 19717: 182, 8966: 166, 38150: 194, 26888: 210, 27917: 214, 39184: 186, 48401: 148, 24336: 170, 6416: 186, 23316: 170, 37144: 146, 31513: 222, 42266: 178, 29989: 188, 27434: 222, 45867: 212, 36139: 242, 29489: 170, 27443: 200, 27955: 216, 22838: 152, 7993: 174, 13114: 168, 13629: 212, 28991: 200, 40771: 170, 25413: 230, 44870: 168, 18247: 230, 47944: 208, 35657: 192, 26953: 196, 13651: 226, 27991: 202, 26456: 206, 48990: 182, 34655: 190, 16225: 132, 28518: 148, 20839: 192, 43367: 256, 10092: 212, 11116: 154, 31086: 226, 29040: 180, 50033: 182, 5490: 196, 39795: 176, 48505: 166, 40316: 206, 24958: 170, 38783: 164, 19838: 216, 23425: 172, 24962: 172, 13187: 170, 49028: 186, 12167: 218, 43406: 178, 14737: 218, 18322: 152, 43921: 236, 12694: 224, 16286: 204, 48545: 190, 29092: 188, 15273: 188, 16809: 182, 22455: 128, 24504: 190, 30140: 210, 27581: 180, 21438: 186, 35262: 166, 36292: 196, 6086: 166, 21960: 174, 20428: 234, 17361: 212, 33747: 144, 2516: 246, 13268: 432, 45014: 186, 25556: 214, 33240: 200, 36312: 234, 16863: 194, 28642: 194, 10213: 188, 16358: 222, 25062: 164, 23528: 206, 35307: 238, 19436: 162, 25579: 224, 15859: 208, 38900: 130, 7670: 202, 8698: 202, 12284: 174, 44542: 214, 31231: 184}, 4: {50178: 200, 46600: 186, 31755: 194, 46604: 200, 10765: 246, 11276: 184, 33811: 192, 46612: 238, 16916: 232, 18966: 224, 12824: 164, 32794: 232, 7195: 182, 33821: 180, 37921: 206, 33313: 230, 31270: 188, 29222: 148, 28712: 200, 18985: 222, 37930: 188, 28200: 168, 7727: 162, 24112: 178, 36400: 224, 32817: 204, 5171: 188, 44085: 204, 35382: 180, 14912: 156, 30274: 174, 20554: 160, 15435: 156, 33357: 180, 49231: 162, 38994: 202, 21587: 216, 7252: 172, 40537: 176, 27738: 198, 44123: 158, 44124: 198, 14943: 174, 45664: 174, 15458: 240, 49765: 214, 19046: 228, 35944: 230, 29804: 158, 23662: 166, 37497: 168, 22138: 170, 27773: 258, 28798: 170, 33407: 164, 27264: 200, 9857: 208, 14468: 134, 6277: 194, 35972: 198, 4744: 212, 32905: 164, 32393: 222, 22671: 196, 20628: 184, 32920: 348, 17560: 186, 5119: 162, 21661: 210, 16543: 174, 31903: 230, 18089: 154, 16553: 190, 28331: 216, 41131: 196, 20145: 138, 46262: 214, 30397: 226, 41151: 230, 22723: 236, 23239: 190, 14538: 194, 17100: 178, 37073: 174, 22739: 206, 49365: 180, 16598: 156, 47831: 234, 31959: 192, 22234: 212, 23259: 172, 20189: 248, 45790: 210, 29927: 248, 46312: 202, 31465: 162, 46831: 170, 31472: 232, 29936: 168, 26355: 262, 6393: 204, 26876: 214, 8444: 182, 26878: 184, 6911: 200, 25856: 172, 21249: 202, 19717: 148, 8966: 160, 38150: 196, 26888: 174, 27917: 164, 39184: 168, 48401: 180, 24336: 162, 6416: 192, 23316: 156, 37144: 176, 31513: 192, 42266: 200, 29989: 136, 27434: 160, 45867: 168, 36139: 234, 29489: 198, 27443: 180, 27955: 176, 22838: 202, 7993: 220, 13114: 186, 13629: 184, 28991: 182, 40771: 198, 25413: 214, 44870: 208, 18247: 188, 47944: 192, 35657: 178, 26953: 174, 13651: 158, 27991: 184, 26456: 166, 48990: 144, 34655: 214, 16225: 200, 28518: 144, 20839: 200, 43367: 206, 10092: 164, 11116: 216, 31086: 194, 29040: 252, 50033: 178, 5490: 174, 39795: 204, 48505: 186, 40316: 208, 24958: 192, 38783: 198, 19838: 178, 23425: 198, 24962: 178, 13187: 228, 49028: 180, 12167: 174, 43406: 188, 14737: 188, 18322: 178, 43921: 130, 12694: 162, 16286: 188, 48545: 172, 29092: 194, 15273: 152, 16809: 172, 22455: 180, 24504: 178, 30140: 236, 27581: 170, 21438: 200, 35262: 184, 36292: 190, 6086: 216, 21960: 130, 20428: 200, 17361: 178, 33747: 180, 2516: 166, 13268: 342, 45014: 204, 25556: 164, 33240: 168, 36312: 168, 16863: 196, 28642: 188, 10213: 196, 16358: 194, 25062: 186, 23528: 170, 35307: 192, 19436: 180, 25579: 228, 15859: 186, 38900: 242, 7670: 170, 8698: 172, 12284: 212, 44542: 192, 31231: 218}})\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "LAYER = 39\n",
    "batch_size = 40\n",
    "\n",
    "hook = f\"blocks.{LAYER}.hook_ssm_input\"\n",
    "\n",
    "name_averages = defaultdict(lambda: {})\n",
    "name_choices = defaultdict(lambda: defaultdict(lambda: []))\n",
    "counts = defaultdict(lambda: {})\n",
    "\n",
    "TOTAL_AVG_NAME = \"total\"\n",
    "\n",
    "for tok in name_tokens:\n",
    "    for name_i in range(len(name_positions)):\n",
    "        name_averages[name_i][tok] = torch.zeros([model.cfg.E], device=model.cfg.device)\n",
    "        counts[name_i][tok] = 0\n",
    "\n",
    "for batch_start in tqdm(list(range(0, data.data.size()[0], batch_size))):\n",
    "    batch_end = min(data.data.size()[0], batch_start+batch_size)\n",
    "    data_batch = data.data[batch_start:batch_end]\n",
    "    logits, activations = model.run_with_cache(data_batch, names_filter=[hook], fast_ssm=True, fast_conv=True)\n",
    "    for name_i in range(len(name_positions)):\n",
    "        positions = torch.tensor(name_positions[name_i][batch_start:batch_end], device=model.cfg.device)\n",
    "        batch_name_tokens = data_batch[torch.arange(batch_end-batch_start),positions]\n",
    "        ssm_inputs = activations[hook]\n",
    "        for batch_i, name_tok in enumerate(batch_name_tokens):\n",
    "            #print(ssm_inputs[batch_i, position].size())\n",
    "            try:\n",
    "                position = positions[batch_i]+1\n",
    "                name_averages[name_i][name_tok.item()] += ssm_inputs[batch_i, position]\n",
    "                if len(name_choices[name_i][name_tok.item()]) < 20: # save some memory\n",
    "                    name_choices[name_i][name_tok.item()].append(ssm_inputs[batch_i, position])\n",
    "                #name_averages['all'][name_tok.item()] += ssm_inputs[batch_i, position]\n",
    "                #name_averages[name_i][TOTAL_AVG_NAME] += ssm_inputs[batch_i, position]\n",
    "                counts[name_i][name_tok.item()] += 1\n",
    "                #counts[name_i][TOTAL_AVG_NAME] += 1\n",
    "            except:\n",
    "                print(model.to_str_tokens([name_tok]))\n",
    "                raise\n",
    "    \n",
    "print(counts)\n",
    "for name_i in range(len(name_positions)):\n",
    "    for name_tok in list(name_averages[name_i].keys()):\n",
    "        name_averages[name_i][name_tok] = name_averages[name_i][name_tok] / counts[name_i][name_tok]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "071348f8-ed3d-403d-ae73-0ba8f550161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 50178 tensor(12.7626, device='cuda:0')\n",
      "20\n",
      "166\n",
      "0 50178 tensor(12.3633, device='cuda:0')\n",
      "0 50178 tensor(13.0378, device='cuda:0')\n",
      "\n",
      "0 46600 tensor(12.8618, device='cuda:0')\n",
      "20\n",
      "186\n",
      "0 46600 tensor(13.1206, device='cuda:0')\n",
      "0 46600 tensor(13.1206, device='cuda:0')\n",
      "\n",
      "0 31755 tensor(13.4229, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 31755 tensor(14.2686, device='cuda:0')\n",
      "0 31755 tensor(14.2686, device='cuda:0')\n",
      "\n",
      "0 46604 tensor(12.4573, device='cuda:0')\n",
      "20\n",
      "212\n",
      "0 46604 tensor(13.8661, device='cuda:0')\n",
      "0 46604 tensor(12.3146, device='cuda:0')\n",
      "\n",
      "0 10765 tensor(12.8339, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 10765 tensor(13.7052, device='cuda:0')\n",
      "0 10765 tensor(13.4607, device='cuda:0')\n",
      "\n",
      "0 11276 tensor(13.3126, device='cuda:0')\n",
      "20\n",
      "236\n",
      "0 11276 tensor(14.2519, device='cuda:0')\n",
      "0 11276 tensor(14.2519, device='cuda:0')\n",
      "\n",
      "0 33811 tensor(13.4167, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 33811 tensor(14.3506, device='cuda:0')\n",
      "0 33811 tensor(14.3506, device='cuda:0')\n",
      "\n",
      "0 46612 tensor(13.5347, device='cuda:0')\n",
      "20\n",
      "224\n",
      "0 46612 tensor(14.7716, device='cuda:0')\n",
      "0 46612 tensor(14.7716, device='cuda:0')\n",
      "\n",
      "0 16916 tensor(12.5435, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 16916 tensor(12.5832, device='cuda:0')\n",
      "0 16916 tensor(12.5832, device='cuda:0')\n",
      "\n",
      "0 18966 tensor(12.9463, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 18966 tensor(12.9543, device='cuda:0')\n",
      "0 18966 tensor(13.0794, device='cuda:0')\n",
      "\n",
      "0 12824 tensor(11.8327, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 12824 tensor(11.6573, device='cuda:0')\n",
      "0 12824 tensor(11.6573, device='cuda:0')\n",
      "\n",
      "0 32794 tensor(12.2683, device='cuda:0')\n",
      "20\n",
      "170\n",
      "0 32794 tensor(12.4698, device='cuda:0')\n",
      "0 32794 tensor(12.4698, device='cuda:0')\n",
      "\n",
      "0 7195 tensor(12.5167, device='cuda:0')\n",
      "20\n",
      "162\n",
      "0 7195 tensor(13.0059, device='cuda:0')\n",
      "0 7195 tensor(13.3565, device='cuda:0')\n",
      "\n",
      "0 33821 tensor(13.0784, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 33821 tensor(12.7218, device='cuda:0')\n",
      "0 33821 tensor(13.2524, device='cuda:0')\n",
      "\n",
      "0 37921 tensor(13.2030, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 37921 tensor(13.9821, device='cuda:0')\n",
      "0 37921 tensor(13.2424, device='cuda:0')\n",
      "\n",
      "0 33313 tensor(12.8516, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 33313 tensor(13.3062, device='cuda:0')\n",
      "0 33313 tensor(12.4151, device='cuda:0')\n",
      "\n",
      "0 31270 tensor(13.1325, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 31270 tensor(13.5714, device='cuda:0')\n",
      "0 31270 tensor(14.0844, device='cuda:0')\n",
      "\n",
      "0 29222 tensor(12.7585, device='cuda:0')\n",
      "20\n",
      "182\n",
      "0 29222 tensor(13.0037, device='cuda:0')\n",
      "0 29222 tensor(13.0037, device='cuda:0')\n",
      "\n",
      "0 28712 tensor(12.5903, device='cuda:0')\n",
      "20\n",
      "152\n",
      "0 28712 tensor(13.4471, device='cuda:0')\n",
      "0 28712 tensor(13.4471, device='cuda:0')\n",
      "\n",
      "0 18985 tensor(12.5035, device='cuda:0')\n",
      "20\n",
      "190\n",
      "0 18985 tensor(13.4102, device='cuda:0')\n",
      "0 18985 tensor(13.5528, device='cuda:0')\n",
      "\n",
      "0 37930 tensor(12.9887, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 37930 tensor(13.9630, device='cuda:0')\n",
      "0 37930 tensor(14.3912, device='cuda:0')\n",
      "\n",
      "0 28200 tensor(12.4344, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 28200 tensor(12.2348, device='cuda:0')\n",
      "0 28200 tensor(12.2348, device='cuda:0')\n",
      "\n",
      "0 7727 tensor(12.4297, device='cuda:0')\n",
      "20\n",
      "122\n",
      "0 7727 tensor(12.4165, device='cuda:0')\n",
      "0 7727 tensor(13.0009, device='cuda:0')\n",
      "\n",
      "0 24112 tensor(13.6538, device='cuda:0')\n",
      "20\n",
      "196\n",
      "0 24112 tensor(14.9432, device='cuda:0')\n",
      "0 24112 tensor(13.7304, device='cuda:0')\n",
      "\n",
      "0 36400 tensor(12.8940, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 36400 tensor(13.0398, device='cuda:0')\n",
      "0 36400 tensor(13.0398, device='cuda:0')\n",
      "\n",
      "0 32817 tensor(13.5889, device='cuda:0')\n",
      "20\n",
      "238\n",
      "0 32817 tensor(14.4853, device='cuda:0')\n",
      "0 32817 tensor(14.5227, device='cuda:0')\n",
      "\n",
      "0 5171 tensor(12.4680, device='cuda:0')\n",
      "20\n",
      "148\n",
      "0 5171 tensor(13.1653, device='cuda:0')\n",
      "0 5171 tensor(13.1653, device='cuda:0')\n",
      "\n",
      "0 44085 tensor(12.5504, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 44085 tensor(12.7504, device='cuda:0')\n",
      "0 44085 tensor(13.6588, device='cuda:0')\n",
      "\n",
      "0 35382 tensor(13.4250, device='cuda:0')\n",
      "20\n",
      "208\n",
      "0 35382 tensor(13.2224, device='cuda:0')\n",
      "0 35382 tensor(14.4219, device='cuda:0')\n",
      "\n",
      "0 14912 tensor(12.8857, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 14912 tensor(12.7235, device='cuda:0')\n",
      "0 14912 tensor(14.1867, device='cuda:0')\n",
      "\n",
      "0 30274 tensor(12.3714, device='cuda:0')\n",
      "20\n",
      "200\n",
      "0 30274 tensor(12.2414, device='cuda:0')\n",
      "0 30274 tensor(13.4663, device='cuda:0')\n",
      "\n",
      "0 20554 tensor(12.5487, device='cuda:0')\n",
      "20\n",
      "148\n",
      "0 20554 tensor(12.8916, device='cuda:0')\n",
      "0 20554 tensor(13.6043, device='cuda:0')\n",
      "\n",
      "0 15435 tensor(13.1355, device='cuda:0')\n",
      "20\n",
      "244\n",
      "0 15435 tensor(14.2929, device='cuda:0')\n",
      "0 15435 tensor(13.5921, device='cuda:0')\n",
      "\n",
      "0 33357 tensor(12.5574, device='cuda:0')\n",
      "20\n",
      "170\n",
      "0 33357 tensor(12.2488, device='cuda:0')\n",
      "0 33357 tensor(12.9592, device='cuda:0')\n",
      "\n",
      "0 49231 tensor(13.3039, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 49231 tensor(13.8549, device='cuda:0')\n",
      "0 49231 tensor(13.8549, device='cuda:0')\n",
      "\n",
      "0 38994 tensor(13.0173, device='cuda:0')\n",
      "20\n",
      "182\n",
      "0 38994 tensor(13.9752, device='cuda:0')\n",
      "0 38994 tensor(13.3703, device='cuda:0')\n",
      "\n",
      "0 21587 tensor(12.4770, device='cuda:0')\n",
      "20\n",
      "218\n",
      "0 21587 tensor(12.5303, device='cuda:0')\n",
      "0 21587 tensor(13.2892, device='cuda:0')\n",
      "\n",
      "0 7252 tensor(12.0709, device='cuda:0')\n",
      "20\n",
      "146\n",
      "0 7252 tensor(13.0294, device='cuda:0')\n",
      "0 7252 tensor(13.0761, device='cuda:0')\n",
      "\n",
      "0 40537 tensor(13.0609, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 40537 tensor(13.1456, device='cuda:0')\n",
      "0 40537 tensor(13.1456, device='cuda:0')\n",
      "\n",
      "0 27738 tensor(13.3098, device='cuda:0')\n",
      "20\n",
      "224\n",
      "0 27738 tensor(14.4399, device='cuda:0')\n",
      "0 27738 tensor(14.4399, device='cuda:0')\n",
      "\n",
      "0 44123 tensor(13.1284, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 44123 tensor(13.9336, device='cuda:0')\n",
      "0 44123 tensor(12.9097, device='cuda:0')\n",
      "\n",
      "0 44124 tensor(12.5597, device='cuda:0')\n",
      "20\n",
      "220\n",
      "0 44124 tensor(13.2709, device='cuda:0')\n",
      "0 44124 tensor(13.2709, device='cuda:0')\n",
      "\n",
      "0 14943 tensor(13.2119, device='cuda:0')\n",
      "20\n",
      "144\n",
      "0 14943 tensor(14.4973, device='cuda:0')\n",
      "0 14943 tensor(14.4973, device='cuda:0')\n",
      "\n",
      "0 45664 tensor(12.9323, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 45664 tensor(14.1823, device='cuda:0')\n",
      "0 45664 tensor(14.1823, device='cuda:0')\n",
      "\n",
      "0 15458 tensor(12.5931, device='cuda:0')\n",
      "20\n",
      "216\n",
      "0 15458 tensor(14.0393, device='cuda:0')\n",
      "0 15458 tensor(13.1521, device='cuda:0')\n",
      "\n",
      "0 49765 tensor(12.9722, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 49765 tensor(13.2506, device='cuda:0')\n",
      "0 49765 tensor(14.0132, device='cuda:0')\n",
      "\n",
      "0 19046 tensor(12.7682, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 19046 tensor(13.5305, device='cuda:0')\n",
      "0 19046 tensor(13.9737, device='cuda:0')\n",
      "\n",
      "0 35944 tensor(12.4344, device='cuda:0')\n",
      "20\n",
      "204\n",
      "0 35944 tensor(12.4766, device='cuda:0')\n",
      "0 35944 tensor(12.4766, device='cuda:0')\n",
      "\n",
      "0 29804 tensor(13.0494, device='cuda:0')\n",
      "20\n",
      "166\n",
      "0 29804 tensor(12.8638, device='cuda:0')\n",
      "0 29804 tensor(12.8638, device='cuda:0')\n",
      "\n",
      "0 23662 tensor(12.8338, device='cuda:0')\n",
      "20\n",
      "220\n",
      "0 23662 tensor(12.7117, device='cuda:0')\n",
      "0 23662 tensor(12.7117, device='cuda:0')\n",
      "\n",
      "0 37497 tensor(13.1458, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 37497 tensor(14.1370, device='cuda:0')\n",
      "0 37497 tensor(14.3730, device='cuda:0')\n",
      "\n",
      "0 22138 tensor(13.2200, device='cuda:0')\n",
      "20\n",
      "216\n",
      "0 22138 tensor(14.4110, device='cuda:0')\n",
      "0 22138 tensor(13.3316, device='cuda:0')\n",
      "\n",
      "0 27773 tensor(13.1956, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 27773 tensor(13.2370, device='cuda:0')\n",
      "0 27773 tensor(13.2370, device='cuda:0')\n",
      "\n",
      "0 28798 tensor(12.8403, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 28798 tensor(13.4330, device='cuda:0')\n",
      "0 28798 tensor(13.4330, device='cuda:0')\n",
      "\n",
      "0 33407 tensor(13.3381, device='cuda:0')\n",
      "20\n",
      "200\n",
      "0 33407 tensor(12.7921, device='cuda:0')\n",
      "0 33407 tensor(12.7921, device='cuda:0')\n",
      "\n",
      "0 27264 tensor(12.2719, device='cuda:0')\n",
      "20\n",
      "162\n",
      "0 27264 tensor(12.3675, device='cuda:0')\n",
      "0 27264 tensor(12.3675, device='cuda:0')\n",
      "\n",
      "0 9857 tensor(12.8134, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 9857 tensor(13.6642, device='cuda:0')\n",
      "0 9857 tensor(13.6642, device='cuda:0')\n",
      "\n",
      "0 14468 tensor(12.6566, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 14468 tensor(13.7529, device='cuda:0')\n",
      "0 14468 tensor(13.6242, device='cuda:0')\n",
      "\n",
      "0 6277 tensor(12.5546, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 6277 tensor(13.6594, device='cuda:0')\n",
      "0 6277 tensor(13.6594, device='cuda:0')\n",
      "\n",
      "0 35972 tensor(13.4909, device='cuda:0')\n",
      "20\n",
      "164\n",
      "0 35972 tensor(14.2806, device='cuda:0')\n",
      "0 35972 tensor(13.5212, device='cuda:0')\n",
      "\n",
      "0 4744 tensor(12.2108, device='cuda:0')\n",
      "20\n",
      "152\n",
      "0 4744 tensor(12.3553, device='cuda:0')\n",
      "0 4744 tensor(12.3553, device='cuda:0')\n",
      "\n",
      "0 32905 tensor(12.4487, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 32905 tensor(12.4628, device='cuda:0')\n",
      "0 32905 tensor(12.4628, device='cuda:0')\n",
      "\n",
      "0 32393 tensor(13.0485, device='cuda:0')\n",
      "20\n",
      "186\n",
      "0 32393 tensor(13.6030, device='cuda:0')\n",
      "0 32393 tensor(13.8995, device='cuda:0')\n",
      "\n",
      "0 22671 tensor(13.3392, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 22671 tensor(14.4455, device='cuda:0')\n",
      "0 22671 tensor(13.6472, device='cuda:0')\n",
      "\n",
      "0 20628 tensor(13.0219, device='cuda:0')\n",
      "20\n",
      "208\n",
      "0 20628 tensor(13.3048, device='cuda:0')\n",
      "0 20628 tensor(13.3048, device='cuda:0')\n",
      "\n",
      "0 32920 tensor(13.7633, device='cuda:0')\n",
      "20\n",
      "352\n",
      "0 32920 tensor(13.4423, device='cuda:0')\n",
      "0 32920 tensor(14.5938, device='cuda:0')\n",
      "\n",
      "0 17560 tensor(12.8148, device='cuda:0')\n",
      "20\n",
      "166\n",
      "0 17560 tensor(13.5656, device='cuda:0')\n",
      "0 17560 tensor(13.5666, device='cuda:0')\n",
      "\n",
      "0 5119 tensor(12.3343, device='cuda:0')\n",
      "20\n",
      "134\n",
      "0 5119 tensor(13.5068, device='cuda:0')\n",
      "0 5119 tensor(12.3289, device='cuda:0')\n",
      "\n",
      "0 21661 tensor(12.0129, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 21661 tensor(12.5662, device='cuda:0')\n",
      "0 21661 tensor(12.5662, device='cuda:0')\n",
      "\n",
      "0 16543 tensor(13.0676, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 16543 tensor(13.2557, device='cuda:0')\n",
      "0 16543 tensor(13.2557, device='cuda:0')\n",
      "\n",
      "0 31903 tensor(12.6538, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 31903 tensor(13.1728, device='cuda:0')\n",
      "0 31903 tensor(13.3624, device='cuda:0')\n",
      "\n",
      "0 18089 tensor(12.5046, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 18089 tensor(12.6486, device='cuda:0')\n",
      "0 18089 tensor(12.1658, device='cuda:0')\n",
      "\n",
      "0 16553 tensor(12.6228, device='cuda:0')\n",
      "20\n",
      "200\n",
      "0 16553 tensor(13.4852, device='cuda:0')\n",
      "0 16553 tensor(12.6642, device='cuda:0')\n",
      "\n",
      "0 28331 tensor(12.9699, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 28331 tensor(13.5974, device='cuda:0')\n",
      "0 28331 tensor(13.2734, device='cuda:0')\n",
      "\n",
      "0 41131 tensor(13.0920, device='cuda:0')\n",
      "20\n",
      "150\n",
      "0 41131 tensor(13.4138, device='cuda:0')\n",
      "0 41131 tensor(13.4138, device='cuda:0')\n",
      "\n",
      "0 20145 tensor(12.5932, device='cuda:0')\n",
      "20\n",
      "204\n",
      "0 20145 tensor(13.7743, device='cuda:0')\n",
      "0 20145 tensor(13.7743, device='cuda:0')\n",
      "\n",
      "0 46262 tensor(12.7673, device='cuda:0')\n",
      "20\n",
      "160\n",
      "0 46262 tensor(14.4209, device='cuda:0')\n",
      "0 46262 tensor(13.3710, device='cuda:0')\n",
      "\n",
      "0 30397 tensor(12.8803, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 30397 tensor(13.5136, device='cuda:0')\n",
      "0 30397 tensor(13.8564, device='cuda:0')\n",
      "\n",
      "0 41151 tensor(12.5119, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 41151 tensor(13.4766, device='cuda:0')\n",
      "0 41151 tensor(13.5120, device='cuda:0')\n",
      "\n",
      "0 22723 tensor(12.7574, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 22723 tensor(12.9196, device='cuda:0')\n",
      "0 22723 tensor(12.9196, device='cuda:0')\n",
      "\n",
      "0 23239 tensor(13.0141, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 23239 tensor(14.0602, device='cuda:0')\n",
      "0 23239 tensor(14.0602, device='cuda:0')\n",
      "\n",
      "0 14538 tensor(10.5964, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 14538 tensor(11.1933, device='cuda:0')\n",
      "0 14538 tensor(11.2978, device='cuda:0')\n",
      "\n",
      "0 17100 tensor(12.6421, device='cuda:0')\n",
      "20\n",
      "222\n",
      "0 17100 tensor(13.9295, device='cuda:0')\n",
      "0 17100 tensor(12.8804, device='cuda:0')\n",
      "\n",
      "0 37073 tensor(13.1513, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 37073 tensor(14.4043, device='cuda:0')\n",
      "0 37073 tensor(13.2479, device='cuda:0')\n",
      "\n",
      "0 22739 tensor(13.6572, device='cuda:0')\n",
      "20\n",
      "230\n",
      "0 22739 tensor(13.4759, device='cuda:0')\n",
      "0 22739 tensor(13.4759, device='cuda:0')\n",
      "\n",
      "0 49365 tensor(13.1089, device='cuda:0')\n",
      "20\n",
      "146\n",
      "0 49365 tensor(14.3966, device='cuda:0')\n",
      "0 49365 tensor(14.3966, device='cuda:0')\n",
      "\n",
      "0 16598 tensor(12.8477, device='cuda:0')\n",
      "20\n",
      "186\n",
      "0 16598 tensor(13.3732, device='cuda:0')\n",
      "0 16598 tensor(13.3732, device='cuda:0')\n",
      "\n",
      "0 47831 tensor(13.0625, device='cuda:0')\n",
      "20\n",
      "196\n",
      "0 47831 tensor(14.1711, device='cuda:0')\n",
      "0 47831 tensor(14.1711, device='cuda:0')\n",
      "\n",
      "0 31959 tensor(13.2688, device='cuda:0')\n",
      "20\n",
      "226\n",
      "0 31959 tensor(13.4616, device='cuda:0')\n",
      "0 31959 tensor(12.9901, device='cuda:0')\n",
      "\n",
      "0 22234 tensor(12.6123, device='cuda:0')\n",
      "20\n",
      "244\n",
      "0 22234 tensor(12.4557, device='cuda:0')\n",
      "0 22234 tensor(12.4557, device='cuda:0')\n",
      "\n",
      "0 23259 tensor(13.1213, device='cuda:0')\n",
      "20\n",
      "238\n",
      "0 23259 tensor(13.1611, device='cuda:0')\n",
      "0 23259 tensor(13.2463, device='cuda:0')\n",
      "\n",
      "0 20189 tensor(12.9662, device='cuda:0')\n",
      "20\n",
      "178\n",
      "0 20189 tensor(13.8119, device='cuda:0')\n",
      "0 20189 tensor(13.8119, device='cuda:0')\n",
      "\n",
      "0 45790 tensor(12.5666, device='cuda:0')\n",
      "20\n",
      "190\n",
      "0 45790 tensor(13.3464, device='cuda:0')\n",
      "0 45790 tensor(13.4502, device='cuda:0')\n",
      "\n",
      "0 29927 tensor(12.6487, device='cuda:0')\n",
      "20\n",
      "230\n",
      "0 29927 tensor(13.7232, device='cuda:0')\n",
      "0 29927 tensor(12.4084, device='cuda:0')\n",
      "\n",
      "0 46312 tensor(13.1135, device='cuda:0')\n",
      "20\n",
      "238\n",
      "0 46312 tensor(13.3237, device='cuda:0')\n",
      "0 46312 tensor(13.1319, device='cuda:0')\n",
      "\n",
      "0 31465 tensor(11.9781, device='cuda:0')\n",
      "20\n",
      "170\n",
      "0 31465 tensor(12.5426, device='cuda:0')\n",
      "0 31465 tensor(12.1955, device='cuda:0')\n",
      "\n",
      "0 46831 tensor(12.9274, device='cuda:0')\n",
      "20\n",
      "142\n",
      "0 46831 tensor(13.4876, device='cuda:0')\n",
      "0 46831 tensor(13.0505, device='cuda:0')\n",
      "\n",
      "0 31472 tensor(12.6094, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 31472 tensor(13.6778, device='cuda:0')\n",
      "0 31472 tensor(13.6778, device='cuda:0')\n",
      "\n",
      "0 29936 tensor(12.8529, device='cuda:0')\n",
      "20\n",
      "150\n",
      "0 29936 tensor(13.7187, device='cuda:0')\n",
      "0 29936 tensor(13.1125, device='cuda:0')\n",
      "\n",
      "0 26355 tensor(12.3908, device='cuda:0')\n",
      "20\n",
      "142\n",
      "0 26355 tensor(12.3387, device='cuda:0')\n",
      "0 26355 tensor(13.3444, device='cuda:0')\n",
      "\n",
      "0 6393 tensor(12.2386, device='cuda:0')\n",
      "20\n",
      "144\n",
      "0 6393 tensor(13.2844, device='cuda:0')\n",
      "0 6393 tensor(12.2438, device='cuda:0')\n",
      "\n",
      "0 26876 tensor(12.5981, device='cuda:0')\n",
      "20\n",
      "208\n",
      "0 26876 tensor(12.2634, device='cuda:0')\n",
      "0 26876 tensor(13.4663, device='cuda:0')\n",
      "\n",
      "0 8444 tensor(12.0856, device='cuda:0')\n",
      "20\n",
      "156\n",
      "0 8444 tensor(12.7779, device='cuda:0')\n",
      "0 8444 tensor(13.0954, device='cuda:0')\n",
      "\n",
      "0 26878 tensor(13.4137, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 26878 tensor(12.8081, device='cuda:0')\n",
      "0 26878 tensor(13.8060, device='cuda:0')\n",
      "\n",
      "0 6911 tensor(12.2851, device='cuda:0')\n",
      "20\n",
      "152\n",
      "0 6911 tensor(12.2566, device='cuda:0')\n",
      "0 6911 tensor(12.2566, device='cuda:0')\n",
      "\n",
      "0 25856 tensor(13.4219, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 25856 tensor(14.4027, device='cuda:0')\n",
      "0 25856 tensor(13.2543, device='cuda:0')\n",
      "\n",
      "0 21249 tensor(11.3031, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 21249 tensor(11.9372, device='cuda:0')\n",
      "0 21249 tensor(11.9873, device='cuda:0')\n",
      "\n",
      "0 19717 tensor(12.4562, device='cuda:0')\n",
      "20\n",
      "196\n",
      "0 19717 tensor(12.4250, device='cuda:0')\n",
      "0 19717 tensor(12.4250, device='cuda:0')\n",
      "\n",
      "0 8966 tensor(12.7948, device='cuda:0')\n",
      "20\n",
      "168\n",
      "0 8966 tensor(12.5636, device='cuda:0')\n",
      "0 8966 tensor(13.6862, device='cuda:0')\n",
      "\n",
      "0 38150 tensor(13.2872, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 38150 tensor(13.1511, device='cuda:0')\n",
      "0 38150 tensor(13.4320, device='cuda:0')\n",
      "\n",
      "0 26888 tensor(13.2139, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 26888 tensor(13.8056, device='cuda:0')\n",
      "0 26888 tensor(13.8056, device='cuda:0')\n",
      "\n",
      "0 27917 tensor(12.4088, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 27917 tensor(13.0022, device='cuda:0')\n",
      "0 27917 tensor(12.8759, device='cuda:0')\n",
      "\n",
      "0 39184 tensor(11.4426, device='cuda:0')\n",
      "20\n",
      "212\n",
      "0 39184 tensor(11.8262, device='cuda:0')\n",
      "0 39184 tensor(11.8262, device='cuda:0')\n",
      "\n",
      "0 48401 tensor(13.0711, device='cuda:0')\n",
      "20\n",
      "118\n",
      "0 48401 tensor(12.7493, device='cuda:0')\n",
      "0 48401 tensor(13.3075, device='cuda:0')\n",
      "\n",
      "0 24336 tensor(13.1588, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 24336 tensor(12.8981, device='cuda:0')\n",
      "0 24336 tensor(14.2539, device='cuda:0')\n",
      "\n",
      "0 6416 tensor(11.8056, device='cuda:0')\n",
      "20\n",
      "178\n",
      "0 6416 tensor(12.7000, device='cuda:0')\n",
      "0 6416 tensor(12.7000, device='cuda:0')\n",
      "\n",
      "0 23316 tensor(12.8102, device='cuda:0')\n",
      "20\n",
      "156\n",
      "0 23316 tensor(13.0968, device='cuda:0')\n",
      "0 23316 tensor(12.8320, device='cuda:0')\n",
      "\n",
      "0 37144 tensor(12.8887, device='cuda:0')\n",
      "20\n",
      "146\n",
      "0 37144 tensor(13.7380, device='cuda:0')\n",
      "0 37144 tensor(13.7910, device='cuda:0')\n",
      "\n",
      "0 31513 tensor(12.3879, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 31513 tensor(12.5424, device='cuda:0')\n",
      "0 31513 tensor(13.3648, device='cuda:0')\n",
      "\n",
      "0 42266 tensor(12.4492, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 42266 tensor(13.3118, device='cuda:0')\n",
      "0 42266 tensor(13.9107, device='cuda:0')\n",
      "\n",
      "0 29989 tensor(12.9688, device='cuda:0')\n",
      "20\n",
      "178\n",
      "0 29989 tensor(13.9730, device='cuda:0')\n",
      "0 29989 tensor(13.2886, device='cuda:0')\n",
      "\n",
      "0 27434 tensor(13.1300, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 27434 tensor(13.6635, device='cuda:0')\n",
      "0 27434 tensor(14.6617, device='cuda:0')\n",
      "\n",
      "0 45867 tensor(13.1353, device='cuda:0')\n",
      "20\n",
      "204\n",
      "0 45867 tensor(14.3540, device='cuda:0')\n",
      "0 45867 tensor(14.3540, device='cuda:0')\n",
      "\n",
      "0 36139 tensor(13.3852, device='cuda:0')\n",
      "20\n",
      "228\n",
      "0 36139 tensor(14.4462, device='cuda:0')\n",
      "0 36139 tensor(13.4986, device='cuda:0')\n",
      "\n",
      "0 29489 tensor(12.7141, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 29489 tensor(13.7457, device='cuda:0')\n",
      "0 29489 tensor(13.7457, device='cuda:0')\n",
      "\n",
      "0 27443 tensor(12.6511, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 27443 tensor(12.5571, device='cuda:0')\n",
      "0 27443 tensor(13.5634, device='cuda:0')\n",
      "\n",
      "0 27955 tensor(11.9624, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 27955 tensor(11.7787, device='cuda:0')\n",
      "0 27955 tensor(11.7787, device='cuda:0')\n",
      "\n",
      "0 22838 tensor(12.8553, device='cuda:0')\n",
      "20\n",
      "178\n",
      "0 22838 tensor(13.0996, device='cuda:0')\n",
      "0 22838 tensor(13.6889, device='cuda:0')\n",
      "\n",
      "0 7993 tensor(12.4818, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 7993 tensor(13.7628, device='cuda:0')\n",
      "0 7993 tensor(13.1193, device='cuda:0')\n",
      "\n",
      "0 13114 tensor(13.0033, device='cuda:0')\n",
      "20\n",
      "168\n",
      "0 13114 tensor(13.9232, device='cuda:0')\n",
      "0 13114 tensor(13.9232, device='cuda:0')\n",
      "\n",
      "0 13629 tensor(11.9363, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 13629 tensor(12.5863, device='cuda:0')\n",
      "0 13629 tensor(13.0319, device='cuda:0')\n",
      "\n",
      "0 28991 tensor(13.0022, device='cuda:0')\n",
      "20\n",
      "182\n",
      "0 28991 tensor(12.7737, device='cuda:0')\n",
      "0 28991 tensor(13.3921, device='cuda:0')\n",
      "\n",
      "0 40771 tensor(13.0072, device='cuda:0')\n",
      "20\n",
      "178\n",
      "0 40771 tensor(14.0512, device='cuda:0')\n",
      "0 40771 tensor(14.0512, device='cuda:0')\n",
      "\n",
      "0 25413 tensor(12.7161, device='cuda:0')\n",
      "20\n",
      "226\n",
      "0 25413 tensor(13.9946, device='cuda:0')\n",
      "0 25413 tensor(13.9946, device='cuda:0')\n",
      "\n",
      "0 44870 tensor(12.9663, device='cuda:0')\n",
      "20\n",
      "190\n",
      "0 44870 tensor(13.4676, device='cuda:0')\n",
      "0 44870 tensor(14.2967, device='cuda:0')\n",
      "\n",
      "0 18247 tensor(13.0920, device='cuda:0')\n",
      "20\n",
      "230\n",
      "0 18247 tensor(12.8579, device='cuda:0')\n",
      "0 18247 tensor(14.1180, device='cuda:0')\n",
      "\n",
      "0 47944 tensor(12.9271, device='cuda:0')\n",
      "20\n",
      "214\n",
      "0 47944 tensor(13.1308, device='cuda:0')\n",
      "0 47944 tensor(12.9786, device='cuda:0')\n",
      "\n",
      "0 35657 tensor(13.3275, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 35657 tensor(13.1805, device='cuda:0')\n",
      "0 35657 tensor(14.0828, device='cuda:0')\n",
      "\n",
      "0 26953 tensor(12.3184, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 26953 tensor(11.9706, device='cuda:0')\n",
      "0 26953 tensor(11.9706, device='cuda:0')\n",
      "\n",
      "0 13651 tensor(12.2813, device='cuda:0')\n",
      "20\n",
      "236\n",
      "0 13651 tensor(13.0796, device='cuda:0')\n",
      "0 13651 tensor(12.5844, device='cuda:0')\n",
      "\n",
      "0 27991 tensor(12.6054, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 27991 tensor(12.4073, device='cuda:0')\n",
      "0 27991 tensor(12.4073, device='cuda:0')\n",
      "\n",
      "0 26456 tensor(12.6737, device='cuda:0')\n",
      "20\n",
      "216\n",
      "0 26456 tensor(12.8492, device='cuda:0')\n",
      "0 26456 tensor(13.5433, device='cuda:0')\n",
      "\n",
      "0 48990 tensor(13.3650, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 48990 tensor(13.3184, device='cuda:0')\n",
      "0 48990 tensor(13.6652, device='cuda:0')\n",
      "\n",
      "0 34655 tensor(13.2356, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 34655 tensor(14.6680, device='cuda:0')\n",
      "0 34655 tensor(14.6680, device='cuda:0')\n",
      "\n",
      "0 16225 tensor(11.8494, device='cuda:0')\n",
      "20\n",
      "156\n",
      "0 16225 tensor(12.6014, device='cuda:0')\n",
      "0 16225 tensor(11.5291, device='cuda:0')\n",
      "\n",
      "0 28518 tensor(13.7207, device='cuda:0')\n",
      "20\n",
      "142\n",
      "0 28518 tensor(14.6510, device='cuda:0')\n",
      "0 28518 tensor(15.0178, device='cuda:0')\n",
      "\n",
      "0 20839 tensor(11.7493, device='cuda:0')\n",
      "20\n",
      "202\n",
      "0 20839 tensor(11.7740, device='cuda:0')\n",
      "0 20839 tensor(11.7740, device='cuda:0')\n",
      "\n",
      "0 43367 tensor(13.4370, device='cuda:0')\n",
      "20\n",
      "250\n",
      "0 43367 tensor(12.9977, device='cuda:0')\n",
      "0 43367 tensor(14.4773, device='cuda:0')\n",
      "\n",
      "0 10092 tensor(12.0346, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 10092 tensor(12.1111, device='cuda:0')\n",
      "0 10092 tensor(12.1111, device='cuda:0')\n",
      "\n",
      "0 11116 tensor(12.0053, device='cuda:0')\n",
      "20\n",
      "164\n",
      "0 11116 tensor(11.9529, device='cuda:0')\n",
      "0 11116 tensor(11.9529, device='cuda:0')\n",
      "\n",
      "0 31086 tensor(12.3666, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 31086 tensor(12.4945, device='cuda:0')\n",
      "0 31086 tensor(12.4945, device='cuda:0')\n",
      "\n",
      "0 29040 tensor(12.5946, device='cuda:0')\n",
      "20\n",
      "204\n",
      "0 29040 tensor(12.9621, device='cuda:0')\n",
      "0 29040 tensor(12.9621, device='cuda:0')\n",
      "\n",
      "0 50033 tensor(13.0629, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 50033 tensor(14.1688, device='cuda:0')\n",
      "0 50033 tensor(14.0779, device='cuda:0')\n",
      "\n",
      "0 5490 tensor(12.4300, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 5490 tensor(12.0273, device='cuda:0')\n",
      "0 5490 tensor(12.0273, device='cuda:0')\n",
      "\n",
      "0 39795 tensor(12.8661, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 39795 tensor(13.0927, device='cuda:0')\n",
      "0 39795 tensor(13.0927, device='cuda:0')\n",
      "\n",
      "0 48505 tensor(13.0066, device='cuda:0')\n",
      "20\n",
      "162\n",
      "0 48505 tensor(14.2488, device='cuda:0')\n",
      "0 48505 tensor(13.5994, device='cuda:0')\n",
      "\n",
      "0 40316 tensor(12.7434, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 40316 tensor(13.2493, device='cuda:0')\n",
      "0 40316 tensor(13.2493, device='cuda:0')\n",
      "\n",
      "0 24958 tensor(12.2923, device='cuda:0')\n",
      "20\n",
      "212\n",
      "0 24958 tensor(13.1854, device='cuda:0')\n",
      "0 24958 tensor(13.1854, device='cuda:0')\n",
      "\n",
      "0 38783 tensor(11.8074, device='cuda:0')\n",
      "20\n",
      "164\n",
      "0 38783 tensor(12.3036, device='cuda:0')\n",
      "0 38783 tensor(12.8435, device='cuda:0')\n",
      "\n",
      "0 19838 tensor(13.8381, device='cuda:0')\n",
      "20\n",
      "208\n",
      "0 19838 tensor(13.6098, device='cuda:0')\n",
      "0 19838 tensor(14.1108, device='cuda:0')\n",
      "\n",
      "0 23425 tensor(12.8872, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 23425 tensor(13.8529, device='cuda:0')\n",
      "0 23425 tensor(12.4411, device='cuda:0')\n",
      "\n",
      "0 24962 tensor(12.3622, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 24962 tensor(12.7986, device='cuda:0')\n",
      "0 24962 tensor(13.5520, device='cuda:0')\n",
      "\n",
      "0 13187 tensor(12.3380, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 13187 tensor(12.6364, device='cuda:0')\n",
      "0 13187 tensor(13.2399, device='cuda:0')\n",
      "\n",
      "0 49028 tensor(12.2417, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 49028 tensor(12.8061, device='cuda:0')\n",
      "0 49028 tensor(12.6510, device='cuda:0')\n",
      "\n",
      "0 12167 tensor(12.3382, device='cuda:0')\n",
      "20\n",
      "186\n",
      "0 12167 tensor(12.8027, device='cuda:0')\n",
      "0 12167 tensor(12.8027, device='cuda:0')\n",
      "\n",
      "0 43406 tensor(12.9149, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 43406 tensor(13.8973, device='cuda:0')\n",
      "0 43406 tensor(13.9740, device='cuda:0')\n",
      "\n",
      "0 14737 tensor(12.6474, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 14737 tensor(12.5806, device='cuda:0')\n",
      "0 14737 tensor(12.7449, device='cuda:0')\n",
      "\n",
      "0 18322 tensor(12.3136, device='cuda:0')\n",
      "20\n",
      "164\n",
      "0 18322 tensor(12.3880, device='cuda:0')\n",
      "0 18322 tensor(12.3880, device='cuda:0')\n",
      "\n",
      "0 43921 tensor(13.0748, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 43921 tensor(12.7613, device='cuda:0')\n",
      "0 43921 tensor(14.0222, device='cuda:0')\n",
      "\n",
      "0 12694 tensor(12.2579, device='cuda:0')\n",
      "20\n",
      "204\n",
      "0 12694 tensor(12.5586, device='cuda:0')\n",
      "0 12694 tensor(13.2318, device='cuda:0')\n",
      "\n",
      "0 16286 tensor(12.7566, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 16286 tensor(13.7275, device='cuda:0')\n",
      "0 16286 tensor(13.5108, device='cuda:0')\n",
      "\n",
      "0 48545 tensor(13.1752, device='cuda:0')\n",
      "20\n",
      "202\n",
      "0 48545 tensor(12.6424, device='cuda:0')\n",
      "0 48545 tensor(13.3304, device='cuda:0')\n",
      "\n",
      "0 29092 tensor(12.8519, device='cuda:0')\n",
      "20\n",
      "158\n",
      "0 29092 tensor(12.6584, device='cuda:0')\n",
      "0 29092 tensor(13.5610, device='cuda:0')\n",
      "\n",
      "0 15273 tensor(12.5941, device='cuda:0')\n",
      "20\n",
      "200\n",
      "0 15273 tensor(12.8552, device='cuda:0')\n",
      "0 15273 tensor(13.6636, device='cuda:0')\n",
      "\n",
      "0 16809 tensor(13.0251, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 16809 tensor(13.8805, device='cuda:0')\n",
      "0 16809 tensor(13.4084, device='cuda:0')\n",
      "\n",
      "0 22455 tensor(13.1704, device='cuda:0')\n",
      "20\n",
      "132\n",
      "0 22455 tensor(12.8694, device='cuda:0')\n",
      "0 22455 tensor(13.6721, device='cuda:0')\n",
      "\n",
      "0 24504 tensor(13.0767, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 24504 tensor(13.1078, device='cuda:0')\n",
      "0 24504 tensor(13.1078, device='cuda:0')\n",
      "\n",
      "0 30140 tensor(12.9714, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 30140 tensor(14.0629, device='cuda:0')\n",
      "0 30140 tensor(12.8758, device='cuda:0')\n",
      "\n",
      "0 27581 tensor(13.4112, device='cuda:0')\n",
      "20\n",
      "166\n",
      "0 27581 tensor(13.1010, device='cuda:0')\n",
      "0 27581 tensor(14.5210, device='cuda:0')\n",
      "\n",
      "0 21438 tensor(12.4552, device='cuda:0')\n",
      "20\n",
      "196\n",
      "0 21438 tensor(14.2379, device='cuda:0')\n",
      "0 21438 tensor(11.9707, device='cuda:0')\n",
      "\n",
      "0 35262 tensor(13.6834, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 35262 tensor(15.0434, device='cuda:0')\n",
      "0 35262 tensor(14.8274, device='cuda:0')\n",
      "\n",
      "0 36292 tensor(12.2635, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 36292 tensor(12.0955, device='cuda:0')\n",
      "0 36292 tensor(13.8856, device='cuda:0')\n",
      "\n",
      "0 6086 tensor(12.5683, device='cuda:0')\n",
      "20\n",
      "168\n",
      "0 6086 tensor(13.2408, device='cuda:0')\n",
      "0 6086 tensor(13.2408, device='cuda:0')\n",
      "\n",
      "0 21960 tensor(13.3261, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 21960 tensor(14.5252, device='cuda:0')\n",
      "0 21960 tensor(14.5252, device='cuda:0')\n",
      "\n",
      "0 20428 tensor(13.0249, device='cuda:0')\n",
      "20\n",
      "238\n",
      "0 20428 tensor(13.7627, device='cuda:0')\n",
      "0 20428 tensor(13.7627, device='cuda:0')\n",
      "\n",
      "0 17361 tensor(12.0272, device='cuda:0')\n",
      "20\n",
      "228\n",
      "0 17361 tensor(11.5770, device='cuda:0')\n",
      "0 17361 tensor(11.5770, device='cuda:0')\n",
      "\n",
      "0 33747 tensor(13.0465, device='cuda:0')\n",
      "20\n",
      "150\n",
      "0 33747 tensor(14.1489, device='cuda:0')\n",
      "0 33747 tensor(14.1331, device='cuda:0')\n",
      "\n",
      "0 2516 tensor(11.9069, device='cuda:0')\n",
      "20\n",
      "246\n",
      "0 2516 tensor(12.0264, device='cuda:0')\n",
      "0 2516 tensor(12.5887, device='cuda:0')\n",
      "\n",
      "0 13268 tensor(12.4609, device='cuda:0')\n",
      "20\n",
      "422\n",
      "0 13268 tensor(12.0122, device='cuda:0')\n",
      "0 13268 tensor(13.5152, device='cuda:0')\n",
      "\n",
      "0 45014 tensor(13.3116, device='cuda:0')\n",
      "20\n",
      "170\n",
      "0 45014 tensor(14.3072, device='cuda:0')\n",
      "0 45014 tensor(13.4576, device='cuda:0')\n",
      "\n",
      "0 25556 tensor(12.2228, device='cuda:0')\n",
      "20\n",
      "216\n",
      "0 25556 tensor(13.0954, device='cuda:0')\n",
      "0 25556 tensor(13.0954, device='cuda:0')\n",
      "\n",
      "0 33240 tensor(12.4233, device='cuda:0')\n",
      "20\n",
      "222\n",
      "0 33240 tensor(13.1098, device='cuda:0')\n",
      "0 33240 tensor(12.3225, device='cuda:0')\n",
      "\n",
      "0 36312 tensor(13.2771, device='cuda:0')\n",
      "20\n",
      "226\n",
      "0 36312 tensor(14.3066, device='cuda:0')\n",
      "0 36312 tensor(13.2195, device='cuda:0')\n",
      "\n",
      "0 16863 tensor(13.0230, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 16863 tensor(13.9046, device='cuda:0')\n",
      "0 16863 tensor(13.9046, device='cuda:0')\n",
      "\n",
      "0 28642 tensor(12.2957, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 28642 tensor(13.1583, device='cuda:0')\n",
      "0 28642 tensor(13.1583, device='cuda:0')\n",
      "\n",
      "0 10213 tensor(13.3126, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 10213 tensor(13.2984, device='cuda:0')\n",
      "0 10213 tensor(14.3738, device='cuda:0')\n",
      "\n",
      "0 16358 tensor(12.5390, device='cuda:0')\n",
      "20\n",
      "216\n",
      "0 16358 tensor(12.3742, device='cuda:0')\n",
      "0 16358 tensor(13.5036, device='cuda:0')\n",
      "\n",
      "0 25062 tensor(13.0945, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 25062 tensor(13.1179, device='cuda:0')\n",
      "0 25062 tensor(13.1179, device='cuda:0')\n",
      "\n",
      "0 23528 tensor(13.5638, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 23528 tensor(13.5350, device='cuda:0')\n",
      "0 23528 tensor(13.7990, device='cuda:0')\n",
      "\n",
      "0 35307 tensor(13.2558, device='cuda:0')\n",
      "20\n",
      "218\n",
      "0 35307 tensor(14.5309, device='cuda:0')\n",
      "0 35307 tensor(14.5538, device='cuda:0')\n",
      "\n",
      "0 19436 tensor(12.6872, device='cuda:0')\n",
      "20\n",
      "162\n",
      "0 19436 tensor(12.7100, device='cuda:0')\n",
      "0 19436 tensor(13.6665, device='cuda:0')\n",
      "\n",
      "0 25579 tensor(13.2359, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 25579 tensor(14.0493, device='cuda:0')\n",
      "0 25579 tensor(14.1312, device='cuda:0')\n",
      "\n",
      "0 15859 tensor(12.4461, device='cuda:0')\n",
      "20\n",
      "222\n",
      "0 15859 tensor(13.3387, device='cuda:0')\n",
      "0 15859 tensor(12.8957, device='cuda:0')\n",
      "\n",
      "0 38900 tensor(12.2654, device='cuda:0')\n",
      "20\n",
      "138\n",
      "0 38900 tensor(12.7655, device='cuda:0')\n",
      "0 38900 tensor(11.9774, device='cuda:0')\n",
      "\n",
      "0 7670 tensor(10.6032, device='cuda:0')\n",
      "20\n",
      "208\n",
      "0 7670 tensor(10.7171, device='cuda:0')\n",
      "0 7670 tensor(10.7171, device='cuda:0')\n",
      "\n",
      "0 8698 tensor(12.7098, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 8698 tensor(12.4334, device='cuda:0')\n",
      "0 8698 tensor(13.6267, device='cuda:0')\n",
      "\n",
      "0 12284 tensor(12.6145, device='cuda:0')\n",
      "20\n",
      "170\n",
      "0 12284 tensor(13.7517, device='cuda:0')\n",
      "0 12284 tensor(12.8655, device='cuda:0')\n",
      "\n",
      "0 44542 tensor(12.9658, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 44542 tensor(12.9477, device='cuda:0')\n",
      "0 44542 tensor(12.9477, device='cuda:0')\n",
      "\n",
      "0 31231 tensor(13.1420, device='cuda:0')\n",
      "20\n",
      "182\n",
      "0 31231 tensor(14.1063, device='cuda:0')\n",
      "0 31231 tensor(14.4024, device='cuda:0')\n",
      "\n",
      "1 50178 tensor(15.7074, device='cuda:0')\n",
      "20\n",
      "226\n",
      "1 50178 tensor(16.2534, device='cuda:0')\n",
      "1 50178 tensor(15.4733, device='cuda:0')\n",
      "\n",
      "1 46600 tensor(15.4210, device='cuda:0')\n",
      "20\n",
      "160\n",
      "1 46600 tensor(15.7580, device='cuda:0')\n",
      "1 46600 tensor(15.7049, device='cuda:0')\n",
      "\n",
      "1 31755 tensor(16.4432, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 31755 tensor(16.7634, device='cuda:0')\n",
      "1 31755 tensor(16.5680, device='cuda:0')\n",
      "\n",
      "1 46604 tensor(15.9008, device='cuda:0')\n",
      "20\n",
      "170\n",
      "1 46604 tensor(16.1943, device='cuda:0')\n",
      "1 46604 tensor(15.5951, device='cuda:0')\n",
      "\n",
      "1 10765 tensor(15.5257, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 10765 tensor(15.0526, device='cuda:0')\n",
      "1 10765 tensor(16.7608, device='cuda:0')\n",
      "\n",
      "1 11276 tensor(16.4390, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 11276 tensor(17.0363, device='cuda:0')\n",
      "1 11276 tensor(16.0400, device='cuda:0')\n",
      "\n",
      "1 33811 tensor(15.9239, device='cuda:0')\n",
      "20\n",
      "172\n",
      "1 33811 tensor(16.6154, device='cuda:0')\n",
      "1 33811 tensor(16.6154, device='cuda:0')\n",
      "\n",
      "1 46612 tensor(16.3463, device='cuda:0')\n",
      "20\n",
      "220\n",
      "1 46612 tensor(16.7996, device='cuda:0')\n",
      "1 46612 tensor(17.0951, device='cuda:0')\n",
      "\n",
      "1 16916 tensor(15.8676, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 16916 tensor(16.8116, device='cuda:0')\n",
      "1 16916 tensor(17.1821, device='cuda:0')\n",
      "\n",
      "1 18966 tensor(15.7044, device='cuda:0')\n",
      "20\n",
      "202\n",
      "1 18966 tensor(16.9044, device='cuda:0')\n",
      "1 18966 tensor(15.1205, device='cuda:0')\n",
      "\n",
      "1 12824 tensor(14.7762, device='cuda:0')\n",
      "20\n",
      "208\n",
      "1 12824 tensor(14.4470, device='cuda:0')\n",
      "1 12824 tensor(14.5847, device='cuda:0')\n",
      "\n",
      "1 32794 tensor(15.1593, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 32794 tensor(16.2660, device='cuda:0')\n",
      "1 32794 tensor(14.2677, device='cuda:0')\n",
      "\n",
      "1 7195 tensor(14.9728, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 7195 tensor(15.0815, device='cuda:0')\n",
      "1 7195 tensor(15.2455, device='cuda:0')\n",
      "\n",
      "1 33821 tensor(16.2161, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 33821 tensor(16.7100, device='cuda:0')\n",
      "1 33821 tensor(16.0342, device='cuda:0')\n",
      "\n",
      "1 37921 tensor(16.3117, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 37921 tensor(16.8148, device='cuda:0')\n",
      "1 37921 tensor(16.1679, device='cuda:0')\n",
      "\n",
      "1 33313 tensor(16.0555, device='cuda:0')\n",
      "20\n",
      "228\n",
      "1 33313 tensor(15.6224, device='cuda:0')\n",
      "1 33313 tensor(16.6221, device='cuda:0')\n",
      "\n",
      "1 31270 tensor(15.5895, device='cuda:0')\n",
      "20\n",
      "172\n",
      "1 31270 tensor(16.2073, device='cuda:0')\n",
      "1 31270 tensor(16.2073, device='cuda:0')\n",
      "\n",
      "1 29222 tensor(15.2953, device='cuda:0')\n",
      "20\n",
      "156\n",
      "1 29222 tensor(15.7554, device='cuda:0')\n",
      "1 29222 tensor(14.1914, device='cuda:0')\n",
      "\n",
      "1 28712 tensor(15.5100, device='cuda:0')\n",
      "20\n",
      "166\n",
      "1 28712 tensor(15.3509, device='cuda:0')\n",
      "1 28712 tensor(15.4861, device='cuda:0')\n",
      "\n",
      "1 18985 tensor(15.0077, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 18985 tensor(15.1153, device='cuda:0')\n",
      "1 18985 tensor(15.1637, device='cuda:0')\n",
      "\n",
      "1 37930 tensor(15.9600, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 37930 tensor(16.3716, device='cuda:0')\n",
      "1 37930 tensor(16.7532, device='cuda:0')\n",
      "\n",
      "1 28200 tensor(15.1458, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 28200 tensor(16.2742, device='cuda:0')\n",
      "1 28200 tensor(15.2444, device='cuda:0')\n",
      "\n",
      "1 7727 tensor(15.0032, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 7727 tensor(15.7449, device='cuda:0')\n",
      "1 7727 tensor(14.3341, device='cuda:0')\n",
      "\n",
      "1 24112 tensor(16.5894, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 24112 tensor(17.3529, device='cuda:0')\n",
      "1 24112 tensor(16.5836, device='cuda:0')\n",
      "\n",
      "1 36400 tensor(15.7391, device='cuda:0')\n",
      "20\n",
      "214\n",
      "1 36400 tensor(16.7340, device='cuda:0')\n",
      "1 36400 tensor(16.0640, device='cuda:0')\n",
      "\n",
      "1 32817 tensor(15.9051, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 32817 tensor(16.3226, device='cuda:0')\n",
      "1 32817 tensor(16.6031, device='cuda:0')\n",
      "\n",
      "1 5171 tensor(14.7162, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 5171 tensor(15.5868, device='cuda:0')\n",
      "1 5171 tensor(14.6438, device='cuda:0')\n",
      "\n",
      "1 44085 tensor(15.8415, device='cuda:0')\n",
      "20\n",
      "238\n",
      "1 44085 tensor(16.1884, device='cuda:0')\n",
      "1 44085 tensor(16.6560, device='cuda:0')\n",
      "\n",
      "1 35382 tensor(16.3130, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 35382 tensor(16.5542, device='cuda:0')\n",
      "1 35382 tensor(15.6711, device='cuda:0')\n",
      "\n",
      "1 14912 tensor(15.9040, device='cuda:0')\n",
      "20\n",
      "170\n",
      "1 14912 tensor(15.7353, device='cuda:0')\n",
      "1 14912 tensor(17.0310, device='cuda:0')\n",
      "\n",
      "1 30274 tensor(14.9510, device='cuda:0')\n",
      "20\n",
      "186\n",
      "1 30274 tensor(15.6739, device='cuda:0')\n",
      "1 30274 tensor(15.7348, device='cuda:0')\n",
      "\n",
      "1 20554 tensor(15.0991, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 20554 tensor(15.7663, device='cuda:0')\n",
      "1 20554 tensor(16.0638, device='cuda:0')\n",
      "\n",
      "1 15435 tensor(15.9083, device='cuda:0')\n",
      "20\n",
      "150\n",
      "1 15435 tensor(16.1580, device='cuda:0')\n",
      "1 15435 tensor(15.7384, device='cuda:0')\n",
      "\n",
      "1 33357 tensor(15.4399, device='cuda:0')\n",
      "20\n",
      "146\n",
      "1 33357 tensor(16.2427, device='cuda:0')\n",
      "1 33357 tensor(16.3464, device='cuda:0')\n",
      "\n",
      "1 49231 tensor(16.8054, device='cuda:0')\n",
      "20\n",
      "224\n",
      "1 49231 tensor(17.4806, device='cuda:0')\n",
      "1 49231 tensor(17.3705, device='cuda:0')\n",
      "\n",
      "1 38994 tensor(15.0870, device='cuda:0')\n",
      "20\n",
      "172\n",
      "1 38994 tensor(14.0160, device='cuda:0')\n",
      "1 38994 tensor(16.4428, device='cuda:0')\n",
      "\n",
      "1 21587 tensor(15.0068, device='cuda:0')\n",
      "20\n",
      "150\n",
      "1 21587 tensor(15.1557, device='cuda:0')\n",
      "1 21587 tensor(15.9418, device='cuda:0')\n",
      "\n",
      "1 7252 tensor(14.3525, device='cuda:0')\n",
      "20\n",
      "164\n",
      "1 7252 tensor(14.7665, device='cuda:0')\n",
      "1 7252 tensor(15.2643, device='cuda:0')\n",
      "\n",
      "1 40537 tensor(15.6442, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 40537 tensor(15.5102, device='cuda:0')\n",
      "1 40537 tensor(15.5124, device='cuda:0')\n",
      "\n",
      "1 27738 tensor(16.7366, device='cuda:0')\n",
      "20\n",
      "210\n",
      "1 27738 tensor(16.9601, device='cuda:0')\n",
      "1 27738 tensor(16.0083, device='cuda:0')\n",
      "\n",
      "1 44123 tensor(15.9564, device='cuda:0')\n",
      "20\n",
      "170\n",
      "1 44123 tensor(16.5446, device='cuda:0')\n",
      "1 44123 tensor(16.3204, device='cuda:0')\n",
      "\n",
      "1 44124 tensor(15.8120, device='cuda:0')\n",
      "20\n",
      "248\n",
      "1 44124 tensor(16.9179, device='cuda:0')\n",
      "1 44124 tensor(16.6997, device='cuda:0')\n",
      "\n",
      "1 14943 tensor(15.6649, device='cuda:0')\n",
      "20\n",
      "226\n",
      "1 14943 tensor(15.5060, device='cuda:0')\n",
      "1 14943 tensor(16.5952, device='cuda:0')\n",
      "\n",
      "1 45664 tensor(16.1679, device='cuda:0')\n",
      "20\n",
      "156\n",
      "1 45664 tensor(16.5550, device='cuda:0')\n",
      "1 45664 tensor(16.6958, device='cuda:0')\n",
      "\n",
      "1 15458 tensor(15.4787, device='cuda:0')\n",
      "20\n",
      "202\n",
      "1 15458 tensor(16.2398, device='cuda:0')\n",
      "1 15458 tensor(16.7928, device='cuda:0')\n",
      "\n",
      "1 49765 tensor(15.0020, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 49765 tensor(16.5614, device='cuda:0')\n",
      "1 49765 tensor(15.3706, device='cuda:0')\n",
      "\n",
      "1 19046 tensor(15.7741, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 19046 tensor(16.6210, device='cuda:0')\n",
      "1 19046 tensor(14.3126, device='cuda:0')\n",
      "\n",
      "1 35944 tensor(15.4771, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 35944 tensor(15.6351, device='cuda:0')\n",
      "1 35944 tensor(14.6453, device='cuda:0')\n",
      "\n",
      "1 29804 tensor(16.1097, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 29804 tensor(16.8469, device='cuda:0')\n",
      "1 29804 tensor(17.2977, device='cuda:0')\n",
      "\n",
      "1 23662 tensor(15.6475, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 23662 tensor(16.2332, device='cuda:0')\n",
      "1 23662 tensor(16.2332, device='cuda:0')\n",
      "\n",
      "1 37497 tensor(15.9719, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 37497 tensor(15.6662, device='cuda:0')\n",
      "1 37497 tensor(15.9289, device='cuda:0')\n",
      "\n",
      "1 22138 tensor(15.9159, device='cuda:0')\n",
      "20\n",
      "164\n",
      "1 22138 tensor(16.6442, device='cuda:0')\n",
      "1 22138 tensor(16.4719, device='cuda:0')\n",
      "\n",
      "1 27773 tensor(16.2888, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 27773 tensor(15.1288, device='cuda:0')\n",
      "1 27773 tensor(16.5813, device='cuda:0')\n",
      "\n",
      "1 28798 tensor(15.2637, device='cuda:0')\n",
      "20\n",
      "252\n",
      "1 28798 tensor(15.8890, device='cuda:0')\n",
      "1 28798 tensor(15.5642, device='cuda:0')\n",
      "\n",
      "1 33407 tensor(16.5549, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 33407 tensor(17.0652, device='cuda:0')\n",
      "1 33407 tensor(16.8593, device='cuda:0')\n",
      "\n",
      "1 27264 tensor(15.0249, device='cuda:0')\n",
      "20\n",
      "206\n",
      "1 27264 tensor(16.6893, device='cuda:0')\n",
      "1 27264 tensor(16.7239, device='cuda:0')\n",
      "\n",
      "1 9857 tensor(15.5887, device='cuda:0')\n",
      "20\n",
      "168\n",
      "1 9857 tensor(16.1149, device='cuda:0')\n",
      "1 9857 tensor(15.1956, device='cuda:0')\n",
      "\n",
      "1 14468 tensor(15.7740, device='cuda:0')\n",
      "20\n",
      "160\n",
      "1 14468 tensor(15.7208, device='cuda:0')\n",
      "1 14468 tensor(16.7369, device='cuda:0')\n",
      "\n",
      "1 6277 tensor(14.9515, device='cuda:0')\n",
      "20\n",
      "152\n",
      "1 6277 tensor(14.5267, device='cuda:0')\n",
      "1 6277 tensor(16.0850, device='cuda:0')\n",
      "\n",
      "1 35972 tensor(16.2013, device='cuda:0')\n",
      "20\n",
      "222\n",
      "1 35972 tensor(16.7012, device='cuda:0')\n",
      "1 35972 tensor(15.8819, device='cuda:0')\n",
      "\n",
      "1 4744 tensor(14.3911, device='cuda:0')\n",
      "20\n",
      "186\n",
      "1 4744 tensor(14.8862, device='cuda:0')\n",
      "1 4744 tensor(15.0672, device='cuda:0')\n",
      "\n",
      "1 32905 tensor(15.1321, device='cuda:0')\n",
      "20\n",
      "160\n",
      "1 32905 tensor(16.6128, device='cuda:0')\n",
      "1 32905 tensor(15.7300, device='cuda:0')\n",
      "\n",
      "1 32393 tensor(15.6499, device='cuda:0')\n",
      "20\n",
      "224\n",
      "1 32393 tensor(16.0953, device='cuda:0')\n",
      "1 32393 tensor(15.0347, device='cuda:0')\n",
      "\n",
      "1 22671 tensor(15.8846, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 22671 tensor(15.6327, device='cuda:0')\n",
      "1 22671 tensor(15.0493, device='cuda:0')\n",
      "\n",
      "1 20628 tensor(15.7065, device='cuda:0')\n",
      "20\n",
      "202\n",
      "1 20628 tensor(14.7395, device='cuda:0')\n",
      "1 20628 tensor(16.4018, device='cuda:0')\n",
      "\n",
      "1 32920 tensor(16.5663, device='cuda:0')\n",
      "20\n",
      "366\n",
      "1 32920 tensor(16.4159, device='cuda:0')\n",
      "1 32920 tensor(16.9852, device='cuda:0')\n",
      "\n",
      "1 17560 tensor(15.4612, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 17560 tensor(15.7223, device='cuda:0')\n",
      "1 17560 tensor(15.4718, device='cuda:0')\n",
      "\n",
      "1 5119 tensor(14.3575, device='cuda:0')\n",
      "20\n",
      "128\n",
      "1 5119 tensor(14.0584, device='cuda:0')\n",
      "1 5119 tensor(15.3148, device='cuda:0')\n",
      "\n",
      "1 21661 tensor(16.0954, device='cuda:0')\n",
      "20\n",
      "226\n",
      "1 21661 tensor(17.0227, device='cuda:0')\n",
      "1 21661 tensor(16.0576, device='cuda:0')\n",
      "\n",
      "1 16543 tensor(15.8544, device='cuda:0')\n",
      "20\n",
      "142\n",
      "1 16543 tensor(16.4414, device='cuda:0')\n",
      "1 16543 tensor(15.6311, device='cuda:0')\n",
      "\n",
      "1 31903 tensor(15.1589, device='cuda:0')\n",
      "20\n",
      "230\n",
      "1 31903 tensor(15.1406, device='cuda:0')\n",
      "1 31903 tensor(15.2804, device='cuda:0')\n",
      "\n",
      "1 18089 tensor(15.4746, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 18089 tensor(16.7594, device='cuda:0')\n",
      "1 18089 tensor(16.6082, device='cuda:0')\n",
      "\n",
      "1 16553 tensor(15.2905, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 16553 tensor(15.7252, device='cuda:0')\n",
      "1 16553 tensor(16.0583, device='cuda:0')\n",
      "\n",
      "1 28331 tensor(15.4056, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 28331 tensor(16.2916, device='cuda:0')\n",
      "1 28331 tensor(15.6877, device='cuda:0')\n",
      "\n",
      "1 41131 tensor(16.1673, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 41131 tensor(17.0373, device='cuda:0')\n",
      "1 41131 tensor(16.4276, device='cuda:0')\n",
      "\n",
      "1 20145 tensor(15.2838, device='cuda:0')\n",
      "20\n",
      "158\n",
      "1 20145 tensor(15.2750, device='cuda:0')\n",
      "1 20145 tensor(16.5208, device='cuda:0')\n",
      "\n",
      "1 46262 tensor(16.3639, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 46262 tensor(16.7958, device='cuda:0')\n",
      "1 46262 tensor(16.9610, device='cuda:0')\n",
      "\n",
      "1 30397 tensor(16.0097, device='cuda:0')\n",
      "20\n",
      "242\n",
      "1 30397 tensor(16.7662, device='cuda:0')\n",
      "1 30397 tensor(16.7464, device='cuda:0')\n",
      "\n",
      "1 41151 tensor(15.6972, device='cuda:0')\n",
      "20\n",
      "216\n",
      "1 41151 tensor(16.4151, device='cuda:0')\n",
      "1 41151 tensor(16.1207, device='cuda:0')\n",
      "\n",
      "1 22723 tensor(15.3244, device='cuda:0')\n",
      "20\n",
      "208\n",
      "1 22723 tensor(15.2398, device='cuda:0')\n",
      "1 22723 tensor(14.7139, device='cuda:0')\n",
      "\n",
      "1 23239 tensor(15.5627, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 23239 tensor(16.5180, device='cuda:0')\n",
      "1 23239 tensor(16.2509, device='cuda:0')\n",
      "\n",
      "1 14538 tensor(14.9049, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 14538 tensor(15.8362, device='cuda:0')\n",
      "1 14538 tensor(15.4360, device='cuda:0')\n",
      "\n",
      "1 17100 tensor(15.1639, device='cuda:0')\n",
      "20\n",
      "192\n",
      "1 17100 tensor(15.6138, device='cuda:0')\n",
      "1 17100 tensor(14.7737, device='cuda:0')\n",
      "\n",
      "1 37073 tensor(15.7439, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 37073 tensor(16.4165, device='cuda:0')\n",
      "1 37073 tensor(16.6782, device='cuda:0')\n",
      "\n",
      "1 22739 tensor(16.2814, device='cuda:0')\n",
      "20\n",
      "222\n",
      "1 22739 tensor(17.0443, device='cuda:0')\n",
      "1 22739 tensor(16.3561, device='cuda:0')\n",
      "\n",
      "1 49365 tensor(15.8208, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 49365 tensor(15.9210, device='cuda:0')\n",
      "1 49365 tensor(15.9742, device='cuda:0')\n",
      "\n",
      "1 16598 tensor(15.1784, device='cuda:0')\n",
      "20\n",
      "128\n",
      "1 16598 tensor(15.5970, device='cuda:0')\n",
      "1 16598 tensor(15.9540, device='cuda:0')\n",
      "\n",
      "1 47831 tensor(15.6583, device='cuda:0')\n",
      "20\n",
      "188\n",
      "1 47831 tensor(15.8059, device='cuda:0')\n",
      "1 47831 tensor(15.8059, device='cuda:0')\n",
      "\n",
      "1 31959 tensor(16.3444, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 31959 tensor(16.3689, device='cuda:0')\n",
      "1 31959 tensor(16.2707, device='cuda:0')\n",
      "\n",
      "1 22234 tensor(15.3804, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 22234 tensor(15.9557, device='cuda:0')\n",
      "1 22234 tensor(15.7169, device='cuda:0')\n",
      "\n",
      "1 23259 tensor(15.5356, device='cuda:0')\n",
      "20\n",
      "164\n",
      "1 23259 tensor(15.8471, device='cuda:0')\n",
      "1 23259 tensor(16.1310, device='cuda:0')\n",
      "\n",
      "1 20189 tensor(16.2954, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 20189 tensor(15.8486, device='cuda:0')\n",
      "1 20189 tensor(17.1131, device='cuda:0')\n",
      "\n",
      "1 45790 tensor(15.5139, device='cuda:0')\n",
      "20\n",
      "210\n",
      "1 45790 tensor(16.2846, device='cuda:0')\n",
      "1 45790 tensor(16.4870, device='cuda:0')\n",
      "\n",
      "1 29927 tensor(16.1407, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 29927 tensor(15.7981, device='cuda:0')\n",
      "1 29927 tensor(16.7414, device='cuda:0')\n",
      "\n",
      "1 46312 tensor(15.6938, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 46312 tensor(15.3948, device='cuda:0')\n",
      "1 46312 tensor(15.7140, device='cuda:0')\n",
      "\n",
      "1 31465 tensor(15.6636, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 31465 tensor(16.4116, device='cuda:0')\n",
      "1 31465 tensor(15.7018, device='cuda:0')\n",
      "\n",
      "1 46831 tensor(15.7689, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 46831 tensor(15.1687, device='cuda:0')\n",
      "1 46831 tensor(16.5930, device='cuda:0')\n",
      "\n",
      "1 31472 tensor(15.6724, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 31472 tensor(16.2115, device='cuda:0')\n",
      "1 31472 tensor(16.5359, device='cuda:0')\n",
      "\n",
      "1 29936 tensor(15.6651, device='cuda:0')\n",
      "20\n",
      "118\n",
      "1 29936 tensor(16.3777, device='cuda:0')\n",
      "1 29936 tensor(16.3777, device='cuda:0')\n",
      "\n",
      "1 26355 tensor(14.9800, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 26355 tensor(15.1279, device='cuda:0')\n",
      "1 26355 tensor(15.3907, device='cuda:0')\n",
      "\n",
      "1 6393 tensor(14.3200, device='cuda:0')\n",
      "20\n",
      "224\n",
      "1 6393 tensor(15.1956, device='cuda:0')\n",
      "1 6393 tensor(14.6268, device='cuda:0')\n",
      "\n",
      "1 26876 tensor(15.2676, device='cuda:0')\n",
      "20\n",
      "174\n",
      "1 26876 tensor(14.7577, device='cuda:0')\n",
      "1 26876 tensor(15.7584, device='cuda:0')\n",
      "\n",
      "1 8444 tensor(13.7794, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 8444 tensor(14.4685, device='cuda:0')\n",
      "1 8444 tensor(14.4685, device='cuda:0')\n",
      "\n",
      "1 26878 tensor(16.5050, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 26878 tensor(16.4519, device='cuda:0')\n",
      "1 26878 tensor(16.4520, device='cuda:0')\n",
      "\n",
      "1 6911 tensor(15.1405, device='cuda:0')\n",
      "20\n",
      "162\n",
      "1 6911 tensor(16.2840, device='cuda:0')\n",
      "1 6911 tensor(14.8533, device='cuda:0')\n",
      "\n",
      "1 25856 tensor(15.9203, device='cuda:0')\n",
      "20\n",
      "128\n",
      "1 25856 tensor(16.1798, device='cuda:0')\n",
      "1 25856 tensor(16.0398, device='cuda:0')\n",
      "\n",
      "1 21249 tensor(14.9521, device='cuda:0')\n",
      "20\n",
      "158\n",
      "1 21249 tensor(15.7201, device='cuda:0')\n",
      "1 21249 tensor(15.7201, device='cuda:0')\n",
      "\n",
      "1 19717 tensor(15.0450, device='cuda:0')\n",
      "20\n",
      "158\n",
      "1 19717 tensor(16.0011, device='cuda:0')\n",
      "1 19717 tensor(15.2024, device='cuda:0')\n",
      "\n",
      "1 8966 tensor(15.7492, device='cuda:0')\n",
      "20\n",
      "192\n",
      "1 8966 tensor(16.4950, device='cuda:0')\n",
      "1 8966 tensor(16.6421, device='cuda:0')\n",
      "\n",
      "1 38150 tensor(15.8248, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 38150 tensor(15.3894, device='cuda:0')\n",
      "1 38150 tensor(15.6767, device='cuda:0')\n",
      "\n",
      "1 26888 tensor(15.8087, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 26888 tensor(15.1262, device='cuda:0')\n",
      "1 26888 tensor(16.6847, device='cuda:0')\n",
      "\n",
      "1 27917 tensor(15.7817, device='cuda:0')\n",
      "20\n",
      "254\n",
      "1 27917 tensor(15.9347, device='cuda:0')\n",
      "1 27917 tensor(16.4367, device='cuda:0')\n",
      "\n",
      "1 39184 tensor(14.8729, device='cuda:0')\n",
      "20\n",
      "174\n",
      "1 39184 tensor(13.6736, device='cuda:0')\n",
      "1 39184 tensor(12.7051, device='cuda:0')\n",
      "\n",
      "1 48401 tensor(15.7629, device='cuda:0')\n",
      "20\n",
      "216\n",
      "1 48401 tensor(16.4348, device='cuda:0')\n",
      "1 48401 tensor(16.6368, device='cuda:0')\n",
      "\n",
      "1 24336 tensor(16.0766, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 24336 tensor(15.5764, device='cuda:0')\n",
      "1 24336 tensor(16.7060, device='cuda:0')\n",
      "\n",
      "1 6416 tensor(14.8286, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 6416 tensor(15.2773, device='cuda:0')\n",
      "1 6416 tensor(15.6775, device='cuda:0')\n",
      "\n",
      "1 23316 tensor(15.3875, device='cuda:0')\n",
      "20\n",
      "174\n",
      "1 23316 tensor(15.7147, device='cuda:0')\n",
      "1 23316 tensor(16.3953, device='cuda:0')\n",
      "\n",
      "1 37144 tensor(15.7829, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 37144 tensor(15.5775, device='cuda:0')\n",
      "1 37144 tensor(15.8052, device='cuda:0')\n",
      "\n",
      "1 31513 tensor(14.9628, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 31513 tensor(14.3669, device='cuda:0')\n",
      "1 31513 tensor(14.3669, device='cuda:0')\n",
      "\n",
      "1 42266 tensor(15.6460, device='cuda:0')\n",
      "20\n",
      "122\n",
      "1 42266 tensor(15.1210, device='cuda:0')\n",
      "1 42266 tensor(15.2089, device='cuda:0')\n",
      "\n",
      "1 29989 tensor(15.7444, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 29989 tensor(16.0318, device='cuda:0')\n",
      "1 29989 tensor(16.1903, device='cuda:0')\n",
      "\n",
      "1 27434 tensor(16.2788, device='cuda:0')\n",
      "20\n",
      "202\n",
      "1 27434 tensor(16.0359, device='cuda:0')\n",
      "1 27434 tensor(16.0359, device='cuda:0')\n",
      "\n",
      "1 45867 tensor(15.8440, device='cuda:0')\n",
      "20\n",
      "170\n",
      "1 45867 tensor(14.9055, device='cuda:0')\n",
      "1 45867 tensor(15.5798, device='cuda:0')\n",
      "\n",
      "1 36139 tensor(15.9463, device='cuda:0')\n",
      "20\n",
      "224\n",
      "1 36139 tensor(16.6305, device='cuda:0')\n",
      "1 36139 tensor(15.1182, device='cuda:0')\n",
      "\n",
      "1 29489 tensor(15.6783, device='cuda:0')\n",
      "20\n",
      "192\n",
      "1 29489 tensor(15.8427, device='cuda:0')\n",
      "1 29489 tensor(16.0139, device='cuda:0')\n",
      "\n",
      "1 27443 tensor(15.3448, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 27443 tensor(16.3444, device='cuda:0')\n",
      "1 27443 tensor(15.9511, device='cuda:0')\n",
      "\n",
      "1 27955 tensor(15.8246, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 27955 tensor(15.8436, device='cuda:0')\n",
      "1 27955 tensor(16.7534, device='cuda:0')\n",
      "\n",
      "1 22838 tensor(15.7237, device='cuda:0')\n",
      "20\n",
      "186\n",
      "1 22838 tensor(16.6076, device='cuda:0')\n",
      "1 22838 tensor(16.1994, device='cuda:0')\n",
      "\n",
      "1 7993 tensor(15.0867, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 7993 tensor(14.9394, device='cuda:0')\n",
      "1 7993 tensor(15.9982, device='cuda:0')\n",
      "\n",
      "1 13114 tensor(15.9793, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 13114 tensor(15.9124, device='cuda:0')\n",
      "1 13114 tensor(16.8245, device='cuda:0')\n",
      "\n",
      "1 13629 tensor(15.3702, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 13629 tensor(14.9577, device='cuda:0')\n",
      "1 13629 tensor(16.2333, device='cuda:0')\n",
      "\n",
      "1 28991 tensor(15.5514, device='cuda:0')\n",
      "20\n",
      "162\n",
      "1 28991 tensor(15.9481, device='cuda:0')\n",
      "1 28991 tensor(15.9481, device='cuda:0')\n",
      "\n",
      "1 40771 tensor(15.8351, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 40771 tensor(16.5202, device='cuda:0')\n",
      "1 40771 tensor(16.7430, device='cuda:0')\n",
      "\n",
      "1 25413 tensor(15.3287, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 25413 tensor(15.1134, device='cuda:0')\n",
      "1 25413 tensor(15.6632, device='cuda:0')\n",
      "\n",
      "1 44870 tensor(15.8824, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 44870 tensor(15.4818, device='cuda:0')\n",
      "1 44870 tensor(16.1317, device='cuda:0')\n",
      "\n",
      "1 18247 tensor(15.7295, device='cuda:0')\n",
      "20\n",
      "168\n",
      "1 18247 tensor(16.4273, device='cuda:0')\n",
      "1 18247 tensor(16.6584, device='cuda:0')\n",
      "\n",
      "1 47944 tensor(15.3815, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 47944 tensor(15.1232, device='cuda:0')\n",
      "1 47944 tensor(15.7301, device='cuda:0')\n",
      "\n",
      "1 35657 tensor(16.5817, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 35657 tensor(17.0345, device='cuda:0')\n",
      "1 35657 tensor(16.4876, device='cuda:0')\n",
      "\n",
      "1 26953 tensor(16.1912, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 26953 tensor(17.4672, device='cuda:0')\n",
      "1 26953 tensor(16.6245, device='cuda:0')\n",
      "\n",
      "1 13651 tensor(14.6432, device='cuda:0')\n",
      "20\n",
      "164\n",
      "1 13651 tensor(16.4905, device='cuda:0')\n",
      "1 13651 tensor(12.9937, device='cuda:0')\n",
      "\n",
      "1 27991 tensor(15.7175, device='cuda:0')\n",
      "20\n",
      "226\n",
      "1 27991 tensor(15.9466, device='cuda:0')\n",
      "1 27991 tensor(16.3622, device='cuda:0')\n",
      "\n",
      "1 26456 tensor(15.6743, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 26456 tensor(15.8847, device='cuda:0')\n",
      "1 26456 tensor(15.8847, device='cuda:0')\n",
      "\n",
      "1 48990 tensor(16.2221, device='cuda:0')\n",
      "20\n",
      "170\n",
      "1 48990 tensor(16.8305, device='cuda:0')\n",
      "1 48990 tensor(16.4937, device='cuda:0')\n",
      "\n",
      "1 34655 tensor(16.2296, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 34655 tensor(17.3423, device='cuda:0')\n",
      "1 34655 tensor(17.3423, device='cuda:0')\n",
      "\n",
      "1 16225 tensor(14.4860, device='cuda:0')\n",
      "20\n",
      "186\n",
      "1 16225 tensor(14.8133, device='cuda:0')\n",
      "1 16225 tensor(16.0248, device='cuda:0')\n",
      "\n",
      "1 28518 tensor(16.4949, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 28518 tensor(17.2781, device='cuda:0')\n",
      "1 28518 tensor(17.2904, device='cuda:0')\n",
      "\n",
      "1 20839 tensor(14.5389, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 20839 tensor(13.9388, device='cuda:0')\n",
      "1 20839 tensor(15.1566, device='cuda:0')\n",
      "\n",
      "1 43367 tensor(16.4256, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 43367 tensor(17.2750, device='cuda:0')\n",
      "1 43367 tensor(16.7796, device='cuda:0')\n",
      "\n",
      "1 10092 tensor(14.5704, device='cuda:0')\n",
      "20\n",
      "192\n",
      "1 10092 tensor(14.2835, device='cuda:0')\n",
      "1 10092 tensor(14.5991, device='cuda:0')\n",
      "\n",
      "1 11116 tensor(15.2133, device='cuda:0')\n",
      "20\n",
      "164\n",
      "1 11116 tensor(16.1418, device='cuda:0')\n",
      "1 11116 tensor(15.6044, device='cuda:0')\n",
      "\n",
      "1 31086 tensor(15.3876, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 31086 tensor(15.9495, device='cuda:0')\n",
      "1 31086 tensor(15.4706, device='cuda:0')\n",
      "\n",
      "1 29040 tensor(16.0898, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 29040 tensor(15.8347, device='cuda:0')\n",
      "1 29040 tensor(15.8347, device='cuda:0')\n",
      "\n",
      "1 50033 tensor(15.9076, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 50033 tensor(15.9797, device='cuda:0')\n",
      "1 50033 tensor(16.3896, device='cuda:0')\n",
      "\n",
      "1 5490 tensor(14.5660, device='cuda:0')\n",
      "20\n",
      "228\n",
      "1 5490 tensor(15.8681, device='cuda:0')\n",
      "1 5490 tensor(15.0807, device='cuda:0')\n",
      "\n",
      "1 39795 tensor(15.9999, device='cuda:0')\n",
      "20\n",
      "156\n",
      "1 39795 tensor(16.3575, device='cuda:0')\n",
      "1 39795 tensor(16.2746, device='cuda:0')\n",
      "\n",
      "1 48505 tensor(15.7713, device='cuda:0')\n",
      "20\n",
      "168\n",
      "1 48505 tensor(15.1353, device='cuda:0')\n",
      "1 48505 tensor(15.7428, device='cuda:0')\n",
      "\n",
      "1 40316 tensor(15.5743, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 40316 tensor(16.2970, device='cuda:0')\n",
      "1 40316 tensor(16.5755, device='cuda:0')\n",
      "\n",
      "1 24958 tensor(14.8738, device='cuda:0')\n",
      "20\n",
      "136\n",
      "1 24958 tensor(15.4100, device='cuda:0')\n",
      "1 24958 tensor(15.4100, device='cuda:0')\n",
      "\n",
      "1 38783 tensor(15.1988, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 38783 tensor(16.2793, device='cuda:0')\n",
      "1 38783 tensor(16.6827, device='cuda:0')\n",
      "\n",
      "1 19838 tensor(16.4154, device='cuda:0')\n",
      "20\n",
      "210\n",
      "1 19838 tensor(16.9570, device='cuda:0')\n",
      "1 19838 tensor(16.5006, device='cuda:0')\n",
      "\n",
      "1 23425 tensor(15.6889, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 23425 tensor(17.1115, device='cuda:0')\n",
      "1 23425 tensor(14.9262, device='cuda:0')\n",
      "\n",
      "1 24962 tensor(15.2278, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 24962 tensor(16.0251, device='cuda:0')\n",
      "1 24962 tensor(16.0343, device='cuda:0')\n",
      "\n",
      "1 13187 tensor(14.6310, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 13187 tensor(15.0033, device='cuda:0')\n",
      "1 13187 tensor(15.6368, device='cuda:0')\n",
      "\n",
      "1 49028 tensor(15.0600, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 49028 tensor(15.8209, device='cuda:0')\n",
      "1 49028 tensor(15.9436, device='cuda:0')\n",
      "\n",
      "1 12167 tensor(14.7295, device='cuda:0')\n",
      "20\n",
      "214\n",
      "1 12167 tensor(15.2925, device='cuda:0')\n",
      "1 12167 tensor(14.2555, device='cuda:0')\n",
      "\n",
      "1 43406 tensor(15.2562, device='cuda:0')\n",
      "20\n",
      "232\n",
      "1 43406 tensor(16.1534, device='cuda:0')\n",
      "1 43406 tensor(16.3047, device='cuda:0')\n",
      "\n",
      "1 14737 tensor(15.3453, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 14737 tensor(16.2795, device='cuda:0')\n",
      "1 14737 tensor(13.5682, device='cuda:0')\n",
      "\n",
      "1 18322 tensor(15.0890, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 18322 tensor(16.4490, device='cuda:0')\n",
      "1 18322 tensor(16.4490, device='cuda:0')\n",
      "\n",
      "1 43921 tensor(15.7794, device='cuda:0')\n",
      "20\n",
      "202\n",
      "1 43921 tensor(15.2304, device='cuda:0')\n",
      "1 43921 tensor(16.4376, device='cuda:0')\n",
      "\n",
      "1 12694 tensor(14.9134, device='cuda:0')\n",
      "20\n",
      "192\n",
      "1 12694 tensor(15.5206, device='cuda:0')\n",
      "1 12694 tensor(15.5206, device='cuda:0')\n",
      "\n",
      "1 16286 tensor(16.1322, device='cuda:0')\n",
      "20\n",
      "156\n",
      "1 16286 tensor(17.0677, device='cuda:0')\n",
      "1 16286 tensor(16.9400, device='cuda:0')\n",
      "\n",
      "1 48545 tensor(16.7478, device='cuda:0')\n",
      "20\n",
      "152\n",
      "1 48545 tensor(17.4584, device='cuda:0')\n",
      "1 48545 tensor(17.2560, device='cuda:0')\n",
      "\n",
      "1 29092 tensor(15.4415, device='cuda:0')\n",
      "20\n",
      "226\n",
      "1 29092 tensor(16.3317, device='cuda:0')\n",
      "1 29092 tensor(16.4489, device='cuda:0')\n",
      "\n",
      "1 15273 tensor(15.2380, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 15273 tensor(14.5829, device='cuda:0')\n",
      "1 15273 tensor(15.2164, device='cuda:0')\n",
      "\n",
      "1 16809 tensor(15.8510, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 16809 tensor(16.4744, device='cuda:0')\n",
      "1 16809 tensor(15.0937, device='cuda:0')\n",
      "\n",
      "1 22455 tensor(16.0443, device='cuda:0')\n",
      "20\n",
      "172\n",
      "1 22455 tensor(16.8328, device='cuda:0')\n",
      "1 22455 tensor(15.6104, device='cuda:0')\n",
      "\n",
      "1 24504 tensor(16.0494, device='cuda:0')\n",
      "20\n",
      "166\n",
      "1 24504 tensor(16.1406, device='cuda:0')\n",
      "1 24504 tensor(16.0703, device='cuda:0')\n",
      "\n",
      "1 30140 tensor(15.9227, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 30140 tensor(17.0283, device='cuda:0')\n",
      "1 30140 tensor(15.9809, device='cuda:0')\n",
      "\n",
      "1 27581 tensor(16.2392, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 27581 tensor(15.9468, device='cuda:0')\n",
      "1 27581 tensor(16.1117, device='cuda:0')\n",
      "\n",
      "1 21438 tensor(15.6996, device='cuda:0')\n",
      "20\n",
      "188\n",
      "1 21438 tensor(16.7135, device='cuda:0')\n",
      "1 21438 tensor(16.5907, device='cuda:0')\n",
      "\n",
      "1 35262 tensor(16.5704, device='cuda:0')\n",
      "20\n",
      "150\n",
      "1 35262 tensor(17.1456, device='cuda:0')\n",
      "1 35262 tensor(15.9963, device='cuda:0')\n",
      "\n",
      "1 36292 tensor(15.1472, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 36292 tensor(16.4379, device='cuda:0')\n",
      "1 36292 tensor(15.6331, device='cuda:0')\n",
      "\n",
      "1 6086 tensor(14.9196, device='cuda:0')\n",
      "20\n",
      "172\n",
      "1 6086 tensor(14.9052, device='cuda:0')\n",
      "1 6086 tensor(15.3622, device='cuda:0')\n",
      "\n",
      "1 21960 tensor(16.2627, device='cuda:0')\n",
      "20\n",
      "166\n",
      "1 21960 tensor(15.8349, device='cuda:0')\n",
      "1 21960 tensor(15.4861, device='cuda:0')\n",
      "\n",
      "1 20428 tensor(15.1250, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 20428 tensor(15.9056, device='cuda:0')\n",
      "1 20428 tensor(15.0850, device='cuda:0')\n",
      "\n",
      "1 17361 tensor(15.6876, device='cuda:0')\n",
      "20\n",
      "136\n",
      "1 17361 tensor(17.6480, device='cuda:0')\n",
      "1 17361 tensor(13.1893, device='cuda:0')\n",
      "\n",
      "1 33747 tensor(16.1422, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 33747 tensor(16.3109, device='cuda:0')\n",
      "1 33747 tensor(16.2287, device='cuda:0')\n",
      "\n",
      "1 2516 tensor(14.0254, device='cuda:0')\n",
      "20\n",
      "232\n",
      "1 2516 tensor(13.4327, device='cuda:0')\n",
      "1 2516 tensor(15.3727, device='cuda:0')\n",
      "\n",
      "1 13268 tensor(15.7037, device='cuda:0')\n",
      "20\n",
      "376\n",
      "1 13268 tensor(16.8005, device='cuda:0')\n",
      "1 13268 tensor(14.1730, device='cuda:0')\n",
      "\n",
      "1 45014 tensor(16.2805, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 45014 tensor(16.3372, device='cuda:0')\n",
      "1 45014 tensor(16.7377, device='cuda:0')\n",
      "\n",
      "1 25556 tensor(14.4124, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 25556 tensor(16.3900, device='cuda:0')\n",
      "1 25556 tensor(14.1188, device='cuda:0')\n",
      "\n",
      "1 33240 tensor(15.7804, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 33240 tensor(16.8432, device='cuda:0')\n",
      "1 33240 tensor(15.5643, device='cuda:0')\n",
      "\n",
      "1 36312 tensor(15.6359, device='cuda:0')\n",
      "20\n",
      "246\n",
      "1 36312 tensor(15.5736, device='cuda:0')\n",
      "1 36312 tensor(15.8973, device='cuda:0')\n",
      "\n",
      "1 16863 tensor(15.9662, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 16863 tensor(14.9851, device='cuda:0')\n",
      "1 16863 tensor(16.4141, device='cuda:0')\n",
      "\n",
      "1 28642 tensor(15.1849, device='cuda:0')\n",
      "20\n",
      "208\n",
      "1 28642 tensor(16.0892, device='cuda:0')\n",
      "1 28642 tensor(15.3804, device='cuda:0')\n",
      "\n",
      "1 10213 tensor(15.7225, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 10213 tensor(15.8441, device='cuda:0')\n",
      "1 10213 tensor(16.6004, device='cuda:0')\n",
      "\n",
      "1 16358 tensor(15.2835, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 16358 tensor(15.8138, device='cuda:0')\n",
      "1 16358 tensor(15.6897, device='cuda:0')\n",
      "\n",
      "1 25062 tensor(15.8594, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 25062 tensor(16.2548, device='cuda:0')\n",
      "1 25062 tensor(16.3861, device='cuda:0')\n",
      "\n",
      "1 23528 tensor(17.0467, device='cuda:0')\n",
      "20\n",
      "206\n",
      "1 23528 tensor(17.4164, device='cuda:0')\n",
      "1 23528 tensor(17.2045, device='cuda:0')\n",
      "\n",
      "1 35307 tensor(15.5514, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 35307 tensor(15.4003, device='cuda:0')\n",
      "1 35307 tensor(15.5513, device='cuda:0')\n",
      "\n",
      "1 19436 tensor(15.3875, device='cuda:0')\n",
      "20\n",
      "168\n",
      "1 19436 tensor(16.6002, device='cuda:0')\n",
      "1 19436 tensor(16.6002, device='cuda:0')\n",
      "\n",
      "1 25579 tensor(15.1827, device='cuda:0')\n",
      "20\n",
      "234\n",
      "1 25579 tensor(16.3617, device='cuda:0')\n",
      "1 25579 tensor(16.3617, device='cuda:0')\n",
      "\n",
      "1 15859 tensor(15.6321, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 15859 tensor(16.0694, device='cuda:0')\n",
      "1 15859 tensor(16.7443, device='cuda:0')\n",
      "\n",
      "1 38900 tensor(15.0885, device='cuda:0')\n",
      "20\n",
      "232\n",
      "1 38900 tensor(14.6974, device='cuda:0')\n",
      "1 38900 tensor(14.8748, device='cuda:0')\n",
      "\n",
      "1 7670 tensor(12.7100, device='cuda:0')\n",
      "20\n",
      "162\n",
      "1 7670 tensor(13.1538, device='cuda:0')\n",
      "1 7670 tensor(13.8842, device='cuda:0')\n",
      "\n",
      "1 8698 tensor(15.4278, device='cuda:0')\n",
      "20\n",
      "228\n",
      "1 8698 tensor(16.4569, device='cuda:0')\n",
      "1 8698 tensor(14.1622, device='cuda:0')\n",
      "\n",
      "1 12284 tensor(14.9555, device='cuda:0')\n",
      "20\n",
      "246\n",
      "1 12284 tensor(15.8764, device='cuda:0')\n",
      "1 12284 tensor(15.1250, device='cuda:0')\n",
      "\n",
      "1 44542 tensor(15.5844, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 44542 tensor(15.6561, device='cuda:0')\n",
      "1 44542 tensor(16.0732, device='cuda:0')\n",
      "\n",
      "1 31231 tensor(15.8711, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 31231 tensor(16.5346, device='cuda:0')\n",
      "1 31231 tensor(16.3580, device='cuda:0')\n",
      "\n",
      "2 50178 tensor(14.0708, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 50178 tensor(14.1910, device='cuda:0')\n",
      "2 50178 tensor(14.1910, device='cuda:0')\n",
      "\n",
      "2 46600 tensor(13.8219, device='cuda:0')\n",
      "20\n",
      "186\n",
      "2 46600 tensor(14.2281, device='cuda:0')\n",
      "2 46600 tensor(14.2825, device='cuda:0')\n",
      "\n",
      "2 31755 tensor(14.4516, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 31755 tensor(15.1031, device='cuda:0')\n",
      "2 31755 tensor(14.9529, device='cuda:0')\n",
      "\n",
      "2 46604 tensor(13.8597, device='cuda:0')\n",
      "20\n",
      "214\n",
      "2 46604 tensor(13.6086, device='cuda:0')\n",
      "2 46604 tensor(13.8584, device='cuda:0')\n",
      "\n",
      "2 10765 tensor(14.0841, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 10765 tensor(15.0822, device='cuda:0')\n",
      "2 10765 tensor(13.8945, device='cuda:0')\n",
      "\n",
      "2 11276 tensor(14.0197, device='cuda:0')\n",
      "20\n",
      "160\n",
      "2 11276 tensor(14.0914, device='cuda:0')\n",
      "2 11276 tensor(14.9094, device='cuda:0')\n",
      "\n",
      "2 33811 tensor(13.7397, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 33811 tensor(14.5606, device='cuda:0')\n",
      "2 33811 tensor(14.3694, device='cuda:0')\n",
      "\n",
      "2 46612 tensor(14.2519, device='cuda:0')\n",
      "20\n",
      "236\n",
      "2 46612 tensor(14.9976, device='cuda:0')\n",
      "2 46612 tensor(14.9999, device='cuda:0')\n",
      "\n",
      "2 16916 tensor(13.9896, device='cuda:0')\n",
      "20\n",
      "264\n",
      "2 16916 tensor(14.5292, device='cuda:0')\n",
      "2 16916 tensor(14.5292, device='cuda:0')\n",
      "\n",
      "2 18966 tensor(14.1797, device='cuda:0')\n",
      "20\n",
      "214\n",
      "2 18966 tensor(14.2454, device='cuda:0')\n",
      "2 18966 tensor(14.9869, device='cuda:0')\n",
      "\n",
      "2 12824 tensor(12.8813, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 12824 tensor(13.6531, device='cuda:0')\n",
      "2 12824 tensor(13.5610, device='cuda:0')\n",
      "\n",
      "2 32794 tensor(13.2189, device='cuda:0')\n",
      "20\n",
      "234\n",
      "2 32794 tensor(13.3441, device='cuda:0')\n",
      "2 32794 tensor(13.9803, device='cuda:0')\n",
      "\n",
      "2 7195 tensor(13.1370, device='cuda:0')\n",
      "20\n",
      "166\n",
      "2 7195 tensor(13.5370, device='cuda:0')\n",
      "2 7195 tensor(13.1399, device='cuda:0')\n",
      "\n",
      "2 33821 tensor(13.8706, device='cuda:0')\n",
      "20\n",
      "190\n",
      "2 33821 tensor(14.5438, device='cuda:0')\n",
      "2 33821 tensor(14.1179, device='cuda:0')\n",
      "\n",
      "2 37921 tensor(13.8887, device='cuda:0')\n",
      "20\n",
      "210\n",
      "2 37921 tensor(13.9650, device='cuda:0')\n",
      "2 37921 tensor(14.1958, device='cuda:0')\n",
      "\n",
      "2 33313 tensor(14.3440, device='cuda:0')\n",
      "20\n",
      "202\n",
      "2 33313 tensor(15.0639, device='cuda:0')\n",
      "2 33313 tensor(15.3198, device='cuda:0')\n",
      "\n",
      "2 31270 tensor(13.9938, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 31270 tensor(14.1237, device='cuda:0')\n",
      "2 31270 tensor(14.5788, device='cuda:0')\n",
      "\n",
      "2 29222 tensor(13.4345, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 29222 tensor(14.4593, device='cuda:0')\n",
      "2 29222 tensor(13.4928, device='cuda:0')\n",
      "\n",
      "2 28712 tensor(13.6470, device='cuda:0')\n",
      "20\n",
      "212\n",
      "2 28712 tensor(13.6227, device='cuda:0')\n",
      "2 28712 tensor(14.2150, device='cuda:0')\n",
      "\n",
      "2 18985 tensor(13.3522, device='cuda:0')\n",
      "20\n",
      "214\n",
      "2 18985 tensor(14.0923, device='cuda:0')\n",
      "2 18985 tensor(13.4355, device='cuda:0')\n",
      "\n",
      "2 37930 tensor(13.7451, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 37930 tensor(14.1599, device='cuda:0')\n",
      "2 37930 tensor(14.1725, device='cuda:0')\n",
      "\n",
      "2 28200 tensor(13.5604, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 28200 tensor(13.9379, device='cuda:0')\n",
      "2 28200 tensor(14.1842, device='cuda:0')\n",
      "\n",
      "2 7727 tensor(13.6869, device='cuda:0')\n",
      "20\n",
      "154\n",
      "2 7727 tensor(13.8579, device='cuda:0')\n",
      "2 7727 tensor(13.2597, device='cuda:0')\n",
      "\n",
      "2 24112 tensor(14.2739, device='cuda:0')\n",
      "20\n",
      "184\n",
      "2 24112 tensor(14.5175, device='cuda:0')\n",
      "2 24112 tensor(14.8232, device='cuda:0')\n",
      "\n",
      "2 36400 tensor(13.8657, device='cuda:0')\n",
      "20\n",
      "220\n",
      "2 36400 tensor(14.3250, device='cuda:0')\n",
      "2 36400 tensor(14.3913, device='cuda:0')\n",
      "\n",
      "2 32817 tensor(14.0983, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 32817 tensor(14.2502, device='cuda:0')\n",
      "2 32817 tensor(14.5582, device='cuda:0')\n",
      "\n",
      "2 5171 tensor(13.2062, device='cuda:0')\n",
      "20\n",
      "192\n",
      "2 5171 tensor(13.2351, device='cuda:0')\n",
      "2 5171 tensor(13.7287, device='cuda:0')\n",
      "\n",
      "2 44085 tensor(13.6733, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 44085 tensor(14.4718, device='cuda:0')\n",
      "2 44085 tensor(13.7192, device='cuda:0')\n",
      "\n",
      "2 35382 tensor(13.9199, device='cuda:0')\n",
      "20\n",
      "176\n",
      "2 35382 tensor(14.5301, device='cuda:0')\n",
      "2 35382 tensor(14.4497, device='cuda:0')\n",
      "\n",
      "2 14912 tensor(13.9578, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 14912 tensor(14.3912, device='cuda:0')\n",
      "2 14912 tensor(14.3660, device='cuda:0')\n",
      "\n",
      "2 30274 tensor(13.7036, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 30274 tensor(14.2372, device='cuda:0')\n",
      "2 30274 tensor(13.7876, device='cuda:0')\n",
      "\n",
      "2 20554 tensor(13.6105, device='cuda:0')\n",
      "20\n",
      "160\n",
      "2 20554 tensor(14.4422, device='cuda:0')\n",
      "2 20554 tensor(14.1462, device='cuda:0')\n",
      "\n",
      "2 15435 tensor(13.8187, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 15435 tensor(14.3082, device='cuda:0')\n",
      "2 15435 tensor(14.3624, device='cuda:0')\n",
      "\n",
      "2 33357 tensor(13.7650, device='cuda:0')\n",
      "20\n",
      "172\n",
      "2 33357 tensor(14.9191, device='cuda:0')\n",
      "2 33357 tensor(14.9191, device='cuda:0')\n",
      "\n",
      "2 49231 tensor(14.7001, device='cuda:0')\n",
      "20\n",
      "136\n",
      "2 49231 tensor(15.0058, device='cuda:0')\n",
      "2 49231 tensor(14.7774, device='cuda:0')\n",
      "\n",
      "2 38994 tensor(13.8069, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 38994 tensor(14.2684, device='cuda:0')\n",
      "2 38994 tensor(14.6654, device='cuda:0')\n",
      "\n",
      "2 21587 tensor(13.4945, device='cuda:0')\n",
      "20\n",
      "222\n",
      "2 21587 tensor(14.0891, device='cuda:0')\n",
      "2 21587 tensor(13.3355, device='cuda:0')\n",
      "\n",
      "2 7252 tensor(13.2451, device='cuda:0')\n",
      "20\n",
      "182\n",
      "2 7252 tensor(14.0354, device='cuda:0')\n",
      "2 7252 tensor(13.3101, device='cuda:0')\n",
      "\n",
      "2 40537 tensor(13.8075, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 40537 tensor(14.1064, device='cuda:0')\n",
      "2 40537 tensor(15.0806, device='cuda:0')\n",
      "\n",
      "2 27738 tensor(14.3834, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 27738 tensor(14.8218, device='cuda:0')\n",
      "2 27738 tensor(14.6997, device='cuda:0')\n",
      "\n",
      "2 44123 tensor(13.6650, device='cuda:0')\n",
      "20\n",
      "152\n",
      "2 44123 tensor(13.6050, device='cuda:0')\n",
      "2 44123 tensor(14.1791, device='cuda:0')\n",
      "\n",
      "2 44124 tensor(14.6608, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 44124 tensor(15.1619, device='cuda:0')\n",
      "2 44124 tensor(14.4818, device='cuda:0')\n",
      "\n",
      "2 14943 tensor(13.8680, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 14943 tensor(14.5984, device='cuda:0')\n",
      "2 14943 tensor(14.7436, device='cuda:0')\n",
      "\n",
      "2 45664 tensor(14.0220, device='cuda:0')\n",
      "20\n",
      "158\n",
      "2 45664 tensor(14.8613, device='cuda:0')\n",
      "2 45664 tensor(14.3089, device='cuda:0')\n",
      "\n",
      "2 15458 tensor(13.4738, device='cuda:0')\n",
      "20\n",
      "252\n",
      "2 15458 tensor(13.6343, device='cuda:0')\n",
      "2 15458 tensor(14.0732, device='cuda:0')\n",
      "\n",
      "2 49765 tensor(13.4787, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 49765 tensor(12.7116, device='cuda:0')\n",
      "2 49765 tensor(12.8405, device='cuda:0')\n",
      "\n",
      "2 19046 tensor(13.8715, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 19046 tensor(14.4158, device='cuda:0')\n",
      "2 19046 tensor(13.7801, device='cuda:0')\n",
      "\n",
      "2 35944 tensor(13.7066, device='cuda:0')\n",
      "20\n",
      "210\n",
      "2 35944 tensor(14.0159, device='cuda:0')\n",
      "2 35944 tensor(14.3603, device='cuda:0')\n",
      "\n",
      "2 29804 tensor(14.0008, device='cuda:0')\n",
      "20\n",
      "192\n",
      "2 29804 tensor(14.2622, device='cuda:0')\n",
      "2 29804 tensor(14.2622, device='cuda:0')\n",
      "\n",
      "2 23662 tensor(12.9864, device='cuda:0')\n",
      "20\n",
      "170\n",
      "2 23662 tensor(12.9151, device='cuda:0')\n",
      "2 23662 tensor(13.5916, device='cuda:0')\n",
      "\n",
      "2 37497 tensor(14.0943, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 37497 tensor(14.7561, device='cuda:0')\n",
      "2 37497 tensor(14.6232, device='cuda:0')\n",
      "\n",
      "2 22138 tensor(13.6952, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 22138 tensor(13.6933, device='cuda:0')\n",
      "2 22138 tensor(14.3977, device='cuda:0')\n",
      "\n",
      "2 27773 tensor(14.1240, device='cuda:0')\n",
      "20\n",
      "240\n",
      "2 27773 tensor(14.5294, device='cuda:0')\n",
      "2 27773 tensor(14.7956, device='cuda:0')\n",
      "\n",
      "2 28798 tensor(13.8652, device='cuda:0')\n",
      "20\n",
      "152\n",
      "2 28798 tensor(14.2338, device='cuda:0')\n",
      "2 28798 tensor(14.1438, device='cuda:0')\n",
      "\n",
      "2 33407 tensor(14.2508, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 33407 tensor(14.4114, device='cuda:0')\n",
      "2 33407 tensor(14.5303, device='cuda:0')\n",
      "\n",
      "2 27264 tensor(13.8818, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 27264 tensor(13.8197, device='cuda:0')\n",
      "2 27264 tensor(14.1966, device='cuda:0')\n",
      "\n",
      "2 9857 tensor(14.0097, device='cuda:0')\n",
      "20\n",
      "240\n",
      "2 9857 tensor(14.5421, device='cuda:0')\n",
      "2 9857 tensor(14.3594, device='cuda:0')\n",
      "\n",
      "2 14468 tensor(13.5641, device='cuda:0')\n",
      "20\n",
      "162\n",
      "2 14468 tensor(14.5822, device='cuda:0')\n",
      "2 14468 tensor(14.0001, device='cuda:0')\n",
      "\n",
      "2 6277 tensor(13.0716, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 6277 tensor(13.4245, device='cuda:0')\n",
      "2 6277 tensor(13.5775, device='cuda:0')\n",
      "\n",
      "2 35972 tensor(14.0204, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 35972 tensor(14.6332, device='cuda:0')\n",
      "2 35972 tensor(14.3950, device='cuda:0')\n",
      "\n",
      "2 4744 tensor(12.7518, device='cuda:0')\n",
      "20\n",
      "208\n",
      "2 4744 tensor(13.3866, device='cuda:0')\n",
      "2 4744 tensor(13.5297, device='cuda:0')\n",
      "\n",
      "2 32905 tensor(13.4231, device='cuda:0')\n",
      "20\n",
      "184\n",
      "2 32905 tensor(14.1735, device='cuda:0')\n",
      "2 32905 tensor(14.1735, device='cuda:0')\n",
      "\n",
      "2 32393 tensor(13.6988, device='cuda:0')\n",
      "20\n",
      "204\n",
      "2 32393 tensor(13.9779, device='cuda:0')\n",
      "2 32393 tensor(14.1501, device='cuda:0')\n",
      "\n",
      "2 22671 tensor(14.2554, device='cuda:0')\n",
      "20\n",
      "210\n",
      "2 22671 tensor(14.7686, device='cuda:0')\n",
      "2 22671 tensor(14.6177, device='cuda:0')\n",
      "\n",
      "2 20628 tensor(13.7093, device='cuda:0')\n",
      "20\n",
      "172\n",
      "2 20628 tensor(14.0508, device='cuda:0')\n",
      "2 20628 tensor(13.6458, device='cuda:0')\n",
      "\n",
      "2 32920 tensor(14.2567, device='cuda:0')\n",
      "20\n",
      "388\n",
      "2 32920 tensor(14.8701, device='cuda:0')\n",
      "2 32920 tensor(14.9849, device='cuda:0')\n",
      "\n",
      "2 17560 tensor(13.7095, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 17560 tensor(14.4533, device='cuda:0')\n",
      "2 17560 tensor(14.0688, device='cuda:0')\n",
      "\n",
      "2 5119 tensor(13.1031, device='cuda:0')\n",
      "20\n",
      "172\n",
      "2 5119 tensor(14.0023, device='cuda:0')\n",
      "2 5119 tensor(13.7351, device='cuda:0')\n",
      "\n",
      "2 21661 tensor(14.3329, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 21661 tensor(15.0142, device='cuda:0')\n",
      "2 21661 tensor(14.5306, device='cuda:0')\n",
      "\n",
      "2 16543 tensor(13.6567, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 16543 tensor(14.2263, device='cuda:0')\n",
      "2 16543 tensor(13.8069, device='cuda:0')\n",
      "\n",
      "2 31903 tensor(13.7329, device='cuda:0')\n",
      "20\n",
      "212\n",
      "2 31903 tensor(14.2494, device='cuda:0')\n",
      "2 31903 tensor(14.5570, device='cuda:0')\n",
      "\n",
      "2 18089 tensor(13.7410, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 18089 tensor(14.5113, device='cuda:0')\n",
      "2 18089 tensor(14.6928, device='cuda:0')\n",
      "\n",
      "2 16553 tensor(13.5496, device='cuda:0')\n",
      "20\n",
      "158\n",
      "2 16553 tensor(14.2814, device='cuda:0')\n",
      "2 16553 tensor(14.1998, device='cuda:0')\n",
      "\n",
      "2 28331 tensor(13.7757, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 28331 tensor(14.1581, device='cuda:0')\n",
      "2 28331 tensor(14.1298, device='cuda:0')\n",
      "\n",
      "2 41131 tensor(14.2137, device='cuda:0')\n",
      "20\n",
      "220\n",
      "2 41131 tensor(14.3536, device='cuda:0')\n",
      "2 41131 tensor(14.5731, device='cuda:0')\n",
      "\n",
      "2 20145 tensor(13.8264, device='cuda:0')\n",
      "20\n",
      "150\n",
      "2 20145 tensor(14.9357, device='cuda:0')\n",
      "2 20145 tensor(14.3013, device='cuda:0')\n",
      "\n",
      "2 46262 tensor(14.2808, device='cuda:0')\n",
      "20\n",
      "210\n",
      "2 46262 tensor(14.6151, device='cuda:0')\n",
      "2 46262 tensor(14.8844, device='cuda:0')\n",
      "\n",
      "2 30397 tensor(14.1955, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 30397 tensor(15.1911, device='cuda:0')\n",
      "2 30397 tensor(14.3512, device='cuda:0')\n",
      "\n",
      "2 41151 tensor(13.6732, device='cuda:0')\n",
      "20\n",
      "226\n",
      "2 41151 tensor(14.2463, device='cuda:0')\n",
      "2 41151 tensor(14.4497, device='cuda:0')\n",
      "\n",
      "2 22723 tensor(13.5063, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 22723 tensor(13.9623, device='cuda:0')\n",
      "2 22723 tensor(13.9593, device='cuda:0')\n",
      "\n",
      "2 23239 tensor(13.3519, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 23239 tensor(13.5808, device='cuda:0')\n",
      "2 23239 tensor(13.3843, device='cuda:0')\n",
      "\n",
      "2 14538 tensor(13.7691, device='cuda:0')\n",
      "20\n",
      "184\n",
      "2 14538 tensor(14.2401, device='cuda:0')\n",
      "2 14538 tensor(14.1259, device='cuda:0')\n",
      "\n",
      "2 17100 tensor(13.3233, device='cuda:0')\n",
      "20\n",
      "182\n",
      "2 17100 tensor(14.0539, device='cuda:0')\n",
      "2 17100 tensor(14.1519, device='cuda:0')\n",
      "\n",
      "2 37073 tensor(13.9122, device='cuda:0')\n",
      "20\n",
      "180\n",
      "2 37073 tensor(14.5048, device='cuda:0')\n",
      "2 37073 tensor(14.5879, device='cuda:0')\n",
      "\n",
      "2 22739 tensor(14.0924, device='cuda:0')\n",
      "20\n",
      "228\n",
      "2 22739 tensor(14.3172, device='cuda:0')\n",
      "2 22739 tensor(14.3172, device='cuda:0')\n",
      "\n",
      "2 49365 tensor(13.5664, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 49365 tensor(13.5062, device='cuda:0')\n",
      "2 49365 tensor(13.5536, device='cuda:0')\n",
      "\n",
      "2 16598 tensor(14.1277, device='cuda:0')\n",
      "20\n",
      "186\n",
      "2 16598 tensor(14.1903, device='cuda:0')\n",
      "2 16598 tensor(14.5068, device='cuda:0')\n",
      "\n",
      "2 47831 tensor(13.8091, device='cuda:0')\n",
      "20\n",
      "238\n",
      "2 47831 tensor(14.6095, device='cuda:0')\n",
      "2 47831 tensor(13.8667, device='cuda:0')\n",
      "\n",
      "2 31959 tensor(13.9630, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 31959 tensor(14.3254, device='cuda:0')\n",
      "2 31959 tensor(14.6315, device='cuda:0')\n",
      "\n",
      "2 22234 tensor(13.4241, device='cuda:0')\n",
      "20\n",
      "212\n",
      "2 22234 tensor(14.2180, device='cuda:0')\n",
      "2 22234 tensor(14.1623, device='cuda:0')\n",
      "\n",
      "2 23259 tensor(13.4777, device='cuda:0')\n",
      "20\n",
      "162\n",
      "2 23259 tensor(14.1383, device='cuda:0')\n",
      "2 23259 tensor(13.5648, device='cuda:0')\n",
      "\n",
      "2 20189 tensor(14.5482, device='cuda:0')\n",
      "20\n",
      "238\n",
      "2 20189 tensor(15.2071, device='cuda:0')\n",
      "2 20189 tensor(14.9683, device='cuda:0')\n",
      "\n",
      "2 45790 tensor(13.6376, device='cuda:0')\n",
      "20\n",
      "198\n",
      "2 45790 tensor(14.4039, device='cuda:0')\n",
      "2 45790 tensor(14.3817, device='cuda:0')\n",
      "\n",
      "2 29927 tensor(14.1199, device='cuda:0')\n",
      "20\n",
      "258\n",
      "2 29927 tensor(15.2780, device='cuda:0')\n",
      "2 29927 tensor(14.6064, device='cuda:0')\n",
      "\n",
      "2 46312 tensor(13.4745, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 46312 tensor(13.4757, device='cuda:0')\n",
      "2 46312 tensor(14.2325, device='cuda:0')\n",
      "\n",
      "2 31465 tensor(14.5122, device='cuda:0')\n",
      "20\n",
      "144\n",
      "2 31465 tensor(15.8025, device='cuda:0')\n",
      "2 31465 tensor(15.4782, device='cuda:0')\n",
      "\n",
      "2 46831 tensor(14.3177, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 46831 tensor(14.2228, device='cuda:0')\n",
      "2 46831 tensor(14.6680, device='cuda:0')\n",
      "\n",
      "2 31472 tensor(13.1578, device='cuda:0')\n",
      "20\n",
      "230\n",
      "2 31472 tensor(13.9726, device='cuda:0')\n",
      "2 31472 tensor(14.1876, device='cuda:0')\n",
      "\n",
      "2 29936 tensor(13.8348, device='cuda:0')\n",
      "20\n",
      "182\n",
      "2 29936 tensor(14.2055, device='cuda:0')\n",
      "2 29936 tensor(14.9513, device='cuda:0')\n",
      "\n",
      "2 26355 tensor(13.4259, device='cuda:0')\n",
      "20\n",
      "248\n",
      "2 26355 tensor(13.8231, device='cuda:0')\n",
      "2 26355 tensor(14.0709, device='cuda:0')\n",
      "\n",
      "2 6393 tensor(13.0564, device='cuda:0')\n",
      "20\n",
      "150\n",
      "2 6393 tensor(14.2176, device='cuda:0')\n",
      "2 6393 tensor(13.8257, device='cuda:0')\n",
      "\n",
      "2 26876 tensor(13.4937, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 26876 tensor(13.8719, device='cuda:0')\n",
      "2 26876 tensor(13.7288, device='cuda:0')\n",
      "\n",
      "2 8444 tensor(12.7850, device='cuda:0')\n",
      "20\n",
      "208\n",
      "2 8444 tensor(13.6397, device='cuda:0')\n",
      "2 8444 tensor(12.4853, device='cuda:0')\n",
      "\n",
      "2 26878 tensor(14.6022, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 26878 tensor(15.3495, device='cuda:0')\n",
      "2 26878 tensor(14.7732, device='cuda:0')\n",
      "\n",
      "2 6911 tensor(13.2610, device='cuda:0')\n",
      "20\n",
      "220\n",
      "2 6911 tensor(13.5387, device='cuda:0')\n",
      "2 6911 tensor(13.4780, device='cuda:0')\n",
      "\n",
      "2 25856 tensor(13.5780, device='cuda:0')\n",
      "20\n",
      "192\n",
      "2 25856 tensor(14.0250, device='cuda:0')\n",
      "2 25856 tensor(13.9556, device='cuda:0')\n",
      "\n",
      "2 21249 tensor(14.1935, device='cuda:0')\n",
      "20\n",
      "186\n",
      "2 21249 tensor(14.9645, device='cuda:0')\n",
      "2 21249 tensor(14.6813, device='cuda:0')\n",
      "\n",
      "2 19717 tensor(13.3925, device='cuda:0')\n",
      "20\n",
      "152\n",
      "2 19717 tensor(13.0560, device='cuda:0')\n",
      "2 19717 tensor(13.8390, device='cuda:0')\n",
      "\n",
      "2 8966 tensor(13.8393, device='cuda:0')\n",
      "20\n",
      "134\n",
      "2 8966 tensor(14.3261, device='cuda:0')\n",
      "2 8966 tensor(14.5375, device='cuda:0')\n",
      "\n",
      "2 38150 tensor(13.9168, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 38150 tensor(14.7379, device='cuda:0')\n",
      "2 38150 tensor(14.2337, device='cuda:0')\n",
      "\n",
      "2 26888 tensor(14.4961, device='cuda:0')\n",
      "20\n",
      "190\n",
      "2 26888 tensor(15.7015, device='cuda:0')\n",
      "2 26888 tensor(14.5929, device='cuda:0')\n",
      "\n",
      "2 27917 tensor(13.7341, device='cuda:0')\n",
      "20\n",
      "134\n",
      "2 27917 tensor(14.0239, device='cuda:0')\n",
      "2 27917 tensor(14.6852, device='cuda:0')\n",
      "\n",
      "2 39184 tensor(13.7941, device='cuda:0')\n",
      "20\n",
      "142\n",
      "2 39184 tensor(14.3639, device='cuda:0')\n",
      "2 39184 tensor(13.8593, device='cuda:0')\n",
      "\n",
      "2 48401 tensor(13.6590, device='cuda:0')\n",
      "20\n",
      "180\n",
      "2 48401 tensor(13.9145, device='cuda:0')\n",
      "2 48401 tensor(14.5188, device='cuda:0')\n",
      "\n",
      "2 24336 tensor(13.8534, device='cuda:0')\n",
      "20\n",
      "176\n",
      "2 24336 tensor(13.5472, device='cuda:0')\n",
      "2 24336 tensor(14.6621, device='cuda:0')\n",
      "\n",
      "2 6416 tensor(13.2400, device='cuda:0')\n",
      "20\n",
      "212\n",
      "2 6416 tensor(13.5865, device='cuda:0')\n",
      "2 6416 tensor(13.6610, device='cuda:0')\n",
      "\n",
      "2 23316 tensor(13.3522, device='cuda:0')\n",
      "20\n",
      "150\n",
      "2 23316 tensor(13.6391, device='cuda:0')\n",
      "2 23316 tensor(13.6906, device='cuda:0')\n",
      "\n",
      "2 37144 tensor(13.6446, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 37144 tensor(14.0184, device='cuda:0')\n",
      "2 37144 tensor(13.7753, device='cuda:0')\n",
      "\n",
      "2 31513 tensor(13.3491, device='cuda:0')\n",
      "20\n",
      "198\n",
      "2 31513 tensor(13.3281, device='cuda:0')\n",
      "2 31513 tensor(14.2453, device='cuda:0')\n",
      "\n",
      "2 42266 tensor(13.9024, device='cuda:0')\n",
      "20\n",
      "230\n",
      "2 42266 tensor(13.9419, device='cuda:0')\n",
      "2 42266 tensor(15.3233, device='cuda:0')\n",
      "\n",
      "2 29989 tensor(13.9528, device='cuda:0')\n",
      "20\n",
      "134\n",
      "2 29989 tensor(14.1520, device='cuda:0')\n",
      "2 29989 tensor(14.2981, device='cuda:0')\n",
      "\n",
      "2 27434 tensor(14.4759, device='cuda:0')\n",
      "20\n",
      "154\n",
      "2 27434 tensor(14.9627, device='cuda:0')\n",
      "2 27434 tensor(14.7168, device='cuda:0')\n",
      "\n",
      "2 45867 tensor(13.6243, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 45867 tensor(14.4369, device='cuda:0')\n",
      "2 45867 tensor(14.1750, device='cuda:0')\n",
      "\n",
      "2 36139 tensor(14.0174, device='cuda:0')\n",
      "20\n",
      "250\n",
      "2 36139 tensor(14.6039, device='cuda:0')\n",
      "2 36139 tensor(14.1914, device='cuda:0')\n",
      "\n",
      "2 29489 tensor(13.3559, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 29489 tensor(13.3985, device='cuda:0')\n",
      "2 29489 tensor(13.6817, device='cuda:0')\n",
      "\n",
      "2 27443 tensor(13.7498, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 27443 tensor(13.9145, device='cuda:0')\n",
      "2 27443 tensor(13.9506, device='cuda:0')\n",
      "\n",
      "2 27955 tensor(14.4696, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 27955 tensor(14.9232, device='cuda:0')\n",
      "2 27955 tensor(15.1902, device='cuda:0')\n",
      "\n",
      "2 22838 tensor(13.7472, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 22838 tensor(14.8727, device='cuda:0')\n",
      "2 22838 tensor(14.4486, device='cuda:0')\n",
      "\n",
      "2 7993 tensor(13.0984, device='cuda:0')\n",
      "20\n",
      "230\n",
      "2 7993 tensor(14.3241, device='cuda:0')\n",
      "2 7993 tensor(13.3737, device='cuda:0')\n",
      "\n",
      "2 13114 tensor(13.3362, device='cuda:0')\n",
      "20\n",
      "172\n",
      "2 13114 tensor(14.1468, device='cuda:0')\n",
      "2 13114 tensor(13.6826, device='cuda:0')\n",
      "\n",
      "2 13629 tensor(13.6063, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 13629 tensor(14.6684, device='cuda:0')\n",
      "2 13629 tensor(14.5377, device='cuda:0')\n",
      "\n",
      "2 28991 tensor(13.8195, device='cuda:0')\n",
      "20\n",
      "204\n",
      "2 28991 tensor(13.7090, device='cuda:0')\n",
      "2 28991 tensor(14.0837, device='cuda:0')\n",
      "\n",
      "2 40771 tensor(13.8908, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 40771 tensor(14.6479, device='cuda:0')\n",
      "2 40771 tensor(14.9097, device='cuda:0')\n",
      "\n",
      "2 25413 tensor(13.4600, device='cuda:0')\n",
      "20\n",
      "224\n",
      "2 25413 tensor(13.8302, device='cuda:0')\n",
      "2 25413 tensor(14.0471, device='cuda:0')\n",
      "\n",
      "2 44870 tensor(13.8931, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 44870 tensor(14.0311, device='cuda:0')\n",
      "2 44870 tensor(14.2625, device='cuda:0')\n",
      "\n",
      "2 18247 tensor(13.4537, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 18247 tensor(13.7712, device='cuda:0')\n",
      "2 18247 tensor(13.6129, device='cuda:0')\n",
      "\n",
      "2 47944 tensor(13.8425, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 47944 tensor(14.4244, device='cuda:0')\n",
      "2 47944 tensor(14.4244, device='cuda:0')\n",
      "\n",
      "2 35657 tensor(14.3736, device='cuda:0')\n",
      "20\n",
      "182\n",
      "2 35657 tensor(14.4886, device='cuda:0')\n",
      "2 35657 tensor(14.7695, device='cuda:0')\n",
      "\n",
      "2 26953 tensor(13.9647, device='cuda:0')\n",
      "20\n",
      "190\n",
      "2 26953 tensor(14.6228, device='cuda:0')\n",
      "2 26953 tensor(14.3094, device='cuda:0')\n",
      "\n",
      "2 13651 tensor(13.2269, device='cuda:0')\n",
      "20\n",
      "182\n",
      "2 13651 tensor(13.8012, device='cuda:0')\n",
      "2 13651 tensor(13.4852, device='cuda:0')\n",
      "\n",
      "2 27991 tensor(14.0503, device='cuda:0')\n",
      "20\n",
      "154\n",
      "2 27991 tensor(14.0971, device='cuda:0')\n",
      "2 27991 tensor(14.9372, device='cuda:0')\n",
      "\n",
      "2 26456 tensor(13.7472, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 26456 tensor(14.1339, device='cuda:0')\n",
      "2 26456 tensor(14.0657, device='cuda:0')\n",
      "\n",
      "2 48990 tensor(14.0042, device='cuda:0')\n",
      "20\n",
      "158\n",
      "2 48990 tensor(13.5281, device='cuda:0')\n",
      "2 48990 tensor(14.6158, device='cuda:0')\n",
      "\n",
      "2 34655 tensor(13.9569, device='cuda:0')\n",
      "20\n",
      "214\n",
      "2 34655 tensor(14.1891, device='cuda:0')\n",
      "2 34655 tensor(13.9195, device='cuda:0')\n",
      "\n",
      "2 16225 tensor(14.0125, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 16225 tensor(14.8720, device='cuda:0')\n",
      "2 16225 tensor(14.7445, device='cuda:0')\n",
      "\n",
      "2 28518 tensor(14.1976, device='cuda:0')\n",
      "20\n",
      "162\n",
      "2 28518 tensor(14.3492, device='cuda:0')\n",
      "2 28518 tensor(14.6761, device='cuda:0')\n",
      "\n",
      "2 20839 tensor(12.8496, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 20839 tensor(12.9769, device='cuda:0')\n",
      "2 20839 tensor(12.8226, device='cuda:0')\n",
      "\n",
      "2 43367 tensor(14.5612, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 43367 tensor(15.1393, device='cuda:0')\n",
      "2 43367 tensor(15.0564, device='cuda:0')\n",
      "\n",
      "2 10092 tensor(13.0309, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 10092 tensor(12.8620, device='cuda:0')\n",
      "2 10092 tensor(13.2260, device='cuda:0')\n",
      "\n",
      "2 11116 tensor(13.2181, device='cuda:0')\n",
      "20\n",
      "250\n",
      "2 11116 tensor(13.6292, device='cuda:0')\n",
      "2 11116 tensor(13.8785, device='cuda:0')\n",
      "\n",
      "2 31086 tensor(13.8704, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 31086 tensor(14.1703, device='cuda:0')\n",
      "2 31086 tensor(14.5652, device='cuda:0')\n",
      "\n",
      "2 29040 tensor(14.2463, device='cuda:0')\n",
      "20\n",
      "258\n",
      "2 29040 tensor(15.0254, device='cuda:0')\n",
      "2 29040 tensor(13.7948, device='cuda:0')\n",
      "\n",
      "2 50033 tensor(13.8172, device='cuda:0')\n",
      "20\n",
      "166\n",
      "2 50033 tensor(14.4693, device='cuda:0')\n",
      "2 50033 tensor(14.4693, device='cuda:0')\n",
      "\n",
      "2 5490 tensor(12.9279, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 5490 tensor(13.4715, device='cuda:0')\n",
      "2 5490 tensor(13.7623, device='cuda:0')\n",
      "\n",
      "2 39795 tensor(14.2693, device='cuda:0')\n",
      "20\n",
      "226\n",
      "2 39795 tensor(14.8323, device='cuda:0')\n",
      "2 39795 tensor(13.9062, device='cuda:0')\n",
      "\n",
      "2 48505 tensor(14.0362, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 48505 tensor(14.8613, device='cuda:0')\n",
      "2 48505 tensor(14.3733, device='cuda:0')\n",
      "\n",
      "2 40316 tensor(14.0306, device='cuda:0')\n",
      "20\n",
      "238\n",
      "2 40316 tensor(14.4377, device='cuda:0')\n",
      "2 40316 tensor(14.4041, device='cuda:0')\n",
      "\n",
      "2 24958 tensor(13.5850, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 24958 tensor(14.6764, device='cuda:0')\n",
      "2 24958 tensor(14.4047, device='cuda:0')\n",
      "\n",
      "2 38783 tensor(14.1782, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 38783 tensor(14.1767, device='cuda:0')\n",
      "2 38783 tensor(14.2587, device='cuda:0')\n",
      "\n",
      "2 19838 tensor(14.3671, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 19838 tensor(15.3636, device='cuda:0')\n",
      "2 19838 tensor(15.2252, device='cuda:0')\n",
      "\n",
      "2 23425 tensor(13.9259, device='cuda:0')\n",
      "20\n",
      "190\n",
      "2 23425 tensor(13.9019, device='cuda:0')\n",
      "2 23425 tensor(14.3541, device='cuda:0')\n",
      "\n",
      "2 24962 tensor(13.7084, device='cuda:0')\n",
      "20\n",
      "172\n",
      "2 24962 tensor(14.5897, device='cuda:0')\n",
      "2 24962 tensor(14.0837, device='cuda:0')\n",
      "\n",
      "2 13187 tensor(13.2884, device='cuda:0')\n",
      "20\n",
      "212\n",
      "2 13187 tensor(14.1430, device='cuda:0')\n",
      "2 13187 tensor(14.3346, device='cuda:0')\n",
      "\n",
      "2 49028 tensor(13.5540, device='cuda:0')\n",
      "20\n",
      "222\n",
      "2 49028 tensor(14.5540, device='cuda:0')\n",
      "2 49028 tensor(14.1566, device='cuda:0')\n",
      "\n",
      "2 12167 tensor(13.3670, device='cuda:0')\n",
      "20\n",
      "192\n",
      "2 12167 tensor(13.6009, device='cuda:0')\n",
      "2 12167 tensor(14.1893, device='cuda:0')\n",
      "\n",
      "2 43406 tensor(13.5505, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 43406 tensor(14.2483, device='cuda:0')\n",
      "2 43406 tensor(13.8879, device='cuda:0')\n",
      "\n",
      "2 14737 tensor(13.6087, device='cuda:0')\n",
      "20\n",
      "198\n",
      "2 14737 tensor(14.0385, device='cuda:0')\n",
      "2 14737 tensor(14.0929, device='cuda:0')\n",
      "\n",
      "2 18322 tensor(13.1392, device='cuda:0')\n",
      "20\n",
      "184\n",
      "2 18322 tensor(13.5224, device='cuda:0')\n",
      "2 18322 tensor(14.4515, device='cuda:0')\n",
      "\n",
      "2 43921 tensor(13.8826, device='cuda:0')\n",
      "20\n",
      "170\n",
      "2 43921 tensor(14.2019, device='cuda:0')\n",
      "2 43921 tensor(14.4944, device='cuda:0')\n",
      "\n",
      "2 12694 tensor(13.4059, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 12694 tensor(14.0678, device='cuda:0')\n",
      "2 12694 tensor(14.5189, device='cuda:0')\n",
      "\n",
      "2 16286 tensor(13.6626, device='cuda:0')\n",
      "20\n",
      "208\n",
      "2 16286 tensor(13.1575, device='cuda:0')\n",
      "2 16286 tensor(14.4117, device='cuda:0')\n",
      "\n",
      "2 48545 tensor(14.5620, device='cuda:0')\n",
      "20\n",
      "180\n",
      "2 48545 tensor(15.8059, device='cuda:0')\n",
      "2 48545 tensor(15.0824, device='cuda:0')\n",
      "\n",
      "2 29092 tensor(13.7698, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 29092 tensor(14.3413, device='cuda:0')\n",
      "2 29092 tensor(14.5553, device='cuda:0')\n",
      "\n",
      "2 15273 tensor(13.3045, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 15273 tensor(13.6791, device='cuda:0')\n",
      "2 15273 tensor(14.2158, device='cuda:0')\n",
      "\n",
      "2 16809 tensor(13.8380, device='cuda:0')\n",
      "20\n",
      "154\n",
      "2 16809 tensor(14.7876, device='cuda:0')\n",
      "2 16809 tensor(14.5792, device='cuda:0')\n",
      "\n",
      "2 22455 tensor(14.2114, device='cuda:0')\n",
      "20\n",
      "162\n",
      "2 22455 tensor(14.7831, device='cuda:0')\n",
      "2 22455 tensor(15.3181, device='cuda:0')\n",
      "\n",
      "2 24504 tensor(13.7333, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 24504 tensor(14.2453, device='cuda:0')\n",
      "2 24504 tensor(13.8700, device='cuda:0')\n",
      "\n",
      "2 30140 tensor(14.0910, device='cuda:0')\n",
      "20\n",
      "218\n",
      "2 30140 tensor(13.8450, device='cuda:0')\n",
      "2 30140 tensor(14.9538, device='cuda:0')\n",
      "\n",
      "2 27581 tensor(13.7040, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 27581 tensor(13.9938, device='cuda:0')\n",
      "2 27581 tensor(14.5147, device='cuda:0')\n",
      "\n",
      "2 21438 tensor(13.8060, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 21438 tensor(14.4613, device='cuda:0')\n",
      "2 21438 tensor(15.3011, device='cuda:0')\n",
      "\n",
      "2 35262 tensor(14.1510, device='cuda:0')\n",
      "20\n",
      "232\n",
      "2 35262 tensor(14.3621, device='cuda:0')\n",
      "2 35262 tensor(14.8239, device='cuda:0')\n",
      "\n",
      "2 36292 tensor(13.4905, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 36292 tensor(14.8110, device='cuda:0')\n",
      "2 36292 tensor(14.1767, device='cuda:0')\n",
      "\n",
      "2 6086 tensor(13.2845, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 6086 tensor(13.9009, device='cuda:0')\n",
      "2 6086 tensor(14.0030, device='cuda:0')\n",
      "\n",
      "2 21960 tensor(14.0382, device='cuda:0')\n",
      "20\n",
      "124\n",
      "2 21960 tensor(14.4405, device='cuda:0')\n",
      "2 21960 tensor(14.2576, device='cuda:0')\n",
      "\n",
      "2 20428 tensor(13.4850, device='cuda:0')\n",
      "20\n",
      "214\n",
      "2 20428 tensor(14.1540, device='cuda:0')\n",
      "2 20428 tensor(14.3047, device='cuda:0')\n",
      "\n",
      "2 17361 tensor(14.5758, device='cuda:0')\n",
      "20\n",
      "204\n",
      "2 17361 tensor(15.5050, device='cuda:0')\n",
      "2 17361 tensor(14.1710, device='cuda:0')\n",
      "\n",
      "2 33747 tensor(13.9404, device='cuda:0')\n",
      "20\n",
      "198\n",
      "2 33747 tensor(14.1474, device='cuda:0')\n",
      "2 33747 tensor(14.3669, device='cuda:0')\n",
      "\n",
      "2 2516 tensor(12.5068, device='cuda:0')\n",
      "20\n",
      "124\n",
      "2 2516 tensor(12.7838, device='cuda:0')\n",
      "2 2516 tensor(12.7978, device='cuda:0')\n",
      "\n",
      "2 13268 tensor(13.8380, device='cuda:0')\n",
      "20\n",
      "338\n",
      "2 13268 tensor(13.9171, device='cuda:0')\n",
      "2 13268 tensor(13.3720, device='cuda:0')\n",
      "\n",
      "2 45014 tensor(13.9200, device='cuda:0')\n",
      "20\n",
      "236\n",
      "2 45014 tensor(14.3232, device='cuda:0')\n",
      "2 45014 tensor(14.2942, device='cuda:0')\n",
      "\n",
      "2 25556 tensor(14.3233, device='cuda:0')\n",
      "20\n",
      "158\n",
      "2 25556 tensor(13.9698, device='cuda:0')\n",
      "2 25556 tensor(14.8711, device='cuda:0')\n",
      "\n",
      "2 33240 tensor(14.1759, device='cuda:0')\n",
      "20\n",
      "158\n",
      "2 33240 tensor(14.6469, device='cuda:0')\n",
      "2 33240 tensor(14.3745, device='cuda:0')\n",
      "\n",
      "2 36312 tensor(13.9816, device='cuda:0')\n",
      "20\n",
      "166\n",
      "2 36312 tensor(14.3853, device='cuda:0')\n",
      "2 36312 tensor(14.2009, device='cuda:0')\n",
      "\n",
      "2 16863 tensor(14.1196, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 16863 tensor(14.5096, device='cuda:0')\n",
      "2 16863 tensor(13.4936, device='cuda:0')\n",
      "\n",
      "2 28642 tensor(13.9122, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 28642 tensor(14.5892, device='cuda:0')\n",
      "2 28642 tensor(14.5892, device='cuda:0')\n",
      "\n",
      "2 10213 tensor(13.6834, device='cuda:0')\n",
      "20\n",
      "186\n",
      "2 10213 tensor(14.4339, device='cuda:0')\n",
      "2 10213 tensor(14.3592, device='cuda:0')\n",
      "\n",
      "2 16358 tensor(13.5923, device='cuda:0')\n",
      "20\n",
      "190\n",
      "2 16358 tensor(13.4701, device='cuda:0')\n",
      "2 16358 tensor(13.7547, device='cuda:0')\n",
      "\n",
      "2 25062 tensor(14.0888, device='cuda:0')\n",
      "20\n",
      "176\n",
      "2 25062 tensor(14.5844, device='cuda:0')\n",
      "2 25062 tensor(14.8481, device='cuda:0')\n",
      "\n",
      "2 23528 tensor(14.8694, device='cuda:0')\n",
      "20\n",
      "160\n",
      "2 23528 tensor(15.6967, device='cuda:0')\n",
      "2 23528 tensor(15.2026, device='cuda:0')\n",
      "\n",
      "2 35307 tensor(13.9831, device='cuda:0')\n",
      "20\n",
      "166\n",
      "2 35307 tensor(14.3913, device='cuda:0')\n",
      "2 35307 tensor(14.2880, device='cuda:0')\n",
      "\n",
      "2 19436 tensor(13.6068, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 19436 tensor(14.1520, device='cuda:0')\n",
      "2 19436 tensor(14.2919, device='cuda:0')\n",
      "\n",
      "2 25579 tensor(14.1739, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 25579 tensor(14.7616, device='cuda:0')\n",
      "2 25579 tensor(15.2825, device='cuda:0')\n",
      "\n",
      "2 15859 tensor(14.0576, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 15859 tensor(14.8021, device='cuda:0')\n",
      "2 15859 tensor(14.6365, device='cuda:0')\n",
      "\n",
      "2 38900 tensor(13.3968, device='cuda:0')\n",
      "20\n",
      "210\n",
      "2 38900 tensor(13.4974, device='cuda:0')\n",
      "2 38900 tensor(14.3435, device='cuda:0')\n",
      "\n",
      "2 7670 tensor(12.1271, device='cuda:0')\n",
      "20\n",
      "202\n",
      "2 7670 tensor(12.6101, device='cuda:0')\n",
      "2 7670 tensor(13.0524, device='cuda:0')\n",
      "\n",
      "2 8698 tensor(13.8175, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 8698 tensor(14.8483, device='cuda:0')\n",
      "2 8698 tensor(15.0202, device='cuda:0')\n",
      "\n",
      "2 12284 tensor(13.2751, device='cuda:0')\n",
      "20\n",
      "186\n",
      "2 12284 tensor(14.0718, device='cuda:0')\n",
      "2 12284 tensor(13.2523, device='cuda:0')\n",
      "\n",
      "2 44542 tensor(13.5724, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 44542 tensor(13.7540, device='cuda:0')\n",
      "2 44542 tensor(13.8409, device='cuda:0')\n",
      "\n",
      "2 31231 tensor(13.8665, device='cuda:0')\n",
      "20\n",
      "238\n",
      "2 31231 tensor(13.7719, device='cuda:0')\n",
      "2 31231 tensor(14.3703, device='cuda:0')\n",
      "\n",
      "3 50178 tensor(17.1973, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 50178 tensor(18.2997, device='cuda:0')\n",
      "3 50178 tensor(17.0849, device='cuda:0')\n",
      "\n",
      "3 46600 tensor(17.0992, device='cuda:0')\n",
      "20\n",
      "178\n",
      "3 46600 tensor(17.1846, device='cuda:0')\n",
      "3 46600 tensor(16.9256, device='cuda:0')\n",
      "\n",
      "3 31755 tensor(17.6957, device='cuda:0')\n",
      "20\n",
      "192\n",
      "3 31755 tensor(18.1614, device='cuda:0')\n",
      "3 31755 tensor(17.7271, device='cuda:0')\n",
      "\n",
      "3 46604 tensor(17.2492, device='cuda:0')\n",
      "20\n",
      "200\n",
      "3 46604 tensor(17.4047, device='cuda:0')\n",
      "3 46604 tensor(17.7901, device='cuda:0')\n",
      "\n",
      "3 10765 tensor(17.6116, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 10765 tensor(18.1177, device='cuda:0')\n",
      "3 10765 tensor(17.8086, device='cuda:0')\n",
      "\n",
      "3 11276 tensor(17.8999, device='cuda:0')\n",
      "20\n",
      "218\n",
      "3 11276 tensor(17.9299, device='cuda:0')\n",
      "3 11276 tensor(18.7246, device='cuda:0')\n",
      "\n",
      "3 33811 tensor(17.1989, device='cuda:0')\n",
      "20\n",
      "198\n",
      "3 33811 tensor(17.7487, device='cuda:0')\n",
      "3 33811 tensor(16.6974, device='cuda:0')\n",
      "\n",
      "3 46612 tensor(17.1393, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 46612 tensor(17.9258, device='cuda:0')\n",
      "3 46612 tensor(18.2961, device='cuda:0')\n",
      "\n",
      "3 16916 tensor(17.4316, device='cuda:0')\n",
      "20\n",
      "192\n",
      "3 16916 tensor(17.4924, device='cuda:0')\n",
      "3 16916 tensor(17.9802, device='cuda:0')\n",
      "\n",
      "3 18966 tensor(17.7615, device='cuda:0')\n",
      "20\n",
      "142\n",
      "3 18966 tensor(17.9220, device='cuda:0')\n",
      "3 18966 tensor(18.1570, device='cuda:0')\n",
      "\n",
      "3 12824 tensor(16.6450, device='cuda:0')\n",
      "20\n",
      "216\n",
      "3 12824 tensor(17.1621, device='cuda:0')\n",
      "3 12824 tensor(17.3933, device='cuda:0')\n",
      "\n",
      "3 32794 tensor(16.6482, device='cuda:0')\n",
      "20\n",
      "180\n",
      "3 32794 tensor(16.6247, device='cuda:0')\n",
      "3 32794 tensor(17.0725, device='cuda:0')\n",
      "\n",
      "3 7195 tensor(17.2091, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 7195 tensor(17.8513, device='cuda:0')\n",
      "3 7195 tensor(18.0797, device='cuda:0')\n",
      "\n",
      "3 33821 tensor(17.0381, device='cuda:0')\n",
      "20\n",
      "180\n",
      "3 33821 tensor(17.1760, device='cuda:0')\n",
      "3 33821 tensor(17.1543, device='cuda:0')\n",
      "\n",
      "3 37921 tensor(17.4741, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 37921 tensor(18.6376, device='cuda:0')\n",
      "3 37921 tensor(17.7308, device='cuda:0')\n",
      "\n",
      "3 33313 tensor(17.6376, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 33313 tensor(18.8854, device='cuda:0')\n",
      "3 33313 tensor(18.8854, device='cuda:0')\n",
      "\n",
      "3 31270 tensor(16.7878, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 31270 tensor(17.2079, device='cuda:0')\n",
      "3 31270 tensor(17.4090, device='cuda:0')\n",
      "\n",
      "3 29222 tensor(16.9454, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 29222 tensor(17.4239, device='cuda:0')\n",
      "3 29222 tensor(17.2634, device='cuda:0')\n",
      "\n",
      "3 28712 tensor(17.5080, device='cuda:0')\n",
      "20\n",
      "160\n",
      "3 28712 tensor(17.3027, device='cuda:0')\n",
      "3 28712 tensor(17.7097, device='cuda:0')\n",
      "\n",
      "3 18985 tensor(16.8513, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 18985 tensor(17.4742, device='cuda:0')\n",
      "3 18985 tensor(17.4674, device='cuda:0')\n",
      "\n",
      "3 37930 tensor(17.2371, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 37930 tensor(17.3441, device='cuda:0')\n",
      "3 37930 tensor(17.8510, device='cuda:0')\n",
      "\n",
      "3 28200 tensor(17.2260, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 28200 tensor(17.6926, device='cuda:0')\n",
      "3 28200 tensor(17.1772, device='cuda:0')\n",
      "\n",
      "3 7727 tensor(17.1459, device='cuda:0')\n",
      "20\n",
      "126\n",
      "3 7727 tensor(17.0976, device='cuda:0')\n",
      "3 7727 tensor(17.8170, device='cuda:0')\n",
      "\n",
      "3 24112 tensor(17.1621, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 24112 tensor(18.0033, device='cuda:0')\n",
      "3 24112 tensor(16.7845, device='cuda:0')\n",
      "\n",
      "3 36400 tensor(17.2575, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 36400 tensor(17.8197, device='cuda:0')\n",
      "3 36400 tensor(17.3070, device='cuda:0')\n",
      "\n",
      "3 32817 tensor(17.3386, device='cuda:0')\n",
      "20\n",
      "240\n",
      "3 32817 tensor(18.4130, device='cuda:0')\n",
      "3 32817 tensor(17.9088, device='cuda:0')\n",
      "\n",
      "3 5171 tensor(17.0476, device='cuda:0')\n",
      "20\n",
      "156\n",
      "3 5171 tensor(17.7419, device='cuda:0')\n",
      "3 5171 tensor(17.8416, device='cuda:0')\n",
      "\n",
      "3 44085 tensor(17.0153, device='cuda:0')\n",
      "20\n",
      "220\n",
      "3 44085 tensor(17.7581, device='cuda:0')\n",
      "3 44085 tensor(17.4144, device='cuda:0')\n",
      "\n",
      "3 35382 tensor(17.2768, device='cuda:0')\n",
      "20\n",
      "190\n",
      "3 35382 tensor(17.5501, device='cuda:0')\n",
      "3 35382 tensor(17.8951, device='cuda:0')\n",
      "\n",
      "3 14912 tensor(17.3394, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 14912 tensor(17.3372, device='cuda:0')\n",
      "3 14912 tensor(17.4622, device='cuda:0')\n",
      "\n",
      "3 30274 tensor(16.9862, device='cuda:0')\n",
      "20\n",
      "178\n",
      "3 30274 tensor(16.6598, device='cuda:0')\n",
      "3 30274 tensor(16.8473, device='cuda:0')\n",
      "\n",
      "3 20554 tensor(17.1973, device='cuda:0')\n",
      "20\n",
      "140\n",
      "3 20554 tensor(17.5472, device='cuda:0')\n",
      "3 20554 tensor(17.8023, device='cuda:0')\n",
      "\n",
      "3 15435 tensor(17.2641, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 15435 tensor(17.6520, device='cuda:0')\n",
      "3 15435 tensor(17.1931, device='cuda:0')\n",
      "\n",
      "3 33357 tensor(17.2582, device='cuda:0')\n",
      "20\n",
      "166\n",
      "3 33357 tensor(17.3946, device='cuda:0')\n",
      "3 33357 tensor(17.4959, device='cuda:0')\n",
      "\n",
      "3 49231 tensor(17.5707, device='cuda:0')\n",
      "20\n",
      "184\n",
      "3 49231 tensor(18.3745, device='cuda:0')\n",
      "3 49231 tensor(17.7638, device='cuda:0')\n",
      "\n",
      "3 38994 tensor(17.2002, device='cuda:0')\n",
      "20\n",
      "172\n",
      "3 38994 tensor(18.1830, device='cuda:0')\n",
      "3 38994 tensor(17.3276, device='cuda:0')\n",
      "\n",
      "3 21587 tensor(17.2311, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 21587 tensor(18.3826, device='cuda:0')\n",
      "3 21587 tensor(17.0084, device='cuda:0')\n",
      "\n",
      "3 7252 tensor(16.6873, device='cuda:0')\n",
      "20\n",
      "156\n",
      "3 7252 tensor(17.1833, device='cuda:0')\n",
      "3 7252 tensor(16.6655, device='cuda:0')\n",
      "\n",
      "3 40537 tensor(17.1811, device='cuda:0')\n",
      "20\n",
      "196\n",
      "3 40537 tensor(17.4343, device='cuda:0')\n",
      "3 40537 tensor(17.4877, device='cuda:0')\n",
      "\n",
      "3 27738 tensor(17.1853, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 27738 tensor(17.6447, device='cuda:0')\n",
      "3 27738 tensor(17.5774, device='cuda:0')\n",
      "\n",
      "3 44123 tensor(17.2187, device='cuda:0')\n",
      "20\n",
      "160\n",
      "3 44123 tensor(17.0682, device='cuda:0')\n",
      "3 44123 tensor(17.5019, device='cuda:0')\n",
      "\n",
      "3 44124 tensor(17.9296, device='cuda:0')\n",
      "20\n",
      "236\n",
      "3 44124 tensor(18.1662, device='cuda:0')\n",
      "3 44124 tensor(18.3367, device='cuda:0')\n",
      "\n",
      "3 14943 tensor(17.2130, device='cuda:0')\n",
      "20\n",
      "156\n",
      "3 14943 tensor(17.5972, device='cuda:0')\n",
      "3 14943 tensor(17.9999, device='cuda:0')\n",
      "\n",
      "3 45664 tensor(17.4383, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 45664 tensor(17.1240, device='cuda:0')\n",
      "3 45664 tensor(18.0828, device='cuda:0')\n",
      "\n",
      "3 15458 tensor(17.3288, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 15458 tensor(17.4258, device='cuda:0')\n",
      "3 15458 tensor(16.8764, device='cuda:0')\n",
      "\n",
      "3 49765 tensor(17.4507, device='cuda:0')\n",
      "20\n",
      "192\n",
      "3 49765 tensor(17.7417, device='cuda:0')\n",
      "3 49765 tensor(17.8917, device='cuda:0')\n",
      "\n",
      "3 19046 tensor(17.1766, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 19046 tensor(17.4263, device='cuda:0')\n",
      "3 19046 tensor(17.9416, device='cuda:0')\n",
      "\n",
      "3 35944 tensor(16.8927, device='cuda:0')\n",
      "20\n",
      "216\n",
      "3 35944 tensor(17.4792, device='cuda:0')\n",
      "3 35944 tensor(17.7122, device='cuda:0')\n",
      "\n",
      "3 29804 tensor(17.0970, device='cuda:0')\n",
      "20\n",
      "198\n",
      "3 29804 tensor(17.4834, device='cuda:0')\n",
      "3 29804 tensor(18.1947, device='cuda:0')\n",
      "\n",
      "3 23662 tensor(16.8823, device='cuda:0')\n",
      "20\n",
      "218\n",
      "3 23662 tensor(17.1038, device='cuda:0')\n",
      "3 23662 tensor(17.5673, device='cuda:0')\n",
      "\n",
      "3 37497 tensor(17.1941, device='cuda:0')\n",
      "20\n",
      "220\n",
      "3 37497 tensor(17.2130, device='cuda:0')\n",
      "3 37497 tensor(17.2130, device='cuda:0')\n",
      "\n",
      "3 22138 tensor(16.9838, device='cuda:0')\n",
      "20\n",
      "184\n",
      "3 22138 tensor(17.3887, device='cuda:0')\n",
      "3 22138 tensor(17.8810, device='cuda:0')\n",
      "\n",
      "3 27773 tensor(17.1993, device='cuda:0')\n",
      "20\n",
      "176\n",
      "3 27773 tensor(17.7868, device='cuda:0')\n",
      "3 27773 tensor(17.3940, device='cuda:0')\n",
      "\n",
      "3 28798 tensor(16.9767, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 28798 tensor(17.7851, device='cuda:0')\n",
      "3 28798 tensor(17.1566, device='cuda:0')\n",
      "\n",
      "3 33407 tensor(17.9232, device='cuda:0')\n",
      "20\n",
      "226\n",
      "3 33407 tensor(17.7244, device='cuda:0')\n",
      "3 33407 tensor(18.7338, device='cuda:0')\n",
      "\n",
      "3 27264 tensor(16.1607, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 27264 tensor(17.2080, device='cuda:0')\n",
      "3 27264 tensor(16.5949, device='cuda:0')\n",
      "\n",
      "3 9857 tensor(17.7846, device='cuda:0')\n",
      "20\n",
      "208\n",
      "3 9857 tensor(18.6850, device='cuda:0')\n",
      "3 9857 tensor(18.0582, device='cuda:0')\n",
      "\n",
      "3 14468 tensor(16.6425, device='cuda:0')\n",
      "20\n",
      "198\n",
      "3 14468 tensor(17.1813, device='cuda:0')\n",
      "3 14468 tensor(17.0600, device='cuda:0')\n",
      "\n",
      "3 6277 tensor(16.8423, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 6277 tensor(17.2894, device='cuda:0')\n",
      "3 6277 tensor(16.7600, device='cuda:0')\n",
      "\n",
      "3 35972 tensor(17.5101, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 35972 tensor(17.6087, device='cuda:0')\n",
      "3 35972 tensor(17.4312, device='cuda:0')\n",
      "\n",
      "3 4744 tensor(16.6675, device='cuda:0')\n",
      "20\n",
      "146\n",
      "3 4744 tensor(17.1632, device='cuda:0')\n",
      "3 4744 tensor(16.6996, device='cuda:0')\n",
      "\n",
      "3 32905 tensor(17.0702, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 32905 tensor(17.6121, device='cuda:0')\n",
      "3 32905 tensor(18.2648, device='cuda:0')\n",
      "\n",
      "3 32393 tensor(17.0624, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 32393 tensor(17.7467, device='cuda:0')\n",
      "3 32393 tensor(17.0253, device='cuda:0')\n",
      "\n",
      "3 22671 tensor(17.5532, device='cuda:0')\n",
      "20\n",
      "176\n",
      "3 22671 tensor(17.6812, device='cuda:0')\n",
      "3 22671 tensor(18.8773, device='cuda:0')\n",
      "\n",
      "3 20628 tensor(16.6636, device='cuda:0')\n",
      "20\n",
      "218\n",
      "3 20628 tensor(18.0138, device='cuda:0')\n",
      "3 20628 tensor(17.4971, device='cuda:0')\n",
      "\n",
      "3 32920 tensor(17.6388, device='cuda:0')\n",
      "20\n",
      "362\n",
      "3 32920 tensor(18.3946, device='cuda:0')\n",
      "3 32920 tensor(17.8543, device='cuda:0')\n",
      "\n",
      "3 17560 tensor(16.6856, device='cuda:0')\n",
      "20\n",
      "164\n",
      "3 17560 tensor(16.9399, device='cuda:0')\n",
      "3 17560 tensor(17.1245, device='cuda:0')\n",
      "\n",
      "3 5119 tensor(16.8737, device='cuda:0')\n",
      "20\n",
      "140\n",
      "3 5119 tensor(16.9543, device='cuda:0')\n",
      "3 5119 tensor(15.5182, device='cuda:0')\n",
      "\n",
      "3 21661 tensor(18.0723, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 21661 tensor(18.7484, device='cuda:0')\n",
      "3 21661 tensor(17.9885, device='cuda:0')\n",
      "\n",
      "3 16543 tensor(17.2879, device='cuda:0')\n",
      "20\n",
      "172\n",
      "3 16543 tensor(17.1985, device='cuda:0')\n",
      "3 16543 tensor(18.2140, device='cuda:0')\n",
      "\n",
      "3 31903 tensor(17.0226, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 31903 tensor(17.0511, device='cuda:0')\n",
      "3 31903 tensor(17.0724, device='cuda:0')\n",
      "\n",
      "3 18089 tensor(17.3140, device='cuda:0')\n",
      "20\n",
      "184\n",
      "3 18089 tensor(17.9053, device='cuda:0')\n",
      "3 18089 tensor(18.6055, device='cuda:0')\n",
      "\n",
      "3 16553 tensor(16.9536, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 16553 tensor(16.7959, device='cuda:0')\n",
      "3 16553 tensor(17.4995, device='cuda:0')\n",
      "\n",
      "3 28331 tensor(17.0581, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 28331 tensor(16.9385, device='cuda:0')\n",
      "3 28331 tensor(17.0081, device='cuda:0')\n",
      "\n",
      "3 41131 tensor(17.4024, device='cuda:0')\n",
      "20\n",
      "178\n",
      "3 41131 tensor(17.7505, device='cuda:0')\n",
      "3 41131 tensor(17.0158, device='cuda:0')\n",
      "\n",
      "3 20145 tensor(16.7207, device='cuda:0')\n",
      "20\n",
      "174\n",
      "3 20145 tensor(16.7095, device='cuda:0')\n",
      "3 20145 tensor(16.8415, device='cuda:0')\n",
      "\n",
      "3 46262 tensor(17.5420, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 46262 tensor(17.7598, device='cuda:0')\n",
      "3 46262 tensor(17.7598, device='cuda:0')\n",
      "\n",
      "3 30397 tensor(17.2118, device='cuda:0')\n",
      "20\n",
      "200\n",
      "3 30397 tensor(18.2369, device='cuda:0')\n",
      "3 30397 tensor(17.7783, device='cuda:0')\n",
      "\n",
      "3 41151 tensor(16.7074, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 41151 tensor(17.1565, device='cuda:0')\n",
      "3 41151 tensor(16.7834, device='cuda:0')\n",
      "\n",
      "3 22723 tensor(17.0843, device='cuda:0')\n",
      "20\n",
      "210\n",
      "3 22723 tensor(17.0463, device='cuda:0')\n",
      "3 22723 tensor(17.2925, device='cuda:0')\n",
      "\n",
      "3 23239 tensor(16.9730, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 23239 tensor(16.9143, device='cuda:0')\n",
      "3 23239 tensor(16.9143, device='cuda:0')\n",
      "\n",
      "3 14538 tensor(17.3748, device='cuda:0')\n",
      "20\n",
      "174\n",
      "3 14538 tensor(18.7375, device='cuda:0')\n",
      "3 14538 tensor(19.5172, device='cuda:0')\n",
      "\n",
      "3 17100 tensor(17.0303, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 17100 tensor(17.5777, device='cuda:0')\n",
      "3 17100 tensor(17.5777, device='cuda:0')\n",
      "\n",
      "3 37073 tensor(17.1083, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 37073 tensor(17.5042, device='cuda:0')\n",
      "3 37073 tensor(17.4023, device='cuda:0')\n",
      "\n",
      "3 22739 tensor(17.5402, device='cuda:0')\n",
      "20\n",
      "238\n",
      "3 22739 tensor(18.1044, device='cuda:0')\n",
      "3 22739 tensor(17.6337, device='cuda:0')\n",
      "\n",
      "3 49365 tensor(17.3839, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 49365 tensor(17.6252, device='cuda:0')\n",
      "3 49365 tensor(17.9929, device='cuda:0')\n",
      "\n",
      "3 16598 tensor(18.0518, device='cuda:0')\n",
      "20\n",
      "152\n",
      "3 16598 tensor(17.9506, device='cuda:0')\n",
      "3 16598 tensor(18.1730, device='cuda:0')\n",
      "\n",
      "3 47831 tensor(17.2449, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 47831 tensor(17.7296, device='cuda:0')\n",
      "3 47831 tensor(17.7013, device='cuda:0')\n",
      "\n",
      "3 31959 tensor(17.1397, device='cuda:0')\n",
      "20\n",
      "232\n",
      "3 31959 tensor(17.3975, device='cuda:0')\n",
      "3 31959 tensor(17.1025, device='cuda:0')\n",
      "\n",
      "3 22234 tensor(16.7251, device='cuda:0')\n",
      "20\n",
      "252\n",
      "3 22234 tensor(16.6591, device='cuda:0')\n",
      "3 22234 tensor(16.7252, device='cuda:0')\n",
      "\n",
      "3 23259 tensor(17.1412, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 23259 tensor(17.6296, device='cuda:0')\n",
      "3 23259 tensor(17.8709, device='cuda:0')\n",
      "\n",
      "3 20189 tensor(18.0141, device='cuda:0')\n",
      "20\n",
      "176\n",
      "3 20189 tensor(17.8093, device='cuda:0')\n",
      "3 20189 tensor(18.7819, device='cuda:0')\n",
      "\n",
      "3 45790 tensor(17.2313, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 45790 tensor(17.6165, device='cuda:0')\n",
      "3 45790 tensor(18.3123, device='cuda:0')\n",
      "\n",
      "3 29927 tensor(17.1032, device='cuda:0')\n",
      "20\n",
      "226\n",
      "3 29927 tensor(18.2494, device='cuda:0')\n",
      "3 29927 tensor(17.9099, device='cuda:0')\n",
      "\n",
      "3 46312 tensor(17.1807, device='cuda:0')\n",
      "20\n",
      "210\n",
      "3 46312 tensor(17.8692, device='cuda:0')\n",
      "3 46312 tensor(18.4829, device='cuda:0')\n",
      "\n",
      "3 31465 tensor(18.1697, device='cuda:0')\n",
      "20\n",
      "176\n",
      "3 31465 tensor(19.2221, device='cuda:0')\n",
      "3 31465 tensor(18.6080, device='cuda:0')\n",
      "\n",
      "3 46831 tensor(17.4941, device='cuda:0')\n",
      "20\n",
      "158\n",
      "3 46831 tensor(17.7538, device='cuda:0')\n",
      "3 46831 tensor(18.1041, device='cuda:0')\n",
      "\n",
      "3 31472 tensor(16.7316, device='cuda:0')\n",
      "20\n",
      "162\n",
      "3 31472 tensor(16.8648, device='cuda:0')\n",
      "3 31472 tensor(17.3573, device='cuda:0')\n",
      "\n",
      "3 29936 tensor(17.1912, device='cuda:0')\n",
      "20\n",
      "150\n",
      "3 29936 tensor(16.6935, device='cuda:0')\n",
      "3 29936 tensor(16.9325, device='cuda:0')\n",
      "\n",
      "3 26355 tensor(17.0871, device='cuda:0')\n",
      "20\n",
      "136\n",
      "3 26355 tensor(17.1544, device='cuda:0')\n",
      "3 26355 tensor(17.3182, device='cuda:0')\n",
      "\n",
      "3 6393 tensor(16.6373, device='cuda:0')\n",
      "20\n",
      "150\n",
      "3 6393 tensor(17.1188, device='cuda:0')\n",
      "3 6393 tensor(17.0296, device='cuda:0')\n",
      "\n",
      "3 26876 tensor(17.2504, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 26876 tensor(18.0622, device='cuda:0')\n",
      "3 26876 tensor(17.7308, device='cuda:0')\n",
      "\n",
      "3 8444 tensor(16.7551, device='cuda:0')\n",
      "20\n",
      "152\n",
      "3 8444 tensor(17.6767, device='cuda:0')\n",
      "3 8444 tensor(17.2256, device='cuda:0')\n",
      "\n",
      "3 26878 tensor(17.7676, device='cuda:0')\n",
      "20\n",
      "216\n",
      "3 26878 tensor(18.0301, device='cuda:0')\n",
      "3 26878 tensor(17.7057, device='cuda:0')\n",
      "\n",
      "3 6911 tensor(16.8114, device='cuda:0')\n",
      "20\n",
      "162\n",
      "3 6911 tensor(17.0480, device='cuda:0')\n",
      "3 6911 tensor(17.4136, device='cuda:0')\n",
      "\n",
      "3 25856 tensor(16.6836, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 25856 tensor(16.8055, device='cuda:0')\n",
      "3 25856 tensor(16.8165, device='cuda:0')\n",
      "\n",
      "3 21249 tensor(19.1456, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 21249 tensor(19.8635, device='cuda:0')\n",
      "3 21249 tensor(18.8460, device='cuda:0')\n",
      "\n",
      "3 19717 tensor(17.1864, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 19717 tensor(17.9607, device='cuda:0')\n",
      "3 19717 tensor(17.8551, device='cuda:0')\n",
      "\n",
      "3 8966 tensor(17.0771, device='cuda:0')\n",
      "20\n",
      "166\n",
      "3 8966 tensor(17.9519, device='cuda:0')\n",
      "3 8966 tensor(17.5214, device='cuda:0')\n",
      "\n",
      "3 38150 tensor(17.3242, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 38150 tensor(17.1789, device='cuda:0')\n",
      "3 38150 tensor(18.0734, device='cuda:0')\n",
      "\n",
      "3 26888 tensor(16.6885, device='cuda:0')\n",
      "20\n",
      "210\n",
      "3 26888 tensor(16.9196, device='cuda:0')\n",
      "3 26888 tensor(16.7323, device='cuda:0')\n",
      "\n",
      "3 27917 tensor(17.4306, device='cuda:0')\n",
      "20\n",
      "214\n",
      "3 27917 tensor(18.4713, device='cuda:0')\n",
      "3 27917 tensor(17.2069, device='cuda:0')\n",
      "\n",
      "3 39184 tensor(17.9376, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 39184 tensor(18.9651, device='cuda:0')\n",
      "3 39184 tensor(18.9651, device='cuda:0')\n",
      "\n",
      "3 48401 tensor(17.0456, device='cuda:0')\n",
      "20\n",
      "148\n",
      "3 48401 tensor(17.4651, device='cuda:0')\n",
      "3 48401 tensor(17.4651, device='cuda:0')\n",
      "\n",
      "3 24336 tensor(17.3323, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 24336 tensor(18.2614, device='cuda:0')\n",
      "3 24336 tensor(17.3988, device='cuda:0')\n",
      "\n",
      "3 6416 tensor(17.3396, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 6416 tensor(17.4247, device='cuda:0')\n",
      "3 6416 tensor(18.0124, device='cuda:0')\n",
      "\n",
      "3 23316 tensor(17.1351, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 23316 tensor(17.5511, device='cuda:0')\n",
      "3 23316 tensor(16.9708, device='cuda:0')\n",
      "\n",
      "3 37144 tensor(17.2635, device='cuda:0')\n",
      "20\n",
      "146\n",
      "3 37144 tensor(17.2634, device='cuda:0')\n",
      "3 37144 tensor(17.7167, device='cuda:0')\n",
      "\n",
      "3 31513 tensor(17.0061, device='cuda:0')\n",
      "20\n",
      "222\n",
      "3 31513 tensor(16.9085, device='cuda:0')\n",
      "3 31513 tensor(17.6538, device='cuda:0')\n",
      "\n",
      "3 42266 tensor(16.8232, device='cuda:0')\n",
      "20\n",
      "178\n",
      "3 42266 tensor(17.4882, device='cuda:0')\n",
      "3 42266 tensor(16.8773, device='cuda:0')\n",
      "\n",
      "3 29989 tensor(17.1497, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 29989 tensor(18.1717, device='cuda:0')\n",
      "3 29989 tensor(18.1717, device='cuda:0')\n",
      "\n",
      "3 27434 tensor(17.9000, device='cuda:0')\n",
      "20\n",
      "222\n",
      "3 27434 tensor(18.9185, device='cuda:0')\n",
      "3 27434 tensor(17.6370, device='cuda:0')\n",
      "\n",
      "3 45867 tensor(17.1889, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 45867 tensor(17.4729, device='cuda:0')\n",
      "3 45867 tensor(18.0508, device='cuda:0')\n",
      "\n",
      "3 36139 tensor(17.0290, device='cuda:0')\n",
      "20\n",
      "242\n",
      "3 36139 tensor(17.9872, device='cuda:0')\n",
      "3 36139 tensor(17.2153, device='cuda:0')\n",
      "\n",
      "3 29489 tensor(17.5120, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 29489 tensor(17.7269, device='cuda:0')\n",
      "3 29489 tensor(17.1751, device='cuda:0')\n",
      "\n",
      "3 27443 tensor(16.9904, device='cuda:0')\n",
      "20\n",
      "200\n",
      "3 27443 tensor(17.1069, device='cuda:0')\n",
      "3 27443 tensor(17.8947, device='cuda:0')\n",
      "\n",
      "3 27955 tensor(17.8844, device='cuda:0')\n",
      "20\n",
      "216\n",
      "3 27955 tensor(20.0715, device='cuda:0')\n",
      "3 27955 tensor(18.0302, device='cuda:0')\n",
      "\n",
      "3 22838 tensor(17.3829, device='cuda:0')\n",
      "20\n",
      "152\n",
      "3 22838 tensor(17.0930, device='cuda:0')\n",
      "3 22838 tensor(18.0435, device='cuda:0')\n",
      "\n",
      "3 7993 tensor(17.4136, device='cuda:0')\n",
      "20\n",
      "174\n",
      "3 7993 tensor(17.5592, device='cuda:0')\n",
      "3 7993 tensor(17.2758, device='cuda:0')\n",
      "\n",
      "3 13114 tensor(17.3373, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 13114 tensor(18.1833, device='cuda:0')\n",
      "3 13114 tensor(18.1442, device='cuda:0')\n",
      "\n",
      "3 13629 tensor(17.2410, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 13629 tensor(17.6555, device='cuda:0')\n",
      "3 13629 tensor(17.2184, device='cuda:0')\n",
      "\n",
      "3 28991 tensor(17.4447, device='cuda:0')\n",
      "20\n",
      "200\n",
      "3 28991 tensor(18.0293, device='cuda:0')\n",
      "3 28991 tensor(18.1585, device='cuda:0')\n",
      "\n",
      "3 40771 tensor(17.1014, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 40771 tensor(17.0598, device='cuda:0')\n",
      "3 40771 tensor(17.4139, device='cuda:0')\n",
      "\n",
      "3 25413 tensor(16.8587, device='cuda:0')\n",
      "20\n",
      "230\n",
      "3 25413 tensor(16.9734, device='cuda:0')\n",
      "3 25413 tensor(17.5929, device='cuda:0')\n",
      "\n",
      "3 44870 tensor(17.3432, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 44870 tensor(17.8610, device='cuda:0')\n",
      "3 44870 tensor(17.7628, device='cuda:0')\n",
      "\n",
      "3 18247 tensor(17.0453, device='cuda:0')\n",
      "20\n",
      "230\n",
      "3 18247 tensor(16.9418, device='cuda:0')\n",
      "3 18247 tensor(16.7204, device='cuda:0')\n",
      "\n",
      "3 47944 tensor(17.0697, device='cuda:0')\n",
      "20\n",
      "208\n",
      "3 47944 tensor(17.5838, device='cuda:0')\n",
      "3 47944 tensor(17.4025, device='cuda:0')\n",
      "\n",
      "3 35657 tensor(17.1188, device='cuda:0')\n",
      "20\n",
      "192\n",
      "3 35657 tensor(17.6343, device='cuda:0')\n",
      "3 35657 tensor(17.8354, device='cuda:0')\n",
      "\n",
      "3 26953 tensor(17.5129, device='cuda:0')\n",
      "20\n",
      "196\n",
      "3 26953 tensor(17.9278, device='cuda:0')\n",
      "3 26953 tensor(17.2422, device='cuda:0')\n",
      "\n",
      "3 13651 tensor(17.3861, device='cuda:0')\n",
      "20\n",
      "226\n",
      "3 13651 tensor(17.4696, device='cuda:0')\n",
      "3 13651 tensor(18.4552, device='cuda:0')\n",
      "\n",
      "3 27991 tensor(17.1643, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 27991 tensor(17.7380, device='cuda:0')\n",
      "3 27991 tensor(18.0311, device='cuda:0')\n",
      "\n",
      "3 26456 tensor(17.1757, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 26456 tensor(17.5140, device='cuda:0')\n",
      "3 26456 tensor(17.5813, device='cuda:0')\n",
      "\n",
      "3 48990 tensor(17.0131, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 48990 tensor(16.5261, device='cuda:0')\n",
      "3 48990 tensor(17.8499, device='cuda:0')\n",
      "\n",
      "3 34655 tensor(17.2030, device='cuda:0')\n",
      "20\n",
      "190\n",
      "3 34655 tensor(16.8413, device='cuda:0')\n",
      "3 34655 tensor(18.5067, device='cuda:0')\n",
      "\n",
      "3 16225 tensor(17.7966, device='cuda:0')\n",
      "20\n",
      "132\n",
      "3 16225 tensor(18.5499, device='cuda:0')\n",
      "3 16225 tensor(18.2831, device='cuda:0')\n",
      "\n",
      "3 28518 tensor(17.5362, device='cuda:0')\n",
      "20\n",
      "148\n",
      "3 28518 tensor(18.2826, device='cuda:0')\n",
      "3 28518 tensor(18.0054, device='cuda:0')\n",
      "\n",
      "3 20839 tensor(17.1404, device='cuda:0')\n",
      "20\n",
      "192\n",
      "3 20839 tensor(16.9317, device='cuda:0')\n",
      "3 20839 tensor(17.3449, device='cuda:0')\n",
      "\n",
      "3 43367 tensor(17.3565, device='cuda:0')\n",
      "20\n",
      "256\n",
      "3 43367 tensor(17.8717, device='cuda:0')\n",
      "3 43367 tensor(17.6452, device='cuda:0')\n",
      "\n",
      "3 10092 tensor(16.9190, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 10092 tensor(16.5616, device='cuda:0')\n",
      "3 10092 tensor(18.2907, device='cuda:0')\n",
      "\n",
      "3 11116 tensor(16.8912, device='cuda:0')\n",
      "20\n",
      "154\n",
      "3 11116 tensor(17.7727, device='cuda:0')\n",
      "3 11116 tensor(17.1618, device='cuda:0')\n",
      "\n",
      "3 31086 tensor(16.6419, device='cuda:0')\n",
      "20\n",
      "226\n",
      "3 31086 tensor(17.0466, device='cuda:0')\n",
      "3 31086 tensor(17.0311, device='cuda:0')\n",
      "\n",
      "3 29040 tensor(17.1842, device='cuda:0')\n",
      "20\n",
      "180\n",
      "3 29040 tensor(17.7155, device='cuda:0')\n",
      "3 29040 tensor(17.1756, device='cuda:0')\n",
      "\n",
      "3 50033 tensor(17.3265, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 50033 tensor(18.1553, device='cuda:0')\n",
      "3 50033 tensor(17.6150, device='cuda:0')\n",
      "\n",
      "3 5490 tensor(16.8878, device='cuda:0')\n",
      "20\n",
      "196\n",
      "3 5490 tensor(17.0794, device='cuda:0')\n",
      "3 5490 tensor(18.0686, device='cuda:0')\n",
      "\n",
      "3 39795 tensor(17.3735, device='cuda:0')\n",
      "20\n",
      "176\n",
      "3 39795 tensor(17.7635, device='cuda:0')\n",
      "3 39795 tensor(17.3016, device='cuda:0')\n",
      "\n",
      "3 48505 tensor(17.0733, device='cuda:0')\n",
      "20\n",
      "166\n",
      "3 48505 tensor(16.6425, device='cuda:0')\n",
      "3 48505 tensor(17.9484, device='cuda:0')\n",
      "\n",
      "3 40316 tensor(17.3587, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 40316 tensor(17.2122, device='cuda:0')\n",
      "3 40316 tensor(17.0215, device='cuda:0')\n",
      "\n",
      "3 24958 tensor(16.9292, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 24958 tensor(17.4186, device='cuda:0')\n",
      "3 24958 tensor(17.0771, device='cuda:0')\n",
      "\n",
      "3 38783 tensor(17.6346, device='cuda:0')\n",
      "20\n",
      "164\n",
      "3 38783 tensor(18.1086, device='cuda:0')\n",
      "3 38783 tensor(18.1086, device='cuda:0')\n",
      "\n",
      "3 19838 tensor(18.2674, device='cuda:0')\n",
      "20\n",
      "216\n",
      "3 19838 tensor(18.6874, device='cuda:0')\n",
      "3 19838 tensor(18.7389, device='cuda:0')\n",
      "\n",
      "3 23425 tensor(17.3427, device='cuda:0')\n",
      "20\n",
      "172\n",
      "3 23425 tensor(17.9093, device='cuda:0')\n",
      "3 23425 tensor(17.7102, device='cuda:0')\n",
      "\n",
      "3 24962 tensor(17.2097, device='cuda:0')\n",
      "20\n",
      "172\n",
      "3 24962 tensor(17.6120, device='cuda:0')\n",
      "3 24962 tensor(17.9182, device='cuda:0')\n",
      "\n",
      "3 13187 tensor(16.8087, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 13187 tensor(16.8933, device='cuda:0')\n",
      "3 13187 tensor(16.9958, device='cuda:0')\n",
      "\n",
      "3 49028 tensor(17.1909, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 49028 tensor(17.3317, device='cuda:0')\n",
      "3 49028 tensor(17.9423, device='cuda:0')\n",
      "\n",
      "3 12167 tensor(16.8197, device='cuda:0')\n",
      "20\n",
      "218\n",
      "3 12167 tensor(17.0471, device='cuda:0')\n",
      "3 12167 tensor(17.5345, device='cuda:0')\n",
      "\n",
      "3 43406 tensor(16.8036, device='cuda:0')\n",
      "20\n",
      "178\n",
      "3 43406 tensor(16.5084, device='cuda:0')\n",
      "3 43406 tensor(17.9674, device='cuda:0')\n",
      "\n",
      "3 14737 tensor(16.5955, device='cuda:0')\n",
      "20\n",
      "218\n",
      "3 14737 tensor(17.7030, device='cuda:0')\n",
      "3 14737 tensor(17.3460, device='cuda:0')\n",
      "\n",
      "3 18322 tensor(16.9629, device='cuda:0')\n",
      "20\n",
      "152\n",
      "3 18322 tensor(17.4828, device='cuda:0')\n",
      "3 18322 tensor(17.2325, device='cuda:0')\n",
      "\n",
      "3 43921 tensor(17.2458, device='cuda:0')\n",
      "20\n",
      "236\n",
      "3 43921 tensor(17.7385, device='cuda:0')\n",
      "3 43921 tensor(18.3696, device='cuda:0')\n",
      "\n",
      "3 12694 tensor(16.6917, device='cuda:0')\n",
      "20\n",
      "224\n",
      "3 12694 tensor(17.7508, device='cuda:0')\n",
      "3 12694 tensor(16.6148, device='cuda:0')\n",
      "\n",
      "3 16286 tensor(17.5758, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 16286 tensor(18.1021, device='cuda:0')\n",
      "3 16286 tensor(17.6474, device='cuda:0')\n",
      "\n",
      "3 48545 tensor(17.2365, device='cuda:0')\n",
      "20\n",
      "190\n",
      "3 48545 tensor(17.6869, device='cuda:0')\n",
      "3 48545 tensor(17.1804, device='cuda:0')\n",
      "\n",
      "3 29092 tensor(17.0237, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 29092 tensor(17.8472, device='cuda:0')\n",
      "3 29092 tensor(16.0580, device='cuda:0')\n",
      "\n",
      "3 15273 tensor(16.8278, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 15273 tensor(16.1221, device='cuda:0')\n",
      "3 15273 tensor(16.0415, device='cuda:0')\n",
      "\n",
      "3 16809 tensor(17.6645, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 16809 tensor(17.9873, device='cuda:0')\n",
      "3 16809 tensor(18.7470, device='cuda:0')\n",
      "\n",
      "3 22455 tensor(17.6437, device='cuda:0')\n",
      "20\n",
      "128\n",
      "3 22455 tensor(18.1996, device='cuda:0')\n",
      "3 22455 tensor(17.7752, device='cuda:0')\n",
      "\n",
      "3 24504 tensor(16.9805, device='cuda:0')\n",
      "20\n",
      "190\n",
      "3 24504 tensor(17.3800, device='cuda:0')\n",
      "3 24504 tensor(16.9061, device='cuda:0')\n",
      "\n",
      "3 30140 tensor(17.1969, device='cuda:0')\n",
      "20\n",
      "210\n",
      "3 30140 tensor(17.4394, device='cuda:0')\n",
      "3 30140 tensor(17.9524, device='cuda:0')\n",
      "\n",
      "3 27581 tensor(17.3899, device='cuda:0')\n",
      "20\n",
      "180\n",
      "3 27581 tensor(18.3033, device='cuda:0')\n",
      "3 27581 tensor(17.5663, device='cuda:0')\n",
      "\n",
      "3 21438 tensor(17.4138, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 21438 tensor(17.3048, device='cuda:0')\n",
      "3 21438 tensor(17.5399, device='cuda:0')\n",
      "\n",
      "3 35262 tensor(17.7640, device='cuda:0')\n",
      "20\n",
      "166\n",
      "3 35262 tensor(17.9297, device='cuda:0')\n",
      "3 35262 tensor(17.7432, device='cuda:0')\n",
      "\n",
      "3 36292 tensor(17.0051, device='cuda:0')\n",
      "20\n",
      "196\n",
      "3 36292 tensor(17.4944, device='cuda:0')\n",
      "3 36292 tensor(17.3902, device='cuda:0')\n",
      "\n",
      "3 6086 tensor(16.7027, device='cuda:0')\n",
      "20\n",
      "166\n",
      "3 6086 tensor(16.3146, device='cuda:0')\n",
      "3 6086 tensor(16.2940, device='cuda:0')\n",
      "\n",
      "3 21960 tensor(17.2946, device='cuda:0')\n",
      "20\n",
      "174\n",
      "3 21960 tensor(17.6588, device='cuda:0')\n",
      "3 21960 tensor(17.9002, device='cuda:0')\n",
      "\n",
      "3 20428 tensor(16.8031, device='cuda:0')\n",
      "20\n",
      "234\n",
      "3 20428 tensor(17.6147, device='cuda:0')\n",
      "3 20428 tensor(17.5650, device='cuda:0')\n",
      "\n",
      "3 17361 tensor(18.0182, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 17361 tensor(19.6219, device='cuda:0')\n",
      "3 17361 tensor(17.5654, device='cuda:0')\n",
      "\n",
      "3 33747 tensor(17.6554, device='cuda:0')\n",
      "20\n",
      "144\n",
      "3 33747 tensor(18.3375, device='cuda:0')\n",
      "3 33747 tensor(18.4608, device='cuda:0')\n",
      "\n",
      "3 2516 tensor(16.2886, device='cuda:0')\n",
      "20\n",
      "246\n",
      "3 2516 tensor(16.5139, device='cuda:0')\n",
      "3 2516 tensor(16.5335, device='cuda:0')\n",
      "\n",
      "3 13268 tensor(17.4504, device='cuda:0')\n",
      "20\n",
      "432\n",
      "3 13268 tensor(17.5236, device='cuda:0')\n",
      "3 13268 tensor(17.8045, device='cuda:0')\n",
      "\n",
      "3 45014 tensor(17.5379, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 45014 tensor(18.3516, device='cuda:0')\n",
      "3 45014 tensor(18.6247, device='cuda:0')\n",
      "\n",
      "3 25556 tensor(17.4650, device='cuda:0')\n",
      "20\n",
      "214\n",
      "3 25556 tensor(18.4529, device='cuda:0')\n",
      "3 25556 tensor(17.9245, device='cuda:0')\n",
      "\n",
      "3 33240 tensor(17.6620, device='cuda:0')\n",
      "20\n",
      "200\n",
      "3 33240 tensor(17.6144, device='cuda:0')\n",
      "3 33240 tensor(19.1741, device='cuda:0')\n",
      "\n",
      "3 36312 tensor(17.3838, device='cuda:0')\n",
      "20\n",
      "234\n",
      "3 36312 tensor(17.0763, device='cuda:0')\n",
      "3 36312 tensor(17.7958, device='cuda:0')\n",
      "\n",
      "3 16863 tensor(17.8759, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 16863 tensor(18.4257, device='cuda:0')\n",
      "3 16863 tensor(18.0466, device='cuda:0')\n",
      "\n",
      "3 28642 tensor(16.9590, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 28642 tensor(16.7262, device='cuda:0')\n",
      "3 28642 tensor(17.4393, device='cuda:0')\n",
      "\n",
      "3 10213 tensor(17.6111, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 10213 tensor(18.1895, device='cuda:0')\n",
      "3 10213 tensor(17.7066, device='cuda:0')\n",
      "\n",
      "3 16358 tensor(17.0034, device='cuda:0')\n",
      "20\n",
      "222\n",
      "3 16358 tensor(17.6756, device='cuda:0')\n",
      "3 16358 tensor(16.9280, device='cuda:0')\n",
      "\n",
      "3 25062 tensor(16.9434, device='cuda:0')\n",
      "20\n",
      "164\n",
      "3 25062 tensor(17.1917, device='cuda:0')\n",
      "3 25062 tensor(17.3588, device='cuda:0')\n",
      "\n",
      "3 23528 tensor(18.4194, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 23528 tensor(20.4810, device='cuda:0')\n",
      "3 23528 tensor(18.3467, device='cuda:0')\n",
      "\n",
      "3 35307 tensor(17.3344, device='cuda:0')\n",
      "20\n",
      "238\n",
      "3 35307 tensor(17.5295, device='cuda:0')\n",
      "3 35307 tensor(17.2576, device='cuda:0')\n",
      "\n",
      "3 19436 tensor(16.7108, device='cuda:0')\n",
      "20\n",
      "162\n",
      "3 19436 tensor(17.6525, device='cuda:0')\n",
      "3 19436 tensor(16.4212, device='cuda:0')\n",
      "\n",
      "3 25579 tensor(17.8147, device='cuda:0')\n",
      "20\n",
      "224\n",
      "3 25579 tensor(18.6637, device='cuda:0')\n",
      "3 25579 tensor(18.3329, device='cuda:0')\n",
      "\n",
      "3 15859 tensor(17.4743, device='cuda:0')\n",
      "20\n",
      "208\n",
      "3 15859 tensor(17.8919, device='cuda:0')\n",
      "3 15859 tensor(17.7421, device='cuda:0')\n",
      "\n",
      "3 38900 tensor(17.3649, device='cuda:0')\n",
      "20\n",
      "130\n",
      "3 38900 tensor(17.8627, device='cuda:0')\n",
      "3 38900 tensor(17.6117, device='cuda:0')\n",
      "\n",
      "3 7670 tensor(16.8521, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 7670 tensor(16.7230, device='cuda:0')\n",
      "3 7670 tensor(17.5212, device='cuda:0')\n",
      "\n",
      "3 8698 tensor(17.3556, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 8698 tensor(17.5290, device='cuda:0')\n",
      "3 8698 tensor(17.5290, device='cuda:0')\n",
      "\n",
      "3 12284 tensor(17.0931, device='cuda:0')\n",
      "20\n",
      "174\n",
      "3 12284 tensor(17.4681, device='cuda:0')\n",
      "3 12284 tensor(17.3382, device='cuda:0')\n",
      "\n",
      "3 44542 tensor(17.1254, device='cuda:0')\n",
      "20\n",
      "214\n",
      "3 44542 tensor(17.6231, device='cuda:0')\n",
      "3 44542 tensor(17.3217, device='cuda:0')\n",
      "\n",
      "3 31231 tensor(17.0916, device='cuda:0')\n",
      "20\n",
      "184\n",
      "3 31231 tensor(17.1865, device='cuda:0')\n",
      "3 31231 tensor(16.9916, device='cuda:0')\n",
      "\n",
      "4 50178 tensor(16.9806, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 50178 tensor(17.4023, device='cuda:0')\n",
      "4 50178 tensor(17.4738, device='cuda:0')\n",
      "\n",
      "4 46600 tensor(17.1445, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 46600 tensor(18.0372, device='cuda:0')\n",
      "4 46600 tensor(16.9792, device='cuda:0')\n",
      "\n",
      "4 31755 tensor(17.5021, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 31755 tensor(18.4366, device='cuda:0')\n",
      "4 31755 tensor(17.7975, device='cuda:0')\n",
      "\n",
      "4 46604 tensor(16.9537, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 46604 tensor(17.6456, device='cuda:0')\n",
      "4 46604 tensor(16.8113, device='cuda:0')\n",
      "\n",
      "4 10765 tensor(16.5159, device='cuda:0')\n",
      "20\n",
      "246\n",
      "4 10765 tensor(17.8146, device='cuda:0')\n",
      "4 10765 tensor(17.3658, device='cuda:0')\n",
      "\n",
      "4 11276 tensor(17.2815, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 11276 tensor(17.5725, device='cuda:0')\n",
      "4 11276 tensor(18.4010, device='cuda:0')\n",
      "\n",
      "4 33811 tensor(16.9574, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 33811 tensor(17.2995, device='cuda:0')\n",
      "4 33811 tensor(17.3172, device='cuda:0')\n",
      "\n",
      "4 46612 tensor(17.1879, device='cuda:0')\n",
      "20\n",
      "238\n",
      "4 46612 tensor(17.9984, device='cuda:0')\n",
      "4 46612 tensor(17.2658, device='cuda:0')\n",
      "\n",
      "4 16916 tensor(17.0395, device='cuda:0')\n",
      "20\n",
      "232\n",
      "4 16916 tensor(18.3587, device='cuda:0')\n",
      "4 16916 tensor(17.4850, device='cuda:0')\n",
      "\n",
      "4 18966 tensor(17.0526, device='cuda:0')\n",
      "20\n",
      "224\n",
      "4 18966 tensor(17.1445, device='cuda:0')\n",
      "4 18966 tensor(17.2699, device='cuda:0')\n",
      "\n",
      "4 12824 tensor(16.2737, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 12824 tensor(16.1129, device='cuda:0')\n",
      "4 12824 tensor(17.4546, device='cuda:0')\n",
      "\n",
      "4 32794 tensor(16.5465, device='cuda:0')\n",
      "20\n",
      "232\n",
      "4 32794 tensor(16.9963, device='cuda:0')\n",
      "4 32794 tensor(17.3764, device='cuda:0')\n",
      "\n",
      "4 7195 tensor(16.5275, device='cuda:0')\n",
      "20\n",
      "182\n",
      "4 7195 tensor(17.0152, device='cuda:0')\n",
      "4 7195 tensor(17.1859, device='cuda:0')\n",
      "\n",
      "4 33821 tensor(16.8049, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 33821 tensor(17.9364, device='cuda:0')\n",
      "4 33821 tensor(16.3653, device='cuda:0')\n",
      "\n",
      "4 37921 tensor(17.0854, device='cuda:0')\n",
      "20\n",
      "206\n",
      "4 37921 tensor(17.0717, device='cuda:0')\n",
      "4 37921 tensor(17.3068, device='cuda:0')\n",
      "\n",
      "4 33313 tensor(17.0954, device='cuda:0')\n",
      "20\n",
      "230\n",
      "4 33313 tensor(18.0334, device='cuda:0')\n",
      "4 33313 tensor(17.4304, device='cuda:0')\n",
      "\n",
      "4 31270 tensor(16.4435, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 31270 tensor(16.8290, device='cuda:0')\n",
      "4 31270 tensor(16.8009, device='cuda:0')\n",
      "\n",
      "4 29222 tensor(16.5596, device='cuda:0')\n",
      "20\n",
      "148\n",
      "4 29222 tensor(17.6688, device='cuda:0')\n",
      "4 29222 tensor(17.1204, device='cuda:0')\n",
      "\n",
      "4 28712 tensor(16.7048, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 28712 tensor(17.3360, device='cuda:0')\n",
      "4 28712 tensor(17.3360, device='cuda:0')\n",
      "\n",
      "4 18985 tensor(16.4908, device='cuda:0')\n",
      "20\n",
      "222\n",
      "4 18985 tensor(17.7662, device='cuda:0')\n",
      "4 18985 tensor(17.7662, device='cuda:0')\n",
      "\n",
      "4 37930 tensor(16.9680, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 37930 tensor(17.2937, device='cuda:0')\n",
      "4 37930 tensor(16.5158, device='cuda:0')\n",
      "\n",
      "4 28200 tensor(16.4685, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 28200 tensor(16.6309, device='cuda:0')\n",
      "4 28200 tensor(17.2105, device='cuda:0')\n",
      "\n",
      "4 7727 tensor(16.8043, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 7727 tensor(17.4721, device='cuda:0')\n",
      "4 7727 tensor(17.3740, device='cuda:0')\n",
      "\n",
      "4 24112 tensor(16.8835, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 24112 tensor(16.5494, device='cuda:0')\n",
      "4 24112 tensor(17.1194, device='cuda:0')\n",
      "\n",
      "4 36400 tensor(16.4508, device='cuda:0')\n",
      "20\n",
      "224\n",
      "4 36400 tensor(16.4365, device='cuda:0')\n",
      "4 36400 tensor(16.6966, device='cuda:0')\n",
      "\n",
      "4 32817 tensor(17.0109, device='cuda:0')\n",
      "20\n",
      "204\n",
      "4 32817 tensor(17.6501, device='cuda:0')\n",
      "4 32817 tensor(16.6234, device='cuda:0')\n",
      "\n",
      "4 5171 tensor(16.6329, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 5171 tensor(17.2269, device='cuda:0')\n",
      "4 5171 tensor(17.2264, device='cuda:0')\n",
      "\n",
      "4 44085 tensor(17.0273, device='cuda:0')\n",
      "20\n",
      "204\n",
      "4 44085 tensor(17.2252, device='cuda:0')\n",
      "4 44085 tensor(17.2075, device='cuda:0')\n",
      "\n",
      "4 35382 tensor(16.9787, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 35382 tensor(16.8288, device='cuda:0')\n",
      "4 35382 tensor(17.0906, device='cuda:0')\n",
      "\n",
      "4 14912 tensor(16.7944, device='cuda:0')\n",
      "20\n",
      "156\n",
      "4 14912 tensor(16.6773, device='cuda:0')\n",
      "4 14912 tensor(16.3365, device='cuda:0')\n",
      "\n",
      "4 30274 tensor(16.1431, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 30274 tensor(17.0472, device='cuda:0')\n",
      "4 30274 tensor(17.1682, device='cuda:0')\n",
      "\n",
      "4 20554 tensor(16.7943, device='cuda:0')\n",
      "20\n",
      "160\n",
      "4 20554 tensor(17.4301, device='cuda:0')\n",
      "4 20554 tensor(16.5411, device='cuda:0')\n",
      "\n",
      "4 15435 tensor(16.8897, device='cuda:0')\n",
      "20\n",
      "156\n",
      "4 15435 tensor(16.7200, device='cuda:0')\n",
      "4 15435 tensor(16.3640, device='cuda:0')\n",
      "\n",
      "4 33357 tensor(16.8477, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 33357 tensor(17.4583, device='cuda:0')\n",
      "4 33357 tensor(17.4903, device='cuda:0')\n",
      "\n",
      "4 49231 tensor(17.5542, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 49231 tensor(18.1494, device='cuda:0')\n",
      "4 49231 tensor(17.6199, device='cuda:0')\n",
      "\n",
      "4 38994 tensor(17.0890, device='cuda:0')\n",
      "20\n",
      "202\n",
      "4 38994 tensor(16.9499, device='cuda:0')\n",
      "4 38994 tensor(17.5359, device='cuda:0')\n",
      "\n",
      "4 21587 tensor(16.8261, device='cuda:0')\n",
      "20\n",
      "216\n",
      "4 21587 tensor(17.0769, device='cuda:0')\n",
      "4 21587 tensor(17.6862, device='cuda:0')\n",
      "\n",
      "4 7252 tensor(16.2119, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 7252 tensor(17.0806, device='cuda:0')\n",
      "4 7252 tensor(16.9526, device='cuda:0')\n",
      "\n",
      "4 40537 tensor(16.9692, device='cuda:0')\n",
      "20\n",
      "176\n",
      "4 40537 tensor(17.7589, device='cuda:0')\n",
      "4 40537 tensor(17.7829, device='cuda:0')\n",
      "\n",
      "4 27738 tensor(17.0927, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 27738 tensor(17.2732, device='cuda:0')\n",
      "4 27738 tensor(17.0747, device='cuda:0')\n",
      "\n",
      "4 44123 tensor(16.8898, device='cuda:0')\n",
      "20\n",
      "158\n",
      "4 44123 tensor(17.2205, device='cuda:0')\n",
      "4 44123 tensor(17.9864, device='cuda:0')\n",
      "\n",
      "4 44124 tensor(17.1543, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 44124 tensor(17.9622, device='cuda:0')\n",
      "4 44124 tensor(17.0476, device='cuda:0')\n",
      "\n",
      "4 14943 tensor(17.2316, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 14943 tensor(17.8116, device='cuda:0')\n",
      "4 14943 tensor(17.9897, device='cuda:0')\n",
      "\n",
      "4 45664 tensor(17.0437, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 45664 tensor(17.4828, device='cuda:0')\n",
      "4 45664 tensor(17.7883, device='cuda:0')\n",
      "\n",
      "4 15458 tensor(16.9388, device='cuda:0')\n",
      "20\n",
      "240\n",
      "4 15458 tensor(17.5925, device='cuda:0')\n",
      "4 15458 tensor(16.9251, device='cuda:0')\n",
      "\n",
      "4 49765 tensor(16.4585, device='cuda:0')\n",
      "20\n",
      "214\n",
      "4 49765 tensor(17.2426, device='cuda:0')\n",
      "4 49765 tensor(17.2426, device='cuda:0')\n",
      "\n",
      "4 19046 tensor(16.5728, device='cuda:0')\n",
      "20\n",
      "228\n",
      "4 19046 tensor(16.4731, device='cuda:0')\n",
      "4 19046 tensor(16.7333, device='cuda:0')\n",
      "\n",
      "4 35944 tensor(16.7388, device='cuda:0')\n",
      "20\n",
      "230\n",
      "4 35944 tensor(17.5684, device='cuda:0')\n",
      "4 35944 tensor(16.4816, device='cuda:0')\n",
      "\n",
      "4 29804 tensor(17.1020, device='cuda:0')\n",
      "20\n",
      "158\n",
      "4 29804 tensor(17.4946, device='cuda:0')\n",
      "4 29804 tensor(17.3031, device='cuda:0')\n",
      "\n",
      "4 23662 tensor(16.8098, device='cuda:0')\n",
      "20\n",
      "166\n",
      "4 23662 tensor(16.8679, device='cuda:0')\n",
      "4 23662 tensor(17.1427, device='cuda:0')\n",
      "\n",
      "4 37497 tensor(16.5984, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 37497 tensor(16.8282, device='cuda:0')\n",
      "4 37497 tensor(17.1344, device='cuda:0')\n",
      "\n",
      "4 22138 tensor(16.8631, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 22138 tensor(16.9348, device='cuda:0')\n",
      "4 22138 tensor(16.9103, device='cuda:0')\n",
      "\n",
      "4 27773 tensor(17.2142, device='cuda:0')\n",
      "20\n",
      "258\n",
      "4 27773 tensor(18.1593, device='cuda:0')\n",
      "4 27773 tensor(16.6901, device='cuda:0')\n",
      "\n",
      "4 28798 tensor(16.9987, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 28798 tensor(17.8463, device='cuda:0')\n",
      "4 28798 tensor(17.9563, device='cuda:0')\n",
      "\n",
      "4 33407 tensor(17.2801, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 33407 tensor(18.4940, device='cuda:0')\n",
      "4 33407 tensor(17.3686, device='cuda:0')\n",
      "\n",
      "4 27264 tensor(17.0417, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 27264 tensor(16.9604, device='cuda:0')\n",
      "4 27264 tensor(17.3989, device='cuda:0')\n",
      "\n",
      "4 9857 tensor(16.9474, device='cuda:0')\n",
      "20\n",
      "208\n",
      "4 9857 tensor(17.6064, device='cuda:0')\n",
      "4 9857 tensor(16.6875, device='cuda:0')\n",
      "\n",
      "4 14468 tensor(16.6929, device='cuda:0')\n",
      "20\n",
      "134\n",
      "4 14468 tensor(16.4244, device='cuda:0')\n",
      "4 14468 tensor(17.6430, device='cuda:0')\n",
      "\n",
      "4 6277 tensor(16.6165, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 6277 tensor(17.3643, device='cuda:0')\n",
      "4 6277 tensor(17.2692, device='cuda:0')\n",
      "\n",
      "4 35972 tensor(16.9996, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 35972 tensor(17.9860, device='cuda:0')\n",
      "4 35972 tensor(17.0673, device='cuda:0')\n",
      "\n",
      "4 4744 tensor(16.3616, device='cuda:0')\n",
      "20\n",
      "212\n",
      "4 4744 tensor(16.6872, device='cuda:0')\n",
      "4 4744 tensor(16.6341, device='cuda:0')\n",
      "\n",
      "4 32905 tensor(16.0120, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 32905 tensor(17.0610, device='cuda:0')\n",
      "4 32905 tensor(16.4830, device='cuda:0')\n",
      "\n",
      "4 32393 tensor(16.8913, device='cuda:0')\n",
      "20\n",
      "222\n",
      "4 32393 tensor(17.0827, device='cuda:0')\n",
      "4 32393 tensor(16.6550, device='cuda:0')\n",
      "\n",
      "4 22671 tensor(17.0973, device='cuda:0')\n",
      "20\n",
      "196\n",
      "4 22671 tensor(17.2438, device='cuda:0')\n",
      "4 22671 tensor(18.0707, device='cuda:0')\n",
      "\n",
      "4 20628 tensor(16.5693, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 20628 tensor(18.0358, device='cuda:0')\n",
      "4 20628 tensor(17.1159, device='cuda:0')\n",
      "\n",
      "4 32920 tensor(17.1745, device='cuda:0')\n",
      "20\n",
      "348\n",
      "4 32920 tensor(17.2506, device='cuda:0')\n",
      "4 32920 tensor(17.7536, device='cuda:0')\n",
      "\n",
      "4 17560 tensor(16.7767, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 17560 tensor(16.5668, device='cuda:0')\n",
      "4 17560 tensor(17.8957, device='cuda:0')\n",
      "\n",
      "4 5119 tensor(16.6098, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 5119 tensor(16.6658, device='cuda:0')\n",
      "4 5119 tensor(18.1501, device='cuda:0')\n",
      "\n",
      "4 21661 tensor(17.1139, device='cuda:0')\n",
      "20\n",
      "210\n",
      "4 21661 tensor(17.6879, device='cuda:0')\n",
      "4 21661 tensor(17.1808, device='cuda:0')\n",
      "\n",
      "4 16543 tensor(16.8505, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 16543 tensor(15.5487, device='cuda:0')\n",
      "4 16543 tensor(16.9144, device='cuda:0')\n",
      "\n",
      "4 31903 tensor(16.7044, device='cuda:0')\n",
      "20\n",
      "230\n",
      "4 31903 tensor(16.1549, device='cuda:0')\n",
      "4 31903 tensor(17.6791, device='cuda:0')\n",
      "\n",
      "4 18089 tensor(16.5903, device='cuda:0')\n",
      "20\n",
      "154\n",
      "4 18089 tensor(16.4771, device='cuda:0')\n",
      "4 18089 tensor(16.9648, device='cuda:0')\n",
      "\n",
      "4 16553 tensor(16.8930, device='cuda:0')\n",
      "20\n",
      "190\n",
      "4 16553 tensor(17.3299, device='cuda:0')\n",
      "4 16553 tensor(16.8636, device='cuda:0')\n",
      "\n",
      "4 28331 tensor(16.6516, device='cuda:0')\n",
      "20\n",
      "216\n",
      "4 28331 tensor(17.3258, device='cuda:0')\n",
      "4 28331 tensor(17.3095, device='cuda:0')\n",
      "\n",
      "4 41131 tensor(17.1445, device='cuda:0')\n",
      "20\n",
      "196\n",
      "4 41131 tensor(16.7716, device='cuda:0')\n",
      "4 41131 tensor(17.1977, device='cuda:0')\n",
      "\n",
      "4 20145 tensor(16.4757, device='cuda:0')\n",
      "20\n",
      "138\n",
      "4 20145 tensor(16.4291, device='cuda:0')\n",
      "4 20145 tensor(17.3871, device='cuda:0')\n",
      "\n",
      "4 46262 tensor(16.8239, device='cuda:0')\n",
      "20\n",
      "214\n",
      "4 46262 tensor(17.2250, device='cuda:0')\n",
      "4 46262 tensor(16.8925, device='cuda:0')\n",
      "\n",
      "4 30397 tensor(17.2250, device='cuda:0')\n",
      "20\n",
      "226\n",
      "4 30397 tensor(17.8228, device='cuda:0')\n",
      "4 30397 tensor(18.1338, device='cuda:0')\n",
      "\n",
      "4 41151 tensor(16.5573, device='cuda:0')\n",
      "20\n",
      "230\n",
      "4 41151 tensor(15.8959, device='cuda:0')\n",
      "4 41151 tensor(17.2418, device='cuda:0')\n",
      "\n",
      "4 22723 tensor(16.9757, device='cuda:0')\n",
      "20\n",
      "236\n",
      "4 22723 tensor(16.7727, device='cuda:0')\n",
      "4 22723 tensor(16.9578, device='cuda:0')\n",
      "\n",
      "4 23239 tensor(16.9286, device='cuda:0')\n",
      "20\n",
      "190\n",
      "4 23239 tensor(17.0682, device='cuda:0')\n",
      "4 23239 tensor(16.7592, device='cuda:0')\n",
      "\n",
      "4 14538 tensor(16.7423, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 14538 tensor(16.9853, device='cuda:0')\n",
      "4 14538 tensor(17.2636, device='cuda:0')\n",
      "\n",
      "4 17100 tensor(16.7674, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 17100 tensor(16.5386, device='cuda:0')\n",
      "4 17100 tensor(16.9668, device='cuda:0')\n",
      "\n",
      "4 37073 tensor(16.7228, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 37073 tensor(16.5621, device='cuda:0')\n",
      "4 37073 tensor(18.0508, device='cuda:0')\n",
      "\n",
      "4 22739 tensor(17.1007, device='cuda:0')\n",
      "20\n",
      "206\n",
      "4 22739 tensor(17.1715, device='cuda:0')\n",
      "4 22739 tensor(16.9896, device='cuda:0')\n",
      "\n",
      "4 49365 tensor(16.6298, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 49365 tensor(17.0356, device='cuda:0')\n",
      "4 49365 tensor(16.8073, device='cuda:0')\n",
      "\n",
      "4 16598 tensor(16.6810, device='cuda:0')\n",
      "20\n",
      "156\n",
      "4 16598 tensor(16.9248, device='cuda:0')\n",
      "4 16598 tensor(17.0191, device='cuda:0')\n",
      "\n",
      "4 47831 tensor(16.6788, device='cuda:0')\n",
      "20\n",
      "234\n",
      "4 47831 tensor(17.0673, device='cuda:0')\n",
      "4 47831 tensor(16.6749, device='cuda:0')\n",
      "\n",
      "4 31959 tensor(16.8944, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 31959 tensor(18.0440, device='cuda:0')\n",
      "4 31959 tensor(18.0440, device='cuda:0')\n",
      "\n",
      "4 22234 tensor(16.5578, device='cuda:0')\n",
      "20\n",
      "212\n",
      "4 22234 tensor(16.4496, device='cuda:0')\n",
      "4 22234 tensor(17.5851, device='cuda:0')\n",
      "\n",
      "4 23259 tensor(16.8629, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 23259 tensor(17.6560, device='cuda:0')\n",
      "4 23259 tensor(17.5082, device='cuda:0')\n",
      "\n",
      "4 20189 tensor(17.0976, device='cuda:0')\n",
      "20\n",
      "248\n",
      "4 20189 tensor(17.2669, device='cuda:0')\n",
      "4 20189 tensor(17.2669, device='cuda:0')\n",
      "\n",
      "4 45790 tensor(16.7226, device='cuda:0')\n",
      "20\n",
      "210\n",
      "4 45790 tensor(17.2217, device='cuda:0')\n",
      "4 45790 tensor(16.8258, device='cuda:0')\n",
      "\n",
      "4 29927 tensor(16.8394, device='cuda:0')\n",
      "20\n",
      "248\n",
      "4 29927 tensor(17.5100, device='cuda:0')\n",
      "4 29927 tensor(17.1672, device='cuda:0')\n",
      "\n",
      "4 46312 tensor(16.5277, device='cuda:0')\n",
      "20\n",
      "202\n",
      "4 46312 tensor(16.0791, device='cuda:0')\n",
      "4 46312 tensor(16.9057, device='cuda:0')\n",
      "\n",
      "4 31465 tensor(17.5052, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 31465 tensor(18.6442, device='cuda:0')\n",
      "4 31465 tensor(17.4212, device='cuda:0')\n",
      "\n",
      "4 46831 tensor(16.8408, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 46831 tensor(17.1201, device='cuda:0')\n",
      "4 46831 tensor(18.2358, device='cuda:0')\n",
      "\n",
      "4 31472 tensor(16.7210, device='cuda:0')\n",
      "20\n",
      "232\n",
      "4 31472 tensor(16.6785, device='cuda:0')\n",
      "4 31472 tensor(16.9140, device='cuda:0')\n",
      "\n",
      "4 29936 tensor(16.5526, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 29936 tensor(16.8253, device='cuda:0')\n",
      "4 29936 tensor(17.2434, device='cuda:0')\n",
      "\n",
      "4 26355 tensor(16.7987, device='cuda:0')\n",
      "20\n",
      "262\n",
      "4 26355 tensor(17.1011, device='cuda:0')\n",
      "4 26355 tensor(17.5923, device='cuda:0')\n",
      "\n",
      "4 6393 tensor(16.5037, device='cuda:0')\n",
      "20\n",
      "204\n",
      "4 6393 tensor(16.2560, device='cuda:0')\n",
      "4 6393 tensor(16.9500, device='cuda:0')\n",
      "\n",
      "4 26876 tensor(16.4632, device='cuda:0')\n",
      "20\n",
      "214\n",
      "4 26876 tensor(16.9069, device='cuda:0')\n",
      "4 26876 tensor(17.5328, device='cuda:0')\n",
      "\n",
      "4 8444 tensor(16.3011, device='cuda:0')\n",
      "20\n",
      "182\n",
      "4 8444 tensor(17.0838, device='cuda:0')\n",
      "4 8444 tensor(17.0838, device='cuda:0')\n",
      "\n",
      "4 26878 tensor(17.3063, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 26878 tensor(18.1398, device='cuda:0')\n",
      "4 26878 tensor(18.4423, device='cuda:0')\n",
      "\n",
      "4 6911 tensor(16.5453, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 6911 tensor(17.0750, device='cuda:0')\n",
      "4 6911 tensor(17.0184, device='cuda:0')\n",
      "\n",
      "4 25856 tensor(16.6474, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 25856 tensor(17.9348, device='cuda:0')\n",
      "4 25856 tensor(17.2182, device='cuda:0')\n",
      "\n",
      "4 21249 tensor(17.1046, device='cuda:0')\n",
      "20\n",
      "202\n",
      "4 21249 tensor(17.8486, device='cuda:0')\n",
      "4 21249 tensor(16.9214, device='cuda:0')\n",
      "\n",
      "4 19717 tensor(16.4756, device='cuda:0')\n",
      "20\n",
      "148\n",
      "4 19717 tensor(16.6793, device='cuda:0')\n",
      "4 19717 tensor(16.6992, device='cuda:0')\n",
      "\n",
      "4 8966 tensor(16.7430, device='cuda:0')\n",
      "20\n",
      "160\n",
      "4 8966 tensor(17.3722, device='cuda:0')\n",
      "4 8966 tensor(17.4279, device='cuda:0')\n",
      "\n",
      "4 38150 tensor(17.0897, device='cuda:0')\n",
      "20\n",
      "196\n",
      "4 38150 tensor(16.6687, device='cuda:0')\n",
      "4 38150 tensor(16.6687, device='cuda:0')\n",
      "\n",
      "4 26888 tensor(16.9404, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 26888 tensor(17.6389, device='cuda:0')\n",
      "4 26888 tensor(17.2525, device='cuda:0')\n",
      "\n",
      "4 27917 tensor(17.1142, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 27917 tensor(17.8806, device='cuda:0')\n",
      "4 27917 tensor(17.8806, device='cuda:0')\n",
      "\n",
      "4 39184 tensor(17.0829, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 39184 tensor(17.5626, device='cuda:0')\n",
      "4 39184 tensor(16.9554, device='cuda:0')\n",
      "\n",
      "4 48401 tensor(16.3287, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 48401 tensor(17.9291, device='cuda:0')\n",
      "4 48401 tensor(16.3723, device='cuda:0')\n",
      "\n",
      "4 24336 tensor(16.7824, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 24336 tensor(17.0381, device='cuda:0')\n",
      "4 24336 tensor(17.3670, device='cuda:0')\n",
      "\n",
      "4 6416 tensor(16.7885, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 6416 tensor(16.5114, device='cuda:0')\n",
      "4 6416 tensor(17.0241, device='cuda:0')\n",
      "\n",
      "4 23316 tensor(16.7547, device='cuda:0')\n",
      "20\n",
      "156\n",
      "4 23316 tensor(16.8225, device='cuda:0')\n",
      "4 23316 tensor(17.1217, device='cuda:0')\n",
      "\n",
      "4 37144 tensor(16.7538, device='cuda:0')\n",
      "20\n",
      "176\n",
      "4 37144 tensor(17.2288, device='cuda:0')\n",
      "4 37144 tensor(16.5769, device='cuda:0')\n",
      "\n",
      "4 31513 tensor(16.5106, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 31513 tensor(17.5989, device='cuda:0')\n",
      "4 31513 tensor(16.1859, device='cuda:0')\n",
      "\n",
      "4 42266 tensor(16.3584, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 42266 tensor(17.5415, device='cuda:0')\n",
      "4 42266 tensor(16.4459, device='cuda:0')\n",
      "\n",
      "4 29989 tensor(16.5234, device='cuda:0')\n",
      "20\n",
      "136\n",
      "4 29989 tensor(16.7325, device='cuda:0')\n",
      "4 29989 tensor(16.2242, device='cuda:0')\n",
      "\n",
      "4 27434 tensor(17.5034, device='cuda:0')\n",
      "20\n",
      "160\n",
      "4 27434 tensor(17.6725, device='cuda:0')\n",
      "4 27434 tensor(17.9584, device='cuda:0')\n",
      "\n",
      "4 45867 tensor(17.0943, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 45867 tensor(17.2206, device='cuda:0')\n",
      "4 45867 tensor(17.2206, device='cuda:0')\n",
      "\n",
      "4 36139 tensor(16.9474, device='cuda:0')\n",
      "20\n",
      "234\n",
      "4 36139 tensor(17.7759, device='cuda:0')\n",
      "4 36139 tensor(17.1153, device='cuda:0')\n",
      "\n",
      "4 29489 tensor(17.1553, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 29489 tensor(17.2103, device='cuda:0')\n",
      "4 29489 tensor(16.6350, device='cuda:0')\n",
      "\n",
      "4 27443 tensor(16.6497, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 27443 tensor(17.4646, device='cuda:0')\n",
      "4 27443 tensor(17.4454, device='cuda:0')\n",
      "\n",
      "4 27955 tensor(16.9808, device='cuda:0')\n",
      "20\n",
      "176\n",
      "4 27955 tensor(16.9727, device='cuda:0')\n",
      "4 27955 tensor(17.4772, device='cuda:0')\n",
      "\n",
      "4 22838 tensor(16.8490, device='cuda:0')\n",
      "20\n",
      "202\n",
      "4 22838 tensor(16.8979, device='cuda:0')\n",
      "4 22838 tensor(17.2859, device='cuda:0')\n",
      "\n",
      "4 7993 tensor(16.8200, device='cuda:0')\n",
      "20\n",
      "220\n",
      "4 7993 tensor(17.5102, device='cuda:0')\n",
      "4 7993 tensor(17.4782, device='cuda:0')\n",
      "\n",
      "4 13114 tensor(16.8477, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 13114 tensor(18.1160, device='cuda:0')\n",
      "4 13114 tensor(18.4109, device='cuda:0')\n",
      "\n",
      "4 13629 tensor(16.6012, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 13629 tensor(17.2001, device='cuda:0')\n",
      "4 13629 tensor(17.2001, device='cuda:0')\n",
      "\n",
      "4 28991 tensor(16.3053, device='cuda:0')\n",
      "20\n",
      "182\n",
      "4 28991 tensor(16.5552, device='cuda:0')\n",
      "4 28991 tensor(17.3727, device='cuda:0')\n",
      "\n",
      "4 40771 tensor(17.1108, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 40771 tensor(17.0577, device='cuda:0')\n",
      "4 40771 tensor(17.7302, device='cuda:0')\n",
      "\n",
      "4 25413 tensor(16.7292, device='cuda:0')\n",
      "20\n",
      "214\n",
      "4 25413 tensor(17.8747, device='cuda:0')\n",
      "4 25413 tensor(17.0002, device='cuda:0')\n",
      "\n",
      "4 44870 tensor(16.9762, device='cuda:0')\n",
      "20\n",
      "208\n",
      "4 44870 tensor(16.6782, device='cuda:0')\n",
      "4 44870 tensor(17.8953, device='cuda:0')\n",
      "\n",
      "4 18247 tensor(16.7647, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 18247 tensor(17.3860, device='cuda:0')\n",
      "4 18247 tensor(17.3956, device='cuda:0')\n",
      "\n",
      "4 47944 tensor(16.7887, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 47944 tensor(17.3776, device='cuda:0')\n",
      "4 47944 tensor(18.0996, device='cuda:0')\n",
      "\n",
      "4 35657 tensor(16.8920, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 35657 tensor(17.1842, device='cuda:0')\n",
      "4 35657 tensor(17.9381, device='cuda:0')\n",
      "\n",
      "4 26953 tensor(17.0774, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 26953 tensor(17.6554, device='cuda:0')\n",
      "4 26953 tensor(18.1275, device='cuda:0')\n",
      "\n",
      "4 13651 tensor(16.5051, device='cuda:0')\n",
      "20\n",
      "158\n",
      "4 13651 tensor(16.6627, device='cuda:0')\n",
      "4 13651 tensor(17.6104, device='cuda:0')\n",
      "\n",
      "4 27991 tensor(16.7709, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 27991 tensor(17.5004, device='cuda:0')\n",
      "4 27991 tensor(17.0828, device='cuda:0')\n",
      "\n",
      "4 26456 tensor(16.6740, device='cuda:0')\n",
      "20\n",
      "166\n",
      "4 26456 tensor(17.4102, device='cuda:0')\n",
      "4 26456 tensor(16.9773, device='cuda:0')\n",
      "\n",
      "4 48990 tensor(16.9026, device='cuda:0')\n",
      "20\n",
      "144\n",
      "4 48990 tensor(17.6449, device='cuda:0')\n",
      "4 48990 tensor(17.6449, device='cuda:0')\n",
      "\n",
      "4 34655 tensor(16.8402, device='cuda:0')\n",
      "20\n",
      "214\n",
      "4 34655 tensor(17.4355, device='cuda:0')\n",
      "4 34655 tensor(16.7894, device='cuda:0')\n",
      "\n",
      "4 16225 tensor(16.7891, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 16225 tensor(18.2994, device='cuda:0')\n",
      "4 16225 tensor(18.2994, device='cuda:0')\n",
      "\n",
      "4 28518 tensor(17.3829, device='cuda:0')\n",
      "20\n",
      "144\n",
      "4 28518 tensor(17.9985, device='cuda:0')\n",
      "4 28518 tensor(17.8168, device='cuda:0')\n",
      "\n",
      "4 20839 tensor(16.4552, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 20839 tensor(17.5653, device='cuda:0')\n",
      "4 20839 tensor(15.9654, device='cuda:0')\n",
      "\n",
      "4 43367 tensor(17.0008, device='cuda:0')\n",
      "20\n",
      "206\n",
      "4 43367 tensor(17.4583, device='cuda:0')\n",
      "4 43367 tensor(17.6423, device='cuda:0')\n",
      "\n",
      "4 10092 tensor(16.4748, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 10092 tensor(15.6300, device='cuda:0')\n",
      "4 10092 tensor(17.6000, device='cuda:0')\n",
      "\n",
      "4 11116 tensor(16.4616, device='cuda:0')\n",
      "20\n",
      "216\n",
      "4 11116 tensor(17.3191, device='cuda:0')\n",
      "4 11116 tensor(16.5850, device='cuda:0')\n",
      "\n",
      "4 31086 tensor(16.6277, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 31086 tensor(17.2138, device='cuda:0')\n",
      "4 31086 tensor(16.0267, device='cuda:0')\n",
      "\n",
      "4 29040 tensor(17.3219, device='cuda:0')\n",
      "20\n",
      "252\n",
      "4 29040 tensor(17.2739, device='cuda:0')\n",
      "4 29040 tensor(17.5354, device='cuda:0')\n",
      "\n",
      "4 50033 tensor(16.7806, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 50033 tensor(17.9938, device='cuda:0')\n",
      "4 50033 tensor(16.5770, device='cuda:0')\n",
      "\n",
      "4 5490 tensor(16.5037, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 5490 tensor(16.8125, device='cuda:0')\n",
      "4 5490 tensor(16.0336, device='cuda:0')\n",
      "\n",
      "4 39795 tensor(16.7212, device='cuda:0')\n",
      "20\n",
      "204\n",
      "4 39795 tensor(16.7677, device='cuda:0')\n",
      "4 39795 tensor(16.7677, device='cuda:0')\n",
      "\n",
      "4 48505 tensor(16.5148, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 48505 tensor(17.2317, device='cuda:0')\n",
      "4 48505 tensor(17.0327, device='cuda:0')\n",
      "\n",
      "4 40316 tensor(16.4917, device='cuda:0')\n",
      "20\n",
      "208\n",
      "4 40316 tensor(16.7275, device='cuda:0')\n",
      "4 40316 tensor(17.5440, device='cuda:0')\n",
      "\n",
      "4 24958 tensor(16.6529, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 24958 tensor(17.4585, device='cuda:0')\n",
      "4 24958 tensor(16.6717, device='cuda:0')\n",
      "\n",
      "4 38783 tensor(16.6326, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 38783 tensor(17.2940, device='cuda:0')\n",
      "4 38783 tensor(16.9925, device='cuda:0')\n",
      "\n",
      "4 19838 tensor(17.0370, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 19838 tensor(17.1654, device='cuda:0')\n",
      "4 19838 tensor(16.9161, device='cuda:0')\n",
      "\n",
      "4 23425 tensor(16.7710, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 23425 tensor(17.3764, device='cuda:0')\n",
      "4 23425 tensor(17.3764, device='cuda:0')\n",
      "\n",
      "4 24962 tensor(16.7497, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 24962 tensor(17.2860, device='cuda:0')\n",
      "4 24962 tensor(17.2586, device='cuda:0')\n",
      "\n",
      "4 13187 tensor(16.7572, device='cuda:0')\n",
      "20\n",
      "228\n",
      "4 13187 tensor(18.1718, device='cuda:0')\n",
      "4 13187 tensor(18.1718, device='cuda:0')\n",
      "\n",
      "4 49028 tensor(16.7291, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 49028 tensor(17.2628, device='cuda:0')\n",
      "4 49028 tensor(16.9093, device='cuda:0')\n",
      "\n",
      "4 12167 tensor(16.3885, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 12167 tensor(17.5848, device='cuda:0')\n",
      "4 12167 tensor(16.5890, device='cuda:0')\n",
      "\n",
      "4 43406 tensor(16.6856, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 43406 tensor(17.2956, device='cuda:0')\n",
      "4 43406 tensor(17.2799, device='cuda:0')\n",
      "\n",
      "4 14737 tensor(16.7687, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 14737 tensor(17.6683, device='cuda:0')\n",
      "4 14737 tensor(17.4956, device='cuda:0')\n",
      "\n",
      "4 18322 tensor(16.3427, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 18322 tensor(16.8686, device='cuda:0')\n",
      "4 18322 tensor(16.7214, device='cuda:0')\n",
      "\n",
      "4 43921 tensor(16.5194, device='cuda:0')\n",
      "20\n",
      "130\n",
      "4 43921 tensor(17.9190, device='cuda:0')\n",
      "4 43921 tensor(16.3714, device='cuda:0')\n",
      "\n",
      "4 12694 tensor(16.4316, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 12694 tensor(16.7399, device='cuda:0')\n",
      "4 12694 tensor(17.2297, device='cuda:0')\n",
      "\n",
      "4 16286 tensor(16.7514, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 16286 tensor(17.7025, device='cuda:0')\n",
      "4 16286 tensor(17.3236, device='cuda:0')\n",
      "\n",
      "4 48545 tensor(17.2775, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 48545 tensor(17.5000, device='cuda:0')\n",
      "4 48545 tensor(17.7628, device='cuda:0')\n",
      "\n",
      "4 29092 tensor(16.5354, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 29092 tensor(16.4750, device='cuda:0')\n",
      "4 29092 tensor(16.9248, device='cuda:0')\n",
      "\n",
      "4 15273 tensor(16.5296, device='cuda:0')\n",
      "20\n",
      "152\n",
      "4 15273 tensor(16.6474, device='cuda:0')\n",
      "4 15273 tensor(17.1445, device='cuda:0')\n",
      "\n",
      "4 16809 tensor(17.1826, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 16809 tensor(16.6544, device='cuda:0')\n",
      "4 16809 tensor(17.5593, device='cuda:0')\n",
      "\n",
      "4 22455 tensor(17.0528, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 22455 tensor(18.5422, device='cuda:0')\n",
      "4 22455 tensor(17.4651, device='cuda:0')\n",
      "\n",
      "4 24504 tensor(16.8639, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 24504 tensor(17.6208, device='cuda:0')\n",
      "4 24504 tensor(16.9752, device='cuda:0')\n",
      "\n",
      "4 30140 tensor(16.8900, device='cuda:0')\n",
      "20\n",
      "236\n",
      "4 30140 tensor(18.2565, device='cuda:0')\n",
      "4 30140 tensor(16.7198, device='cuda:0')\n",
      "\n",
      "4 27581 tensor(16.8714, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 27581 tensor(17.7435, device='cuda:0')\n",
      "4 27581 tensor(16.6930, device='cuda:0')\n",
      "\n",
      "4 21438 tensor(16.6599, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 21438 tensor(17.0848, device='cuda:0')\n",
      "4 21438 tensor(17.0372, device='cuda:0')\n",
      "\n",
      "4 35262 tensor(17.3906, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 35262 tensor(17.4645, device='cuda:0')\n",
      "4 35262 tensor(17.9176, device='cuda:0')\n",
      "\n",
      "4 36292 tensor(16.5194, device='cuda:0')\n",
      "20\n",
      "190\n",
      "4 36292 tensor(17.0897, device='cuda:0')\n",
      "4 36292 tensor(17.0326, device='cuda:0')\n",
      "\n",
      "4 6086 tensor(16.4280, device='cuda:0')\n",
      "20\n",
      "216\n",
      "4 6086 tensor(17.8904, device='cuda:0')\n",
      "4 6086 tensor(16.5046, device='cuda:0')\n",
      "\n",
      "4 21960 tensor(17.2356, device='cuda:0')\n",
      "20\n",
      "130\n",
      "4 21960 tensor(16.8711, device='cuda:0')\n",
      "4 21960 tensor(17.2914, device='cuda:0')\n",
      "\n",
      "4 20428 tensor(16.5865, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 20428 tensor(17.1577, device='cuda:0')\n",
      "4 20428 tensor(17.3543, device='cuda:0')\n",
      "\n",
      "4 17361 tensor(17.1807, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 17361 tensor(17.5043, device='cuda:0')\n",
      "4 17361 tensor(18.4304, device='cuda:0')\n",
      "\n",
      "4 33747 tensor(17.4348, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 33747 tensor(18.0056, device='cuda:0')\n",
      "4 33747 tensor(17.4511, device='cuda:0')\n",
      "\n",
      "4 2516 tensor(16.3310, device='cuda:0')\n",
      "20\n",
      "166\n",
      "4 2516 tensor(17.5132, device='cuda:0')\n",
      "4 2516 tensor(17.1361, device='cuda:0')\n",
      "\n",
      "4 13268 tensor(16.9463, device='cuda:0')\n",
      "20\n",
      "342\n",
      "4 13268 tensor(17.5145, device='cuda:0')\n",
      "4 13268 tensor(16.3564, device='cuda:0')\n",
      "\n",
      "4 45014 tensor(17.0467, device='cuda:0')\n",
      "20\n",
      "204\n",
      "4 45014 tensor(17.6844, device='cuda:0')\n",
      "4 45014 tensor(17.8717, device='cuda:0')\n",
      "\n",
      "4 25556 tensor(17.3067, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 25556 tensor(17.9846, device='cuda:0')\n",
      "4 25556 tensor(16.2968, device='cuda:0')\n",
      "\n",
      "4 33240 tensor(16.9463, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 33240 tensor(17.2419, device='cuda:0')\n",
      "4 33240 tensor(16.7694, device='cuda:0')\n",
      "\n",
      "4 36312 tensor(16.8825, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 36312 tensor(17.2395, device='cuda:0')\n",
      "4 36312 tensor(17.2395, device='cuda:0')\n",
      "\n",
      "4 16863 tensor(16.8465, device='cuda:0')\n",
      "20\n",
      "196\n",
      "4 16863 tensor(16.9617, device='cuda:0')\n",
      "4 16863 tensor(16.9724, device='cuda:0')\n",
      "\n",
      "4 28642 tensor(16.8109, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 28642 tensor(16.5918, device='cuda:0')\n",
      "4 28642 tensor(16.4916, device='cuda:0')\n",
      "\n",
      "4 10213 tensor(16.9994, device='cuda:0')\n",
      "20\n",
      "196\n",
      "4 10213 tensor(17.3928, device='cuda:0')\n",
      "4 10213 tensor(17.2169, device='cuda:0')\n",
      "\n",
      "4 16358 tensor(16.4285, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 16358 tensor(16.1710, device='cuda:0')\n",
      "4 16358 tensor(16.7045, device='cuda:0')\n",
      "\n",
      "4 25062 tensor(16.8426, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 25062 tensor(17.4301, device='cuda:0')\n",
      "4 25062 tensor(17.2572, device='cuda:0')\n",
      "\n",
      "4 23528 tensor(17.3810, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 23528 tensor(17.8498, device='cuda:0')\n",
      "4 23528 tensor(18.0543, device='cuda:0')\n",
      "\n",
      "4 35307 tensor(16.7369, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 35307 tensor(17.3492, device='cuda:0')\n",
      "4 35307 tensor(16.9511, device='cuda:0')\n",
      "\n",
      "4 19436 tensor(16.5964, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 19436 tensor(17.7034, device='cuda:0')\n",
      "4 19436 tensor(16.9775, device='cuda:0')\n",
      "\n",
      "4 25579 tensor(17.1939, device='cuda:0')\n",
      "20\n",
      "228\n",
      "4 25579 tensor(17.9771, device='cuda:0')\n",
      "4 25579 tensor(18.0562, device='cuda:0')\n",
      "\n",
      "4 15859 tensor(17.0210, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 15859 tensor(17.4674, device='cuda:0')\n",
      "4 15859 tensor(17.4217, device='cuda:0')\n",
      "\n",
      "4 38900 tensor(16.8629, device='cuda:0')\n",
      "20\n",
      "242\n",
      "4 38900 tensor(17.2877, device='cuda:0')\n",
      "4 38900 tensor(17.3116, device='cuda:0')\n",
      "\n",
      "4 7670 tensor(16.2687, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 7670 tensor(16.8835, device='cuda:0')\n",
      "4 7670 tensor(16.4513, device='cuda:0')\n",
      "\n",
      "4 8698 tensor(16.6881, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 8698 tensor(17.1818, device='cuda:0')\n",
      "4 8698 tensor(17.8189, device='cuda:0')\n",
      "\n",
      "4 12284 tensor(16.8805, device='cuda:0')\n",
      "20\n",
      "212\n",
      "4 12284 tensor(16.8258, device='cuda:0')\n",
      "4 12284 tensor(17.5692, device='cuda:0')\n",
      "\n",
      "4 44542 tensor(16.4063, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 44542 tensor(17.2938, device='cuda:0')\n",
      "4 44542 tensor(17.0585, device='cuda:0')\n",
      "\n",
      "4 31231 tensor(16.7062, device='cuda:0')\n",
      "20\n",
      "218\n",
      "4 31231 tensor(16.8727, device='cuda:0')\n",
      "4 31231 tensor(16.9133, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "random.seed(27)\n",
    "for name_i in range(len(name_positions)):\n",
    "    for name_tok in list(name_averages[name_i].keys()):\n",
    "        print()\n",
    "        print(name_i, name_tok, torch.linalg.norm(name_averages[name_i][name_tok], ord=2))\n",
    "        print(len(name_choices[name_i][name_tok]))\n",
    "        print(counts[name_i][name_tok])\n",
    "        print(name_i, name_tok, torch.linalg.norm(random.choice(name_choices[name_i][name_tok]), ord=2))\n",
    "        print(name_i, name_tok, torch.linalg.norm(random.choice(name_choices[name_i][name_tok]), ord=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8cba178a-3688-4632-be14-0445f634da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "\n",
    "DO_DIFF = True\n",
    "\n",
    "model_kwargs = {\"fast_ssm\": True, \"fast_conv\": True}\n",
    "\n",
    "original_corrects = {}\n",
    "original_replaces = {}\n",
    "replace_corrects = {}\n",
    "replace_replaces = {}\n",
    "patched_corrects = {}\n",
    "patched_replaces = {}\n",
    "\n",
    "for position_1 in range(3):\n",
    "    for position_2 in range(5):\n",
    "        print(position_1, position_2)\n",
    "        original_correct = []\n",
    "        original_replace = []\n",
    "        replace_correct = []\n",
    "        replace_replace = []\n",
    "        patched_correct = []\n",
    "        patched_replace = []\n",
    "\n",
    "        original_corrects[(position_1, position_2)] = original_correct\n",
    "        original_replaces[(position_1, position_2)] = original_replace\n",
    "        replace_corrects[(position_1, position_2)] = replace_correct\n",
    "        replace_replaces[(position_1, position_2)] = replace_replace\n",
    "        patched_corrects[(position_1, position_2)] = patched_correct\n",
    "        patched_replaces[(position_1, position_2)] = patched_replace\n",
    "\n",
    "        batched_inputs = []\n",
    "        batched_corrupted_inputs = []\n",
    "        num_found = 0\n",
    "        hooks = []\n",
    "        corrupted_hooks = []\n",
    "        last_token_positions = []\n",
    "        replace_toks = []\n",
    "        answer_toks = []\n",
    "        batch_i = 0\n",
    "        while True:\n",
    "            data_i = random.choice(list(range(data.data.size()[0])))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i]\n",
    "            corrupted_tokens = data.data[patched_i]\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            \n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                replace_vec,\n",
    "                replace_add_vec,\n",
    "                batch_i,\n",
    "            ):\n",
    "                if not replace_vec is None:\n",
    "                    x[batch_i, position] = replace_vec\n",
    "                if not replace_add_vec is None:\n",
    "                    x[batch_i, position] += replace_add_vec\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(name_positions)):\n",
    "                position = name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                    break\n",
    "                \n",
    "                name_i = position_2\n",
    "                replace_vec = random.choice(name_choices[name_i][replace_tok])\n",
    "                # two ways to do it\n",
    "                # diff(name) = avg - name\n",
    "                # if we add this it should \"erase\" name\n",
    "                # if we subtract this it should \"add\" name\n",
    "                # so we can do\n",
    "                # replace_add_vec = diff(answer) - diff(replace)\n",
    "                #diff_answer = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][answer_tok]\n",
    "                #diff_replace = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][replace_tok]\n",
    "                #replace_add_vec = diff_answer - diff_replace\n",
    "                # this is (avg-a) - (avg-r) = r-a\n",
    "                # in other words the average doesn't matter for this\n",
    "                # and it's just subtract avg for a and add average for b\n",
    "                replace_add_vec = name_averages[name_i][replace_tok] - name_averages[name_i][answer_tok]\n",
    "                # then we do\n",
    "                # replace_vec\n",
    "                # we have x\n",
    "                # we want y\n",
    "                # we can do\n",
    "                # x-y\n",
    "                # and apply it to y\n",
    "                #replace_diff = name_averages[name_i][TOTAL_AVG_NAME]\n",
    "        \n",
    "                if DO_DIFF:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            batched_inputs.append(data_tokens.view(1, -1))\n",
    "            #logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            batched_corrupted_inputs.append(corrupted_tokens.view(1, -1))\n",
    "            for name_i, position in answer_positions:\n",
    "                name_i = position_2\n",
    "                replace_vec = name_averages[name_i][answer_tok]\n",
    "                replace_add_vec = name_averages[name_i][answer_tok] - name_averages[name_i][replace_tok]            \n",
    "                if DO_DIFF:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "            last_token_positions.append(last_token_pos)\n",
    "            replace_toks.append(replace_tok)\n",
    "            answer_toks.append(answer_tok)\n",
    "\n",
    "            \n",
    "            batch_i += 1\n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 100:\n",
    "                break\n",
    "\n",
    "        batched_inputs = torch.cat(batched_inputs, dim=0)\n",
    "        batched_corrupted_inputs = torch.cat(batched_corrupted_inputs, dim=0)\n",
    "        \n",
    "        logits_modified = model.run_with_hooks(batched_inputs, fwd_hooks=hooks, **model_kwargs)\n",
    "        #print(logits_modified.size())\n",
    "        #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "        #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "        for i in range(batched_inputs.size()[0]):\n",
    "            replace_correct.append(logits_modified[i,last_token_positions[i],answer_toks[i]].item())\n",
    "            replace_replace.append(logits_modified[i,last_token_positions[i],replace_toks[i]].item())        \n",
    "        del logits_modified\n",
    "        logits_modified_corrupted = model.run_with_hooks(batched_corrupted_inputs, fwd_hooks=corrupted_hooks, **model_kwargs)\n",
    "        for i in range(batched_inputs.size()[0]):\n",
    "            replace_correct.append(logits_modified_corrupted[i,last_token_positions[i],replace_toks[i]].item())\n",
    "            replace_replace.append(logits_modified_corrupted[i,last_token_positions[i],answer_toks[i]].item())\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de9db7-907d-41d4-a4c3-1814720177d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a963471-2615-44aa-8be8-64f3e274530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_correct_matrix = torch.zeros([3,5])\n",
    "\n",
    "for pos1 in range(3):\n",
    "    for pos2 in range(5):\n",
    "        #original_diff = -torch.tensor(original_correct) + torch.tensor(original_replace)\n",
    "        replace_diff = -torch.tensor(replace_corrects[(pos1,pos2)]) + torch.tensor(replace_replaces[(pos1,pos2)])\n",
    "        #patched_diff = -torch.tensor(patched_correct) + torch.tensor(patched_replace)\n",
    "        \n",
    "        #print(f'original min diff {torch.min(original_diff)} max diff {torch.max(original_diff)} avg diff {torch.mean(original_diff)}')\n",
    "        #print(f'replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "        #print(f'patch min diff {torch.min(patched_diff)} max diff {torch.max(patched_diff)} avg diff {torch.mean(patched_diff)}')\n",
    "\n",
    "        n_correct_matrix[pos1, pos2] = torch.sum(replace_diff > 0)/replace_diff.size()[0]\n",
    "        #print(f'original n correct {torch.sum(original_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'replace n correct {torch.sum(replace_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'patch n correct {torch.sum(patched_diff < 0)} / {original_diff.size()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8637d98c-498d-4ad2-bd9f-1f23265ab475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "y": [
          0,
          1,
          2
         ],
         "yaxis": "y",
         "z": [
          [
           0.9851484894752502,
           0.9851484894752502,
           0.9851484894752502,
           0.6485148668289185,
           0.5544554591178894
          ],
          [
           0.9801980257034302,
           0.9950494766235352,
           0.9653465151786804,
           0.7079207897186279,
           0.6089109182357788
          ],
          [
           1,
           1,
           0.9900990128517151,
           0.9108911156654358,
           0.7722772359848022
          ]
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "replacing with subtract and add average"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.21209213051823417,
          0.7879078694817658
         ],
         "range": [
          -0.5,
          4.5
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          2.5,
          -0.5
         ],
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"e55473c8-4e4c-42a8-81c7-7ac8ab8b37f5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e55473c8-4e4c-42a8-81c7-7ac8ab8b37f5\")) {                    Plotly.newPlot(                        \"e55473c8-4e4c-42a8-81c7-7ac8ab8b37f5\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"y\":[0,1,2],\"z\":[[0.9851484894752502,0.9851484894752502,0.9851484894752502,0.6485148668289185,0.5544554591178894],[0.9801980257034302,0.9950494766235352,0.9653465151786804,0.7079207897186279,0.6089109182357788],[1.0,1.0,0.9900990128517151,0.9108911156654358,0.7722772359848022]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"title\":{\"text\":\"replacing with subtract and add average\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e55473c8-4e4c-42a8-81c7-7ac8ab8b37f5');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# modified from neel nanda's examples\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", font_size=None, show=True, color_continuous_midpoint=0.0, fix_size=False, **kwargs):\n",
    "    import plotly.express as px\n",
    "    import transformer_lens.utils as utils\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=color_continuous_midpoint, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show()\n",
    "\n",
    "imshow(n_correct_matrix, color_continuous_midpoint=None, y=[0,1,2], title='replacing with subtract and add average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c750123a-7369-4ef9-a872-2855db55a66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f4f0aed0014fae9fe1269cb29ce27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "\n",
    "DO_DIFF = True\n",
    "\n",
    "model_kwargs = {\"fast_ssm\": True, \"fast_conv\": True}\n",
    "\n",
    "original_corrects = {}\n",
    "original_replaces = {}\n",
    "replace_corrects = {}\n",
    "replace_replaces = {}\n",
    "patched_corrects = {}\n",
    "patched_replaces = {}\n",
    "import itertools\n",
    "name_toks = sorted(list(name_tokens))[:50]\n",
    "\n",
    "for position_1, name_tok_1, name_tok_2 in tqdm(list(itertools.product(*[range(1), name_toks, name_toks]))):\n",
    "        original_correct = []\n",
    "        original_replace = []\n",
    "        replace_correct = []\n",
    "        replace_replace = []\n",
    "        patched_correct = []\n",
    "        patched_replace = []\n",
    "         \n",
    "        key = (position_1, name_tok_1, name_tok_2)\n",
    "        original_corrects[key] = original_correct\n",
    "        original_replaces[key] = original_replace\n",
    "        replace_corrects[key] = replace_correct\n",
    "        replace_replaces[key] = replace_replace\n",
    "        patched_corrects[key] = patched_correct\n",
    "        patched_replaces[key] = patched_replace\n",
    "\n",
    "\n",
    "        batched_inputs = []\n",
    "        batched_corrupted_inputs = []\n",
    "        num_found = 0\n",
    "        hooks = []\n",
    "        corrupted_hooks = []\n",
    "        last_token_positions = []\n",
    "        replace_toks = []\n",
    "        answer_toks = []\n",
    "        batch_i = 0\n",
    "        while True:\n",
    "            data_i = random.choice(list(range(data.data.size()[0])))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i].clone()\n",
    "            corrupted_tokens = data.data[patched_i].clone()\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            \n",
    "            all_names = set([x.item() for x in data.incorrect[data_i]]) | set([answer_tok]) | set([replace_tok])\n",
    "            if name_tok_1 in all_names or name_tok_2 in all_names:\n",
    "                continue\n",
    "\n",
    "        \n",
    "            \n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                replace_vec,\n",
    "                replace_add_vec,\n",
    "                batch_i,\n",
    "            ):\n",
    "                if not replace_vec is None:\n",
    "                    x[batch_i, position] = replace_vec\n",
    "                if not replace_add_vec is None:\n",
    "                    x[batch_i, position] += replace_add_vec\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(name_positions)):\n",
    "                position = name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    data_tokens[position] = name_tok_1\n",
    "                    corrupted_tokens[position] = name_tok_2\n",
    "                    answer_positions.append((name_i, position))\n",
    "\n",
    "            answer_tok = name_tok_1\n",
    "            replace_tok = name_tok_2\n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                    break\n",
    "                \n",
    "                name_i = position_1\n",
    "                replace_vec = random.choice(name_choices[name_i][replace_tok])\n",
    "                # two ways to do it\n",
    "                # diff(name) = avg - name\n",
    "                # if we add this it should \"erase\" name\n",
    "                # if we subtract this it should \"add\" name\n",
    "                # so we can do\n",
    "                # replace_add_vec = diff(answer) - diff(replace)\n",
    "                #diff_answer = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][answer_tok]\n",
    "                #diff_replace = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][replace_tok]\n",
    "                #replace_add_vec = diff_answer - diff_replace\n",
    "                # this is (avg-a) - (avg-r) = r-a\n",
    "                # in other words the average doesn't matter for this\n",
    "                # and it's just subtract avg for a and add average for b\n",
    "                replace_add_vec = name_averages[name_i][replace_tok] - name_averages[name_i][answer_tok]\n",
    "                # then we do\n",
    "                # replace_vec\n",
    "                # we have x\n",
    "                # we want y\n",
    "                # we can do\n",
    "                # x-y\n",
    "                # and apply it to y\n",
    "                #replace_diff = name_averages[name_i][TOTAL_AVG_NAME]\n",
    "        \n",
    "                if DO_DIFF:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "\n",
    "            batched_inputs.append(data_tokens.view(1, -1))\n",
    "            #logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            '''\n",
    "            batched_corrupted_inputs.append(corrupted_tokens.view(1, -1))\n",
    "            for name_i, position in answer_positions:\n",
    "                name_i = position_2\n",
    "                replace_vec = name_averages[name_i][answer_tok]\n",
    "                replace_add_vec = name_averages[name_i][answer_tok] - name_averages[name_i][replace_tok]            \n",
    "                if DO_DIFF:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "            '''\n",
    "            last_token_positions.append(last_token_pos)\n",
    "            replace_toks.append(replace_tok)\n",
    "            answer_toks.append(answer_tok)\n",
    "\n",
    "            \n",
    "            batch_i += 1\n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 20:\n",
    "                break\n",
    "\n",
    "        batched_inputs = torch.cat(batched_inputs, dim=0)\n",
    "        #batched_corrupted_inputs = torch.cat(batched_corrupted_inputs, dim=0)\n",
    "        \n",
    "        logits_modified = model.run_with_hooks(batched_inputs, fwd_hooks=hooks, **model_kwargs)\n",
    "        #print(logits_modified.size())\n",
    "        #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "        #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "        for i in range(batched_inputs.size()[0]):\n",
    "            replace_correct.append(logits_modified[i,last_token_positions[i],answer_toks[i]].item())\n",
    "            replace_replace.append(logits_modified[i,last_token_positions[i],replace_toks[i]].item())        \n",
    "        del logits_modified\n",
    "        #logits_modified_corrupted = model.run_with_hooks(batched_corrupted_inputs, fwd_hooks=corrupted_hooks, **model_kwargs)\n",
    "        #for i in range(batched_inputs.size()[0]):\n",
    "        #    replace_correct.append(logits_modified_corrupted[i,last_token_positions[i],replace_toks[i]].item())\n",
    "        #    replace_replace.append(logits_modified_corrupted[i,last_token_positions[i],answer_toks[i]].item())\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "831bcefc-f11c-4a43-a7cb-257ef74cc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_correct_matrix = torch.zeros([len(name_toks),len(name_toks)])\n",
    "\n",
    "for position_1, name_tok_1, name_tok_2 in list(itertools.product(*[range(1), name_toks, name_toks])):\n",
    "        \n",
    "        key = (position_1, name_tok_1, name_tok_2)\n",
    "        pos1 = name_toks.index(name_tok_1)\n",
    "        pos2 = name_toks.index(name_tok_2)\n",
    "        #original_diff = -torch.tensor(original_correct) + torch.tensor(original_replace)\n",
    "        replace_diff = -torch.tensor(replace_corrects[key]) + torch.tensor(replace_replaces[key])\n",
    "        #patched_diff = -torch.tensor(patched_correct) + torch.tensor(patched_replace)\n",
    "        \n",
    "        #print(f'original min diff {torch.min(original_diff)} max diff {torch.max(original_diff)} avg diff {torch.mean(original_diff)}')\n",
    "        #print(f'replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "        #print(f'patch min diff {torch.min(patched_diff)} max diff {torch.max(patched_diff)} avg diff {torch.mean(patched_diff)}')\n",
    "\n",
    "        n_correct_matrix[pos1, pos2] = torch.sum(replace_diff > 0)/replace_diff.size()[0]\n",
    "        if pos1 == pos2:\n",
    "            n_correct_matrix[pos1, pos2] = 1.0 # ez\n",
    "        #print(f'original n correct {torch.sum(original_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'replace n correct {torch.sum(replace_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'patch n correct {torch.sum(patched_diff < 0)} / {original_diff.size()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f6eca2c-0491-4557-b8fb-df3c099b1bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' John', ' Mark', ' David', ' Paul', ' James', ' George', ' Michael', ' Mary', ' Christian', ' Robert', ' Thomas', ' William', ' Jesus', ' Richard', ' Peter', ' Charles', ' Martin', ' Henry', ' Jackson', ' Joseph', ' Daniel', ' Francisco', ' Andrew', ' Taylor', ' Stephen', ' Eric', ' Elizabeth', ' Edward', ' Ryan', ' Adam']\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam"
         ],
         "xaxis": "x",
         "y": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam"
         ],
         "yaxis": "y",
         "z": [
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           0.9523809552192688,
           1,
           0.9047619104385376,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8571428656578064,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           0.9523809552192688,
           0.9523809552192688,
           0.9523809552192688,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           0.9523809552192688,
           0.9523809552192688,
           1,
           0.9523809552192688,
           0.9523809552192688,
           1,
           0.9047619104385376,
           1,
           1,
           0.8571428656578064,
           1,
           0.8571428656578064,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           0.8095238208770752,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           0.9047619104385376,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           0.9523809552192688,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8571428656578064,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8571428656578064,
           1,
           1,
           1,
           1,
           1,
           0.8571428656578064,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           0.9523809552192688,
           1,
           1,
           0.9523809552192688,
           0.9523809552192688,
           0.9523809552192688,
           0.9523809552192688,
           1,
           0.9523809552192688,
           1,
           1,
           0.9047619104385376,
           0.761904776096344,
           0.9523809552192688,
           1,
           1,
           0.9047619104385376,
           0.9523809552192688,
           0.8571428656578064,
           1,
           1,
           0.761904776096344,
           0.9523809552192688,
           1,
           0.9523809552192688,
           0.9047619104385376,
           1,
           1,
           0.761904776096344,
           0.9047619104385376
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1
          ],
          [
           0.9047619104385376,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           0.9047619104385376,
           1,
           0.7142857313156128,
           0.9523809552192688,
           1,
           0.9523809552192688,
           1,
           0.9523809552192688,
           0.9047619104385376,
           0.9523809552192688,
           0.9047619104385376,
           1,
           0.761904776096344,
           1,
           1,
           0.8095238208770752,
           0.8571428656578064,
           0.761904776096344,
           0.9047619104385376,
           0.8095238208770752,
           0.9523809552192688,
           0.9047619104385376,
           0.9523809552192688,
           0.9523809552192688
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           0.9047619104385376,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8571428656578064,
           1,
           1,
           0.8095238208770752,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           0.9523809552192688,
           0.9523809552192688,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           0.8571428656578064,
           1,
           0.9523809552192688,
           0.9523809552192688,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           0.9523809552192688,
           1,
           0.8571428656578064,
           1,
           0.9523809552192688,
           0.9523809552192688,
           0.9523809552192688,
           0.9523809552192688,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8571428656578064,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           0.9523809552192688,
           1,
           0.9523809552192688,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.761904776096344,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9523809552192688,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           0.9047619104385376,
           1,
           1,
           0.9523809552192688,
           1,
           1,
           1,
           1,
           1
          ]
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "font": {
         "color": "black",
         "size": 8
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "replacing with subtract and add average"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.3279158699808795,
          0.6720841300191205
         ],
         "range": [
          -0.5,
          29.5
         ],
         "scaleanchor": "y",
         "tickmode": "array",
         "ticktext": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam"
         ],
         "tickvals": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam"
         ],
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          29.5,
          -0.5
         ],
         "tickmode": "array",
         "ticktext": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam"
         ],
         "tickvals": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam"
         ],
         "type": "category"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"584899f3-100d-4855-9121-e0cec7a73afe\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"584899f3-100d-4855-9121-e0cec7a73afe\")) {                    Plotly.newPlot(                        \"584899f3-100d-4855-9121-e0cec7a73afe\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\"],\"y\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\"],\"z\":[[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,0.9047619104385376,1.0,1.0,1.0,1.0,0.9047619104385376,1.0,1.0,0.9523809552192688,1.0,0.9047619104385376,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8571428656578064,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,0.9523809552192688,0.9523809552192688,0.9523809552192688,1.0,0.9523809552192688,1.0,1.0,1.0,0.9523809552192688,0.9523809552192688,1.0,0.9523809552192688,0.9523809552192688,1.0,0.9047619104385376,1.0,1.0,0.8571428656578064,1.0,0.8571428656578064,1.0,1.0,1.0,1.0,0.9523809552192688,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9047619104385376,1.0,1.0,1.0,0.9047619104385376,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,0.8095238208770752,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,0.9047619104385376,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,0.9523809552192688,1.0,1.0,0.9523809552192688,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8571428656578064,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8571428656578064,1.0,1.0,1.0,1.0,1.0,0.8571428656578064,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[0.9523809552192688,1.0,1.0,0.9523809552192688,0.9523809552192688,0.9523809552192688,0.9523809552192688,1.0,0.9523809552192688,1.0,1.0,0.9047619104385376,0.761904776096344,0.9523809552192688,1.0,1.0,0.9047619104385376,0.9523809552192688,0.8571428656578064,1.0,1.0,0.761904776096344,0.9523809552192688,1.0,0.9523809552192688,0.9047619104385376,1.0,1.0,0.761904776096344,0.9047619104385376],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9047619104385376,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,0.9523809552192688,1.0],[0.9047619104385376,1.0,1.0,1.0,1.0,0.9523809552192688,0.9047619104385376,1.0,0.7142857313156128,0.9523809552192688,1.0,0.9523809552192688,1.0,0.9523809552192688,0.9047619104385376,0.9523809552192688,0.9047619104385376,1.0,0.761904776096344,1.0,1.0,0.8095238208770752,0.8571428656578064,0.761904776096344,0.9047619104385376,0.8095238208770752,0.9523809552192688,0.9047619104385376,0.9523809552192688,0.9523809552192688],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,0.9047619104385376,1.0,1.0,0.9047619104385376,1.0,1.0,1.0,1.0,1.0,1.0,0.8571428656578064,1.0,1.0,0.8095238208770752,1.0,0.9523809552192688,1.0,1.0,1.0,0.9523809552192688,0.9523809552192688,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9047619104385376,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9047619104385376,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,0.8571428656578064,1.0,0.9523809552192688,0.9523809552192688,1.0,0.9523809552192688,1.0,1.0,1.0,0.9047619104385376,1.0,1.0,0.9523809552192688,1.0,1.0,0.9523809552192688,1.0,0.8571428656578064,1.0,0.9523809552192688,0.9523809552192688,0.9523809552192688,0.9523809552192688,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8571428656578064,1.0,1.0,1.0,1.0,0.9523809552192688,0.9523809552192688,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,0.9047619104385376,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9047619104385376,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,0.9523809552192688,1.0,0.9523809552192688,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.761904776096344,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9523809552192688,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0,0.9047619104385376,1.0,1.0,0.9047619104385376,1.0,1.0,0.9523809552192688,1.0,1.0,1.0,1.0,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"tickmode\":\"array\",\"tickvals\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\"],\"ticktext\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\"]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"tickmode\":\"array\",\"tickvals\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\"],\"ticktext\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\"]},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"title\":{\"text\":\"replacing with subtract and add average\"},\"font\":{\"size\":8,\"color\":\"black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('584899f3-100d-4855-9121-e0cec7a73afe');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", font_size=None, show=True, color_continuous_midpoint=0.0, **kwargs):\n",
    "    import plotly.express as px\n",
    "    import transformer_lens.utils as utils\n",
    "    fig = px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=color_continuous_midpoint, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs)\n",
    "    if not font_size is None:\n",
    "        if 'x' in kwargs:\n",
    "            fig.update_layout(\n",
    "              xaxis = dict(\n",
    "                tickmode='array',\n",
    "                tickvals = kwargs['x'],\n",
    "                ticktext = kwargs['x'], \n",
    "                ),\n",
    "               font=dict(size=font_size, color=\"black\"))\n",
    "        if 'y' in kwargs:\n",
    "            fig.update_layout(\n",
    "              yaxis = dict(\n",
    "                tickmode='array',\n",
    "                tickvals = kwargs['y'],\n",
    "                ticktext = kwargs['y'], \n",
    "                ),\n",
    "               font=dict(size=font_size, color=\"black\"))\n",
    "    if show:\n",
    "        fig.show(renderer)\n",
    "    else:\n",
    "        return fig\n",
    "\n",
    "name_toks_strs = [model.to_str_tokens(torch.tensor([t]))[0] for t in name_toks]\n",
    "print(name_toks_strs)\n",
    "imshow(n_correct_matrix, color_continuous_midpoint=None, y=name_toks_strs, x=name_toks_strs, title='replacing with subtract and add average', font_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ba32f2c-2128-463f-9979-48b48b813d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 0 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 0 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 0 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 0 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 1 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 1 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 1 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 1 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 1 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 2 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 2 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 2 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 2 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 2 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 3 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 3 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 3 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 3 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 3 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 4 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 4 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 197\u001b[0m\n\u001b[1;32m    195\u001b[0m         logits_modified_corrupted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mrun_with_hooks(batched_corrupted_inputs, fwd_hooks\u001b[38;5;241m=\u001b[39mcorrupted_hooks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batched_inputs\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m--> 197\u001b[0m             replace_correct\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlogits_modified_corrupted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlast_token_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreplace_tok\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    198\u001b[0m             replace_replace\u001b[38;5;241m.\u001b[39mappend(logits_modified_corrupted[i,last_token_pos,answer_tok]\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar_chart\u001b[39m(data, x_labels, y_label, title, font_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "\n",
    "DO_DIFF = True\n",
    "\n",
    "model_kwargs = {\"fast_ssm\": True, \"fast_conv\": True}\n",
    "\n",
    "original_corrects = {}\n",
    "original_replaces = {}\n",
    "replace_corrects = {}\n",
    "replace_replaces = {}\n",
    "patched_corrects = {}\n",
    "patched_replaces = {}\n",
    "\n",
    "for position_1 in range(3):\n",
    "  for name_tok_1 in list(name_tokens):\n",
    "     for name_tok_2 in list(name_tokens):\n",
    "        print(position_1, name_tok_1, name_tok_2)\n",
    "        original_correct = []\n",
    "        original_replace = []\n",
    "        replace_correct = []\n",
    "        replace_replace = []\n",
    "        patched_correct = []\n",
    "        patched_replace = []\n",
    "\n",
    "        key = (position_1, name_tok_1, name_tok_2)\n",
    "        original_corrects[key] = original_correct\n",
    "        original_replaces[key] = original_replace\n",
    "        replace_corrects[key] = replace_correct\n",
    "        replace_replaces[key] = replace_replace\n",
    "        patched_corrects[key] = patched_correct\n",
    "        patched_replaces[key] = patched_replace\n",
    "\n",
    "        batched_inputs = []\n",
    "        batched_corrupted_inputs = []\n",
    "        num_found = 0\n",
    "        hooks = []\n",
    "        corrupted_hooks = []\n",
    "        last_token_positions = []\n",
    "        replace_toks = []\n",
    "        answer_toks = []\n",
    "        while True:\n",
    "            batch_i = 0\n",
    "            data_i = random.choice(list(range(data.data.size()[0])))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i].clone()\n",
    "            corrupted_tokens = data.data[patched_i].clone()\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "\n",
    "\n",
    "            all_names = set([x.item() for x in data.incorrect[data_i]]) | set([answer_tok]) | set([replace_tok])\n",
    "            if name_tok_1 in all_names or name_tok_2 in all_names:\n",
    "                continue\n",
    "\n",
    "            answer_tok = name_tok_1\n",
    "            replace_tok = name_tok_2\n",
    "            \n",
    "            \n",
    "            replace_toks.append(replace_tok)\n",
    "            answer_toks.append(answer_tok)\n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            last_token_positions.append(last_token_pos)\n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                replace_vec,\n",
    "                replace_add_vec,\n",
    "                batch_i,\n",
    "            ):\n",
    "                if not replace_vec is None:\n",
    "                    x[batch_i, position] = replace_vec\n",
    "                if not replace_add_vec is None:\n",
    "                    x[batch_i, position] += replace_add_vec\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(name_positions)):\n",
    "                position = name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "                    data_tokens[position] = name_tok_1\n",
    "                    corrupted_tokens[position] = name_tok_2\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                    break\n",
    "\n",
    "                \n",
    "                \n",
    "                name_i = position_2\n",
    "                replace_vec = random.choice(name_choices[name_i][replace_tok])\n",
    "                # two ways to do it\n",
    "                # diff(name) = avg - name\n",
    "                # if we add this it should \"erase\" name\n",
    "                # if we subtract this it should \"add\" name\n",
    "                # so we can do\n",
    "                # replace_add_vec = diff(answer) - diff(replace)\n",
    "                #diff_answer = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][answer_tok]\n",
    "                #diff_replace = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][replace_tok]\n",
    "                #replace_add_vec = diff_answer - diff_replace\n",
    "                # this is (avg-a) - (avg-r) = r-a\n",
    "                # in other words the average doesn't matter for this\n",
    "                # and it's just subtract avg for a and add average for b\n",
    "                replace_add_vec = random.choice(name_choices[name_i][replace_tok]) - name_averages[name_i][answer_tok]\n",
    "                # then we do\n",
    "                # replace_vec\n",
    "                # we have x\n",
    "                # we want y\n",
    "                # we can do\n",
    "                # x-y\n",
    "                # and apply it to y\n",
    "                #replace_diff = name_averages[name_i][TOTAL_AVG_NAME]\n",
    "        \n",
    "                if DO_DIFF:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            batched_inputs.append(data_tokens.view(1, -1))\n",
    "            #logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            batched_corrupted_inputs.append(corrupted_tokens.view(1, -1))\n",
    "            for name_i, position in answer_positions:\n",
    "                name_i = position_2\n",
    "                replace_vec = name_averages[name_i][answer_tok]\n",
    "                replace_add_vec = name_averages[name_i][answer_tok] - name_averages[name_i][replace_tok]            \n",
    "                if DO_DIFF:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "\n",
    "            \n",
    "    \n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 50:\n",
    "                break\n",
    "\n",
    "        batched_inputs = torch.cat(batched_inputs, dim=0)\n",
    "        batched_corrupted_inputs = torch.cat(batched_corrupted_inputs, dim=0)\n",
    "        \n",
    "        logits_modified = model.run_with_hooks(batched_inputs, fwd_hooks=hooks, **model_kwargs)\n",
    "        #print(logits_modified.size())\n",
    "        #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "        #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "        for i in range(batched_inputs.size()[0]):\n",
    "            replace_correct.append(logits_modified[i,last_token_positions[i],answer_toks[i]].item())\n",
    "            replace_replace.append(logits_modified[i,last_token_positions[i],replace_toks[i]].item())        \n",
    "        del logits_modified\n",
    "        logits_modified_corrupted = model.run_with_hooks(batched_corrupted_inputs, fwd_hooks=corrupted_hooks, **model_kwargs)\n",
    "        for i in range(batched_inputs.size()[0]):\n",
    "            replace_correct.append(logits_modified_corrupted[i,last_token_pos,replace_tok].item())\n",
    "            replace_replace.append(logits_modified_corrupted[i,last_token_pos,answer_tok].item())\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd58f192-1209-4e50-91ed-6fae7bc1b021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9901, 0.9901, 1.0000, 0.4752, 0.4752],\n",
       "        [1.0000, 1.0000, 0.9901, 0.6040, 0.5842],\n",
       "        [0.9802, 1.0000, 0.9901, 0.4455, 0.3861]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_correct_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "88a02596-53c9-4a4c-a6bf-512407cd28b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 120000/120000 [00:21<00:00, 5619.17it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 120000/120000 [00:21<00:00, 5499.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 400/400 [07:01<00:00,  1.05s/it]\n",
      "  1%|▌                                                                                  | 3/400 [00:04<08:54,  1.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 149\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#del X\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m#del Y\u001b[39;00m\n\u001b[1;32m    148\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m--> 149\u001b[0m vX, vY \u001b[38;5;241m=\u001b[39m \u001b[43mget_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvdata_name_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m pY \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mpredict(vX)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# we want cosine similarity to actual embedding vectors\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m#avg_sim = cosine_similarity(pY, vY).mean().item()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[89], line 133\u001b[0m, in \u001b[0;36mget_training_data\u001b[0;34m(dat, name_positions, batch_size)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_end\u001b[38;5;241m-\u001b[39mbatch_start):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m#print(ssm_inputs[batch_i, position].size())\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     position \u001b[38;5;241m=\u001b[39m positions[batch_i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# +1 because conv\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     bX \u001b[38;5;241m=\u001b[39m \u001b[43mget_linear_classification_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(bX)\n\u001b[1;32m    135\u001b[0m     Y\u001b[38;5;241m.\u001b[39mappend(name_tokens[batch_i]\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[89], line 102\u001b[0m, in \u001b[0;36mget_linear_classification_X\u001b[0;34m(activations, layer, batch_i, position_x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_linear_classification_X\u001b[39m(activations, layer, batch_i, position_x):\n\u001b[0;32m--> 102\u001b[0m     vec \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblocks.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.hook_ssm_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43mposition_x\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m#vec = vec / torch.linalg.norm(vec, ord=2) / divTerm\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vec\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "# we want to predict the name from the representation\n",
    "# there are two ways to do this:\n",
    "# 1. Predict the probability of a rep being a name (output logits for each name)\n",
    "# 2. Output the name embedding\n",
    "# we'll start with the second one because it is more general, if that doesn't work we can try the first one\n",
    "\n",
    "\n",
    "# we're basically doing a tuned lens sorta? idk\n",
    "# lets start with not batched\n",
    "\n",
    "# okay so say we are trying to output the name embedding\n",
    "# on layer i, that could mean:\n",
    "#    predict emb after it's projected into E space (which is after norm, but before conv)\n",
    "#    predict emb after conv\n",
    "#    predict emb after conv and silu\n",
    "#    predict emb from hidden state or some other internal rep\n",
    "# the point is that we train this linear map for some specific thing, then how well it performs suggests how well that thing encodes our data,\n",
    "# so we can try it for lots of intermediate stuff\n",
    "# some of the maps won't work, that's ok\n",
    "from mamba_lens.input_dependent_hooks import clean_hooks\n",
    "import torch\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from jaxtyping import Float\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "# this is useful because sometimes if you spam ctrl-c too many times some hooks will stay around\n",
    "clean_hooks(model)\n",
    "\n",
    "# make sure we have no overlap\n",
    "#joined_data = torch.cat([data.data, data.valid_data], dim=0)\n",
    "#torch.sort(joined_data, dim=0)\n",
    "#unique = torch.unique(joined_data, dim=0)\n",
    "#torch.manual_seed(27)\n",
    "# shuffle data\n",
    "#unique = unique[torch.randperm(unique.size()[0])]\n",
    "#B = unique.size()[0]//3\n",
    "# split into train valid and test\n",
    "#dataset, vdataset, tdataset = unique[:B], unique[B:2*B], unique[2*B:3*B]\n",
    "dataset = data.data\n",
    "vdataset = data.valid_data\n",
    "\n",
    "\n",
    "\n",
    "from acdc.data.ioi import good_names\n",
    "from collections import defaultdict\n",
    "name_tokens = set([model.to_single_token(\" \" + name) for name in good_names])\n",
    "\n",
    "\n",
    "name_tok_to_class = {}\n",
    "for i, tok in enumerate(sorted(list(name_tokens))):\n",
    "    name_tok_to_class[tok] = i\n",
    "\n",
    "def get_name_positions(dat):\n",
    "    name_positions = defaultdict(lambda: [])\n",
    "    for i in tqdm(list(range(dat.size()[0]))):\n",
    "        prompt_tokens = dat[i]\n",
    "        name_pos = 0\n",
    "        for i, tok in enumerate(prompt_tokens):\n",
    "            if tok.item() in name_tokens:\n",
    "                name_positions[name_pos].append(i)\n",
    "                name_pos += 1\n",
    "        if name_pos != 5: raise ValueError(f\"data point {model.to_str_tokens(data)} does not have 5 names\")\n",
    "    return name_positions\n",
    "\n",
    "data_name_positions, vdata_name_positions = get_name_positions(dataset), get_name_positions(vdataset)\n",
    "\n",
    "model_kwargs = {\n",
    "    \"fast_ssm\": True,\n",
    "    \"fast_conv\": True,\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 300\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "B,L = dataset.size()\n",
    "\n",
    "# for each position that varies, for each other position, fit a linear model\n",
    "\n",
    "global probing_dataset_X\n",
    "probing_dataset_X = []\n",
    "def dataset_gathering_hook(\n",
    "    x: Float[torch.Tensor, \"B L D\"],\n",
    "    hook: HookPoint,\n",
    "    position: int\n",
    "):\n",
    "    global probing_dataset_X\n",
    "    probing_dataset_X.append(x[:,position,:].cpu())\n",
    "    return x\n",
    "\n",
    "layer = 39\n",
    "\n",
    "linear_models = []\n",
    "E = model.cfg.E\n",
    "divTerm = float(math.sqrt(math.sqrt(float(E))*E))\n",
    "for name_i in range(5):\n",
    "    \n",
    "    # make dataset\n",
    "    \n",
    "    def get_linear_classification_X(activations, layer, batch_i, position_x):\n",
    "        vec = activations[f'blocks.{layer}.hook_ssm_input'][batch_i,position_x].view(-1)\n",
    "        #vec = vec / torch.linalg.norm(vec, ord=2) / divTerm\n",
    "        return vec.view(1,-1).detach().cpu().numpy()\n",
    "\n",
    "    def get_linear_classification_Y(labels):\n",
    "        B = labels.size()[0]\n",
    "        Y = np.zeros([B,len(name_tokens)])\n",
    "        #Y = model.embedding.weight[input_data[:,position_y]]\n",
    "        #return Y.detach().cpu().numpy()\n",
    "        Y[:] = -1 # predict a vector with -1 for incorrect class and 1 for correct class\n",
    "        for i in range(B):\n",
    "            value = labels[i].item()\n",
    "            Y[i,name_tok_to_class[value]] = 1\n",
    "        return Y#/math.sqrt(float(model.cfg.E))\n",
    "    \n",
    "    names_filter = [f'blocks.{layer}.hook_ssm_input']\n",
    "    \n",
    "    print(f\"collecting data...\")\n",
    "\n",
    "    def get_training_data(dat, name_positions, batch_size):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for batch_start in tqdm(list(range(0, dat.size()[0], batch_size))):\n",
    "            batch_end = min(batch_start + batch_size, dataset.size()[0])\n",
    "            data_batch = dat[batch_start:batch_end]\n",
    "            positions = torch.tensor(name_positions[name_i][batch_start:batch_end], device=model.cfg.device)\n",
    "            name_tokens = data_batch[torch.arange(batch_end-batch_start),positions]\n",
    "            logits, activations = model.run_with_cache(data_batch, names_filter=names_filter, **model_kwargs)\n",
    "            for batch_i in range(batch_end-batch_start):\n",
    "                #print(ssm_inputs[batch_i, position].size())\n",
    "                position = positions[batch_i] + 1 # +1 because conv\n",
    "                bX = get_linear_classification_X(activations=activations, layer=layer, batch_i=batch_i, position_x=position)\n",
    "                X.append(bX)\n",
    "                Y.append(name_tokens[batch_i].item())\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        Y = torch.tensor(Y)\n",
    "        Y = get_linear_classification_Y(labels=Y)\n",
    "        return X, Y\n",
    "\n",
    "    X, Y = get_training_data(dat=dataset, name_positions=data_name_positions, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X, Y)\n",
    "    linear_models.append(linear_model)\n",
    "    #del X\n",
    "    #del Y\n",
    "    torch.cuda.empty_cache()\n",
    "    vX, vY = get_training_data(dat=vdataset, name_positions=vdata_name_positions, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    pY = linear_model.predict(vX)\n",
    "    # we want cosine similarity to actual embedding vectors\n",
    "    #avg_sim = cosine_similarity(pY, vY).mean().item()\n",
    "    predicted_inds = np.argmax(pY, axis=1)\n",
    "    actual_inds = np.argmax(vY, axis=1)\n",
    "    acc = np.sum(predicted_inds==actual_inds)/float(predicted_inds.shape[0])\n",
    "    print(f\"position {name_i} layer {layer} acc {acc}\")\n",
    "    #outpaut_accuracies[position_i, layer, other_position] = avg_sim\n",
    "\n",
    "print(f\"these token positions vary their value: {positions_that_vary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e19606-dde4-49fc-840e-8cd3c035e560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_fit',\n",
       " '_fit_full',\n",
       " '_fit_svd_solver',\n",
       " '_fit_truncated',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_n_features_out',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sklearn_auto_wrap_output_keys',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " 'components_',\n",
       " 'copy',\n",
       " 'explained_variance_',\n",
       " 'explained_variance_ratio_',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_covariance',\n",
       " 'get_feature_names_out',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'get_precision',\n",
       " 'inverse_transform',\n",
       " 'iterated_power',\n",
       " 'mean_',\n",
       " 'n_components',\n",
       " 'n_components_',\n",
       " 'n_features_in_',\n",
       " 'n_oversamples',\n",
       " 'n_samples_',\n",
       " 'noise_variance_',\n",
       " 'power_iteration_normalizer',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'set_output',\n",
       " 'set_params',\n",
       " 'singular_values_',\n",
       " 'svd_solver',\n",
       " 'tol',\n",
       " 'transform',\n",
       " 'whiten']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "470a3314-2d8d-4337-9f01-28af455ab120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div term 304.4370214406966\n",
      "worst case mag 5.129492386402035e-10\n",
      "div term 304.4370214406966\n",
      "worst case mag 5.129643376733384e-10\n",
      "div term 304.4370214406966\n",
      "worst case mag 5.129641711398847e-10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "np.random.seed(27)\n",
    "\n",
    "class NameBasis(object):\n",
    "    def __init__(self, linear_model):\n",
    "        self.linear_model = linear_model\n",
    "        #       [C,E] [E,1] [C] [C]\n",
    "        # we have A  @  x  + b = y which is -1 for not name and 1 for name\n",
    "        # we want a V s.t.\n",
    "        #       [E,E] [E,1] [E]  [E]\n",
    "        #         V  @  x  + d =  y\n",
    "        # where V is invertible so\n",
    "        #        [E]   [E,E]    [E] [E]\n",
    "        #         x  = V^-1  @  (y - d)\n",
    "        # and\n",
    "        #          [C,E]    [E,1]     [C]\n",
    "        #        V[:C,:]  @   x   +  d[:C] =\n",
    "        #            A                 b\n",
    "        # the simplest way to do this is to set those extra bias terms to zero\n",
    "        # and those extra rows to normally distributed random values\n",
    "        # (with high pr the matrix should be invertible as long as first C aren't linearly dependent)\n",
    "        A = linear_model.coef_\n",
    "        b = linear_model.intercept_\n",
    "        C,E = A.shape\n",
    "        self.E = E\n",
    "        d = np.zeros([E])\n",
    "        d[:C] = b\n",
    "        V = np.random.randn(E,E)\n",
    "        V[:C] = A\n",
    "        # normalize rows to help it be more well behaved\n",
    "        # actually if they are normalized, the input is normalized so output values\n",
    "        # go from -1 to 1\n",
    "        # but that's too big, that means output norm is sqrt(E)\n",
    "        # what we want is norm of result is 1\n",
    "        # each row should be magnitude 1/sqrt(E)\n",
    "        # if input is also size 1/sqrt(E) then dot product gives us\n",
    "        # ((-1,1)*1/sqrt(E)*1/sqrt(E) which is (-1/E,1/E)\n",
    "        # which would give us sqrt(E*E^2) = E^3/2 which is not unit\n",
    "        # we have mag1 mag2 and dot product gives\n",
    "        # mag1*mag2\n",
    "        # and magnitude gives\n",
    "        # sqrt(E*mag1^2*mag2^2) = sqrt(E)*mag1*mag2\n",
    "        # we want this to be 1, so\n",
    "        # 1 = sqrt(E)*mag1*mag2\n",
    "        # assume mag=mag1=mag2\n",
    "        # 1 = sqrt(E)*mag^2\n",
    "        # 1/sqrt(E) = mag^2\n",
    "        # 1/sqrt(sqrt(E)) = mag\n",
    "        # lets double check that\n",
    "        # consider 111111 vector\n",
    "        # when we divide by 1/sqrt(sqrt(E)) we get lots of terms of \n",
    "        # we have two vectors each full of 1/sqrt(sqrt(E)) terms\n",
    "        # dot product will give lots of\n",
    "        # E*(1/sqrt(sqrt(E)))*(1/sqrt(sqrt(E)))\n",
    "        # E*1/sqrt(E)\n",
    "        # The magnitude of that is\n",
    "        # sqrt(E*(E^2/E)) = E\n",
    "        # not what we want\n",
    "        # okay so we have a matrix full of 1/v\n",
    "        # we dot product each row with another vector full of 1/v\n",
    "        # each entry in result is E*1/v^2\n",
    "        # So total magnitude is\n",
    "        # sqrt(E*(E^2/v^4))\n",
    "        # = sqrt(E)*E/v^2\n",
    "        # we want this to be 1\n",
    "        # thus\n",
    "        # 1 = sqrt(E)*E/v^2\n",
    "        # v^2 = sqrt(E)*E\n",
    "        # v = sqrt(sqrt(E)*E)\n",
    "        # lets double check that\n",
    "        # E*1/sqrt(sqrt(E)*E)*1/sqrt(sqrt(E)*E) is each term\n",
    "        # E*1/sqrt(E)*1/E\n",
    "        # 1/sqrt(E) is each term in the result\n",
    "        # sqrt(E*1/E) = sqrt(1) nice!\n",
    "        self.divTerm = float(math.sqrt(math.sqrt(float(E))*E))\n",
    "        print(\"div term\", self.divTerm)\n",
    "        for row in range(C,E):\n",
    "            vrow = V[row]\n",
    "            V[row] = vrow / np.linalg.norm(vrow, ord=2) / self.divTerm\n",
    "        V_inv = np.linalg.inv(V)\n",
    "        \n",
    "        self.d = torch.tensor(d, device=model.cfg.device, dtype=torch.double)\n",
    "        self.V = torch.tensor(V, device=model.cfg.device, dtype=torch.double)\n",
    "        self.V_inv = torch.tensor(V_inv, device=model.cfg.device, dtype=torch.double)\n",
    "        # test to make sure it's invertible\n",
    "        mags = []\n",
    "        for i in range(200):\n",
    "            x = torch.tensor(vX[i] / np.linalg.norm(vX[i], ord=2) / self.divTerm, device=model.cfg.device)\n",
    "            coords = self.map_to_coords(x)\n",
    "            backx = self.map_from_coords(coords)\n",
    "            mags.append(torch.linalg.norm(x-backx, dim=0, ord=2))\n",
    "        print(f\"worst case mag {torch.max(torch.tensor(mags))}\")\n",
    "    \n",
    "    def map_to_coords(self, vec):\n",
    "        vec = vec.double() / torch.linalg.norm(vec, ord=2) / self.divTerm\n",
    "        return ((self.V @ vec.view(self.E, 1))[:,0] + self.d)\n",
    "\n",
    "    def map_from_coords(self, coords):\n",
    "        return (self.V_inv @ (coords - self.d).view(self.E, 1))[:,0].float()        \n",
    "\n",
    "\n",
    "name_bases = [NameBasis(linear_model) for linear_model in linear_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db46432-3422-47fc-9698-78ccba2ddf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                               | 1/20 [00:19<06:17, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                           | 2/20 [00:39<05:51, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▌                                                                       | 3/20 [00:59<05:38, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 4/20 [01:19<05:21, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████                                                               | 5/20 [01:39<04:57, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▏                                                          | 6/20 [01:59<04:39, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████▍                                                      | 7/20 [02:18<04:15, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 8/20 [02:38<03:55, 19.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▊                                              | 9/20 [02:58<03:37, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 10/20 [03:18<03:19, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████▋                                     | 11/20 [03:38<02:59, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 12/20 [03:59<02:42, 20.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▉                             | 13/20 [04:20<02:23, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 14/20 [04:41<02:03, 20.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████▎                    | 15/20 [05:02<01:43, 20.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 16/20 [05:21<01:21, 20.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████████████████▌            | 17/20 [05:41<01:00, 20.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 18/20 [06:02<00:40, 20.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████████████████▊    | 19/20 [06:21<00:20, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fb5f8629f60>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dev/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 20/20 [06:42<00:00, 20.11s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "replace_corrects = []\n",
    "replace_replaces = []\n",
    "pca_sizes = []\n",
    "X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "print(X_proj[:,-1])\n",
    "\n",
    "for n_components in tqdm(list(range(1, 100, 5))):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_proj)\n",
    "    pca_sizes.append(n_components)\n",
    "    replace_correct = []\n",
    "    replace_replace = []\n",
    "    print(f\"layer {layer}\")\n",
    "    name_bases = [0]\n",
    "    for position_1, name_basis in enumerate(name_bases):\n",
    "        num_found = 0\n",
    "        while True:            \n",
    "            data_i = random.choice(list(range(10000)))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i]\n",
    "            corrupted_tokens = data.data[data_i+1]\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            \n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                answer_name_tok,\n",
    "                replace_name_tok,\n",
    "                name_basis\n",
    "            ):\n",
    "                B,L,E = x.size()\n",
    "                for b in range(B):\n",
    "                    vec = x[b,position]\n",
    "                    add_ones = np.concatenate([vec.detach().cpu().numpy(), np.array([1.0])], axis=0).reshape(1,-1)\n",
    "                    pcad = pca.transform(add_ones)\n",
    "                    x[b,position] = torch.tensor(pca.inverse_transform(pcad), device=model.cfg.device).reshape(-1)[:-1]\n",
    "                    '''\n",
    "                    coords = name_basis.map_to_coords(vec/torch.linalg.norm(vec, ord=2))\n",
    "                    C = len(name_tok_to_class)\n",
    "                    sorted = torch.argsort(coords[:C])\n",
    "                    print(coords[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"predict {maxi} {coords[maxi]}\")\n",
    "                    print(f\"answer {name_tok_to_class[answer_name_tok]} replace {name_tok_to_class[replace_name_tok]}\")\n",
    "                    coords[name_tok_to_class[answer_name_tok]] = -0.0692\n",
    "                    coords[name_tok_to_class[replace_name_tok]] = 0.0692\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"now predict {maxi} {coords[maxi]}\")\n",
    "                    patched_vec = name_basis.map_from_coords(coords)\n",
    "                    print(f\"orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    patched_veco = patched_vec / torch.linalg.norm(patched_vec, ord=2) * torch.linalg.norm(vec, ord=2)\n",
    "                    print(f\"now orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    coords2 = name_basis.map_to_coords(patched_vec)\n",
    "                    sorted = torch.argsort(coords2[:C])\n",
    "                    print(\"predict2\", coords2[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords2[:C])\n",
    "                    print(f\"predict2 {maxi} {coords2[maxi]}\")\n",
    "                    '''\n",
    "                    #x[b,position] = patched_veco\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(data_name_positions)):\n",
    "                position = data_name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            hooks = []\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                \n",
    "                hooks.append((\n",
    "                    f'blocks.{layer}.hook_ssm_input', \n",
    "                    partial(replace_hook,\n",
    "                            position=position+1,\n",
    "                            answer_name_tok=answer_tok,\n",
    "                            replace_name_tok=replace_tok,\n",
    "                            name_basis=name_basis\n",
    "                    )\n",
    "                ))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            \n",
    "            logits_modified = model.run_with_hooks(corrupted_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 100:\n",
    "                break\n",
    "        break\n",
    "    replace_corrects.append(replace_correct)\n",
    "    replace_replaces.append(replace_replace)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aae9b467-00ca-41a5-b319-5d67412fd57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca 1 replace min diff -6.385058403015137 max diff 3.271770477294922 avg diff -1.354062795639038\n",
      "pca 6 replace min diff -5.725831985473633 max diff 2.4847850799560547 avg diff -1.5583744049072266\n",
      "pca 11 replace min diff -6.683233261108398 max diff 2.3404159545898438 avg diff -1.9905790090560913\n",
      "pca 16 replace min diff -7.113604545593262 max diff 3.5367918014526367 avg diff -2.205662965774536\n",
      "pca 21 replace min diff -9.534707069396973 max diff 1.856553077697754 avg diff -2.4536325931549072\n",
      "pca 26 replace min diff -8.919142723083496 max diff 1.7314033508300781 avg diff -2.710315704345703\n",
      "pca 31 replace min diff -7.971835136413574 max diff 1.7389650344848633 avg diff -2.910799741744995\n",
      "pca 36 replace min diff -7.82713508605957 max diff 1.1897377967834473 avg diff -2.9427006244659424\n",
      "pca 41 replace min diff -8.441636085510254 max diff 1.600846290588379 avg diff -3.3408656120300293\n",
      "pca 46 replace min diff -9.645776748657227 max diff 1.5369129180908203 avg diff -3.474529504776001\n",
      "pca 51 replace min diff -10.496797561645508 max diff 0.248779296875 avg diff -3.81083083152771\n",
      "pca 56 replace min diff -8.755396842956543 max diff 0.24278831481933594 avg diff -3.885650873184204\n",
      "pca 61 replace min diff -11.150490760803223 max diff 0.4462156295776367 avg diff -4.142153263092041\n",
      "pca 66 replace min diff -9.073711395263672 max diff 0.8152923583984375 avg diff -4.223395824432373\n",
      "pca 71 replace min diff -8.688760757446289 max diff 0.28945446014404297 avg diff -4.340442180633545\n",
      "pca 76 replace min diff -9.15414810180664 max diff -0.8808870315551758 avg diff -4.480126857757568\n",
      "pca 81 replace min diff -9.430322647094727 max diff -0.569371223449707 avg diff -4.623082637786865\n",
      "pca 86 replace min diff -11.85174560546875 max diff -0.02276611328125 avg diff -4.782935619354248\n",
      "pca 91 replace min diff -9.480352401733398 max diff -0.3169670104980469 avg diff -4.726596832275391\n",
      "pca 96 replace min diff -9.863895416259766 max diff -0.45804882049560547 avg diff -5.036709308624268\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "x=%{x}<br>num incorrect=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1,
          6,
          11,
          16,
          21,
          26,
          31,
          36,
          41,
          46,
          51,
          56,
          61,
          66,
          71,
          76,
          81,
          86,
          91,
          96
         ],
         "xaxis": "x",
         "y": [
          46,
          35,
          26,
          25,
          21,
          14,
          10,
          5,
          6,
          5,
          1,
          2,
          1,
          2,
          2,
          0,
          0,
          0,
          0,
          0
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": true,
        "barmode": "relative",
        "font": {
         "color": "black",
         "size": 10
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "projective pca reduction num incorrect / 202"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -1.5,
          98.5
         ],
         "tickmode": "array",
         "ticktext": [
          1,
          6,
          11,
          16,
          21,
          26,
          31,
          36,
          41,
          46,
          51,
          56,
          61,
          66,
          71,
          76,
          81,
          86,
          91,
          96
         ],
         "tickvals": [
          1,
          6,
          11,
          16,
          21,
          26,
          31,
          36,
          41,
          46,
          51,
          56,
          61,
          66,
          71,
          76,
          81,
          86,
          91,
          96
         ],
         "title": {
          "text": "x"
         },
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          48.421052631578945
         ],
         "title": {
          "text": "num incorrect"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"a35b1e48-9602-4f04-9fed-02cafa87a37a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a35b1e48-9602-4f04-9fed-02cafa87a37a\")) {                    Plotly.newPlot(                        \"a35b1e48-9602-4f04-9fed-02cafa87a37a\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}\\u003cbr\\u003enum incorrect=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[1,6,11,16,21,26,31,36,41,46,51,56,61,66,71,76,81,86,91,96],\"xaxis\":\"x\",\"y\":[46,35,26,25,21,14,10,5,6,5,1,2,1,2,2,0,0,0,0,0],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"},\"tickmode\":\"array\",\"tickvals\":[1,6,11,16,21,26,31,36,41,46,51,56,61,66,71,76,81,86,91,96],\"ticktext\":[1,6,11,16,21,26,31,36,41,46,51,56,61,66,71,76,81,86,91,96]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"num incorrect\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"projective pca reduction num incorrect \\u002f 202\"},\"barmode\":\"relative\",\"font\":{\"size\":10,\"color\":\"black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a35b1e48-9602-4f04-9fed-02cafa87a37a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.82138442993164 11.173883438110352\n",
      "12.736701965332031 10.217185974121094\n",
      "8.846115112304688 6.645937442779541\n",
      "7.833235740661621 6.569667816162109\n",
      "11.275167465209961 9.637931823730469\n",
      "11.706157684326172 10.110433578491211\n",
      "10.820472717285156 9.33121109008789\n",
      "9.343393325805664 9.4407377243042\n",
      "7.741237640380859 5.295808792114258\n",
      "11.029853820800781 7.26798152923584\n",
      "9.24068832397461 8.79992389678955\n",
      "12.335310935974121 7.3508076667785645\n",
      "11.4617919921875 10.812494277954102\n",
      "12.249700546264648 9.514029502868652\n",
      "9.796886444091797 9.914495468139648\n",
      "10.353769302368164 8.812589645385742\n",
      "13.758966445922852 9.780296325683594\n",
      "11.305784225463867 10.323810577392578\n",
      "7.346553325653076 5.561267852783203\n",
      "6.7610931396484375 6.760856628417969\n",
      "12.463811874389648 11.240272521972656\n",
      "11.58830738067627 11.424102783203125\n",
      "11.935590744018555 9.477813720703125\n",
      "10.57258415222168 9.6211519241333\n",
      "12.906749725341797 9.574055671691895\n",
      "12.236769676208496 10.673309326171875\n",
      "8.085566520690918 9.532452583312988\n",
      "11.367392539978027 7.331670761108398\n",
      "9.44795036315918 5.439880847930908\n",
      "8.970124244689941 7.604208469390869\n",
      "9.568976402282715 10.046334266662598\n",
      "10.426973342895508 7.972574710845947\n",
      "11.153364181518555 6.23821496963501\n",
      "9.093563079833984 9.273422241210938\n",
      "9.705839157104492 8.230713844299316\n",
      "9.845163345336914 9.030946731567383\n",
      "8.61175537109375 6.784881591796875\n",
      "8.1769437789917 5.850738048553467\n",
      "13.15955924987793 10.660138130187988\n",
      "11.52824592590332 13.080982208251953\n",
      "9.138144493103027 7.357149600982666\n",
      "9.617812156677246 6.641775131225586\n",
      "7.178480625152588 7.275465965270996\n",
      "7.993780136108398 5.953423976898193\n",
      "11.678421020507812 10.713802337646484\n",
      "12.163931846618652 10.626363754272461\n",
      "8.071128845214844 6.695095539093018\n",
      "8.767404556274414 6.991397857666016\n",
      "10.45274829864502 9.172473907470703\n",
      "10.720008850097656 9.83204460144043\n",
      "10.372379302978516 6.889727592468262\n",
      "7.009171009063721 7.680910587310791\n",
      "8.584653854370117 2.1995954513549805\n",
      "6.501134872436523 6.687055587768555\n",
      "10.292490005493164 8.57479476928711\n",
      "10.871880531311035 11.175724983215332\n",
      "10.157279968261719 5.042340278625488\n",
      "8.931731224060059 8.045745849609375\n",
      "7.343886375427246 8.759236335754395\n",
      "9.946905136108398 7.241683006286621\n",
      "8.011834144592285 5.217484474182129\n",
      "7.777530193328857 8.136749267578125\n",
      "7.854931831359863 6.8462324142456055\n",
      "7.600063323974609 5.9740190505981445\n",
      "9.880928993225098 10.607848167419434\n",
      "11.441099166870117 8.816179275512695\n",
      "10.102273941040039 8.818135261535645\n",
      "10.355039596557617 8.35733699798584\n",
      "10.02355670928955 10.525150299072266\n",
      "9.980942726135254 8.55744743347168\n",
      "8.919565200805664 7.377824306488037\n",
      "8.014500617980957 7.8161821365356445\n",
      "8.082802772521973 6.254266262054443\n",
      "11.87661075592041 8.519800186157227\n",
      "10.36467456817627 10.137242317199707\n",
      "11.525394439697266 9.578553199768066\n",
      "11.112127304077148 10.043296813964844\n",
      "9.942113876342773 10.388795852661133\n",
      "10.340627670288086 10.38489818572998\n",
      "11.189665794372559 8.554141998291016\n",
      "10.482337951660156 9.6416015625\n",
      "11.092926025390625 8.462176322937012\n",
      "9.085617065429688 6.455327033996582\n",
      "9.882442474365234 8.481016159057617\n",
      "9.939321517944336 10.563427925109863\n",
      "12.193060874938965 9.030574798583984\n",
      "9.368901252746582 11.42994499206543\n",
      "12.560968399047852 8.981766700744629\n",
      "8.631667137145996 9.08941650390625\n",
      "9.766006469726562 7.052516937255859\n",
      "12.750507354736328 11.585031509399414\n",
      "13.86790657043457 11.32711410522461\n",
      "8.767786979675293 9.437551498413086\n",
      "11.291702270507812 6.035971641540527\n",
      "8.143950462341309 6.657054901123047\n",
      "8.331369400024414 5.593354225158691\n",
      "9.006256103515625 6.433910846710205\n",
      "7.76837158203125 7.088249206542969\n",
      "13.209383964538574 6.946290969848633\n",
      "11.771954536437988 10.52676010131836\n",
      "6.604437828063965 5.945704936981201\n",
      "9.604927062988281 4.239669322967529\n",
      "6.498605728149414 7.74258279800415\n",
      "8.063379287719727 6.335928916931152\n",
      "11.245794296264648 10.385636329650879\n",
      "9.274681091308594 8.268399238586426\n",
      "12.649630546569824 9.217443466186523\n",
      "11.596834182739258 11.266002655029297\n",
      "10.577555656433105 10.347478866577148\n",
      "10.874801635742188 8.240960121154785\n",
      "9.705839157104492 8.230713844299316\n",
      "9.845163345336914 9.030946731567383\n",
      "10.976018905639648 10.999357223510742\n",
      "7.618655204772949 5.923557758331299\n",
      "7.740528583526611 6.883609771728516\n",
      "8.456459045410156 5.746333599090576\n",
      "9.757234573364258 9.329662322998047\n",
      "11.488872528076172 10.028802871704102\n",
      "9.333450317382812 10.927244186401367\n",
      "10.560724258422852 7.579588890075684\n",
      "13.225317001342773 7.90593147277832\n",
      "10.331476211547852 13.603246688842773\n",
      "10.820472717285156 9.33121109008789\n",
      "9.343393325805664 9.4407377243042\n",
      "11.19087028503418 8.692405700683594\n",
      "10.086915016174316 10.87360954284668\n",
      "10.202108383178711 8.780006408691406\n",
      "9.685901641845703 9.203184127807617\n",
      "10.121858596801758 11.52665901184082\n",
      "11.293508529663086 9.64724349975586\n",
      "10.143451690673828 10.562411308288574\n",
      "11.752883911132812 9.691624641418457\n",
      "6.5698041915893555 5.4159440994262695\n",
      "6.250579833984375 5.271914482116699\n",
      "11.442590713500977 7.242542266845703\n",
      "9.511819839477539 10.050323486328125\n",
      "10.38708209991455 11.03580379486084\n",
      "10.666099548339844 7.358905792236328\n",
      "9.636833190917969 5.889793395996094\n",
      "10.958550453186035 8.762382507324219\n",
      "11.237150192260742 9.311643600463867\n",
      "10.727337837219238 8.99577522277832\n",
      "10.913508415222168 9.263092041015625\n",
      "10.930493354797363 10.362013816833496\n",
      "11.06956672668457 7.510549545288086\n",
      "8.053606033325195 10.21324634552002\n",
      "11.883007049560547 8.593852996826172\n",
      "10.630781173706055 9.921819686889648\n",
      "10.55055046081543 11.06204891204834\n",
      "10.363893508911133 8.861485481262207\n",
      "11.81227970123291 11.460952758789062\n",
      "12.305299758911133 9.944406509399414\n",
      "11.917722702026367 12.092464447021484\n",
      "13.397371292114258 11.019512176513672\n",
      "10.808452606201172 11.301603317260742\n",
      "12.303353309631348 9.940918922424316\n",
      "8.465506553649902 8.433185577392578\n",
      "10.081113815307617 8.19450569152832\n",
      "7.7534074783325195 8.943455696105957\n",
      "10.605315208435059 8.789491653442383\n",
      "10.19941520690918 9.749045372009277\n",
      "11.231992721557617 8.155952453613281\n",
      "8.325687408447266 8.213493347167969\n",
      "9.075226783752441 8.483946800231934\n",
      "11.569820404052734 10.559743881225586\n",
      "11.743306159973145 10.061901092529297\n",
      "10.482376098632812 10.617559432983398\n",
      "11.359151840209961 10.052759170532227\n",
      "7.7663164138793945 8.385099411010742\n",
      "9.129294395446777 7.348080158233643\n",
      "10.865220069885254 8.130353927612305\n",
      "8.043354988098145 9.080892562866211\n",
      "9.403135299682617 11.191118240356445\n",
      "12.229394912719727 9.155508995056152\n",
      "5.430807590484619 4.843462944030762\n",
      "5.57808780670166 1.9580473899841309\n",
      "10.483532905578613 9.353864669799805\n",
      "11.181320190429688 11.00922679901123\n",
      "8.289859771728516 7.422601699829102\n",
      "8.618532180786133 7.104608535766602\n",
      "11.890957832336426 8.626033782958984\n",
      "10.324531555175781 10.76175308227539\n",
      "11.185176849365234 9.262042045593262\n",
      "7.4928975105285645 6.53530216217041\n",
      "12.649630546569824 9.217443466186523\n",
      "11.596834182739258 11.266002655029297\n",
      "9.368901252746582 11.42994499206543\n",
      "12.560968399047852 8.981766700744629\n",
      "9.819631576538086 9.461490631103516\n",
      "11.687419891357422 9.635668754577637\n",
      "9.666617393493652 9.291219711303711\n",
      "10.80374813079834 8.969524383544922\n",
      "8.709712028503418 9.432348251342773\n",
      "9.512109756469727 6.584179878234863\n",
      "9.898179054260254 6.0724334716796875\n",
      "7.772026062011719 8.70802116394043\n",
      "9.348716735839844 8.872407913208008\n",
      "8.064765930175781 8.2152099609375\n",
      "10.178813934326172 9.813162803649902\n",
      "9.68673324584961 9.201980590820312\n",
      "12.302922248840332 9.306802749633789\n",
      "11.566715240478516 11.800349235534668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_x = pca_sizes[:len(replace_corrects)]\n",
    "data_y = []\n",
    "for i in range(len(replace_corrects)):\n",
    "    replace_diff = -torch.tensor(replace_corrects[i]) + torch.tensor(replace_replaces[i])\n",
    "    n_correct = torch.sum(replace_diff > 0)\n",
    "    data_y.append(n_correct)\n",
    "    print(f'pca {data_x[i]} replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "\n",
    "data_y = torch.tensor(data_y, device=model.cfg.device)\n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "bar_chart(data_y, x_labels=data_x, y_label='num incorrect', title=f'projective pca reduction num incorrect / {len(replace_replaces[0])}', font_size=10)\n",
    "\n",
    "for i in range(len(replace_corrects[0])):\n",
    "    print(replace_corrects[0][i], replace_replaces[0][i])\n",
    "#patched_diff = -torch.tensor(patched_correct) + torch.tensor(patched_replace)\n",
    "\n",
    "#print(n_correct_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f369477e-4828-477e-b16b-d882309f5184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(len(name_tokens))\n",
    "pca = PCA(n_components=pca_dim)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d78207-1556-4aaf-bffb-b609de24f15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4854c-42c7-4696-a92b-b3401d460bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79a7ebf1-7fc4-473c-9ebc-3a4542f0ca63",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m answer_tok \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcorrect[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     17\u001b[0m template \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdata[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 18\u001b[0m components \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_proj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m grouped_by_answers[answer_tok]\u001b[38;5;241m.\u001b[39mappend((components[component_1], components[component_2]))\n\u001b[1;32m     20\u001b[0m grouped_by_template[template]\u001b[38;5;241m.\u001b[39mappend((components[component_1], components[component_2]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/decomposition/_base.py:145\u001b[0m, in \u001b[0;36m_BasePCA.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    141\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    143\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1049\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:121\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    122\u001b[0m     first_pass_isfinite \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misfinite(xp\u001b[38;5;241m.\u001b[39msum(X))\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:431\u001b[0m, in \u001b[0;36merrstate.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldstate \u001b[38;5;241m=\u001b[39m \u001b[43mseterr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Unspecified:\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldcall \u001b[38;5;241m=\u001b[39m seterrcall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:111\u001b[0m, in \u001b[0;36mseterr\u001b[0;34m(all, divide, over, under, invalid)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mSet how floating-point errors are handled.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m pyvals \u001b[38;5;241m=\u001b[39m umath\u001b[38;5;241m.\u001b[39mgeterrobj()\n\u001b[0;32m--> 111\u001b[0m old \u001b[38;5;241m=\u001b[39m \u001b[43mgeterr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m divide \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     divide \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m old[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivide\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:168\u001b[0m, in \u001b[0;36mgeterr\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgeterr\u001b[39m():\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    Get the current way of handling floating-point errors.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     maskvalue \u001b[38;5;241m=\u001b[39m \u001b[43mumath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeterrobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    169\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[1;32m    170\u001b[0m     res \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name_points = []\n",
    "pca_dim = 90\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "\n",
    "\n",
    "for component_1 in range(0, pca_dim, 2):\n",
    "    component_2 = component_1 + 1\n",
    "    grouped_by_answers = defaultdict(lambda: [])\n",
    "    grouped_by_template = defaultdict(lambda: [])\n",
    "        \n",
    "    for i in range(X.shape[0]):\n",
    "        answer_tok = data.correct[i][0].item()\n",
    "        template = data.data[i][1].item()\n",
    "        components = pca.transform(X_proj[i].reshape(1, -1)).reshape(-1)\n",
    "        grouped_by_answers[answer_tok].append((components[component_1], components[component_2]))\n",
    "        grouped_by_template[template].append((components[component_1], components[component_2]))\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    grouped_by_answers = sorted(list(grouped_by_answers.items()))[:20]\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(grouped_by_answers)))\n",
    "    \n",
    "    for (answer_i, points), c in zip(grouped_by_answers, colors):\n",
    "        x = np.array([point[0] for point in points])\n",
    "        y = np.array([point[1] for point in points])\n",
    "        plt.scatter(x, y, color=c)\n",
    "    plt.title(f'components {component_1} {component_2} colored by name')\n",
    "    plt.savefig(f'{component_1} {component_2} name.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    grouped_by_template = sorted(list(grouped_by_template.items()))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(grouped_by_template)))\n",
    "    \n",
    "    for (answer_i, points), c in zip(grouped_by_template, colors):\n",
    "        x = np.array([point[0] for point in points])\n",
    "        y = np.array([point[1] for point in points])\n",
    "        plt.scatter(x, y, color=c)\n",
    "    plt.title(f'components {component_1} {component_2} colored by template')\n",
    "    plt.savefig(f'{component_1} {component_2} template.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "862073d2-6a9f-410a-bc91-071871ac0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then, [NAME], [NAME] and [NAME] went to the [PLACE]. [NAME] and [NAME] gave a [OBJECT] to\n",
      "Afterwards [NAME], [NAME] and [NAME] went to the [PLACE]. [NAME] and [NAME] gave a [OBJECT] to\n",
      "When [NAME], [NAME] and [NAME] arrived at the [PLACE], [NAME] and [NAME] gave a [OBJECT] to\n",
      "Friends [NAME], [NAME] and [NAME] went to the [PLACE]. [NAME] and [NAME] gave a [OBJECT] to\n"
     ]
    }
   ],
   "source": [
    "for x in ABC_TEMPLATES:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b3da994c-a396-498d-80f4-542563c2580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get positive examples\n",
      "get negative examples\n",
      "shuffle data\n",
      "training erasers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/209 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                  | 1/209 [00:00<02:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1176, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                  | 2/209 [00:01<01:57,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                 | 3/209 [00:01<01:54,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                 | 4/209 [00:02<01:52,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                 | 5/209 [00:02<01:52,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                | 6/209 [00:03<01:51,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                | 7/209 [00:03<01:54,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                               | 8/209 [00:04<01:52,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                               | 9/209 [00:05<01:55,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1300, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                              | 10/209 [00:05<01:55,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1220, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                             | 11/209 [00:06<01:54,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                             | 12/209 [00:06<01:51,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                             | 13/209 [00:07<01:51,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                            | 14/209 [00:07<01:53,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▉                                                                            | 15/209 [00:08<01:51,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▎                                                                           | 16/209 [00:09<01:49,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                           | 17/209 [00:09<01:48,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████                                                                           | 18/209 [00:10<01:47,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1152, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▍                                                                          | 19/209 [00:10<01:46,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▊                                                                          | 20/209 [00:11<01:45,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▏                                                                         | 21/209 [00:11<01:44,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1192, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▋                                                                         | 22/209 [00:12<01:48,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1244, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████                                                                         | 23/209 [00:13<01:51,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▍                                                                        | 24/209 [00:13<01:48,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▊                                                                        | 25/209 [00:14<01:47,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▏                                                                       | 26/209 [00:14<01:45,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1220, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▌                                                                       | 27/209 [00:15<01:44,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▉                                                                       | 28/209 [00:15<01:43,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▍                                                                      | 29/209 [00:16<01:42,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▊                                                                      | 30/209 [00:17<01:40,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▏                                                                     | 31/209 [00:17<01:40,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1080, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▌                                                                     | 32/209 [00:18<01:43,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▉                                                                     | 33/209 [00:18<01:41,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▎                                                                    | 34/209 [00:19<01:40,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▋                                                                    | 35/209 [00:19<01:40,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████                                                                    | 36/209 [00:20<01:41,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                   | 37/209 [00:21<01:41,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1236, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▉                                                                   | 38/209 [00:21<01:39,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▎                                                                  | 39/209 [00:22<01:38,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1152, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▋                                                                  | 40/209 [00:22<01:37,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1240, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████                                                                  | 41/209 [00:23<01:38,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▍                                                                 | 42/209 [00:24<01:36,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▊                                                                 | 43/209 [00:24<01:35,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████▎                                                                | 44/209 [00:25<01:35,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1280, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▋                                                                | 45/209 [00:25<01:39,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████                                                                | 46/209 [00:26<01:36,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▍                                                               | 47/209 [00:27<01:37,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▊                                                               | 48/209 [00:27<01:36,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▏                                                              | 49/209 [00:28<01:34,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▌                                                              | 50/209 [00:28<01:31,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████                                                              | 51/209 [00:29<01:29,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▍                                                             | 52/209 [00:29<01:28,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                             | 53/209 [00:30<01:28,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████▏                                                            | 54/209 [00:30<01:26,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████▌                                                            | 55/209 [00:31<01:25,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([996, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▉                                                            | 56/209 [00:32<01:23,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████▎                                                           | 57/209 [00:32<01:24,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▊                                                           | 58/209 [00:33<01:23,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1292, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████▏                                                          | 59/209 [00:33<01:24,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▌                                                          | 60/209 [00:34<01:23,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1060, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▉                                                          | 61/209 [00:34<01:21,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1100, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▎                                                         | 62/209 [00:35<01:20,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▋                                                         | 63/209 [00:35<01:20,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████                                                         | 64/209 [00:36<01:20,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▌                                                        | 65/209 [00:37<01:19,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████▉                                                        | 66/209 [00:37<01:18,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████▎                                                       | 67/209 [00:38<01:17,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████▋                                                       | 68/209 [00:38<01:17,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1244, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████                                                       | 69/209 [00:39<01:17,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████▍                                                      | 70/209 [00:39<01:16,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1292, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▊                                                      | 71/209 [00:40<01:19,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████▏                                                     | 72/209 [00:41<01:18,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1328, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████▋                                                     | 73/209 [00:41<01:18,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                     | 74/209 [00:42<01:24,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▍                                                    | 75/209 [00:42<01:20,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▊                                                    | 76/209 [00:43<01:18,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████▏                                                   | 77/209 [00:44<01:16,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████▌                                                   | 78/209 [00:44<01:16,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1176, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▉                                                   | 79/209 [00:45<01:15,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▍                                                  | 80/209 [00:45<01:13,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████▊                                                  | 81/209 [00:46<01:13,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████▏                                                 | 82/209 [00:46<01:11,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▌                                                 | 83/209 [00:47<01:10,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▉                                                 | 84/209 [00:47<01:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████▎                                                | 85/209 [00:48<01:09,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████▋                                                | 86/209 [00:49<01:09,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▏                                               | 87/209 [00:49<01:07,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▌                                               | 88/209 [00:50<01:08,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▉                                               | 89/209 [00:50<01:09,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████▎                                              | 90/209 [00:51<01:08,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1100, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████▋                                              | 91/209 [00:51<01:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████                                              | 92/209 [00:52<01:08,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████▍                                             | 93/209 [00:53<01:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1056, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████▉                                             | 94/209 [00:53<01:04,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1080, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                            | 95/209 [00:54<01:06,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▋                                            | 96/209 [00:54<01:05,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████                                            | 97/209 [00:55<01:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████▍                                           | 98/209 [00:55<01:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████▊                                           | 99/209 [00:56<01:01,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▊                                          | 100/209 [00:57<01:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████▏                                         | 101/209 [00:57<01:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████▌                                         | 102/209 [00:58<01:06,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████▉                                         | 103/209 [00:58<01:03,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▎                                        | 104/209 [00:59<01:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1224, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▋                                        | 105/209 [01:00<01:01,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([976, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████                                        | 106/209 [01:00<00:59,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1044, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████▍                                       | 107/209 [01:01<01:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████▊                                       | 108/209 [01:01<01:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████▏                                      | 109/209 [01:02<01:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████▋                                      | 110/209 [01:03<01:01,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1244, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████████████████████████████                                      | 111/209 [01:03<00:59,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████▍                                     | 112/209 [01:04<00:58,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████▊                                     | 113/209 [01:04<00:56,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1224, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████▏                                    | 114/209 [01:05<00:55,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████▌                                    | 115/209 [01:06<00:54,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▉                                    | 116/209 [01:06<00:53,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████▎                                   | 117/209 [01:07<00:53,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1036, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████▋                                   | 118/209 [01:07<00:53,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████                                   | 119/209 [01:08<00:53,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1280, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████▌                                  | 120/209 [01:08<00:52,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████▉                                  | 121/209 [01:09<00:51,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████▎                                 | 122/209 [01:10<00:50,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████▋                                 | 123/209 [01:10<00:49,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████████████                                 | 124/209 [01:11<00:48,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1060, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████▍                                | 125/209 [01:11<00:47,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1216, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████▊                                | 126/209 [01:12<00:47,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████▏                               | 127/209 [01:13<00:48,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1020, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████▌                               | 128/209 [01:13<00:46,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████▉                               | 129/209 [01:14<00:45,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████▍                              | 130/209 [01:14<00:44,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▊                              | 131/209 [01:15<00:43,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1168, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████▏                             | 132/209 [01:15<00:42,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▌                             | 133/209 [01:16<00:42,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([932, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▉                             | 134/209 [01:16<00:40,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1008, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████▎                            | 135/209 [01:17<00:40,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1084, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████▋                            | 136/209 [01:17<00:40,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████                            | 137/209 [01:18<00:40,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([980, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████▍                           | 138/209 [01:19<00:39,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1116, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████▊                           | 139/209 [01:19<00:38,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████▎                          | 140/209 [01:20<00:38,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1032, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████▋                          | 141/209 [01:20<00:37,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1260, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████                          | 142/209 [01:21<00:37,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████▍                         | 143/209 [01:21<00:38,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████▊                         | 144/209 [01:22<00:39,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1076, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████▏                        | 145/209 [01:23<00:39,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▌                        | 146/209 [01:23<00:37,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▉                        | 147/209 [01:24<00:35,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████▎                       | 148/209 [01:24<00:34,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████▋                       | 149/209 [01:25<00:34,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████▏                      | 150/209 [01:26<00:33,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████▌                      | 151/209 [01:26<00:33,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████▉                      | 152/209 [01:27<00:32,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████████████▎                     | 153/209 [01:27<00:31,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1168, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████▋                     | 154/209 [01:28<00:31,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████████████                     | 155/209 [01:28<00:31,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1260, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████▍                    | 156/209 [01:29<00:31,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1008, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████▊                    | 157/209 [01:30<00:29,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████▏                   | 158/209 [01:30<00:28,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████▌                   | 159/209 [01:31<00:28,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████████                   | 160/209 [01:31<00:27,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████████▍                  | 161/209 [01:32<00:26,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1128, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████▊                  | 162/209 [01:32<00:26,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████▏                 | 163/209 [01:33<00:26,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████▌                 | 164/209 [01:33<00:25,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████▉                 | 165/209 [01:34<00:24,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████████▎                | 166/209 [01:35<00:25,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1044, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████▋                | 167/209 [01:35<00:23,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████                | 168/209 [01:36<00:23,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████▍               | 169/209 [01:36<00:22,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████▉               | 170/209 [01:37<00:21,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1052, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████▎              | 171/209 [01:37<00:21,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1128, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████▋              | 172/209 [01:38<00:20,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1084, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████              | 173/209 [01:39<00:20,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████▍             | 174/209 [01:39<00:19,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████▊             | 175/209 [01:40<00:19,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1060, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████▏            | 176/209 [01:40<00:18,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████▌            | 177/209 [01:41<00:18,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████▉            | 178/209 [01:41<00:18,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████▎           | 179/209 [01:42<00:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([960, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████▊           | 180/209 [01:43<00:16,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████▏          | 181/209 [01:43<00:15,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████▌          | 182/209 [01:44<00:15,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1128, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████▉          | 183/209 [01:44<00:14,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1168, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████▎         | 184/209 [01:45<00:14,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████▋         | 185/209 [01:45<00:13,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1188, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████         | 186/209 [01:46<00:13,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1052, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████▍        | 187/209 [01:47<00:12,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1148, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████▊        | 188/209 [01:47<00:12,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▏       | 189/209 [01:48<00:11,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████▋       | 190/209 [01:48<00:10,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1084, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████       | 191/209 [01:49<00:10,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████▍      | 192/209 [01:49<00:09,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1028, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████▊      | 193/209 [01:50<00:08,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████▏     | 194/209 [01:50<00:08,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████▌     | 195/209 [01:51<00:07,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▉     | 196/209 [01:52<00:07,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████▎    | 197/209 [01:52<00:06,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1080, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████████▋    | 198/209 [01:53<00:06,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████    | 199/209 [01:53<00:05,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████▌   | 200/209 [01:54<00:05,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████▉   | 201/209 [01:55<00:04,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1028, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████████▎  | 202/209 [01:55<00:04,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████████▋  | 203/209 [01:56<00:03,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████  | 204/209 [01:56<00:02,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████▍ | 205/209 [01:57<00:02,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████▊ | 206/209 [01:57<00:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1252, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████▏| 207/209 [01:58<00:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1188, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████▌| 208/209 [01:59<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1036, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 209/209 [01:59<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "from concept_erasure import LeaceEraser\n",
    "from collections import defaultdict\n",
    "X_data_by_name = defaultdict(lambda: [])\n",
    "Y_data_by_name = defaultdict(lambda: [])\n",
    "X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "\n",
    "# gather positive examples\n",
    "print(\"get positive examples\")\n",
    "for i in range(X_proj.shape[0]):\n",
    "    answer_tok = data.correct[i][0].item()\n",
    "    X_data_by_name[answer_tok].append(X_proj[i])\n",
    "    Y_data_by_name[answer_tok].append([1.0,0.0])\n",
    "\n",
    "# gather negative examples\n",
    "print(\"get negative examples\")\n",
    "for answer, X_data in X_data_by_name.items():\n",
    "    num_points = len(X_data)\n",
    "    while len(X_data) < num_points*2:\n",
    "        random_data_i = random.randint(0, X_proj.shape[0]-1)\n",
    "        random_data_answer = data.correct[random_data_i][0].item()\n",
    "        if random_data_answer != answer:\n",
    "            X_data.append(X_proj[random_data_i])\n",
    "            Y_data_by_name[answer].append([0.0, 1.0])\n",
    "\n",
    "# shuffle data\n",
    "print(\"shuffle data\")\n",
    "for answer in list(X_data_by_name.keys()):\n",
    "    inds = list(range(len(X_data_by_name[answer])))\n",
    "    random.shuffle(inds)\n",
    "    X_data_by_name[answer] = [X_data_by_name[answer][i] for i in inds]\n",
    "    Y_data_by_name[answer] = [Y_data_by_name[answer][i] for i in inds]\n",
    "\n",
    "print(\"training erasers\")\n",
    "# train leace\n",
    "name_erasers = {}\n",
    "\n",
    "\n",
    "for answer in tqdm(list(X_data_by_name.keys())):\n",
    "    Xd, Yd = X_data_by_name[answer], Y_data_by_name[answer]\n",
    "    Xd = torch.tensor(Xd, device=model.cfg.device)\n",
    "    Yd = torch.tensor(Yd, device=model.cfg.device)\n",
    "    print(Xd.size())\n",
    "    name_erasers[answer] = LeaceEraser.fit(Xd, Yd)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e8d4940a-afa0-42a5-b71a-fc3878dd24b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "replace_corrects = []\n",
    "replace_replaces = []\n",
    "original_corrects = []\n",
    "original_replaces = []\n",
    "#pca_sizes = []\n",
    "#X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "#print(X_proj[:,-1])\n",
    "\n",
    "# subtract to erase\n",
    "# add to add\n",
    "def apply_eraser(eraser, x):\n",
    "    delta = x - eraser.bias\n",
    "    diff = (delta @ eraser.proj_right.mH) @ eraser.proj_left.mH\n",
    "    return x - diff\n",
    "\n",
    "def invert_eraser(eraser, x):\n",
    "    # (AB)^-1 = B^-1 A^-1\n",
    "    eye = torch.eye(x.size()[0], device=model.cfg.device, dtype=eraser.proj_left.dtype)\n",
    "    \n",
    "    #Inv = torch.linalg.inv(eraser.proj_right.mH @ eraser.proj_left.mH)\n",
    "    #Inv = torch.linalg.pinv(eye-eraser.proj_right.mH @ eraser.proj_left.mH)\n",
    "    # approximation to the inverse\n",
    "    res = eye\n",
    "    prod = eraser.proj_right.mH @ eraser.proj_left.mH\n",
    "    for i in range(40):\n",
    "        res += prod\n",
    "        prod = prod @ eraser.proj_right.mH @ eraser.proj_left.mH\n",
    "    #print(f\"inverse {Inv}\")\n",
    "    bA = (eraser.bias @ eraser.proj_right.mH) @ eraser.proj_left.mH\n",
    "    return (x-bA)@res\n",
    "\n",
    "for _ in range(1):\n",
    "    original_correct = []\n",
    "    original_replace = []\n",
    "    replace_correct = []\n",
    "    replace_replace = []\n",
    "    print(f\"layer {layer}\")\n",
    "    name_bases = [0]\n",
    "    for position_1, name_basis in enumerate(name_bases):\n",
    "        num_found = 0\n",
    "        while True:            \n",
    "            data_i = random.choice(list(range(10000)))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i]\n",
    "            corrupted_tokens = data.data[data_i+1]\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            \n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                answer_name_tok,\n",
    "                replace_name_tok,\n",
    "            ):\n",
    "                B,L,E = x.size()\n",
    "                for b in range(B):\n",
    "                    veco = torch.concatenate([x[b,position], torch.tensor([1.0], device=model.cfg.device)])\n",
    "                    vec = apply_eraser(name_erasers[answer_name_tok], veco)\n",
    "                    vec2 = invert_eraser(name_erasers[replace_name_tok], vec)\n",
    "                    invert_diff = vec2 - vec\n",
    "                    vec = vec + invert_diff*100\n",
    "                    # we can do vec + diff to get vec2\n",
    "                    # instead we will do vec - diff to do inverse\n",
    "                    #vec = vec2\n",
    "                    \n",
    "                    #print(vec)\n",
    "                    #print(\"done\")\n",
    "                    x[b,position] = vec[:-1]\n",
    "\n",
    "                    #add_ones = np.concatenate([vec.detach().cpu().numpy(), np.array([1.0])], axis=0).reshape(1,-1)\n",
    "                    #pcad = pca.transform(add_ones)\n",
    "                    #x[b,position] = torch.tensor(pca.inverse_transform(pcad), device=model.cfg.device).reshape(-1)[:-1]\n",
    "                    '''\n",
    "                    coords = name_basis.map_to_coords(vec/torch.linalg.norm(vec, ord=2))\n",
    "                    C = len(name_tok_to_class)\n",
    "                    sorted = torch.argsort(coords[:C])\n",
    "                    print(coords[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"predict {maxi} {coords[maxi]}\")\n",
    "                    print(f\"answer {name_tok_to_class[answer_name_tok]} replace {name_tok_to_class[replace_name_tok]}\")\n",
    "                    coords[name_tok_to_class[answer_name_tok]] = -0.0692\n",
    "                    coords[name_tok_to_class[replace_name_tok]] = 0.0692\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"now predict {maxi} {coords[maxi]}\")\n",
    "                    patched_vec = name_basis.map_from_coords(coords)\n",
    "                    print(f\"orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    patched_veco = patched_vec / torch.linalg.norm(patched_vec, ord=2) * torch.linalg.norm(vec, ord=2)\n",
    "                    print(f\"now orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    coords2 = name_basis.map_to_coords(patched_vec)\n",
    "                    sorted = torch.argsort(coords2[:C])\n",
    "                    print(\"predict2\", coords2[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords2[:C])\n",
    "                    print(f\"predict2 {maxi} {coords2[maxi]}\")\n",
    "                    '''\n",
    "                    #x[b,position] = patched_veco\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(data_name_positions)):\n",
    "                position = data_name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            hooks = []\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                \n",
    "                hooks.append((\n",
    "                    f'blocks.{layer}.hook_ssm_input', \n",
    "                    partial(replace_hook,\n",
    "                            position=position+1,\n",
    "                            answer_name_tok=answer_tok,\n",
    "                            replace_name_tok=replace_tok,\n",
    "                    )\n",
    "                ))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            hooks = []\n",
    "            for name_i, position in answer_positions:\n",
    "                hooks.append((\n",
    "                    f'blocks.{layer}.hook_ssm_input', \n",
    "                    partial(replace_hook,\n",
    "                            position=position+1,\n",
    "                            answer_name_tok=replace_tok,\n",
    "                            replace_name_tok=answer_tok,\n",
    "                    )\n",
    "                ))\n",
    "            \n",
    "            logits = model(corrupted_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            original_correct.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            original_replace.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            \n",
    "            logits_modified = model.run_with_hooks(corrupted_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 100:\n",
    "                break\n",
    "        break\n",
    "    original_corrects.append(original_correct)\n",
    "    original_replaces.append(original_replace)\n",
    "    replace_corrects.append(replace_correct)\n",
    "    replace_replaces.append(replace_replace)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1aca3665-2d22-4db2-9cda-852e1f55761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/202\n",
      "replace min diff -68.55792999267578 max diff 69.87189483642578 avg diff -0.19875283539295197\n",
      "h\n",
      "16.470701217651367 9.71561050415039\n",
      "-5.661073684692383 -22.156082153320312\n",
      "h\n",
      "14.580031394958496 9.408432006835938\n",
      "0.48569345474243164 6.747767448425293\n",
      "h\n",
      "14.380048751831055 7.109065055847168\n",
      "-2.442127227783203 -24.21950912475586\n",
      "h\n",
      "16.272052764892578 7.420269966125488\n",
      "-7.698086738586426 62.173805236816406\n",
      "h\n",
      "14.879524230957031 9.761422157287598\n",
      "-3.2463455200195312 25.89336395263672\n",
      "h\n",
      "14.439093589782715 5.619184970855713\n",
      "8.848220825195312 -33.423301696777344\n",
      "h\n",
      "14.669663429260254 8.600264549255371\n",
      "2.081355094909668 -1.9556349515914917\n",
      "h\n",
      "15.520383834838867 7.870769500732422\n",
      "1.4222896099090576 22.22512435913086\n",
      "h\n",
      "17.11648941040039 11.07115650177002\n",
      "-10.067371368408203 -39.855567932128906\n",
      "h\n",
      "14.599285125732422 9.929826736450195\n",
      "-6.593348979949951 -6.830587863922119\n",
      "h\n",
      "16.378326416015625 11.30602741241455\n",
      "5.956884860992432 -38.610435485839844\n",
      "h\n",
      "17.24477195739746 12.21163272857666\n",
      "4.230982780456543 8.75568675994873\n",
      "h\n",
      "17.055301666259766 9.792766571044922\n",
      "-6.7681660652160645 -40.46263122558594\n",
      "h\n",
      "15.095385551452637 8.833169937133789\n",
      "-8.643159866333008 9.353684425354004\n",
      "h\n",
      "17.705638885498047 10.347694396972656\n",
      "-1.1137534379959106 36.980987548828125\n",
      "h\n",
      "17.70909881591797 12.46829891204834\n",
      "4.278864860534668 10.1322021484375\n",
      "h\n",
      "13.674509048461914 2.729785203933716\n",
      "8.848783493041992 14.957258224487305\n",
      "h\n",
      "11.015439987182617 7.332038879394531\n",
      "-0.40244436264038086 6.306756973266602\n",
      "h\n",
      "17.063003540039062 9.478687286376953\n",
      "-0.5124579668045044 -10.10653018951416\n",
      "h\n",
      "17.016000747680664 9.74824333190918\n",
      "-0.053635597229003906 28.03034210205078\n",
      "h\n",
      "14.829706192016602 5.538116931915283\n",
      "0.1917802095413208 50.553794860839844\n",
      "h\n",
      "15.466934204101562 10.313305854797363\n",
      "1.0343191623687744 -2.2826528549194336\n",
      "h\n",
      "12.930335998535156 5.6602678298950195\n",
      "0.40245652198791504 -49.356834411621094\n",
      "h\n",
      "13.753924369812012 6.906387805938721\n",
      "14.573183059692383 40.302452087402344\n",
      "h\n",
      "15.272117614746094 7.513121128082275\n",
      "-1.9908170700073242 25.334665298461914\n",
      "h\n",
      "14.374013900756836 5.310833930969238\n",
      "2.037912368774414 61.625709533691406\n",
      "h\n",
      "13.430246353149414 6.389962196350098\n",
      "-3.8849401473999023 30.17223358154297\n",
      "h\n",
      "12.919710159301758 7.869196891784668\n",
      "-4.0385966300964355 8.03372573852539\n",
      "h\n",
      "17.368846893310547 10.586111068725586\n",
      "-8.072798728942871 5.658577919006348\n",
      "h\n",
      "17.00928497314453 11.611640930175781\n",
      "1.7490825653076172 18.310752868652344\n",
      "h\n",
      "15.7691011428833 6.738853931427002\n",
      "1.6175341606140137 10.121139526367188\n",
      "h\n",
      "14.03289794921875 6.293128967285156\n",
      "-2.97029447555542 -35.81845474243164\n",
      "h\n",
      "14.218904495239258 9.513717651367188\n",
      "5.595700263977051 -18.34531593322754\n",
      "h\n",
      "16.62076187133789 8.895003318786621\n",
      "5.766347885131836 -42.54839324951172\n",
      "h\n",
      "12.203004837036133 6.083037853240967\n",
      "-1.0008347034454346 23.98700714111328\n",
      "h\n",
      "14.704365730285645 7.946584701538086\n",
      "-0.016435742378234863 -14.676387786865234\n",
      "h\n",
      "8.897337913513184 1.077894687652588\n",
      "-3.877026319503784 19.058242797851562\n",
      "h\n",
      "8.121967315673828 -1.0396852493286133\n",
      "-3.933058261871338 47.77484130859375\n",
      "h\n",
      "15.813190460205078 10.41125774383545\n",
      "-4.233362674713135 51.51629638671875\n",
      "h\n",
      "17.074491500854492 8.385383605957031\n",
      "1.612729549407959 9.170707702636719\n",
      "h\n",
      "15.585822105407715 11.576179504394531\n",
      "2.741321325302124 -5.563211441040039\n",
      "h\n",
      "16.00225257873535 8.32889175415039\n",
      "-3.1251511573791504 -39.8695068359375\n",
      "h\n",
      "18.544811248779297 11.8841552734375\n",
      "-2.204787015914917 -15.113668441772461\n",
      "h\n",
      "18.548494338989258 13.399232864379883\n",
      "1.0070135593414307 37.28767776489258\n",
      "h\n",
      "16.36518669128418 10.43846321105957\n",
      "-2.407611608505249 -0.21759843826293945\n",
      "h\n",
      "16.766250610351562 9.270914077758789\n",
      "-3.3712310791015625 30.524829864501953\n",
      "h\n",
      "14.669663429260254 8.600264549255371\n",
      "2.081355094909668 -1.9556349515914917\n",
      "h\n",
      "15.520383834838867 7.870769500732422\n",
      "1.4222896099090576 22.22512435913086\n",
      "h\n",
      "16.39776039123535 7.390601634979248\n",
      "0.17546308040618896 -40.02701187133789\n",
      "h\n",
      "16.6684513092041 10.163793563842773\n",
      "9.735057830810547 -4.866774559020996\n",
      "h\n",
      "14.380048751831055 7.109065055847168\n",
      "-2.442127227783203 -24.21950912475586\n",
      "h\n",
      "16.272052764892578 7.420269966125488\n",
      "-7.698086738586426 62.173805236816406\n",
      "h\n",
      "10.861021041870117 4.524538516998291\n",
      "-0.8411014080047607 32.92559051513672\n",
      "h\n",
      "11.794175148010254 3.1382973194122314\n",
      "6.587797164916992 -3.79280948638916\n",
      "h\n",
      "16.336885452270508 6.245671272277832\n",
      "-9.842906951904297 -47.97581481933594\n",
      "h\n",
      "15.646645545959473 7.008029460906982\n",
      "1.6293400526046753 61.09855651855469\n",
      "h\n",
      "16.299503326416016 9.718326568603516\n",
      "3.4221134185791016 -28.932390213012695\n",
      "h\n",
      "14.449541091918945 11.833253860473633\n",
      "-3.2021055221557617 -35.85157012939453\n",
      "h\n",
      "15.406458854675293 10.657981872558594\n",
      "2.1399261951446533 49.92259979248047\n",
      "h\n",
      "17.072769165039062 11.170125961303711\n",
      "-7.728151798248291 -31.958995819091797\n",
      "h\n",
      "14.30941390991211 7.718364715576172\n",
      "-0.0828852653503418 -27.250425338745117\n",
      "h\n",
      "16.768972396850586 11.284313201904297\n",
      "3.9116079807281494 -54.83154296875\n",
      "h\n",
      "14.224660873413086 6.028111457824707\n",
      "3.5183351039886475 -8.583236694335938\n",
      "h\n",
      "14.157243728637695 4.108088493347168\n",
      "-2.8067798614501953 48.64846420288086\n",
      "h\n",
      "19.83786392211914 12.366390228271484\n",
      "7.711895942687988 0.3670095205307007\n",
      "h\n",
      "18.613697052001953 12.455986022949219\n",
      "-5.930981159210205 30.85239028930664\n",
      "h\n",
      "14.095074653625488 6.3821611404418945\n",
      "9.584667205810547 -30.38941192626953\n",
      "h\n",
      "15.425775527954102 10.400848388671875\n",
      "4.956835746765137 -10.735883712768555\n",
      "h\n",
      "16.855308532714844 9.954970359802246\n",
      "-0.8591716289520264 -7.199571132659912\n",
      "h\n",
      "17.992345809936523 10.363795280456543\n",
      "9.615142822265625 12.433926582336426\n",
      "h\n",
      "11.22191047668457 3.653398275375366\n",
      "1.8061182498931885 -20.239566802978516\n",
      "h\n",
      "9.185664176940918 4.289755821228027\n",
      "0.4170109033584595 -19.251052856445312\n",
      "h\n",
      "16.299503326416016 9.718326568603516\n",
      "3.4221134185791016 -28.932390213012695\n",
      "h\n",
      "14.449541091918945 11.833253860473633\n",
      "-3.2021055221557617 -35.85157012939453\n",
      "h\n",
      "14.052519798278809 9.695889472961426\n",
      "7.987891674041748 -15.997453689575195\n",
      "h\n",
      "14.83008861541748 7.414546489715576\n",
      "-3.505863666534424 -47.1068229675293\n",
      "h\n",
      "16.48956298828125 9.136743545532227\n",
      "-2.1396608352661133 -3.536954402923584\n",
      "h\n",
      "15.77269172668457 9.213828086853027\n",
      "-8.737995147705078 -11.788990020751953\n",
      "h\n",
      "17.51837158203125 9.624862670898438\n",
      "4.503121376037598 -41.50974655151367\n",
      "h\n",
      "16.068586349487305 9.978069305419922\n",
      "1.532455563545227 -15.997509002685547\n",
      "h\n",
      "15.161977767944336 4.8690667152404785\n",
      "2.584624767303467 -13.022727966308594\n",
      "h\n",
      "14.288325309753418 10.116472244262695\n",
      "7.917823314666748 -60.640106201171875\n",
      "h\n",
      "15.050782203674316 10.455619812011719\n",
      "3.980501890182495 9.842601776123047\n",
      "h\n",
      "13.355952262878418 8.135208129882812\n",
      "-3.7414815425872803 12.320381164550781\n",
      "h\n",
      "14.79833984375 10.084672927856445\n",
      "6.437402248382568 55.108848571777344\n",
      "h\n",
      "10.920382499694824 1.7902164459228516\n",
      "-0.6614793539047241 -12.868444442749023\n",
      "h\n",
      "13.344636917114258 7.28670597076416\n",
      "-0.513707160949707 46.30146026611328\n",
      "h\n",
      "16.567476272583008 9.052946090698242\n",
      "2.6877522468566895 20.682714462280273\n",
      "h\n",
      "15.591033935546875 11.579273223876953\n",
      "-6.953457832336426 4.992960453033447\n",
      "h\n",
      "15.871563911437988 8.972944259643555\n",
      "-1.3056917190551758 -16.025474548339844\n",
      "h\n",
      "15.332590103149414 8.09166145324707\n",
      "-1.4696078300476074 9.947774887084961\n",
      "h\n",
      "15.952951431274414 9.328046798706055\n",
      "-8.466363906860352 -33.127723693847656\n",
      "h\n",
      "12.545150756835938 6.543041229248047\n",
      "3.718639850616455 -31.48052406311035\n",
      "h\n",
      "11.745452880859375 4.749141693115234\n",
      "-4.059512615203857 -31.17159652709961\n",
      "h\n",
      "14.710734367370605 7.189019203186035\n",
      "-8.113587379455566 16.371967315673828\n",
      "h\n",
      "15.396932601928711 9.213991165161133\n",
      "-2.7745323181152344 6.283504962921143\n",
      "h\n",
      "15.46364974975586 7.662905693054199\n",
      "-5.817660331726074 -4.512526035308838\n",
      "h\n",
      "15.516579627990723 8.438018798828125\n",
      "7.574199199676514 -40.14968490600586\n",
      "h\n",
      "18.00779914855957 11.00239086151123\n",
      "-3.845308303833008 -25.69446563720703\n",
      "h\n",
      "16.74390411376953 11.326934814453125\n",
      "-5.264564514160156 23.29741859436035\n",
      "h\n",
      "15.607980728149414 8.785783767700195\n",
      "4.279184341430664 21.17559242248535\n",
      "h\n",
      "15.31121826171875 10.23464584350586\n",
      "-1.3506779670715332 35.27305603027344\n",
      "h\n",
      "16.545787811279297 9.748418807983398\n",
      "5.1703362464904785 -14.891695022583008\n",
      "h\n",
      "15.641013145446777 12.105112075805664\n",
      "-4.339848518371582 -2.8296098709106445\n",
      "h\n",
      "17.89249610900879 9.464522361755371\n",
      "2.066053867340088 38.74785232543945\n",
      "h\n",
      "16.218936920166016 9.47114086151123\n",
      "-5.354866027832031 16.037155151367188\n",
      "h\n",
      "14.24139404296875 8.756010055541992\n",
      "4.923202991485596 41.001220703125\n",
      "h\n",
      "14.029823303222656 6.8785505294799805\n",
      "6.097702980041504 43.89731979370117\n",
      "h\n",
      "17.364980697631836 8.91641616821289\n",
      "-0.628294825553894 36.6123161315918\n",
      "h\n",
      "18.27509307861328 12.241517066955566\n",
      "3.087888240814209 -33.56169128417969\n",
      "h\n",
      "14.829706192016602 5.538116931915283\n",
      "0.1917802095413208 50.553794860839844\n",
      "h\n",
      "15.466934204101562 10.313305854797363\n",
      "1.0343191623687744 -2.2826528549194336\n",
      "h\n",
      "16.935216903686523 7.608884811401367\n",
      "-2.2093348503112793 -3.8333492279052734\n",
      "h\n",
      "17.26114273071289 10.614680290222168\n",
      "4.5497636795043945 -34.496795654296875\n",
      "h\n",
      "15.367265701293945 7.916478157043457\n",
      "0.17589432001113892 5.268338203430176\n",
      "h\n",
      "16.1202335357666 7.427145957946777\n",
      "6.865468978881836 32.02280807495117\n",
      "h\n",
      "14.906461715698242 7.238569736480713\n",
      "1.9232205152511597 34.59309768676758\n",
      "h\n",
      "14.982187271118164 10.453558921813965\n",
      "-3.2551188468933105 -41.273555755615234\n",
      "h\n",
      "15.953706741333008 9.514832496643066\n",
      "-11.219736099243164 27.329790115356445\n",
      "h\n",
      "16.191654205322266 11.261881828308105\n",
      "-25.088703155517578 -26.26083755493164\n",
      "h\n",
      "12.981090545654297 4.800163745880127\n",
      "6.47797966003418 -29.343719482421875\n",
      "h\n",
      "12.702577590942383 5.3510541915893555\n",
      "0.045181989669799805 27.955537796020508\n",
      "h\n",
      "18.05076026916504 8.262930870056152\n",
      "-26.727258682250977 -20.908039093017578\n",
      "h\n",
      "13.114811897277832 8.236100196838379\n",
      "6.163795471191406 -10.405448913574219\n",
      "h\n",
      "11.184981346130371 5.477569580078125\n",
      "-0.823401689529419 -37.131561279296875\n",
      "h\n",
      "12.11019515991211 5.487217426300049\n",
      "6.398008823394775 1.1598834991455078\n",
      "h\n",
      "13.631156921386719 5.005945205688477\n",
      "-1.3013010025024414 -35.36598205566406\n",
      "h\n",
      "14.353663444519043 9.097090721130371\n",
      "-4.851175785064697 35.707313537597656\n",
      "h\n",
      "17.855365753173828 8.765284538269043\n",
      "-5.845831871032715 34.547393798828125\n",
      "h\n",
      "14.91015911102295 8.219558715820312\n",
      "-26.652511596679688 -9.593456268310547\n",
      "h\n",
      "13.329482078552246 9.186090469360352\n",
      "-2.7445895671844482 -38.9617805480957\n",
      "h\n",
      "12.575907707214355 3.318831443786621\n",
      "-2.0611305236816406 -0.8795684576034546\n",
      "h\n",
      "15.52709674835205 7.9920525550842285\n",
      "-2.611707925796509 28.657346725463867\n",
      "h\n",
      "15.117034912109375 8.496362686157227\n",
      "0.487715482711792 -22.42041778564453\n",
      "h\n",
      "16.837112426757812 9.816349029541016\n",
      "-7.890166282653809 -30.835987091064453\n",
      "h\n",
      "15.798788070678711 9.763764381408691\n",
      "3.669558525085449 22.46722984313965\n",
      "h\n",
      "16.238201141357422 7.920373439788818\n",
      "-2.11696195602417 36.563568115234375\n",
      "h\n",
      "14.977234840393066 7.65087366104126\n",
      "-13.844106674194336 51.51967239379883\n",
      "h\n",
      "13.773504257202148 8.524214744567871\n",
      "2.0446596145629883 5.833892822265625\n",
      "h\n",
      "13.961038589477539 9.59559440612793\n",
      "-16.38018798828125 -35.64924621582031\n",
      "h\n",
      "13.866863250732422 10.403433799743652\n",
      "0.18948078155517578 -5.849045276641846\n",
      "h\n",
      "16.57666015625 6.441707611083984\n",
      "4.734696388244629 52.837406158447266\n",
      "h\n",
      "14.015767097473145 7.827755928039551\n",
      "-5.012124061584473 -50.24174880981445\n",
      "h\n",
      "14.888607025146484 8.124990463256836\n",
      "-4.5537614822387695 27.047649383544922\n",
      "h\n",
      "13.07066535949707 5.752313613891602\n",
      "-13.06021499633789 7.693819522857666\n",
      "h\n",
      "14.98537826538086 8.10573959350586\n",
      "4.445674419403076 -6.269136428833008\n",
      "h\n",
      "16.95366859436035 10.334005355834961\n",
      "3.146125316619873 -22.511152267456055\n",
      "h\n",
      "17.195240020751953 10.66891098022461\n",
      "-5.892423152923584 0.8991451263427734\n",
      "h\n",
      "17.33126449584961 12.410531044006348\n",
      "-11.9546480178833 -55.83887481689453\n",
      "h\n",
      "16.502975463867188 12.980813026428223\n",
      "0.5605758428573608 -28.651676177978516\n",
      "h\n",
      "14.320621490478516 5.762042045593262\n",
      "-5.752760887145996 -46.874881744384766\n",
      "h\n",
      "12.848661422729492 6.104880332946777\n",
      "-10.425561904907227 -18.884552001953125\n",
      "h\n",
      "16.39776039123535 7.390601634979248\n",
      "0.17546308040618896 -40.02701187133789\n",
      "h\n",
      "16.6684513092041 10.163793563842773\n",
      "9.735057830810547 -4.866774559020996\n",
      "h\n",
      "14.368732452392578 7.548228740692139\n",
      "-4.609913349151611 -36.13181686401367\n",
      "h\n",
      "15.064282417297363 8.308619499206543\n",
      "2.828176498413086 -43.8228874206543\n",
      "h\n",
      "15.272117614746094 7.513121128082275\n",
      "-1.9908170700073242 25.334665298461914\n",
      "h\n",
      "14.374013900756836 5.310833930969238\n",
      "2.037912368774414 61.625709533691406\n",
      "h\n",
      "15.859074592590332 8.208483695983887\n",
      "-5.304727554321289 3.60602068901062\n",
      "h\n",
      "17.013866424560547 8.498764038085938\n",
      "3.4107937812805176 -12.180163383483887\n",
      "h\n",
      "11.89676284790039 7.33900260925293\n",
      "3.0724446773529053 35.774662017822266\n",
      "h\n",
      "14.052923202514648 5.363186359405518\n",
      "-1.5547268390655518 47.63958740234375\n",
      "h\n",
      "19.005756378173828 13.246550559997559\n",
      "1.1653929948806763 6.207075595855713\n",
      "h\n",
      "17.389223098754883 13.453790664672852\n",
      "1.821940302848816 -13.385778427124023\n",
      "h\n",
      "17.68056869506836 5.611257553100586\n",
      "9.42885971069336 9.587654113769531\n",
      "h\n",
      "14.44775104522705 10.439446449279785\n",
      "29.327693939208984 18.844890594482422\n",
      "h\n",
      "11.746161460876465 5.573391914367676\n",
      "-5.846700191497803 -9.517237663269043\n",
      "h\n",
      "11.99139404296875 7.325329780578613\n",
      "-10.146591186523438 -25.697967529296875\n",
      "h\n",
      "16.178407669067383 9.0160551071167\n",
      "6.311351776123047 6.120110034942627\n",
      "h\n",
      "17.384723663330078 8.490104675292969\n",
      "3.763883590698242 -19.53798484802246\n",
      "h\n",
      "14.345429420471191 8.967655181884766\n",
      "-0.42703962326049805 -25.33700180053711\n",
      "h\n",
      "14.806262016296387 4.610994338989258\n",
      "-1.4173917770385742 5.9518938064575195\n",
      "h\n",
      "16.100406646728516 10.995957374572754\n",
      "-1.6567704677581787 10.212364196777344\n",
      "h\n",
      "17.979389190673828 7.976305961608887\n",
      "1.6969459056854248 -45.14743423461914\n",
      "h\n",
      "12.717581748962402 5.667555332183838\n",
      "3.310988187789917 17.849430084228516\n",
      "h\n",
      "13.893537521362305 5.038000583648682\n",
      "-3.183180332183838 -8.53040885925293\n",
      "h\n",
      "15.307296752929688 7.891786575317383\n",
      "5.204636573791504 -19.465051651000977\n",
      "h\n",
      "12.196322441101074 3.679227828979492\n",
      "0.5914669036865234 -50.718353271484375\n",
      "h\n",
      "13.329482078552246 9.186090469360352\n",
      "-2.7445895671844482 -38.9617805480957\n",
      "h\n",
      "12.575907707214355 3.318831443786621\n",
      "-2.0611305236816406 -0.8795684576034546\n",
      "h\n",
      "12.203004837036133 6.083037853240967\n",
      "-1.0008347034454346 23.98700714111328\n",
      "h\n",
      "14.704365730285645 7.946584701538086\n",
      "-0.016435742378234863 -14.676387786865234\n",
      "h\n",
      "15.698116302490234 6.560624122619629\n",
      "4.125256061553955 2.9740285873413086\n",
      "h\n",
      "14.413520812988281 7.559412956237793\n",
      "-18.824169158935547 36.48233413696289\n",
      "h\n",
      "15.054311752319336 7.013485431671143\n",
      "-0.33341383934020996 32.88636016845703\n",
      "h\n",
      "14.400745391845703 8.226999282836914\n",
      "-2.319897174835205 16.9798583984375\n",
      "h\n",
      "16.742595672607422 9.596820831298828\n",
      "-4.120171070098877 -10.617629051208496\n",
      "h\n",
      "14.751602172851562 6.340147018432617\n",
      "12.920976638793945 5.698291778564453\n",
      "h\n",
      "14.489692687988281 5.523256778717041\n",
      "-6.964242935180664 15.203484535217285\n",
      "h\n",
      "14.315783500671387 6.335674285888672\n",
      "7.384576320648193 -5.65513277053833\n",
      "h\n",
      "12.951492309570312 4.968156337738037\n",
      "-0.3871188163757324 15.705499649047852\n",
      "h\n",
      "13.207586288452148 4.612159729003906\n",
      "-23.842777252197266 -11.337262153625488\n",
      "h\n",
      "16.299503326416016 9.718326568603516\n",
      "3.4221134185791016 -28.932390213012695\n",
      "h\n",
      "14.449541091918945 11.833253860473633\n",
      "-3.2021055221557617 -35.85157012939453\n",
      "h\n",
      "15.706313133239746 6.989566326141357\n",
      "4.806384086608887 -6.323780059814453\n",
      "h\n",
      "15.175418853759766 8.616482734680176\n",
      "-1.0566871166229248 -21.671432495117188\n",
      "h\n",
      "15.926142692565918 9.8261137008667\n",
      "2.6988489627838135 15.621175765991211\n",
      "h\n",
      "17.27912712097168 11.191543579101562\n",
      "5.8326616287231445 -13.644901275634766\n",
      "h\n",
      "16.545787811279297 9.748418807983398\n",
      "5.1703362464904785 -14.891695022583008\n",
      "h\n",
      "15.641013145446777 12.105112075805664\n",
      "-4.339848518371582 -2.8296098709106445\n",
      "h\n",
      "15.317859649658203 9.43427848815918\n",
      "0.5738344192504883 15.901336669921875\n",
      "h\n",
      "13.300771713256836 7.8972930908203125\n",
      "0.8151917457580566 -12.686817169189453\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(len(replace_corrects)):\n",
    "    replace_diff = -torch.tensor(replace_corrects[i]) + torch.tensor(replace_replaces[i])\n",
    "    n_correct = torch.sum(replace_diff > 0)\n",
    "    print(f\"{n_correct}/{len(replace_corrects[i])}\")\n",
    "    print(f'replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "\n",
    "    for j in range(len(replace_corrects[i])):\n",
    "        print(\"h\")\n",
    "        print(original_corrects[i][j], original_replaces[i][j])\n",
    "        print(replace_corrects[i][j], replace_replaces[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd4e2e-ae43-403d-9410-ad374a7ce622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
