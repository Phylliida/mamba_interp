{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2150298-45a8-4a12-84ef-a4a42ccb7b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fc8577db640>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requires\n",
    "# pip install git+https://github.com/Phylliida/MambaLens.git\n",
    "\n",
    "# do PCA (and projective PCA?)\n",
    "# todo: for each name look at its PCA (make a colored graph for different components?)\n",
    "# train projection from PCA space to classifier space?\n",
    "\n",
    "from mamba_lens import HookedMamba # this will take a little while to import\n",
    "import torch\n",
    "model_path = \"state-spaces/mamba-370m\"\n",
    "model = HookedMamba.from_pretrained(model_path, device='cuda')\n",
    "torch.set_grad_enabled(False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29eba0c2-102b-4450-ad2f-7c9fce14cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to do\n",
    "# pip install -e .\n",
    "# in the root directory of this repo\n",
    "# also\n",
    "# to install graphviz:\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install graphviz xdg-utils\n",
    "\n",
    "from acdc.data.ioi import ioi_data_generator, ABC_TEMPLATES, get_all_single_name_abc_patching_formats\n",
    "from acdc.data.utils import generate_dataset\n",
    "\n",
    "num_patching_pairs = 10000\n",
    "seed = 27\n",
    "valid_seed = 28\n",
    "constrain_to_answers = True\n",
    "has_symmetric_patching = True\n",
    "\n",
    "from acdc.data.ioi import BABA_TEMPLATES\n",
    "#templates = [BABA_TEMPLATES[1]]\n",
    "templates = ABC_TEMPLATES\n",
    "patching_formats = list(get_all_single_name_abc_patching_formats())\n",
    "'''\n",
    "patching_formats = [\n",
    "    'AB A B\\nAC A C', # 85, \n",
    "    #'AB A B\\nCB C B', # 66\n",
    "    #'AB B A\\nAC C A', # 74\n",
    "    #'AB B A\\nCB B C' # 85\n",
    "]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "data = generate_dataset(model=model,\n",
    "                  data_generator=ioi_data_generator,\n",
    "                  num_patching_pairs=num_patching_pairs,\n",
    "                  seed=seed,\n",
    "                  valid_seed=valid_seed,\n",
    "                  constrain_to_answers=constrain_to_answers,\n",
    "                  has_symmetric_patching=has_symmetric_patching, \n",
    "                  varying_data_lengths=True,\n",
    "                  templates=templates,\n",
    "                  patching_formats=patching_formats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284e540-c8bd-4153-b272-1ed5f4cdd57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9bdd55cd3140e0873a5d93490da6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted [(39, 0.825), (23, 0.055), (47, 0.055), (46, 0.055), (45, 0.055), (33, 0.055), (25, 0.055), (24, 0.055), (0, 0.055), (19, 0.055), (18, 0.055), (17, 0.055), (16, 0.055), (11, 0.055), (10, 0.055), (7, 0.055), (28, 0.0525)]\n",
      "not patching layer 39\n",
      "baseline 0.825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdeac99c903d4b22abc7fca40a7e7b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted [(47, 0.855), (17, 0.84), (19, 0.8375), (10, 0.835), (16, 0.8325), (24, 0.8325), (25, 0.8325), (0, 0.83), (7, 0.8275), (11, 0.8275), (33, 0.8275), (45, 0.8275), (18, 0.825), (46, 0.825), (28, 0.8175), (23, 0.8075)]\n",
      "not patching layer 47\n",
      "baseline 0.855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcc5d2d8d904191a1c96c1e96f20673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted [(19, 0.865), (11, 0.8575), (25, 0.8575), (28, 0.8575), (7, 0.855), (10, 0.855), (17, 0.855), (33, 0.855), (16, 0.8525), (24, 0.8525), (0, 0.85), (46, 0.85), (18, 0.8475), (45, 0.8475), (23, 0.8425)]\n",
      "not patching layer 19\n",
      "baseline 0.865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254f622a2c28466da0bef03465646973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from mamba_lens.input_dependent_hooks import clean_hooks\n",
    "from acdc import accuracy_metric\n",
    "from acdc import ACDCEvalData\n",
    "from acdc import get_pad_token\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "'''\n",
    "patching_formats = [\n",
    "    'AB A B\\nAC A C', # 85, \n",
    "    #'AB A B\\nCB C B', # 66 bad, need to change the output\n",
    "    #'AB B A\\nAC C A', # 74 bad, need to change the output\n",
    "    'AB B A\\nCB B C' # 85\n",
    "]\n",
    "'''\n",
    "patching_formats = list(get_all_single_name_abc_patching_formats())\n",
    "templates = ABC_TEMPLATES\n",
    "\n",
    "model_kwargs = {\n",
    "    \"fast_ssm\": True,\n",
    "    \"fast_conv\": False,\n",
    "}\n",
    "\n",
    "all_important_layers = defaultdict(lambda: defaultdict(lambda: []))\n",
    "#patching_formats = list(get_all_single_name_abc_patching_formats())\n",
    "scores = torch.zeros([len(templates), len(patching_formats)])\n",
    "template_to_i = dict([(t,i) for (i,t) in enumerate(templates)])\n",
    "patching_to_i = dict([(t,i) for (i,t) in enumerate(patching_formats)])\n",
    "\n",
    "num_patching_pairs = 200\n",
    "limited_layers  = [0, 7, 10, 11, 16, 17, 18, 19, 23, 24, 25, 28, 33, 39, 45, 46, 47]\n",
    "#limited_layers = list(range(model.cfg.n_layers))\n",
    "\n",
    "def patch_layer_hook(\n",
    "    h: Float[torch.Tensor, \"B E N\"],\n",
    "    hook: HookPoint,\n",
    ") -> Float[torch.Tensor, \"B E N\"]:\n",
    "    # patch in corrupted (they come in pairs)\n",
    "    for i in range(0, h.size()[0], 2):\n",
    "        h[i] = h[i+1]\n",
    "    return h\n",
    "\n",
    "def hooks_to_remove_token_cross_talk(layers):\n",
    "    # remove conv cross talk\n",
    "    hooks = []\n",
    "    \n",
    "    for layer in layers:\n",
    "        L = data.data.size()[1]\n",
    "        hooks.append((f\"blocks.{layer}.hook_conv\", patch_layer_hook))\n",
    "        #for l in range(L):\n",
    "        #    hooks.append((f\"blocks.{layer}.hook_h.{l}\", patch_layer_hook))\n",
    "    return hooks\n",
    "\n",
    "for template, patching_format in itertools.product(templates, patching_formats):\n",
    "    \n",
    "    data = generate_dataset(model=model,\n",
    "                      data_generator=ioi_data_generator,\n",
    "                      num_patching_pairs=num_patching_pairs,\n",
    "                      seed=seed,\n",
    "                      valid_seed=valid_seed,\n",
    "                      constrain_to_answers=constrain_to_answers,\n",
    "                      has_symmetric_patching=has_symmetric_patching, \n",
    "                      varying_data_lengths=True,\n",
    "                      templates=[template],\n",
    "                      patching_formats=[patching_format])\n",
    "    \n",
    "    clean_hooks(model)\n",
    "    def top_is_correct_metric(data: ACDCEvalData):\n",
    "        return data.patched.top_is_correct\n",
    "    #limited_layers = [0, 7, 10, 11, 16, 17, 18, 19, 23, 24, 25, 28, 33, 39, 45, 46, 47]\n",
    "    from functools import partial\n",
    "    def wrap_run_with_hooks(model, fwd_hooks, bwd_hooks=[], **kwargs):\n",
    "        '''\n",
    "        Makes a fake object that acts like model\n",
    "        but when you call it it'll actually call run_with_hooks with the provided hooks\n",
    "        '''\n",
    "        def wrapper(input, fwd_hooks, bwd_hooks):\n",
    "            #print(f\"running model with {len(fwd_hooks)} fwd hooks and {len(bwd_hooks)} bwd hooks\")\n",
    "            return model.run_with_hooks(input, only_use_these_layers=limited_layers, fwd_hooks=fwd_hooks, bwd_hooks=bwd_hooks, **kwargs)\n",
    "        wrapper_with_hooks = partial(wrapper, fwd_hooks=fwd_hooks, bwd_hooks=bwd_hooks)\n",
    "        wrapper_with_hooks.tokenizer = model.tokenizer\n",
    "        wrapper_with_hooks.cfg = model.cfg\n",
    "        return wrapper_with_hooks\n",
    "\n",
    "    def eval_layers(model, layers_to_patch):\n",
    "        model_wrapped = wrap_run_with_hooks(model, fwd_hooks=hooks_to_remove_token_cross_talk(layers=layers_to_patch), **model_kwargs)        \n",
    "        top_is_correct = data.eval(model=model_wrapped, batch_size=100, metric=top_is_correct_metric)\n",
    "        accuracy = top_is_correct.sum().item()/top_is_correct.size()[0]\n",
    "        return accuracy\n",
    "\n",
    "    important_layers = []\n",
    "    layers_patching = copy.deepcopy(limited_layers)\n",
    "    while True:\n",
    "        baseline_acc = eval_layers(model, layers_to_patch=layers_patching)\n",
    "        print(\"baseline\", baseline_acc)\n",
    "        accuracies = []\n",
    "        for layer in tqdm(layers_patching):\n",
    "            layers_except = copy.deepcopy(layers_patching)\n",
    "            layers_except.remove(layer)\n",
    "            acc_if_not_patching = eval_layers(model, layers_to_patch=layers_except)\n",
    "            accuracies.append(acc_if_not_patching)\n",
    "        inds = torch.argsort(-torch.tensor(accuracies))\n",
    "        # the highest accuracy is the change we want to do\n",
    "        print(f\"sorted\", [(layers_patching[i], accuracies[i]) for i in inds])\n",
    "        important_layer = layers_patching[inds[0]]\n",
    "        print(f\"not patching layer {important_layer}\")\n",
    "        layers_patching.remove(important_layer)\n",
    "        important_layers.append((accuracies[inds[0]], important_layer))\n",
    "        if accuracies[inds[0]] > 0.92:\n",
    "            break\n",
    "    print(f\"template: {template}\")\n",
    "    print(f\"patching format:\")\n",
    "    print(patching_format)\n",
    "    print(f\"important layers\", important_layers)\n",
    "    all_important_layers[template_to_i[template]][patching_to_i[patching_format]] = important_layers\n",
    "\n",
    "'''\n",
    "sorted [(39, 0.8525), (10, 0.05), (11, 0.05), (45, 0.05), (25, 0.05), (47, 0.0475), (16, 0.0475), (17, 0.0475), (18, 0.0475), (46, 0.0475), (0, 0.0475), (28, 0.0475), (33, 0.0475), (23, 0.045), (24, 0.045), (19, 0.045), (7, 0.045)]\n",
    "not patching layer 39\n",
    "baseline 0.8525\n",
    "\n",
    "100%\n",
    "16/16 [00:33<00:00, 2.09s/it]\n",
    "\n",
    "sorted [(47, 0.875), (19, 0.87), (28, 0.8625), (0, 0.86), (45, 0.8575), (16, 0.855), (10, 0.8525), (17, 0.8525), (18, 0.8525), (24, 0.8525), (7, 0.85), (33, 0.85), (11, 0.8475), (25, 0.8475), (46, 0.8475), (23, 0.8425)]\n",
    "not patching layer 47\n",
    "baseline 0.875\n",
    "\n",
    "100%\n",
    "15/15 [00:30<00:00, 2.03s/it]\n",
    "\n",
    "sorted [(19, 0.8975), (0, 0.8875), (16, 0.8825), (28, 0.8825), (17, 0.88), (24, 0.88), (25, 0.88), (46, 0.88), (11, 0.8775), (33, 0.8775), (10, 0.875), (45, 0.875), (7, 0.8725), (18, 0.8725), (23, 0.87)]\n",
    "not patching layer 19\n",
    "baseline 0.8975\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "226e8048-7de9-4d8d-94a8-e31b1affc4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to",
          "Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to",
          "After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to",
          "While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to",
          "While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to",
          "After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to",
          "The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to",
          "Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to"
         ],
         "xaxis": "x",
         "y": [
          "AB A B\nAC A C",
          "AB A B\nCB C B",
          "AB B A\nAC C A",
          "AB B A\nCB B C"
         ],
         "yaxis": "y",
         "z": [
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "font": {
         "color": "black",
         "size": 7
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.049581005586592175,
          0.9504189944134078
         ],
         "range": [
          -0.5,
          14.5
         ],
         "scaleanchor": "y",
         "tickmode": "array",
         "ticktext": [
          "Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to",
          "Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to",
          "After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to",
          "While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to",
          "While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to",
          "After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to",
          "The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to",
          "Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to"
         ],
         "tickvals": [
          "Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to",
          "Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to",
          "After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to",
          "When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to",
          "While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to",
          "While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to",
          "After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to",
          "Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to",
          "The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to",
          "Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to"
         ],
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          3.5,
          -0.5
         ],
         "tickmode": "array",
         "ticktext": [
          "AB A B\nAC A C",
          "AB A B\nCB C B",
          "AB B A\nAC C A",
          "AB B A\nCB B C"
         ],
         "tickvals": [
          "AB A B\nAC A C",
          "AB A B\nCB C B",
          "AB B A\nAC C A",
          "AB B A\nCB B C"
         ],
         "type": "category"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"a845914d-b3af-4703-8073-212be6790b95\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a845914d-b3af-4703-8073-212be6790b95\")) {                    Plotly.newPlot(                        \"a845914d-b3af-4703-8073-212be6790b95\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to\",\"Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to\",\"After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to\",\"While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to\",\"While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to\",\"After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to\",\"The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to\",\"Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to\"],\"y\":[\"AB A B\\nAC A C\",\"AB A B\\nCB C B\",\"AB B A\\nAC C A\",\"AB B A\\nCB B C\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"tickmode\":\"array\",\"tickvals\":[\"Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to\",\"Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to\",\"After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to\",\"While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to\",\"While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to\",\"After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to\",\"The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to\",\"Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to\"],\"ticktext\":[\"Then, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a lot of fun at the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] were working at the [PLACE]. [NAME] decided to give a [OBJECT] to\",\"Then, [NAME] and [NAME] were thinking about going to the [PLACE]. [NAME] wanted to give a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument, and afterwards [NAME] said to\",\"After [NAME] and [NAME] went to the [PLACE], [NAME] gave a [OBJECT] to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give it to\",\"When [NAME] and [NAME] got a [OBJECT] at the [PLACE], [NAME] decided to give the [OBJECT] to\",\"While [NAME] and [NAME] were working at the [PLACE], [NAME] gave a [OBJECT] to\",\"While [NAME] and [NAME] were commuting to the [PLACE], [NAME] gave a [OBJECT] to\",\"After the lunch, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Afterwards, [NAME] and [NAME] went to the [PLACE]. [NAME] gave a [OBJECT] to\",\"Then, [NAME] and [NAME] had a long argument. Afterwards [NAME] said to\",\"The [PLACE] [NAME] and [NAME] went to had a [OBJECT]. [NAME] gave it to\",\"Friends [NAME] and [NAME] found a [OBJECT] at the [PLACE]. [NAME] gave it to\"]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"tickmode\":\"array\",\"tickvals\":[\"AB A B\\nAC A C\",\"AB A B\\nCB C B\",\"AB B A\\nAC C A\",\"AB B A\\nCB B C\"],\"ticktext\":[\"AB A B\\nAC A C\",\"AB A B\\nCB C B\",\"AB B A\\nAC C A\",\"AB B A\\nCB B C\"]},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"margin\":{\"t\":60},\"font\":{\"size\":7,\"color\":\"black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a845914d-b3af-4703-8073-212be6790b95');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import transformer_lens.utils as utils\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", font_size=None, show=True, color_continuous_midpoint=0.0, **kwargs):\n",
    "    fig = px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=color_continuous_midpoint, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs)\n",
    "    if not font_size is None:\n",
    "        if 'x' in kwargs:\n",
    "            fig.update_layout(\n",
    "              xaxis = dict(\n",
    "                tickmode='array',\n",
    "                tickvals = kwargs['x'],\n",
    "                ticktext = kwargs['x'], \n",
    "                ),\n",
    "               font=dict(size=font_size, color=\"black\"))\n",
    "        if 'y' in kwargs:\n",
    "            fig.update_layout(\n",
    "              yaxis = dict(\n",
    "                tickmode='array',\n",
    "                tickvals = kwargs['y'],\n",
    "                ticktext = kwargs['y'], \n",
    "                ),\n",
    "               font=dict(size=font_size, color=\"black\"))\n",
    "    if show:\n",
    "        fig.show(renderer)\n",
    "    else:\n",
    "        return fig\n",
    "\n",
    "imshow(scores[:len(BABA_TEMPLATES)].T, x=BABA_TEMPLATES, y=patching_formats, font_size=7, color_continuous_midpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19a57466-f934-4acd-b912-869aa8898ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from einops import rearrange\n",
    "global storage\n",
    "storage = {}\n",
    "\n",
    "def in_proj_stofrage_hook(\n",
    "    in_proj: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    global storage\n",
    "    storage[\"in_proj\"] = in_proj\n",
    "\n",
    "def ignore_conv_crfoss_talk_hook(\n",
    "    x_conv: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint,\n",
    "    layer: int,\n",
    ") -> Float[torch.Tensor, \"B L E\"]:    \n",
    "    D_CONV = model.cfg.d_conv\n",
    "    global storage\n",
    "    conv_input = storage[\"in_proj\"]\n",
    "    B, L, E = conv_input.size()\n",
    "    conv_input = rearrange(conv_input, 'B L E -> B E L')\n",
    "    \n",
    "    ### This is identical to what the conv is doing\n",
    "    # pad zeros in front\n",
    "    # [B,E,D_CONV-1+L]\n",
    "    padded_input = torch.nn.functional.pad(conv_input, (D_CONV-1,0), mode='constant', value=0)\n",
    "    output = torch.zeros([B,E,L], device=model.cfg.device)\n",
    "    # [E,1,D_CONV]\n",
    "    conv_weight = model.blocks[layer].conv1d.weight\n",
    "    # [E]\n",
    "    conv_bias = model.blocks[layer].conv1d.bias\n",
    "    for i in range(D_CONV):\n",
    "        #                 [E]                    [B,E,L]\n",
    "        #output += conv_weight[:,0,i].view(E,1)*padded_input[:,:,i:i+L] # this is what conv is doing\n",
    "        output += conv_weight[:,0,i].view(E,1)*conv_input\n",
    "        #if i == D_CONV-1:\n",
    "        #    output += conv_weight[:,0,i].view(E,1)*conv_input\n",
    "    \n",
    "    output += conv_bias.view(E, 1)\n",
    "    \n",
    "    output = rearrange(output, 'B E L -> B L E')\n",
    "    return output\n",
    "\n",
    "\n",
    "def ssm_input_stofrage_hook(\n",
    "    ssm_input: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    global storage\n",
    "    storage[\"ssm_input\"] = ssm_input\n",
    "    return ssm_input\n",
    "\n",
    "global storage\n",
    "def B_bar_storfage_hook(\n",
    "    B_bar: Float[torch.Tensor, \"B L E N\"],\n",
    "    hook: HookPoint,\n",
    ") -> Float[torch.Tensor, \"B L E N\"]:\n",
    "    global storage\n",
    "    storage['B_bar'] = B_bar\n",
    "    return B_bar\n",
    "\n",
    "def h_no_token_crofss_talk_hook(\n",
    "    h: Float[torch.Tensor, \"B E N\"],\n",
    "    hook: HookPoint,\n",
    "    position: int,\n",
    ") -> Float[torch.Tensor, \"B E N\"]:\n",
    "    B,E,N = h.size()\n",
    "    # [B E N]\n",
    "    global storage\n",
    "    B_bar = storage['B_bar'][:,position,:,:]\n",
    "    # [B E 1]\n",
    "    x = storage['ssm_input'][:,position].view(B,E,1)\n",
    "    my_contribution = B_bar*x\n",
    "    #corrupted_\n",
    "    return B_bar*x\n",
    "\n",
    "# doesn't work, 0.2 accuracy\n",
    "def skip_ssm_hfook(\n",
    "    y: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    global ssm_input_storage\n",
    "    return ssm_input_storage[\"ssm_input\"]\n",
    "\n",
    "# 80%\n",
    "def patch_ssm_hofok(\n",
    "    y: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    y[0::2] = y[1::2]\n",
    "    return y\n",
    "\n",
    "# 85%\n",
    "def patch_h_hofok(\n",
    "    h: Float[torch.Tensor, \"B E N\"],\n",
    "    hook: HookPoint,\n",
    "    position: int,\n",
    ") -> Float[torch.Tensor, \"B E N\"]:\n",
    "    corrupted = h[1::2]\n",
    "    h[0::2] = corrupted\n",
    "    return h\n",
    "\n",
    "class EmptyObject(object):\n",
    "    pass\n",
    "\n",
    "ssm_inputs_storage = EmptyObject()\n",
    "\n",
    "\n",
    "def ssm_infput_hook(\n",
    "    ssm_input: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint,\n",
    "    layer: int,\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    ssm_inputs_storage.ssm_input = ssm_input\n",
    "    return ssm_input\n",
    "\n",
    "def C_hofok(\n",
    "    C: Float[torch.Tensor, \"B L N\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L N\"]:\n",
    "    ssm_inputs_storage.C = C\n",
    "    return C\n",
    "\n",
    "def B_bar_hofok(\n",
    "    B_bar: Float[torch.Tensor, \"B L E N\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"B L E N\"]:\n",
    "    ssm_inputs_storage.B_bar = B_bar\n",
    "    return B_bar\n",
    "\n",
    "def ssm_outpuft_hook(\n",
    "    ssm_output: Float[torch.Tensor, \"B L E\"],\n",
    "    hook: HookPoint,\n",
    "    layer: int,\n",
    ") -> Float[torch.Tensor, \"B L E\"]:\n",
    "    # return ssm_output\n",
    "    # [B,L,E]\n",
    "    x = ssm_inputs_storage.ssm_input\n",
    "    B,L,E = x.size()\n",
    "    # [B,L,N]\n",
    "    C = ssm_inputs_storage.C\n",
    "    B,L,N = C.size()\n",
    "    # [B,L,E,N]\n",
    "    B_bar = ssm_inputs_storage.B_bar\n",
    "    output = torch.zeros((B,L,E), device=model.cfg.device)\n",
    "    for n in range(N):\n",
    "        #  [B,L,E]             [B,L,E]        [B,L,E]\n",
    "        h_contributions =   B_bar[:,:,:,n]   *   x\n",
    "        #[B,L,E]    [B,L,E]               [B,L,1]\n",
    "        output   +=  h_contributions *  C[:,:,n].view(B,L,1)\n",
    "        \n",
    "    #     [B,L,E]         [B,L,E]           [E]\n",
    "    return   output     +   x    *  model.blocks[layer].W_D\n",
    "\n",
    "def patch_layer_hook(\n",
    "    h: Float[torch.Tensor, \"B E N\"],\n",
    "    hook: HookPoint,\n",
    ") -> Float[torch.Tensor, \"B E N\"]:\n",
    "    # patch in corrupted (they come in pairs)\n",
    "    for i in range(0, h.size()[0], 2):\n",
    "        h[i] = h[i+1]\n",
    "    return h\n",
    "\n",
    "def hooks_to_remove_token_cross_talk(layers):\n",
    "    # remove conv cross talk\n",
    "    hooks = []\n",
    "    \n",
    "    for layer in layers:\n",
    "        L = data.data.size()[1]\n",
    "        hooks.append((f\"blocks.{layer}.hook_conv\", patch_layer_hook))\n",
    "        for l in range(L):\n",
    "            hooks.append((f\"blocks.{layer}.hook_h.{l}\", patch_layer_hook))\n",
    "    '''\n",
    "    for layer in layers:\n",
    "        #hooks.append((f\"blocks.{layer}.hook_in_proj\", in_proj_storage_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_conv\", partial(ignore_conv_cross_talk_hook, layer=layer)))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_conv\", patch_ssm_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_ssm_input\", ssm_input_storage_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_B_bar\", B_bar_storage_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_ssm_input\", partial(ssm_input_hook, layer=layer)))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_C\", C_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_B_bar\", B_bar_hook))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_ssm_output\", partial(ssm_output_hook, layer=layer)))\n",
    "        \n",
    "\n",
    "        \n",
    "        #L = data.data.size()[1]\n",
    "        for l in range(L):\n",
    "            #hooks.append((f\"blocks.{layer}.hook_h.{l}\", partial(h_no_token_cross_talk_hook, position=l)))\n",
    "            #hooks.append((f\"blocks.{layer}.hook_h.{l}\", partial(patch_h_hook, position=l)))\n",
    "            hooks.append((f\"blocks.{layer}.hook_h.{l}\", partial(patch_h_hook, position=l)))\n",
    "        #hooks.append((f\"blocks.{layer}.hook_ssm_input\", patch_h_hook))\n",
    "    '''\n",
    "    return hooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac732959-bdab-4903-8f05-97298bf467e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{50178, 46600, 31755, 46604, 10765, 11276, 33811, 46612, 16916, 18966, 12824, 32794, 7195, 33821, 37921, 33313, 31270, 29222, 28712, 18985, 37930, 28200, 7727, 24112, 36400, 32817, 5171, 44085, 35382, 14912, 30274, 20554, 15435, 33357, 49231, 38994, 21587, 7252, 40537, 27738, 44123, 44124, 14943, 45664, 15458, 49765, 19046, 35944, 29804, 23662, 37497, 22138, 27773, 28798, 33407, 27264, 9857, 14468, 6277, 35972, 4744, 32905, 32393, 22671, 20628, 32920, 17560, 5119, 21661, 16543, 31903, 18089, 16553, 28331, 41131, 20145, 46262, 30397, 41151, 22723, 23239, 14538, 17100, 37073, 22739, 49365, 16598, 47831, 31959, 22234, 23259, 20189, 45790, 29927, 46312, 31465, 46831, 31472, 29936, 26355, 6393, 26876, 8444, 26878, 6911, 25856, 21249, 19717, 8966, 38150, 26888, 27917, 39184, 48401, 24336, 6416, 23316, 37144, 31513, 42266, 29989, 27434, 45867, 36139, 29489, 27443, 27955, 22838, 7993, 13114, 13629, 28991, 40771, 25413, 44870, 18247, 47944, 35657, 26953, 13651, 27991, 26456, 48990, 34655, 16225, 28518, 20839, 43367, 10092, 11116, 31086, 29040, 50033, 5490, 39795, 48505, 40316, 24958, 38783, 19838, 23425, 24962, 13187, 49028, 12167, 43406, 14737, 18322, 43921, 12694, 16286, 48545, 29092, 15273, 16809, 22455, 24504, 30140, 27581, 21438, 35262, 36292, 6086, 21960, 20428, 17361, 33747, 2516, 13268, 45014, 25556, 33240, 36312, 16863, 28642, 10213, 16358, 25062, 23528, 35307, 19436, 25579, 15859, 38900, 7670, 8698, 12284, 44542, 31231}\n",
      "torch.Size([40000, 20])\n"
     ]
    }
   ],
   "source": [
    "from acdc.data.ioi import good_names\n",
    "from collections import defaultdict\n",
    "name_tokens = set([model.to_single_token(\" \" + name) for name in good_names])\\\n",
    "\n",
    "print(name_tokens)\n",
    "print(data.data.size())\n",
    "name_positions = defaultdict(lambda: [])\n",
    "for i in range(data.data.size()[0]):\n",
    "    prompt_tokens = data.data[i]\n",
    "    name_pos = 0\n",
    "    for i, tok in enumerate(prompt_tokens):\n",
    "        if tok.item() in name_tokens:\n",
    "            name_positions[name_pos].append(i) # +1 because conv\n",
    "            name_pos += 1\n",
    "    if name_pos != 5: raise ValueError(f\"data point {model.to_str_tokens(data)} does not have 5 names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a127f0f-b5db-415a-ab4f-7468f72dd099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "969917bf-e5cc-4b9c-b12c-c16a3fa6d3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2fafad053a434793c8118195acd55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7fc428aac790>, {0: {50178: 166, 46600: 186, 31755: 180, 46604: 212, 10765: 194, 11276: 236, 33811: 180, 46612: 224, 16916: 192, 18966: 176, 12824: 210, 32794: 170, 7195: 162, 33821: 174, 37921: 172, 33313: 206, 31270: 206, 29222: 182, 28712: 152, 18985: 190, 37930: 180, 28200: 206, 7727: 122, 24112: 196, 36400: 198, 32817: 238, 5171: 148, 44085: 210, 35382: 208, 14912: 198, 30274: 200, 20554: 148, 15435: 244, 33357: 170, 49231: 176, 38994: 182, 21587: 218, 7252: 146, 40537: 184, 27738: 224, 44123: 180, 44124: 220, 14943: 144, 45664: 194, 15458: 216, 49765: 194, 19046: 194, 35944: 204, 29804: 166, 23662: 220, 37497: 198, 22138: 216, 27773: 188, 28798: 172, 33407: 200, 27264: 162, 9857: 184, 14468: 206, 6277: 188, 35972: 164, 4744: 152, 32905: 198, 32393: 186, 22671: 172, 20628: 208, 32920: 352, 17560: 166, 5119: 134, 21661: 184, 16543: 180, 31903: 206, 18089: 184, 16553: 200, 28331: 188, 41131: 150, 20145: 204, 46262: 160, 30397: 206, 41151: 210, 22723: 198, 23239: 194, 14538: 172, 17100: 222, 37073: 172, 22739: 230, 49365: 146, 16598: 186, 47831: 196, 31959: 226, 22234: 244, 23259: 238, 20189: 178, 45790: 190, 29927: 230, 46312: 238, 31465: 170, 46831: 142, 31472: 174, 29936: 150, 26355: 142, 6393: 144, 26876: 208, 8444: 156, 26878: 192, 6911: 152, 25856: 174, 21249: 192, 19717: 196, 8966: 168, 38150: 180, 26888: 210, 27917: 188, 39184: 212, 48401: 118, 24336: 172, 6416: 178, 23316: 156, 37144: 146, 31513: 210, 42266: 184, 29989: 178, 27434: 210, 45867: 204, 36139: 228, 29489: 184, 27443: 206, 27955: 206, 22838: 178, 7993: 174, 13114: 168, 13629: 210, 28991: 182, 40771: 178, 25413: 226, 44870: 190, 18247: 230, 47944: 214, 35657: 174, 26953: 174, 13651: 236, 27991: 206, 26456: 216, 48990: 198, 34655: 176, 16225: 156, 28518: 142, 20839: 202, 43367: 250, 10092: 194, 11116: 164, 31086: 192, 29040: 204, 50033: 192, 5490: 210, 39795: 194, 48505: 162, 40316: 188, 24958: 212, 38783: 164, 19838: 208, 23425: 174, 24962: 188, 13187: 176, 49028: 210, 12167: 186, 43406: 198, 14737: 192, 18322: 164, 43921: 210, 12694: 204, 16286: 192, 48545: 202, 29092: 158, 15273: 200, 16809: 188, 22455: 132, 24504: 206, 30140: 210, 27581: 166, 21438: 196, 35262: 176, 36292: 194, 6086: 168, 21960: 198, 20428: 238, 17361: 228, 33747: 150, 2516: 246, 13268: 422, 45014: 170, 25556: 216, 33240: 222, 36312: 226, 16863: 184, 28642: 206, 10213: 184, 16358: 216, 25062: 176, 23528: 192, 35307: 218, 19436: 162, 25579: 188, 15859: 222, 38900: 138, 7670: 208, 8698: 194, 12284: 170, 44542: 184, 31231: 182}, 1: {50178: 226, 46600: 160, 31755: 178, 46604: 170, 10765: 218, 11276: 204, 33811: 172, 46612: 220, 16916: 154, 18966: 202, 12824: 208, 32794: 182, 7195: 194, 33821: 184, 37921: 184, 33313: 228, 31270: 172, 29222: 156, 28712: 166, 18985: 196, 37930: 194, 28200: 184, 7727: 182, 24112: 212, 36400: 214, 32817: 194, 5171: 200, 44085: 238, 35382: 184, 14912: 170, 30274: 186, 20554: 154, 15435: 150, 33357: 146, 49231: 224, 38994: 172, 21587: 150, 7252: 164, 40537: 218, 27738: 210, 44123: 170, 44124: 248, 14943: 226, 45664: 156, 15458: 202, 49765: 190, 19046: 218, 35944: 218, 29804: 176, 23662: 154, 37497: 204, 22138: 164, 27773: 200, 28798: 252, 33407: 190, 27264: 206, 9857: 168, 14468: 160, 6277: 152, 35972: 222, 4744: 186, 32905: 160, 32393: 224, 22671: 196, 20628: 202, 32920: 366, 17560: 178, 5119: 128, 21661: 226, 16543: 142, 31903: 230, 18089: 180, 16553: 184, 28331: 198, 41131: 184, 20145: 158, 46262: 198, 30397: 242, 41151: 216, 22723: 208, 23239: 212, 14538: 182, 17100: 192, 37073: 180, 22739: 222, 49365: 218, 16598: 128, 47831: 188, 31959: 198, 22234: 178, 23259: 164, 20189: 180, 45790: 210, 29927: 204, 46312: 204, 31465: 204, 46831: 180, 31472: 176, 29936: 118, 26355: 178, 6393: 224, 26876: 174, 8444: 190, 26878: 198, 6911: 162, 25856: 128, 21249: 158, 19717: 158, 8966: 192, 38150: 198, 26888: 204, 27917: 254, 39184: 174, 48401: 216, 24336: 178, 6416: 200, 23316: 174, 37144: 190, 31513: 194, 42266: 122, 29989: 196, 27434: 202, 45867: 170, 36139: 224, 29489: 192, 27443: 196, 27955: 190, 22838: 186, 7993: 184, 13114: 180, 13629: 198, 28991: 162, 40771: 194, 25413: 218, 44870: 198, 18247: 168, 47944: 176, 35657: 198, 26953: 190, 13651: 164, 27991: 226, 26456: 198, 48990: 170, 34655: 212, 16225: 186, 28518: 154, 20839: 194, 43367: 194, 10092: 192, 11116: 164, 31086: 218, 29040: 178, 50033: 176, 5490: 228, 39795: 156, 48505: 168, 40316: 194, 24958: 136, 38783: 180, 19838: 210, 23425: 196, 24962: 212, 13187: 198, 49028: 154, 12167: 214, 43406: 232, 14737: 212, 18322: 154, 43921: 202, 12694: 192, 16286: 156, 48545: 152, 29092: 226, 15273: 180, 16809: 204, 22455: 172, 24504: 166, 30140: 218, 27581: 178, 21438: 188, 35262: 150, 36292: 200, 6086: 172, 21960: 166, 20428: 190, 17361: 136, 33747: 182, 2516: 232, 13268: 376, 45014: 182, 25556: 194, 33240: 204, 36312: 246, 16863: 212, 28642: 208, 10213: 196, 16358: 200, 25062: 176, 23528: 206, 35307: 212, 19436: 168, 25579: 234, 15859: 200, 38900: 232, 7670: 162, 8698: 228, 12284: 246, 44542: 182, 31231: 176}, 2: {50178: 188, 46600: 186, 31755: 194, 46604: 214, 10765: 200, 11276: 160, 33811: 178, 46612: 236, 16916: 264, 18966: 214, 12824: 164, 32794: 234, 7195: 166, 33821: 190, 37921: 210, 33313: 202, 31270: 178, 29222: 156, 28712: 212, 18985: 214, 37930: 194, 28200: 174, 7727: 154, 24112: 184, 36400: 220, 32817: 206, 5171: 192, 44085: 194, 35382: 176, 14912: 194, 30274: 156, 20554: 160, 15435: 168, 33357: 172, 49231: 136, 38994: 216, 21587: 222, 7252: 182, 40537: 164, 27738: 178, 44123: 152, 44124: 156, 14943: 156, 45664: 158, 15458: 252, 49765: 216, 19046: 196, 35944: 210, 29804: 192, 23662: 170, 37497: 178, 22138: 174, 27773: 240, 28798: 152, 33407: 188, 27264: 196, 9857: 240, 14468: 162, 6277: 200, 35972: 174, 4744: 208, 32905: 184, 32393: 204, 22671: 210, 20628: 172, 32920: 388, 17560: 196, 5119: 172, 21661: 216, 16543: 216, 31903: 212, 18089: 156, 16553: 158, 28331: 200, 41131: 220, 20145: 150, 46262: 210, 30397: 168, 41151: 226, 22723: 206, 23239: 168, 14538: 184, 17100: 182, 37073: 180, 22739: 228, 49365: 156, 16598: 186, 47831: 238, 31959: 200, 22234: 212, 23259: 162, 20189: 238, 45790: 198, 29927: 258, 46312: 196, 31465: 144, 46831: 188, 31472: 230, 29936: 182, 26355: 248, 6393: 150, 26876: 188, 8444: 208, 26878: 206, 6911: 220, 25856: 192, 21249: 186, 19717: 152, 8966: 134, 38150: 168, 26888: 190, 27917: 134, 39184: 142, 48401: 180, 24336: 176, 6416: 212, 23316: 150, 37144: 216, 31513: 198, 42266: 230, 29989: 134, 27434: 154, 45867: 188, 36139: 250, 29489: 194, 27443: 178, 27955: 200, 22838: 194, 7993: 230, 13114: 172, 13629: 174, 28991: 204, 40771: 178, 25413: 224, 44870: 188, 18247: 206, 47944: 194, 35657: 182, 26953: 190, 13651: 182, 27991: 154, 26456: 156, 48990: 158, 34655: 214, 16225: 200, 28518: 162, 20839: 200, 43367: 206, 10092: 196, 11116: 250, 31086: 216, 29040: 258, 50033: 166, 5490: 168, 39795: 226, 48505: 196, 40316: 238, 24958: 196, 38783: 188, 19838: 196, 23425: 190, 24962: 172, 13187: 212, 49028: 222, 12167: 192, 43406: 168, 14737: 198, 18322: 184, 43921: 170, 12694: 164, 16286: 208, 48545: 180, 29092: 168, 15273: 164, 16809: 154, 22455: 162, 24504: 174, 30140: 218, 27581: 164, 21438: 206, 35262: 232, 36292: 174, 6086: 196, 21960: 124, 20428: 214, 17361: 204, 33747: 198, 2516: 124, 13268: 338, 45014: 236, 25556: 158, 33240: 158, 36312: 166, 16863: 178, 28642: 164, 10213: 186, 16358: 190, 25062: 176, 23528: 160, 35307: 166, 19436: 196, 25579: 196, 15859: 174, 38900: 210, 7670: 202, 8698: 164, 12284: 186, 44542: 216, 31231: 238}, 3: {50178: 188, 46600: 178, 31755: 192, 46604: 200, 10765: 204, 11276: 218, 33811: 198, 46612: 206, 16916: 192, 18966: 142, 12824: 216, 32794: 180, 7195: 188, 33821: 180, 37921: 168, 33313: 204, 31270: 194, 29222: 186, 28712: 160, 18985: 206, 37930: 204, 28200: 202, 7727: 126, 24112: 202, 36400: 170, 32817: 240, 5171: 156, 44085: 220, 35382: 190, 14912: 206, 30274: 178, 20554: 140, 15435: 188, 33357: 166, 49231: 184, 38994: 172, 21587: 202, 7252: 156, 40537: 196, 27738: 186, 44123: 160, 44124: 236, 14943: 156, 45664: 170, 15458: 202, 49765: 192, 19046: 188, 35944: 216, 29804: 198, 23662: 218, 37497: 220, 22138: 184, 27773: 176, 28798: 212, 33407: 226, 27264: 168, 9857: 208, 14468: 198, 6277: 170, 35972: 182, 4744: 146, 32905: 186, 32393: 202, 22671: 176, 20628: 218, 32920: 362, 17560: 164, 5119: 140, 21661: 182, 16543: 172, 31903: 212, 18089: 184, 16553: 194, 28331: 186, 41131: 178, 20145: 174, 46262: 168, 30397: 200, 41151: 202, 22723: 210, 23239: 206, 14538: 174, 17100: 204, 37073: 170, 22739: 238, 49365: 168, 16598: 152, 47831: 204, 31959: 232, 22234: 252, 23259: 194, 20189: 176, 45790: 188, 29927: 226, 46312: 210, 31465: 176, 46831: 158, 31472: 162, 29936: 150, 26355: 136, 6393: 150, 26876: 182, 8444: 152, 26878: 216, 6911: 162, 25856: 170, 21249: 186, 19717: 182, 8966: 166, 38150: 194, 26888: 210, 27917: 214, 39184: 186, 48401: 148, 24336: 170, 6416: 186, 23316: 170, 37144: 146, 31513: 222, 42266: 178, 29989: 188, 27434: 222, 45867: 212, 36139: 242, 29489: 170, 27443: 200, 27955: 216, 22838: 152, 7993: 174, 13114: 168, 13629: 212, 28991: 200, 40771: 170, 25413: 230, 44870: 168, 18247: 230, 47944: 208, 35657: 192, 26953: 196, 13651: 226, 27991: 202, 26456: 206, 48990: 182, 34655: 190, 16225: 132, 28518: 148, 20839: 192, 43367: 256, 10092: 212, 11116: 154, 31086: 226, 29040: 180, 50033: 182, 5490: 196, 39795: 176, 48505: 166, 40316: 206, 24958: 170, 38783: 164, 19838: 216, 23425: 172, 24962: 172, 13187: 170, 49028: 186, 12167: 218, 43406: 178, 14737: 218, 18322: 152, 43921: 236, 12694: 224, 16286: 204, 48545: 190, 29092: 188, 15273: 188, 16809: 182, 22455: 128, 24504: 190, 30140: 210, 27581: 180, 21438: 186, 35262: 166, 36292: 196, 6086: 166, 21960: 174, 20428: 234, 17361: 212, 33747: 144, 2516: 246, 13268: 432, 45014: 186, 25556: 214, 33240: 200, 36312: 234, 16863: 194, 28642: 194, 10213: 188, 16358: 222, 25062: 164, 23528: 206, 35307: 238, 19436: 162, 25579: 224, 15859: 208, 38900: 130, 7670: 202, 8698: 202, 12284: 174, 44542: 214, 31231: 184}, 4: {50178: 200, 46600: 186, 31755: 194, 46604: 200, 10765: 246, 11276: 184, 33811: 192, 46612: 238, 16916: 232, 18966: 224, 12824: 164, 32794: 232, 7195: 182, 33821: 180, 37921: 206, 33313: 230, 31270: 188, 29222: 148, 28712: 200, 18985: 222, 37930: 188, 28200: 168, 7727: 162, 24112: 178, 36400: 224, 32817: 204, 5171: 188, 44085: 204, 35382: 180, 14912: 156, 30274: 174, 20554: 160, 15435: 156, 33357: 180, 49231: 162, 38994: 202, 21587: 216, 7252: 172, 40537: 176, 27738: 198, 44123: 158, 44124: 198, 14943: 174, 45664: 174, 15458: 240, 49765: 214, 19046: 228, 35944: 230, 29804: 158, 23662: 166, 37497: 168, 22138: 170, 27773: 258, 28798: 170, 33407: 164, 27264: 200, 9857: 208, 14468: 134, 6277: 194, 35972: 198, 4744: 212, 32905: 164, 32393: 222, 22671: 196, 20628: 184, 32920: 348, 17560: 186, 5119: 162, 21661: 210, 16543: 174, 31903: 230, 18089: 154, 16553: 190, 28331: 216, 41131: 196, 20145: 138, 46262: 214, 30397: 226, 41151: 230, 22723: 236, 23239: 190, 14538: 194, 17100: 178, 37073: 174, 22739: 206, 49365: 180, 16598: 156, 47831: 234, 31959: 192, 22234: 212, 23259: 172, 20189: 248, 45790: 210, 29927: 248, 46312: 202, 31465: 162, 46831: 170, 31472: 232, 29936: 168, 26355: 262, 6393: 204, 26876: 214, 8444: 182, 26878: 184, 6911: 200, 25856: 172, 21249: 202, 19717: 148, 8966: 160, 38150: 196, 26888: 174, 27917: 164, 39184: 168, 48401: 180, 24336: 162, 6416: 192, 23316: 156, 37144: 176, 31513: 192, 42266: 200, 29989: 136, 27434: 160, 45867: 168, 36139: 234, 29489: 198, 27443: 180, 27955: 176, 22838: 202, 7993: 220, 13114: 186, 13629: 184, 28991: 182, 40771: 198, 25413: 214, 44870: 208, 18247: 188, 47944: 192, 35657: 178, 26953: 174, 13651: 158, 27991: 184, 26456: 166, 48990: 144, 34655: 214, 16225: 200, 28518: 144, 20839: 200, 43367: 206, 10092: 164, 11116: 216, 31086: 194, 29040: 252, 50033: 178, 5490: 174, 39795: 204, 48505: 186, 40316: 208, 24958: 192, 38783: 198, 19838: 178, 23425: 198, 24962: 178, 13187: 228, 49028: 180, 12167: 174, 43406: 188, 14737: 188, 18322: 178, 43921: 130, 12694: 162, 16286: 188, 48545: 172, 29092: 194, 15273: 152, 16809: 172, 22455: 180, 24504: 178, 30140: 236, 27581: 170, 21438: 200, 35262: 184, 36292: 190, 6086: 216, 21960: 130, 20428: 200, 17361: 178, 33747: 180, 2516: 166, 13268: 342, 45014: 204, 25556: 164, 33240: 168, 36312: 168, 16863: 196, 28642: 188, 10213: 196, 16358: 194, 25062: 186, 23528: 170, 35307: 192, 19436: 180, 25579: 228, 15859: 186, 38900: 242, 7670: 170, 8698: 172, 12284: 212, 44542: 192, 31231: 218}})\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "LAYER = 39\n",
    "batch_size = 40\n",
    "\n",
    "hook = f\"blocks.{LAYER}.hook_ssm_input\"\n",
    "\n",
    "name_averages = defaultdict(lambda: {})\n",
    "name_choices = defaultdict(lambda: defaultdict(lambda: []))\n",
    "counts = defaultdict(lambda: {})\n",
    "\n",
    "TOTAL_AVG_NAME = \"total\"\n",
    "\n",
    "for tok in name_tokens:\n",
    "    for name_i in range(len(name_positions)):\n",
    "        name_averages[name_i][tok] = torch.zeros([model.cfg.E], device=model.cfg.device)\n",
    "        counts[name_i][tok] = 0\n",
    "\n",
    "for batch_start in tqdm(list(range(0, data.data.size()[0], batch_size))):\n",
    "    batch_end = min(data.data.size()[0], batch_start+batch_size)\n",
    "    data_batch = data.data[batch_start:batch_end]\n",
    "    logits, activations = model.run_with_cache(data_batch, names_filter=[hook], fast_ssm=True, fast_conv=True)\n",
    "    for name_i in range(len(name_positions)):\n",
    "        positions = torch.tensor(name_positions[name_i][batch_start:batch_end], device=model.cfg.device)\n",
    "        batch_name_tokens = data_batch[torch.arange(batch_end-batch_start),positions]\n",
    "        ssm_inputs = activations[hook]\n",
    "        for batch_i, name_tok in enumerate(batch_name_tokens):\n",
    "            #print(ssm_inputs[batch_i, position].size())\n",
    "            try:\n",
    "                position = positions[batch_i]+1\n",
    "                name_averages[name_i][name_tok.item()] += ssm_inputs[batch_i, position]\n",
    "                if len(name_choices[name_i][name_tok.item()]) < 20: # save some memory\n",
    "                    name_choices[name_i][name_tok.item()].append(ssm_inputs[batch_i, position])\n",
    "                #name_averages['all'][name_tok.item()] += ssm_inputs[batch_i, position]\n",
    "                #name_averages[name_i][TOTAL_AVG_NAME] += ssm_inputs[batch_i, position]\n",
    "                counts[name_i][name_tok.item()] += 1\n",
    "                #counts[name_i][TOTAL_AVG_NAME] += 1\n",
    "            except:\n",
    "                print(model.to_str_tokens([name_tok]))\n",
    "                raise\n",
    "    \n",
    "print(counts)\n",
    "for name_i in range(len(name_positions)):\n",
    "    for name_tok in list(name_averages[name_i].keys()):\n",
    "        name_averages[name_i][name_tok] = name_averages[name_i][name_tok] / counts[name_i][name_tok]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "071348f8-ed3d-403d-ae73-0ba8f550161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 50178 tensor(12.7626, device='cuda:0')\n",
      "20\n",
      "166\n",
      "0 50178 tensor(12.3633, device='cuda:0')\n",
      "0 50178 tensor(13.0378, device='cuda:0')\n",
      "\n",
      "0 46600 tensor(12.8618, device='cuda:0')\n",
      "20\n",
      "186\n",
      "0 46600 tensor(13.1206, device='cuda:0')\n",
      "0 46600 tensor(13.1206, device='cuda:0')\n",
      "\n",
      "0 31755 tensor(13.4229, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 31755 tensor(14.2686, device='cuda:0')\n",
      "0 31755 tensor(14.2686, device='cuda:0')\n",
      "\n",
      "0 46604 tensor(12.4573, device='cuda:0')\n",
      "20\n",
      "212\n",
      "0 46604 tensor(13.8661, device='cuda:0')\n",
      "0 46604 tensor(12.3146, device='cuda:0')\n",
      "\n",
      "0 10765 tensor(12.8339, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 10765 tensor(13.7052, device='cuda:0')\n",
      "0 10765 tensor(13.4607, device='cuda:0')\n",
      "\n",
      "0 11276 tensor(13.3126, device='cuda:0')\n",
      "20\n",
      "236\n",
      "0 11276 tensor(14.2519, device='cuda:0')\n",
      "0 11276 tensor(14.2519, device='cuda:0')\n",
      "\n",
      "0 33811 tensor(13.4167, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 33811 tensor(14.3506, device='cuda:0')\n",
      "0 33811 tensor(14.3506, device='cuda:0')\n",
      "\n",
      "0 46612 tensor(13.5347, device='cuda:0')\n",
      "20\n",
      "224\n",
      "0 46612 tensor(14.7716, device='cuda:0')\n",
      "0 46612 tensor(14.7716, device='cuda:0')\n",
      "\n",
      "0 16916 tensor(12.5435, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 16916 tensor(12.5832, device='cuda:0')\n",
      "0 16916 tensor(12.5832, device='cuda:0')\n",
      "\n",
      "0 18966 tensor(12.9463, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 18966 tensor(12.9543, device='cuda:0')\n",
      "0 18966 tensor(13.0794, device='cuda:0')\n",
      "\n",
      "0 12824 tensor(11.8327, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 12824 tensor(11.6573, device='cuda:0')\n",
      "0 12824 tensor(11.6573, device='cuda:0')\n",
      "\n",
      "0 32794 tensor(12.2683, device='cuda:0')\n",
      "20\n",
      "170\n",
      "0 32794 tensor(12.4698, device='cuda:0')\n",
      "0 32794 tensor(12.4698, device='cuda:0')\n",
      "\n",
      "0 7195 tensor(12.5167, device='cuda:0')\n",
      "20\n",
      "162\n",
      "0 7195 tensor(13.0059, device='cuda:0')\n",
      "0 7195 tensor(13.3565, device='cuda:0')\n",
      "\n",
      "0 33821 tensor(13.0784, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 33821 tensor(12.7218, device='cuda:0')\n",
      "0 33821 tensor(13.2524, device='cuda:0')\n",
      "\n",
      "0 37921 tensor(13.2030, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 37921 tensor(13.9821, device='cuda:0')\n",
      "0 37921 tensor(13.2424, device='cuda:0')\n",
      "\n",
      "0 33313 tensor(12.8516, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 33313 tensor(13.3062, device='cuda:0')\n",
      "0 33313 tensor(12.4151, device='cuda:0')\n",
      "\n",
      "0 31270 tensor(13.1325, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 31270 tensor(13.5714, device='cuda:0')\n",
      "0 31270 tensor(14.0844, device='cuda:0')\n",
      "\n",
      "0 29222 tensor(12.7585, device='cuda:0')\n",
      "20\n",
      "182\n",
      "0 29222 tensor(13.0037, device='cuda:0')\n",
      "0 29222 tensor(13.0037, device='cuda:0')\n",
      "\n",
      "0 28712 tensor(12.5903, device='cuda:0')\n",
      "20\n",
      "152\n",
      "0 28712 tensor(13.4471, device='cuda:0')\n",
      "0 28712 tensor(13.4471, device='cuda:0')\n",
      "\n",
      "0 18985 tensor(12.5035, device='cuda:0')\n",
      "20\n",
      "190\n",
      "0 18985 tensor(13.4102, device='cuda:0')\n",
      "0 18985 tensor(13.5528, device='cuda:0')\n",
      "\n",
      "0 37930 tensor(12.9887, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 37930 tensor(13.9630, device='cuda:0')\n",
      "0 37930 tensor(14.3912, device='cuda:0')\n",
      "\n",
      "0 28200 tensor(12.4344, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 28200 tensor(12.2348, device='cuda:0')\n",
      "0 28200 tensor(12.2348, device='cuda:0')\n",
      "\n",
      "0 7727 tensor(12.4297, device='cuda:0')\n",
      "20\n",
      "122\n",
      "0 7727 tensor(12.4165, device='cuda:0')\n",
      "0 7727 tensor(13.0009, device='cuda:0')\n",
      "\n",
      "0 24112 tensor(13.6538, device='cuda:0')\n",
      "20\n",
      "196\n",
      "0 24112 tensor(14.9432, device='cuda:0')\n",
      "0 24112 tensor(13.7304, device='cuda:0')\n",
      "\n",
      "0 36400 tensor(12.8940, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 36400 tensor(13.0398, device='cuda:0')\n",
      "0 36400 tensor(13.0398, device='cuda:0')\n",
      "\n",
      "0 32817 tensor(13.5889, device='cuda:0')\n",
      "20\n",
      "238\n",
      "0 32817 tensor(14.4853, device='cuda:0')\n",
      "0 32817 tensor(14.5227, device='cuda:0')\n",
      "\n",
      "0 5171 tensor(12.4680, device='cuda:0')\n",
      "20\n",
      "148\n",
      "0 5171 tensor(13.1653, device='cuda:0')\n",
      "0 5171 tensor(13.1653, device='cuda:0')\n",
      "\n",
      "0 44085 tensor(12.5504, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 44085 tensor(12.7504, device='cuda:0')\n",
      "0 44085 tensor(13.6588, device='cuda:0')\n",
      "\n",
      "0 35382 tensor(13.4250, device='cuda:0')\n",
      "20\n",
      "208\n",
      "0 35382 tensor(13.2224, device='cuda:0')\n",
      "0 35382 tensor(14.4219, device='cuda:0')\n",
      "\n",
      "0 14912 tensor(12.8857, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 14912 tensor(12.7235, device='cuda:0')\n",
      "0 14912 tensor(14.1867, device='cuda:0')\n",
      "\n",
      "0 30274 tensor(12.3714, device='cuda:0')\n",
      "20\n",
      "200\n",
      "0 30274 tensor(12.2414, device='cuda:0')\n",
      "0 30274 tensor(13.4663, device='cuda:0')\n",
      "\n",
      "0 20554 tensor(12.5487, device='cuda:0')\n",
      "20\n",
      "148\n",
      "0 20554 tensor(12.8916, device='cuda:0')\n",
      "0 20554 tensor(13.6043, device='cuda:0')\n",
      "\n",
      "0 15435 tensor(13.1355, device='cuda:0')\n",
      "20\n",
      "244\n",
      "0 15435 tensor(14.2929, device='cuda:0')\n",
      "0 15435 tensor(13.5921, device='cuda:0')\n",
      "\n",
      "0 33357 tensor(12.5574, device='cuda:0')\n",
      "20\n",
      "170\n",
      "0 33357 tensor(12.2488, device='cuda:0')\n",
      "0 33357 tensor(12.9592, device='cuda:0')\n",
      "\n",
      "0 49231 tensor(13.3039, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 49231 tensor(13.8549, device='cuda:0')\n",
      "0 49231 tensor(13.8549, device='cuda:0')\n",
      "\n",
      "0 38994 tensor(13.0173, device='cuda:0')\n",
      "20\n",
      "182\n",
      "0 38994 tensor(13.9752, device='cuda:0')\n",
      "0 38994 tensor(13.3703, device='cuda:0')\n",
      "\n",
      "0 21587 tensor(12.4770, device='cuda:0')\n",
      "20\n",
      "218\n",
      "0 21587 tensor(12.5303, device='cuda:0')\n",
      "0 21587 tensor(13.2892, device='cuda:0')\n",
      "\n",
      "0 7252 tensor(12.0709, device='cuda:0')\n",
      "20\n",
      "146\n",
      "0 7252 tensor(13.0294, device='cuda:0')\n",
      "0 7252 tensor(13.0761, device='cuda:0')\n",
      "\n",
      "0 40537 tensor(13.0609, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 40537 tensor(13.1456, device='cuda:0')\n",
      "0 40537 tensor(13.1456, device='cuda:0')\n",
      "\n",
      "0 27738 tensor(13.3098, device='cuda:0')\n",
      "20\n",
      "224\n",
      "0 27738 tensor(14.4399, device='cuda:0')\n",
      "0 27738 tensor(14.4399, device='cuda:0')\n",
      "\n",
      "0 44123 tensor(13.1284, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 44123 tensor(13.9336, device='cuda:0')\n",
      "0 44123 tensor(12.9097, device='cuda:0')\n",
      "\n",
      "0 44124 tensor(12.5597, device='cuda:0')\n",
      "20\n",
      "220\n",
      "0 44124 tensor(13.2709, device='cuda:0')\n",
      "0 44124 tensor(13.2709, device='cuda:0')\n",
      "\n",
      "0 14943 tensor(13.2119, device='cuda:0')\n",
      "20\n",
      "144\n",
      "0 14943 tensor(14.4973, device='cuda:0')\n",
      "0 14943 tensor(14.4973, device='cuda:0')\n",
      "\n",
      "0 45664 tensor(12.9323, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 45664 tensor(14.1823, device='cuda:0')\n",
      "0 45664 tensor(14.1823, device='cuda:0')\n",
      "\n",
      "0 15458 tensor(12.5931, device='cuda:0')\n",
      "20\n",
      "216\n",
      "0 15458 tensor(14.0393, device='cuda:0')\n",
      "0 15458 tensor(13.1521, device='cuda:0')\n",
      "\n",
      "0 49765 tensor(12.9722, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 49765 tensor(13.2506, device='cuda:0')\n",
      "0 49765 tensor(14.0132, device='cuda:0')\n",
      "\n",
      "0 19046 tensor(12.7682, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 19046 tensor(13.5305, device='cuda:0')\n",
      "0 19046 tensor(13.9737, device='cuda:0')\n",
      "\n",
      "0 35944 tensor(12.4344, device='cuda:0')\n",
      "20\n",
      "204\n",
      "0 35944 tensor(12.4766, device='cuda:0')\n",
      "0 35944 tensor(12.4766, device='cuda:0')\n",
      "\n",
      "0 29804 tensor(13.0494, device='cuda:0')\n",
      "20\n",
      "166\n",
      "0 29804 tensor(12.8638, device='cuda:0')\n",
      "0 29804 tensor(12.8638, device='cuda:0')\n",
      "\n",
      "0 23662 tensor(12.8338, device='cuda:0')\n",
      "20\n",
      "220\n",
      "0 23662 tensor(12.7117, device='cuda:0')\n",
      "0 23662 tensor(12.7117, device='cuda:0')\n",
      "\n",
      "0 37497 tensor(13.1458, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 37497 tensor(14.1370, device='cuda:0')\n",
      "0 37497 tensor(14.3730, device='cuda:0')\n",
      "\n",
      "0 22138 tensor(13.2200, device='cuda:0')\n",
      "20\n",
      "216\n",
      "0 22138 tensor(14.4110, device='cuda:0')\n",
      "0 22138 tensor(13.3316, device='cuda:0')\n",
      "\n",
      "0 27773 tensor(13.1956, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 27773 tensor(13.2370, device='cuda:0')\n",
      "0 27773 tensor(13.2370, device='cuda:0')\n",
      "\n",
      "0 28798 tensor(12.8403, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 28798 tensor(13.4330, device='cuda:0')\n",
      "0 28798 tensor(13.4330, device='cuda:0')\n",
      "\n",
      "0 33407 tensor(13.3381, device='cuda:0')\n",
      "20\n",
      "200\n",
      "0 33407 tensor(12.7921, device='cuda:0')\n",
      "0 33407 tensor(12.7921, device='cuda:0')\n",
      "\n",
      "0 27264 tensor(12.2719, device='cuda:0')\n",
      "20\n",
      "162\n",
      "0 27264 tensor(12.3675, device='cuda:0')\n",
      "0 27264 tensor(12.3675, device='cuda:0')\n",
      "\n",
      "0 9857 tensor(12.8134, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 9857 tensor(13.6642, device='cuda:0')\n",
      "0 9857 tensor(13.6642, device='cuda:0')\n",
      "\n",
      "0 14468 tensor(12.6566, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 14468 tensor(13.7529, device='cuda:0')\n",
      "0 14468 tensor(13.6242, device='cuda:0')\n",
      "\n",
      "0 6277 tensor(12.5546, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 6277 tensor(13.6594, device='cuda:0')\n",
      "0 6277 tensor(13.6594, device='cuda:0')\n",
      "\n",
      "0 35972 tensor(13.4909, device='cuda:0')\n",
      "20\n",
      "164\n",
      "0 35972 tensor(14.2806, device='cuda:0')\n",
      "0 35972 tensor(13.5212, device='cuda:0')\n",
      "\n",
      "0 4744 tensor(12.2108, device='cuda:0')\n",
      "20\n",
      "152\n",
      "0 4744 tensor(12.3553, device='cuda:0')\n",
      "0 4744 tensor(12.3553, device='cuda:0')\n",
      "\n",
      "0 32905 tensor(12.4487, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 32905 tensor(12.4628, device='cuda:0')\n",
      "0 32905 tensor(12.4628, device='cuda:0')\n",
      "\n",
      "0 32393 tensor(13.0485, device='cuda:0')\n",
      "20\n",
      "186\n",
      "0 32393 tensor(13.6030, device='cuda:0')\n",
      "0 32393 tensor(13.8995, device='cuda:0')\n",
      "\n",
      "0 22671 tensor(13.3392, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 22671 tensor(14.4455, device='cuda:0')\n",
      "0 22671 tensor(13.6472, device='cuda:0')\n",
      "\n",
      "0 20628 tensor(13.0219, device='cuda:0')\n",
      "20\n",
      "208\n",
      "0 20628 tensor(13.3048, device='cuda:0')\n",
      "0 20628 tensor(13.3048, device='cuda:0')\n",
      "\n",
      "0 32920 tensor(13.7633, device='cuda:0')\n",
      "20\n",
      "352\n",
      "0 32920 tensor(13.4423, device='cuda:0')\n",
      "0 32920 tensor(14.5938, device='cuda:0')\n",
      "\n",
      "0 17560 tensor(12.8148, device='cuda:0')\n",
      "20\n",
      "166\n",
      "0 17560 tensor(13.5656, device='cuda:0')\n",
      "0 17560 tensor(13.5666, device='cuda:0')\n",
      "\n",
      "0 5119 tensor(12.3343, device='cuda:0')\n",
      "20\n",
      "134\n",
      "0 5119 tensor(13.5068, device='cuda:0')\n",
      "0 5119 tensor(12.3289, device='cuda:0')\n",
      "\n",
      "0 21661 tensor(12.0129, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 21661 tensor(12.5662, device='cuda:0')\n",
      "0 21661 tensor(12.5662, device='cuda:0')\n",
      "\n",
      "0 16543 tensor(13.0676, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 16543 tensor(13.2557, device='cuda:0')\n",
      "0 16543 tensor(13.2557, device='cuda:0')\n",
      "\n",
      "0 31903 tensor(12.6538, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 31903 tensor(13.1728, device='cuda:0')\n",
      "0 31903 tensor(13.3624, device='cuda:0')\n",
      "\n",
      "0 18089 tensor(12.5046, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 18089 tensor(12.6486, device='cuda:0')\n",
      "0 18089 tensor(12.1658, device='cuda:0')\n",
      "\n",
      "0 16553 tensor(12.6228, device='cuda:0')\n",
      "20\n",
      "200\n",
      "0 16553 tensor(13.4852, device='cuda:0')\n",
      "0 16553 tensor(12.6642, device='cuda:0')\n",
      "\n",
      "0 28331 tensor(12.9699, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 28331 tensor(13.5974, device='cuda:0')\n",
      "0 28331 tensor(13.2734, device='cuda:0')\n",
      "\n",
      "0 41131 tensor(13.0920, device='cuda:0')\n",
      "20\n",
      "150\n",
      "0 41131 tensor(13.4138, device='cuda:0')\n",
      "0 41131 tensor(13.4138, device='cuda:0')\n",
      "\n",
      "0 20145 tensor(12.5932, device='cuda:0')\n",
      "20\n",
      "204\n",
      "0 20145 tensor(13.7743, device='cuda:0')\n",
      "0 20145 tensor(13.7743, device='cuda:0')\n",
      "\n",
      "0 46262 tensor(12.7673, device='cuda:0')\n",
      "20\n",
      "160\n",
      "0 46262 tensor(14.4209, device='cuda:0')\n",
      "0 46262 tensor(13.3710, device='cuda:0')\n",
      "\n",
      "0 30397 tensor(12.8803, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 30397 tensor(13.5136, device='cuda:0')\n",
      "0 30397 tensor(13.8564, device='cuda:0')\n",
      "\n",
      "0 41151 tensor(12.5119, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 41151 tensor(13.4766, device='cuda:0')\n",
      "0 41151 tensor(13.5120, device='cuda:0')\n",
      "\n",
      "0 22723 tensor(12.7574, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 22723 tensor(12.9196, device='cuda:0')\n",
      "0 22723 tensor(12.9196, device='cuda:0')\n",
      "\n",
      "0 23239 tensor(13.0141, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 23239 tensor(14.0602, device='cuda:0')\n",
      "0 23239 tensor(14.0602, device='cuda:0')\n",
      "\n",
      "0 14538 tensor(10.5964, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 14538 tensor(11.1933, device='cuda:0')\n",
      "0 14538 tensor(11.2978, device='cuda:0')\n",
      "\n",
      "0 17100 tensor(12.6421, device='cuda:0')\n",
      "20\n",
      "222\n",
      "0 17100 tensor(13.9295, device='cuda:0')\n",
      "0 17100 tensor(12.8804, device='cuda:0')\n",
      "\n",
      "0 37073 tensor(13.1513, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 37073 tensor(14.4043, device='cuda:0')\n",
      "0 37073 tensor(13.2479, device='cuda:0')\n",
      "\n",
      "0 22739 tensor(13.6572, device='cuda:0')\n",
      "20\n",
      "230\n",
      "0 22739 tensor(13.4759, device='cuda:0')\n",
      "0 22739 tensor(13.4759, device='cuda:0')\n",
      "\n",
      "0 49365 tensor(13.1089, device='cuda:0')\n",
      "20\n",
      "146\n",
      "0 49365 tensor(14.3966, device='cuda:0')\n",
      "0 49365 tensor(14.3966, device='cuda:0')\n",
      "\n",
      "0 16598 tensor(12.8477, device='cuda:0')\n",
      "20\n",
      "186\n",
      "0 16598 tensor(13.3732, device='cuda:0')\n",
      "0 16598 tensor(13.3732, device='cuda:0')\n",
      "\n",
      "0 47831 tensor(13.0625, device='cuda:0')\n",
      "20\n",
      "196\n",
      "0 47831 tensor(14.1711, device='cuda:0')\n",
      "0 47831 tensor(14.1711, device='cuda:0')\n",
      "\n",
      "0 31959 tensor(13.2688, device='cuda:0')\n",
      "20\n",
      "226\n",
      "0 31959 tensor(13.4616, device='cuda:0')\n",
      "0 31959 tensor(12.9901, device='cuda:0')\n",
      "\n",
      "0 22234 tensor(12.6123, device='cuda:0')\n",
      "20\n",
      "244\n",
      "0 22234 tensor(12.4557, device='cuda:0')\n",
      "0 22234 tensor(12.4557, device='cuda:0')\n",
      "\n",
      "0 23259 tensor(13.1213, device='cuda:0')\n",
      "20\n",
      "238\n",
      "0 23259 tensor(13.1611, device='cuda:0')\n",
      "0 23259 tensor(13.2463, device='cuda:0')\n",
      "\n",
      "0 20189 tensor(12.9662, device='cuda:0')\n",
      "20\n",
      "178\n",
      "0 20189 tensor(13.8119, device='cuda:0')\n",
      "0 20189 tensor(13.8119, device='cuda:0')\n",
      "\n",
      "0 45790 tensor(12.5666, device='cuda:0')\n",
      "20\n",
      "190\n",
      "0 45790 tensor(13.3464, device='cuda:0')\n",
      "0 45790 tensor(13.4502, device='cuda:0')\n",
      "\n",
      "0 29927 tensor(12.6487, device='cuda:0')\n",
      "20\n",
      "230\n",
      "0 29927 tensor(13.7232, device='cuda:0')\n",
      "0 29927 tensor(12.4084, device='cuda:0')\n",
      "\n",
      "0 46312 tensor(13.1135, device='cuda:0')\n",
      "20\n",
      "238\n",
      "0 46312 tensor(13.3237, device='cuda:0')\n",
      "0 46312 tensor(13.1319, device='cuda:0')\n",
      "\n",
      "0 31465 tensor(11.9781, device='cuda:0')\n",
      "20\n",
      "170\n",
      "0 31465 tensor(12.5426, device='cuda:0')\n",
      "0 31465 tensor(12.1955, device='cuda:0')\n",
      "\n",
      "0 46831 tensor(12.9274, device='cuda:0')\n",
      "20\n",
      "142\n",
      "0 46831 tensor(13.4876, device='cuda:0')\n",
      "0 46831 tensor(13.0505, device='cuda:0')\n",
      "\n",
      "0 31472 tensor(12.6094, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 31472 tensor(13.6778, device='cuda:0')\n",
      "0 31472 tensor(13.6778, device='cuda:0')\n",
      "\n",
      "0 29936 tensor(12.8529, device='cuda:0')\n",
      "20\n",
      "150\n",
      "0 29936 tensor(13.7187, device='cuda:0')\n",
      "0 29936 tensor(13.1125, device='cuda:0')\n",
      "\n",
      "0 26355 tensor(12.3908, device='cuda:0')\n",
      "20\n",
      "142\n",
      "0 26355 tensor(12.3387, device='cuda:0')\n",
      "0 26355 tensor(13.3444, device='cuda:0')\n",
      "\n",
      "0 6393 tensor(12.2386, device='cuda:0')\n",
      "20\n",
      "144\n",
      "0 6393 tensor(13.2844, device='cuda:0')\n",
      "0 6393 tensor(12.2438, device='cuda:0')\n",
      "\n",
      "0 26876 tensor(12.5981, device='cuda:0')\n",
      "20\n",
      "208\n",
      "0 26876 tensor(12.2634, device='cuda:0')\n",
      "0 26876 tensor(13.4663, device='cuda:0')\n",
      "\n",
      "0 8444 tensor(12.0856, device='cuda:0')\n",
      "20\n",
      "156\n",
      "0 8444 tensor(12.7779, device='cuda:0')\n",
      "0 8444 tensor(13.0954, device='cuda:0')\n",
      "\n",
      "0 26878 tensor(13.4137, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 26878 tensor(12.8081, device='cuda:0')\n",
      "0 26878 tensor(13.8060, device='cuda:0')\n",
      "\n",
      "0 6911 tensor(12.2851, device='cuda:0')\n",
      "20\n",
      "152\n",
      "0 6911 tensor(12.2566, device='cuda:0')\n",
      "0 6911 tensor(12.2566, device='cuda:0')\n",
      "\n",
      "0 25856 tensor(13.4219, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 25856 tensor(14.4027, device='cuda:0')\n",
      "0 25856 tensor(13.2543, device='cuda:0')\n",
      "\n",
      "0 21249 tensor(11.3031, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 21249 tensor(11.9372, device='cuda:0')\n",
      "0 21249 tensor(11.9873, device='cuda:0')\n",
      "\n",
      "0 19717 tensor(12.4562, device='cuda:0')\n",
      "20\n",
      "196\n",
      "0 19717 tensor(12.4250, device='cuda:0')\n",
      "0 19717 tensor(12.4250, device='cuda:0')\n",
      "\n",
      "0 8966 tensor(12.7948, device='cuda:0')\n",
      "20\n",
      "168\n",
      "0 8966 tensor(12.5636, device='cuda:0')\n",
      "0 8966 tensor(13.6862, device='cuda:0')\n",
      "\n",
      "0 38150 tensor(13.2872, device='cuda:0')\n",
      "20\n",
      "180\n",
      "0 38150 tensor(13.1511, device='cuda:0')\n",
      "0 38150 tensor(13.4320, device='cuda:0')\n",
      "\n",
      "0 26888 tensor(13.2139, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 26888 tensor(13.8056, device='cuda:0')\n",
      "0 26888 tensor(13.8056, device='cuda:0')\n",
      "\n",
      "0 27917 tensor(12.4088, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 27917 tensor(13.0022, device='cuda:0')\n",
      "0 27917 tensor(12.8759, device='cuda:0')\n",
      "\n",
      "0 39184 tensor(11.4426, device='cuda:0')\n",
      "20\n",
      "212\n",
      "0 39184 tensor(11.8262, device='cuda:0')\n",
      "0 39184 tensor(11.8262, device='cuda:0')\n",
      "\n",
      "0 48401 tensor(13.0711, device='cuda:0')\n",
      "20\n",
      "118\n",
      "0 48401 tensor(12.7493, device='cuda:0')\n",
      "0 48401 tensor(13.3075, device='cuda:0')\n",
      "\n",
      "0 24336 tensor(13.1588, device='cuda:0')\n",
      "20\n",
      "172\n",
      "0 24336 tensor(12.8981, device='cuda:0')\n",
      "0 24336 tensor(14.2539, device='cuda:0')\n",
      "\n",
      "0 6416 tensor(11.8056, device='cuda:0')\n",
      "20\n",
      "178\n",
      "0 6416 tensor(12.7000, device='cuda:0')\n",
      "0 6416 tensor(12.7000, device='cuda:0')\n",
      "\n",
      "0 23316 tensor(12.8102, device='cuda:0')\n",
      "20\n",
      "156\n",
      "0 23316 tensor(13.0968, device='cuda:0')\n",
      "0 23316 tensor(12.8320, device='cuda:0')\n",
      "\n",
      "0 37144 tensor(12.8887, device='cuda:0')\n",
      "20\n",
      "146\n",
      "0 37144 tensor(13.7380, device='cuda:0')\n",
      "0 37144 tensor(13.7910, device='cuda:0')\n",
      "\n",
      "0 31513 tensor(12.3879, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 31513 tensor(12.5424, device='cuda:0')\n",
      "0 31513 tensor(13.3648, device='cuda:0')\n",
      "\n",
      "0 42266 tensor(12.4492, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 42266 tensor(13.3118, device='cuda:0')\n",
      "0 42266 tensor(13.9107, device='cuda:0')\n",
      "\n",
      "0 29989 tensor(12.9688, device='cuda:0')\n",
      "20\n",
      "178\n",
      "0 29989 tensor(13.9730, device='cuda:0')\n",
      "0 29989 tensor(13.2886, device='cuda:0')\n",
      "\n",
      "0 27434 tensor(13.1300, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 27434 tensor(13.6635, device='cuda:0')\n",
      "0 27434 tensor(14.6617, device='cuda:0')\n",
      "\n",
      "0 45867 tensor(13.1353, device='cuda:0')\n",
      "20\n",
      "204\n",
      "0 45867 tensor(14.3540, device='cuda:0')\n",
      "0 45867 tensor(14.3540, device='cuda:0')\n",
      "\n",
      "0 36139 tensor(13.3852, device='cuda:0')\n",
      "20\n",
      "228\n",
      "0 36139 tensor(14.4462, device='cuda:0')\n",
      "0 36139 tensor(13.4986, device='cuda:0')\n",
      "\n",
      "0 29489 tensor(12.7141, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 29489 tensor(13.7457, device='cuda:0')\n",
      "0 29489 tensor(13.7457, device='cuda:0')\n",
      "\n",
      "0 27443 tensor(12.6511, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 27443 tensor(12.5571, device='cuda:0')\n",
      "0 27443 tensor(13.5634, device='cuda:0')\n",
      "\n",
      "0 27955 tensor(11.9624, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 27955 tensor(11.7787, device='cuda:0')\n",
      "0 27955 tensor(11.7787, device='cuda:0')\n",
      "\n",
      "0 22838 tensor(12.8553, device='cuda:0')\n",
      "20\n",
      "178\n",
      "0 22838 tensor(13.0996, device='cuda:0')\n",
      "0 22838 tensor(13.6889, device='cuda:0')\n",
      "\n",
      "0 7993 tensor(12.4818, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 7993 tensor(13.7628, device='cuda:0')\n",
      "0 7993 tensor(13.1193, device='cuda:0')\n",
      "\n",
      "0 13114 tensor(13.0033, device='cuda:0')\n",
      "20\n",
      "168\n",
      "0 13114 tensor(13.9232, device='cuda:0')\n",
      "0 13114 tensor(13.9232, device='cuda:0')\n",
      "\n",
      "0 13629 tensor(11.9363, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 13629 tensor(12.5863, device='cuda:0')\n",
      "0 13629 tensor(13.0319, device='cuda:0')\n",
      "\n",
      "0 28991 tensor(13.0022, device='cuda:0')\n",
      "20\n",
      "182\n",
      "0 28991 tensor(12.7737, device='cuda:0')\n",
      "0 28991 tensor(13.3921, device='cuda:0')\n",
      "\n",
      "0 40771 tensor(13.0072, device='cuda:0')\n",
      "20\n",
      "178\n",
      "0 40771 tensor(14.0512, device='cuda:0')\n",
      "0 40771 tensor(14.0512, device='cuda:0')\n",
      "\n",
      "0 25413 tensor(12.7161, device='cuda:0')\n",
      "20\n",
      "226\n",
      "0 25413 tensor(13.9946, device='cuda:0')\n",
      "0 25413 tensor(13.9946, device='cuda:0')\n",
      "\n",
      "0 44870 tensor(12.9663, device='cuda:0')\n",
      "20\n",
      "190\n",
      "0 44870 tensor(13.4676, device='cuda:0')\n",
      "0 44870 tensor(14.2967, device='cuda:0')\n",
      "\n",
      "0 18247 tensor(13.0920, device='cuda:0')\n",
      "20\n",
      "230\n",
      "0 18247 tensor(12.8579, device='cuda:0')\n",
      "0 18247 tensor(14.1180, device='cuda:0')\n",
      "\n",
      "0 47944 tensor(12.9271, device='cuda:0')\n",
      "20\n",
      "214\n",
      "0 47944 tensor(13.1308, device='cuda:0')\n",
      "0 47944 tensor(12.9786, device='cuda:0')\n",
      "\n",
      "0 35657 tensor(13.3275, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 35657 tensor(13.1805, device='cuda:0')\n",
      "0 35657 tensor(14.0828, device='cuda:0')\n",
      "\n",
      "0 26953 tensor(12.3184, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 26953 tensor(11.9706, device='cuda:0')\n",
      "0 26953 tensor(11.9706, device='cuda:0')\n",
      "\n",
      "0 13651 tensor(12.2813, device='cuda:0')\n",
      "20\n",
      "236\n",
      "0 13651 tensor(13.0796, device='cuda:0')\n",
      "0 13651 tensor(12.5844, device='cuda:0')\n",
      "\n",
      "0 27991 tensor(12.6054, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 27991 tensor(12.4073, device='cuda:0')\n",
      "0 27991 tensor(12.4073, device='cuda:0')\n",
      "\n",
      "0 26456 tensor(12.6737, device='cuda:0')\n",
      "20\n",
      "216\n",
      "0 26456 tensor(12.8492, device='cuda:0')\n",
      "0 26456 tensor(13.5433, device='cuda:0')\n",
      "\n",
      "0 48990 tensor(13.3650, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 48990 tensor(13.3184, device='cuda:0')\n",
      "0 48990 tensor(13.6652, device='cuda:0')\n",
      "\n",
      "0 34655 tensor(13.2356, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 34655 tensor(14.6680, device='cuda:0')\n",
      "0 34655 tensor(14.6680, device='cuda:0')\n",
      "\n",
      "0 16225 tensor(11.8494, device='cuda:0')\n",
      "20\n",
      "156\n",
      "0 16225 tensor(12.6014, device='cuda:0')\n",
      "0 16225 tensor(11.5291, device='cuda:0')\n",
      "\n",
      "0 28518 tensor(13.7207, device='cuda:0')\n",
      "20\n",
      "142\n",
      "0 28518 tensor(14.6510, device='cuda:0')\n",
      "0 28518 tensor(15.0178, device='cuda:0')\n",
      "\n",
      "0 20839 tensor(11.7493, device='cuda:0')\n",
      "20\n",
      "202\n",
      "0 20839 tensor(11.7740, device='cuda:0')\n",
      "0 20839 tensor(11.7740, device='cuda:0')\n",
      "\n",
      "0 43367 tensor(13.4370, device='cuda:0')\n",
      "20\n",
      "250\n",
      "0 43367 tensor(12.9977, device='cuda:0')\n",
      "0 43367 tensor(14.4773, device='cuda:0')\n",
      "\n",
      "0 10092 tensor(12.0346, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 10092 tensor(12.1111, device='cuda:0')\n",
      "0 10092 tensor(12.1111, device='cuda:0')\n",
      "\n",
      "0 11116 tensor(12.0053, device='cuda:0')\n",
      "20\n",
      "164\n",
      "0 11116 tensor(11.9529, device='cuda:0')\n",
      "0 11116 tensor(11.9529, device='cuda:0')\n",
      "\n",
      "0 31086 tensor(12.3666, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 31086 tensor(12.4945, device='cuda:0')\n",
      "0 31086 tensor(12.4945, device='cuda:0')\n",
      "\n",
      "0 29040 tensor(12.5946, device='cuda:0')\n",
      "20\n",
      "204\n",
      "0 29040 tensor(12.9621, device='cuda:0')\n",
      "0 29040 tensor(12.9621, device='cuda:0')\n",
      "\n",
      "0 50033 tensor(13.0629, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 50033 tensor(14.1688, device='cuda:0')\n",
      "0 50033 tensor(14.0779, device='cuda:0')\n",
      "\n",
      "0 5490 tensor(12.4300, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 5490 tensor(12.0273, device='cuda:0')\n",
      "0 5490 tensor(12.0273, device='cuda:0')\n",
      "\n",
      "0 39795 tensor(12.8661, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 39795 tensor(13.0927, device='cuda:0')\n",
      "0 39795 tensor(13.0927, device='cuda:0')\n",
      "\n",
      "0 48505 tensor(13.0066, device='cuda:0')\n",
      "20\n",
      "162\n",
      "0 48505 tensor(14.2488, device='cuda:0')\n",
      "0 48505 tensor(13.5994, device='cuda:0')\n",
      "\n",
      "0 40316 tensor(12.7434, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 40316 tensor(13.2493, device='cuda:0')\n",
      "0 40316 tensor(13.2493, device='cuda:0')\n",
      "\n",
      "0 24958 tensor(12.2923, device='cuda:0')\n",
      "20\n",
      "212\n",
      "0 24958 tensor(13.1854, device='cuda:0')\n",
      "0 24958 tensor(13.1854, device='cuda:0')\n",
      "\n",
      "0 38783 tensor(11.8074, device='cuda:0')\n",
      "20\n",
      "164\n",
      "0 38783 tensor(12.3036, device='cuda:0')\n",
      "0 38783 tensor(12.8435, device='cuda:0')\n",
      "\n",
      "0 19838 tensor(13.8381, device='cuda:0')\n",
      "20\n",
      "208\n",
      "0 19838 tensor(13.6098, device='cuda:0')\n",
      "0 19838 tensor(14.1108, device='cuda:0')\n",
      "\n",
      "0 23425 tensor(12.8872, device='cuda:0')\n",
      "20\n",
      "174\n",
      "0 23425 tensor(13.8529, device='cuda:0')\n",
      "0 23425 tensor(12.4411, device='cuda:0')\n",
      "\n",
      "0 24962 tensor(12.3622, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 24962 tensor(12.7986, device='cuda:0')\n",
      "0 24962 tensor(13.5520, device='cuda:0')\n",
      "\n",
      "0 13187 tensor(12.3380, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 13187 tensor(12.6364, device='cuda:0')\n",
      "0 13187 tensor(13.2399, device='cuda:0')\n",
      "\n",
      "0 49028 tensor(12.2417, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 49028 tensor(12.8061, device='cuda:0')\n",
      "0 49028 tensor(12.6510, device='cuda:0')\n",
      "\n",
      "0 12167 tensor(12.3382, device='cuda:0')\n",
      "20\n",
      "186\n",
      "0 12167 tensor(12.8027, device='cuda:0')\n",
      "0 12167 tensor(12.8027, device='cuda:0')\n",
      "\n",
      "0 43406 tensor(12.9149, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 43406 tensor(13.8973, device='cuda:0')\n",
      "0 43406 tensor(13.9740, device='cuda:0')\n",
      "\n",
      "0 14737 tensor(12.6474, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 14737 tensor(12.5806, device='cuda:0')\n",
      "0 14737 tensor(12.7449, device='cuda:0')\n",
      "\n",
      "0 18322 tensor(12.3136, device='cuda:0')\n",
      "20\n",
      "164\n",
      "0 18322 tensor(12.3880, device='cuda:0')\n",
      "0 18322 tensor(12.3880, device='cuda:0')\n",
      "\n",
      "0 43921 tensor(13.0748, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 43921 tensor(12.7613, device='cuda:0')\n",
      "0 43921 tensor(14.0222, device='cuda:0')\n",
      "\n",
      "0 12694 tensor(12.2579, device='cuda:0')\n",
      "20\n",
      "204\n",
      "0 12694 tensor(12.5586, device='cuda:0')\n",
      "0 12694 tensor(13.2318, device='cuda:0')\n",
      "\n",
      "0 16286 tensor(12.7566, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 16286 tensor(13.7275, device='cuda:0')\n",
      "0 16286 tensor(13.5108, device='cuda:0')\n",
      "\n",
      "0 48545 tensor(13.1752, device='cuda:0')\n",
      "20\n",
      "202\n",
      "0 48545 tensor(12.6424, device='cuda:0')\n",
      "0 48545 tensor(13.3304, device='cuda:0')\n",
      "\n",
      "0 29092 tensor(12.8519, device='cuda:0')\n",
      "20\n",
      "158\n",
      "0 29092 tensor(12.6584, device='cuda:0')\n",
      "0 29092 tensor(13.5610, device='cuda:0')\n",
      "\n",
      "0 15273 tensor(12.5941, device='cuda:0')\n",
      "20\n",
      "200\n",
      "0 15273 tensor(12.8552, device='cuda:0')\n",
      "0 15273 tensor(13.6636, device='cuda:0')\n",
      "\n",
      "0 16809 tensor(13.0251, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 16809 tensor(13.8805, device='cuda:0')\n",
      "0 16809 tensor(13.4084, device='cuda:0')\n",
      "\n",
      "0 22455 tensor(13.1704, device='cuda:0')\n",
      "20\n",
      "132\n",
      "0 22455 tensor(12.8694, device='cuda:0')\n",
      "0 22455 tensor(13.6721, device='cuda:0')\n",
      "\n",
      "0 24504 tensor(13.0767, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 24504 tensor(13.1078, device='cuda:0')\n",
      "0 24504 tensor(13.1078, device='cuda:0')\n",
      "\n",
      "0 30140 tensor(12.9714, device='cuda:0')\n",
      "20\n",
      "210\n",
      "0 30140 tensor(14.0629, device='cuda:0')\n",
      "0 30140 tensor(12.8758, device='cuda:0')\n",
      "\n",
      "0 27581 tensor(13.4112, device='cuda:0')\n",
      "20\n",
      "166\n",
      "0 27581 tensor(13.1010, device='cuda:0')\n",
      "0 27581 tensor(14.5210, device='cuda:0')\n",
      "\n",
      "0 21438 tensor(12.4552, device='cuda:0')\n",
      "20\n",
      "196\n",
      "0 21438 tensor(14.2379, device='cuda:0')\n",
      "0 21438 tensor(11.9707, device='cuda:0')\n",
      "\n",
      "0 35262 tensor(13.6834, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 35262 tensor(15.0434, device='cuda:0')\n",
      "0 35262 tensor(14.8274, device='cuda:0')\n",
      "\n",
      "0 36292 tensor(12.2635, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 36292 tensor(12.0955, device='cuda:0')\n",
      "0 36292 tensor(13.8856, device='cuda:0')\n",
      "\n",
      "0 6086 tensor(12.5683, device='cuda:0')\n",
      "20\n",
      "168\n",
      "0 6086 tensor(13.2408, device='cuda:0')\n",
      "0 6086 tensor(13.2408, device='cuda:0')\n",
      "\n",
      "0 21960 tensor(13.3261, device='cuda:0')\n",
      "20\n",
      "198\n",
      "0 21960 tensor(14.5252, device='cuda:0')\n",
      "0 21960 tensor(14.5252, device='cuda:0')\n",
      "\n",
      "0 20428 tensor(13.0249, device='cuda:0')\n",
      "20\n",
      "238\n",
      "0 20428 tensor(13.7627, device='cuda:0')\n",
      "0 20428 tensor(13.7627, device='cuda:0')\n",
      "\n",
      "0 17361 tensor(12.0272, device='cuda:0')\n",
      "20\n",
      "228\n",
      "0 17361 tensor(11.5770, device='cuda:0')\n",
      "0 17361 tensor(11.5770, device='cuda:0')\n",
      "\n",
      "0 33747 tensor(13.0465, device='cuda:0')\n",
      "20\n",
      "150\n",
      "0 33747 tensor(14.1489, device='cuda:0')\n",
      "0 33747 tensor(14.1331, device='cuda:0')\n",
      "\n",
      "0 2516 tensor(11.9069, device='cuda:0')\n",
      "20\n",
      "246\n",
      "0 2516 tensor(12.0264, device='cuda:0')\n",
      "0 2516 tensor(12.5887, device='cuda:0')\n",
      "\n",
      "0 13268 tensor(12.4609, device='cuda:0')\n",
      "20\n",
      "422\n",
      "0 13268 tensor(12.0122, device='cuda:0')\n",
      "0 13268 tensor(13.5152, device='cuda:0')\n",
      "\n",
      "0 45014 tensor(13.3116, device='cuda:0')\n",
      "20\n",
      "170\n",
      "0 45014 tensor(14.3072, device='cuda:0')\n",
      "0 45014 tensor(13.4576, device='cuda:0')\n",
      "\n",
      "0 25556 tensor(12.2228, device='cuda:0')\n",
      "20\n",
      "216\n",
      "0 25556 tensor(13.0954, device='cuda:0')\n",
      "0 25556 tensor(13.0954, device='cuda:0')\n",
      "\n",
      "0 33240 tensor(12.4233, device='cuda:0')\n",
      "20\n",
      "222\n",
      "0 33240 tensor(13.1098, device='cuda:0')\n",
      "0 33240 tensor(12.3225, device='cuda:0')\n",
      "\n",
      "0 36312 tensor(13.2771, device='cuda:0')\n",
      "20\n",
      "226\n",
      "0 36312 tensor(14.3066, device='cuda:0')\n",
      "0 36312 tensor(13.2195, device='cuda:0')\n",
      "\n",
      "0 16863 tensor(13.0230, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 16863 tensor(13.9046, device='cuda:0')\n",
      "0 16863 tensor(13.9046, device='cuda:0')\n",
      "\n",
      "0 28642 tensor(12.2957, device='cuda:0')\n",
      "20\n",
      "206\n",
      "0 28642 tensor(13.1583, device='cuda:0')\n",
      "0 28642 tensor(13.1583, device='cuda:0')\n",
      "\n",
      "0 10213 tensor(13.3126, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 10213 tensor(13.2984, device='cuda:0')\n",
      "0 10213 tensor(14.3738, device='cuda:0')\n",
      "\n",
      "0 16358 tensor(12.5390, device='cuda:0')\n",
      "20\n",
      "216\n",
      "0 16358 tensor(12.3742, device='cuda:0')\n",
      "0 16358 tensor(13.5036, device='cuda:0')\n",
      "\n",
      "0 25062 tensor(13.0945, device='cuda:0')\n",
      "20\n",
      "176\n",
      "0 25062 tensor(13.1179, device='cuda:0')\n",
      "0 25062 tensor(13.1179, device='cuda:0')\n",
      "\n",
      "0 23528 tensor(13.5638, device='cuda:0')\n",
      "20\n",
      "192\n",
      "0 23528 tensor(13.5350, device='cuda:0')\n",
      "0 23528 tensor(13.7990, device='cuda:0')\n",
      "\n",
      "0 35307 tensor(13.2558, device='cuda:0')\n",
      "20\n",
      "218\n",
      "0 35307 tensor(14.5309, device='cuda:0')\n",
      "0 35307 tensor(14.5538, device='cuda:0')\n",
      "\n",
      "0 19436 tensor(12.6872, device='cuda:0')\n",
      "20\n",
      "162\n",
      "0 19436 tensor(12.7100, device='cuda:0')\n",
      "0 19436 tensor(13.6665, device='cuda:0')\n",
      "\n",
      "0 25579 tensor(13.2359, device='cuda:0')\n",
      "20\n",
      "188\n",
      "0 25579 tensor(14.0493, device='cuda:0')\n",
      "0 25579 tensor(14.1312, device='cuda:0')\n",
      "\n",
      "0 15859 tensor(12.4461, device='cuda:0')\n",
      "20\n",
      "222\n",
      "0 15859 tensor(13.3387, device='cuda:0')\n",
      "0 15859 tensor(12.8957, device='cuda:0')\n",
      "\n",
      "0 38900 tensor(12.2654, device='cuda:0')\n",
      "20\n",
      "138\n",
      "0 38900 tensor(12.7655, device='cuda:0')\n",
      "0 38900 tensor(11.9774, device='cuda:0')\n",
      "\n",
      "0 7670 tensor(10.6032, device='cuda:0')\n",
      "20\n",
      "208\n",
      "0 7670 tensor(10.7171, device='cuda:0')\n",
      "0 7670 tensor(10.7171, device='cuda:0')\n",
      "\n",
      "0 8698 tensor(12.7098, device='cuda:0')\n",
      "20\n",
      "194\n",
      "0 8698 tensor(12.4334, device='cuda:0')\n",
      "0 8698 tensor(13.6267, device='cuda:0')\n",
      "\n",
      "0 12284 tensor(12.6145, device='cuda:0')\n",
      "20\n",
      "170\n",
      "0 12284 tensor(13.7517, device='cuda:0')\n",
      "0 12284 tensor(12.8655, device='cuda:0')\n",
      "\n",
      "0 44542 tensor(12.9658, device='cuda:0')\n",
      "20\n",
      "184\n",
      "0 44542 tensor(12.9477, device='cuda:0')\n",
      "0 44542 tensor(12.9477, device='cuda:0')\n",
      "\n",
      "0 31231 tensor(13.1420, device='cuda:0')\n",
      "20\n",
      "182\n",
      "0 31231 tensor(14.1063, device='cuda:0')\n",
      "0 31231 tensor(14.4024, device='cuda:0')\n",
      "\n",
      "1 50178 tensor(15.7074, device='cuda:0')\n",
      "20\n",
      "226\n",
      "1 50178 tensor(16.2534, device='cuda:0')\n",
      "1 50178 tensor(15.4733, device='cuda:0')\n",
      "\n",
      "1 46600 tensor(15.4210, device='cuda:0')\n",
      "20\n",
      "160\n",
      "1 46600 tensor(15.7580, device='cuda:0')\n",
      "1 46600 tensor(15.7049, device='cuda:0')\n",
      "\n",
      "1 31755 tensor(16.4432, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 31755 tensor(16.7634, device='cuda:0')\n",
      "1 31755 tensor(16.5680, device='cuda:0')\n",
      "\n",
      "1 46604 tensor(15.9008, device='cuda:0')\n",
      "20\n",
      "170\n",
      "1 46604 tensor(16.1943, device='cuda:0')\n",
      "1 46604 tensor(15.5951, device='cuda:0')\n",
      "\n",
      "1 10765 tensor(15.5257, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 10765 tensor(15.0526, device='cuda:0')\n",
      "1 10765 tensor(16.7608, device='cuda:0')\n",
      "\n",
      "1 11276 tensor(16.4390, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 11276 tensor(17.0363, device='cuda:0')\n",
      "1 11276 tensor(16.0400, device='cuda:0')\n",
      "\n",
      "1 33811 tensor(15.9239, device='cuda:0')\n",
      "20\n",
      "172\n",
      "1 33811 tensor(16.6154, device='cuda:0')\n",
      "1 33811 tensor(16.6154, device='cuda:0')\n",
      "\n",
      "1 46612 tensor(16.3463, device='cuda:0')\n",
      "20\n",
      "220\n",
      "1 46612 tensor(16.7996, device='cuda:0')\n",
      "1 46612 tensor(17.0951, device='cuda:0')\n",
      "\n",
      "1 16916 tensor(15.8676, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 16916 tensor(16.8116, device='cuda:0')\n",
      "1 16916 tensor(17.1821, device='cuda:0')\n",
      "\n",
      "1 18966 tensor(15.7044, device='cuda:0')\n",
      "20\n",
      "202\n",
      "1 18966 tensor(16.9044, device='cuda:0')\n",
      "1 18966 tensor(15.1205, device='cuda:0')\n",
      "\n",
      "1 12824 tensor(14.7762, device='cuda:0')\n",
      "20\n",
      "208\n",
      "1 12824 tensor(14.4470, device='cuda:0')\n",
      "1 12824 tensor(14.5847, device='cuda:0')\n",
      "\n",
      "1 32794 tensor(15.1593, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 32794 tensor(16.2660, device='cuda:0')\n",
      "1 32794 tensor(14.2677, device='cuda:0')\n",
      "\n",
      "1 7195 tensor(14.9728, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 7195 tensor(15.0815, device='cuda:0')\n",
      "1 7195 tensor(15.2455, device='cuda:0')\n",
      "\n",
      "1 33821 tensor(16.2161, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 33821 tensor(16.7100, device='cuda:0')\n",
      "1 33821 tensor(16.0342, device='cuda:0')\n",
      "\n",
      "1 37921 tensor(16.3117, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 37921 tensor(16.8148, device='cuda:0')\n",
      "1 37921 tensor(16.1679, device='cuda:0')\n",
      "\n",
      "1 33313 tensor(16.0555, device='cuda:0')\n",
      "20\n",
      "228\n",
      "1 33313 tensor(15.6224, device='cuda:0')\n",
      "1 33313 tensor(16.6221, device='cuda:0')\n",
      "\n",
      "1 31270 tensor(15.5895, device='cuda:0')\n",
      "20\n",
      "172\n",
      "1 31270 tensor(16.2073, device='cuda:0')\n",
      "1 31270 tensor(16.2073, device='cuda:0')\n",
      "\n",
      "1 29222 tensor(15.2953, device='cuda:0')\n",
      "20\n",
      "156\n",
      "1 29222 tensor(15.7554, device='cuda:0')\n",
      "1 29222 tensor(14.1914, device='cuda:0')\n",
      "\n",
      "1 28712 tensor(15.5100, device='cuda:0')\n",
      "20\n",
      "166\n",
      "1 28712 tensor(15.3509, device='cuda:0')\n",
      "1 28712 tensor(15.4861, device='cuda:0')\n",
      "\n",
      "1 18985 tensor(15.0077, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 18985 tensor(15.1153, device='cuda:0')\n",
      "1 18985 tensor(15.1637, device='cuda:0')\n",
      "\n",
      "1 37930 tensor(15.9600, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 37930 tensor(16.3716, device='cuda:0')\n",
      "1 37930 tensor(16.7532, device='cuda:0')\n",
      "\n",
      "1 28200 tensor(15.1458, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 28200 tensor(16.2742, device='cuda:0')\n",
      "1 28200 tensor(15.2444, device='cuda:0')\n",
      "\n",
      "1 7727 tensor(15.0032, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 7727 tensor(15.7449, device='cuda:0')\n",
      "1 7727 tensor(14.3341, device='cuda:0')\n",
      "\n",
      "1 24112 tensor(16.5894, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 24112 tensor(17.3529, device='cuda:0')\n",
      "1 24112 tensor(16.5836, device='cuda:0')\n",
      "\n",
      "1 36400 tensor(15.7391, device='cuda:0')\n",
      "20\n",
      "214\n",
      "1 36400 tensor(16.7340, device='cuda:0')\n",
      "1 36400 tensor(16.0640, device='cuda:0')\n",
      "\n",
      "1 32817 tensor(15.9051, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 32817 tensor(16.3226, device='cuda:0')\n",
      "1 32817 tensor(16.6031, device='cuda:0')\n",
      "\n",
      "1 5171 tensor(14.7162, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 5171 tensor(15.5868, device='cuda:0')\n",
      "1 5171 tensor(14.6438, device='cuda:0')\n",
      "\n",
      "1 44085 tensor(15.8415, device='cuda:0')\n",
      "20\n",
      "238\n",
      "1 44085 tensor(16.1884, device='cuda:0')\n",
      "1 44085 tensor(16.6560, device='cuda:0')\n",
      "\n",
      "1 35382 tensor(16.3130, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 35382 tensor(16.5542, device='cuda:0')\n",
      "1 35382 tensor(15.6711, device='cuda:0')\n",
      "\n",
      "1 14912 tensor(15.9040, device='cuda:0')\n",
      "20\n",
      "170\n",
      "1 14912 tensor(15.7353, device='cuda:0')\n",
      "1 14912 tensor(17.0310, device='cuda:0')\n",
      "\n",
      "1 30274 tensor(14.9510, device='cuda:0')\n",
      "20\n",
      "186\n",
      "1 30274 tensor(15.6739, device='cuda:0')\n",
      "1 30274 tensor(15.7348, device='cuda:0')\n",
      "\n",
      "1 20554 tensor(15.0991, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 20554 tensor(15.7663, device='cuda:0')\n",
      "1 20554 tensor(16.0638, device='cuda:0')\n",
      "\n",
      "1 15435 tensor(15.9083, device='cuda:0')\n",
      "20\n",
      "150\n",
      "1 15435 tensor(16.1580, device='cuda:0')\n",
      "1 15435 tensor(15.7384, device='cuda:0')\n",
      "\n",
      "1 33357 tensor(15.4399, device='cuda:0')\n",
      "20\n",
      "146\n",
      "1 33357 tensor(16.2427, device='cuda:0')\n",
      "1 33357 tensor(16.3464, device='cuda:0')\n",
      "\n",
      "1 49231 tensor(16.8054, device='cuda:0')\n",
      "20\n",
      "224\n",
      "1 49231 tensor(17.4806, device='cuda:0')\n",
      "1 49231 tensor(17.3705, device='cuda:0')\n",
      "\n",
      "1 38994 tensor(15.0870, device='cuda:0')\n",
      "20\n",
      "172\n",
      "1 38994 tensor(14.0160, device='cuda:0')\n",
      "1 38994 tensor(16.4428, device='cuda:0')\n",
      "\n",
      "1 21587 tensor(15.0068, device='cuda:0')\n",
      "20\n",
      "150\n",
      "1 21587 tensor(15.1557, device='cuda:0')\n",
      "1 21587 tensor(15.9418, device='cuda:0')\n",
      "\n",
      "1 7252 tensor(14.3525, device='cuda:0')\n",
      "20\n",
      "164\n",
      "1 7252 tensor(14.7665, device='cuda:0')\n",
      "1 7252 tensor(15.2643, device='cuda:0')\n",
      "\n",
      "1 40537 tensor(15.6442, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 40537 tensor(15.5102, device='cuda:0')\n",
      "1 40537 tensor(15.5124, device='cuda:0')\n",
      "\n",
      "1 27738 tensor(16.7366, device='cuda:0')\n",
      "20\n",
      "210\n",
      "1 27738 tensor(16.9601, device='cuda:0')\n",
      "1 27738 tensor(16.0083, device='cuda:0')\n",
      "\n",
      "1 44123 tensor(15.9564, device='cuda:0')\n",
      "20\n",
      "170\n",
      "1 44123 tensor(16.5446, device='cuda:0')\n",
      "1 44123 tensor(16.3204, device='cuda:0')\n",
      "\n",
      "1 44124 tensor(15.8120, device='cuda:0')\n",
      "20\n",
      "248\n",
      "1 44124 tensor(16.9179, device='cuda:0')\n",
      "1 44124 tensor(16.6997, device='cuda:0')\n",
      "\n",
      "1 14943 tensor(15.6649, device='cuda:0')\n",
      "20\n",
      "226\n",
      "1 14943 tensor(15.5060, device='cuda:0')\n",
      "1 14943 tensor(16.5952, device='cuda:0')\n",
      "\n",
      "1 45664 tensor(16.1679, device='cuda:0')\n",
      "20\n",
      "156\n",
      "1 45664 tensor(16.5550, device='cuda:0')\n",
      "1 45664 tensor(16.6958, device='cuda:0')\n",
      "\n",
      "1 15458 tensor(15.4787, device='cuda:0')\n",
      "20\n",
      "202\n",
      "1 15458 tensor(16.2398, device='cuda:0')\n",
      "1 15458 tensor(16.7928, device='cuda:0')\n",
      "\n",
      "1 49765 tensor(15.0020, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 49765 tensor(16.5614, device='cuda:0')\n",
      "1 49765 tensor(15.3706, device='cuda:0')\n",
      "\n",
      "1 19046 tensor(15.7741, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 19046 tensor(16.6210, device='cuda:0')\n",
      "1 19046 tensor(14.3126, device='cuda:0')\n",
      "\n",
      "1 35944 tensor(15.4771, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 35944 tensor(15.6351, device='cuda:0')\n",
      "1 35944 tensor(14.6453, device='cuda:0')\n",
      "\n",
      "1 29804 tensor(16.1097, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 29804 tensor(16.8469, device='cuda:0')\n",
      "1 29804 tensor(17.2977, device='cuda:0')\n",
      "\n",
      "1 23662 tensor(15.6475, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 23662 tensor(16.2332, device='cuda:0')\n",
      "1 23662 tensor(16.2332, device='cuda:0')\n",
      "\n",
      "1 37497 tensor(15.9719, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 37497 tensor(15.6662, device='cuda:0')\n",
      "1 37497 tensor(15.9289, device='cuda:0')\n",
      "\n",
      "1 22138 tensor(15.9159, device='cuda:0')\n",
      "20\n",
      "164\n",
      "1 22138 tensor(16.6442, device='cuda:0')\n",
      "1 22138 tensor(16.4719, device='cuda:0')\n",
      "\n",
      "1 27773 tensor(16.2888, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 27773 tensor(15.1288, device='cuda:0')\n",
      "1 27773 tensor(16.5813, device='cuda:0')\n",
      "\n",
      "1 28798 tensor(15.2637, device='cuda:0')\n",
      "20\n",
      "252\n",
      "1 28798 tensor(15.8890, device='cuda:0')\n",
      "1 28798 tensor(15.5642, device='cuda:0')\n",
      "\n",
      "1 33407 tensor(16.5549, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 33407 tensor(17.0652, device='cuda:0')\n",
      "1 33407 tensor(16.8593, device='cuda:0')\n",
      "\n",
      "1 27264 tensor(15.0249, device='cuda:0')\n",
      "20\n",
      "206\n",
      "1 27264 tensor(16.6893, device='cuda:0')\n",
      "1 27264 tensor(16.7239, device='cuda:0')\n",
      "\n",
      "1 9857 tensor(15.5887, device='cuda:0')\n",
      "20\n",
      "168\n",
      "1 9857 tensor(16.1149, device='cuda:0')\n",
      "1 9857 tensor(15.1956, device='cuda:0')\n",
      "\n",
      "1 14468 tensor(15.7740, device='cuda:0')\n",
      "20\n",
      "160\n",
      "1 14468 tensor(15.7208, device='cuda:0')\n",
      "1 14468 tensor(16.7369, device='cuda:0')\n",
      "\n",
      "1 6277 tensor(14.9515, device='cuda:0')\n",
      "20\n",
      "152\n",
      "1 6277 tensor(14.5267, device='cuda:0')\n",
      "1 6277 tensor(16.0850, device='cuda:0')\n",
      "\n",
      "1 35972 tensor(16.2013, device='cuda:0')\n",
      "20\n",
      "222\n",
      "1 35972 tensor(16.7012, device='cuda:0')\n",
      "1 35972 tensor(15.8819, device='cuda:0')\n",
      "\n",
      "1 4744 tensor(14.3911, device='cuda:0')\n",
      "20\n",
      "186\n",
      "1 4744 tensor(14.8862, device='cuda:0')\n",
      "1 4744 tensor(15.0672, device='cuda:0')\n",
      "\n",
      "1 32905 tensor(15.1321, device='cuda:0')\n",
      "20\n",
      "160\n",
      "1 32905 tensor(16.6128, device='cuda:0')\n",
      "1 32905 tensor(15.7300, device='cuda:0')\n",
      "\n",
      "1 32393 tensor(15.6499, device='cuda:0')\n",
      "20\n",
      "224\n",
      "1 32393 tensor(16.0953, device='cuda:0')\n",
      "1 32393 tensor(15.0347, device='cuda:0')\n",
      "\n",
      "1 22671 tensor(15.8846, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 22671 tensor(15.6327, device='cuda:0')\n",
      "1 22671 tensor(15.0493, device='cuda:0')\n",
      "\n",
      "1 20628 tensor(15.7065, device='cuda:0')\n",
      "20\n",
      "202\n",
      "1 20628 tensor(14.7395, device='cuda:0')\n",
      "1 20628 tensor(16.4018, device='cuda:0')\n",
      "\n",
      "1 32920 tensor(16.5663, device='cuda:0')\n",
      "20\n",
      "366\n",
      "1 32920 tensor(16.4159, device='cuda:0')\n",
      "1 32920 tensor(16.9852, device='cuda:0')\n",
      "\n",
      "1 17560 tensor(15.4612, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 17560 tensor(15.7223, device='cuda:0')\n",
      "1 17560 tensor(15.4718, device='cuda:0')\n",
      "\n",
      "1 5119 tensor(14.3575, device='cuda:0')\n",
      "20\n",
      "128\n",
      "1 5119 tensor(14.0584, device='cuda:0')\n",
      "1 5119 tensor(15.3148, device='cuda:0')\n",
      "\n",
      "1 21661 tensor(16.0954, device='cuda:0')\n",
      "20\n",
      "226\n",
      "1 21661 tensor(17.0227, device='cuda:0')\n",
      "1 21661 tensor(16.0576, device='cuda:0')\n",
      "\n",
      "1 16543 tensor(15.8544, device='cuda:0')\n",
      "20\n",
      "142\n",
      "1 16543 tensor(16.4414, device='cuda:0')\n",
      "1 16543 tensor(15.6311, device='cuda:0')\n",
      "\n",
      "1 31903 tensor(15.1589, device='cuda:0')\n",
      "20\n",
      "230\n",
      "1 31903 tensor(15.1406, device='cuda:0')\n",
      "1 31903 tensor(15.2804, device='cuda:0')\n",
      "\n",
      "1 18089 tensor(15.4746, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 18089 tensor(16.7594, device='cuda:0')\n",
      "1 18089 tensor(16.6082, device='cuda:0')\n",
      "\n",
      "1 16553 tensor(15.2905, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 16553 tensor(15.7252, device='cuda:0')\n",
      "1 16553 tensor(16.0583, device='cuda:0')\n",
      "\n",
      "1 28331 tensor(15.4056, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 28331 tensor(16.2916, device='cuda:0')\n",
      "1 28331 tensor(15.6877, device='cuda:0')\n",
      "\n",
      "1 41131 tensor(16.1673, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 41131 tensor(17.0373, device='cuda:0')\n",
      "1 41131 tensor(16.4276, device='cuda:0')\n",
      "\n",
      "1 20145 tensor(15.2838, device='cuda:0')\n",
      "20\n",
      "158\n",
      "1 20145 tensor(15.2750, device='cuda:0')\n",
      "1 20145 tensor(16.5208, device='cuda:0')\n",
      "\n",
      "1 46262 tensor(16.3639, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 46262 tensor(16.7958, device='cuda:0')\n",
      "1 46262 tensor(16.9610, device='cuda:0')\n",
      "\n",
      "1 30397 tensor(16.0097, device='cuda:0')\n",
      "20\n",
      "242\n",
      "1 30397 tensor(16.7662, device='cuda:0')\n",
      "1 30397 tensor(16.7464, device='cuda:0')\n",
      "\n",
      "1 41151 tensor(15.6972, device='cuda:0')\n",
      "20\n",
      "216\n",
      "1 41151 tensor(16.4151, device='cuda:0')\n",
      "1 41151 tensor(16.1207, device='cuda:0')\n",
      "\n",
      "1 22723 tensor(15.3244, device='cuda:0')\n",
      "20\n",
      "208\n",
      "1 22723 tensor(15.2398, device='cuda:0')\n",
      "1 22723 tensor(14.7139, device='cuda:0')\n",
      "\n",
      "1 23239 tensor(15.5627, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 23239 tensor(16.5180, device='cuda:0')\n",
      "1 23239 tensor(16.2509, device='cuda:0')\n",
      "\n",
      "1 14538 tensor(14.9049, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 14538 tensor(15.8362, device='cuda:0')\n",
      "1 14538 tensor(15.4360, device='cuda:0')\n",
      "\n",
      "1 17100 tensor(15.1639, device='cuda:0')\n",
      "20\n",
      "192\n",
      "1 17100 tensor(15.6138, device='cuda:0')\n",
      "1 17100 tensor(14.7737, device='cuda:0')\n",
      "\n",
      "1 37073 tensor(15.7439, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 37073 tensor(16.4165, device='cuda:0')\n",
      "1 37073 tensor(16.6782, device='cuda:0')\n",
      "\n",
      "1 22739 tensor(16.2814, device='cuda:0')\n",
      "20\n",
      "222\n",
      "1 22739 tensor(17.0443, device='cuda:0')\n",
      "1 22739 tensor(16.3561, device='cuda:0')\n",
      "\n",
      "1 49365 tensor(15.8208, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 49365 tensor(15.9210, device='cuda:0')\n",
      "1 49365 tensor(15.9742, device='cuda:0')\n",
      "\n",
      "1 16598 tensor(15.1784, device='cuda:0')\n",
      "20\n",
      "128\n",
      "1 16598 tensor(15.5970, device='cuda:0')\n",
      "1 16598 tensor(15.9540, device='cuda:0')\n",
      "\n",
      "1 47831 tensor(15.6583, device='cuda:0')\n",
      "20\n",
      "188\n",
      "1 47831 tensor(15.8059, device='cuda:0')\n",
      "1 47831 tensor(15.8059, device='cuda:0')\n",
      "\n",
      "1 31959 tensor(16.3444, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 31959 tensor(16.3689, device='cuda:0')\n",
      "1 31959 tensor(16.2707, device='cuda:0')\n",
      "\n",
      "1 22234 tensor(15.3804, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 22234 tensor(15.9557, device='cuda:0')\n",
      "1 22234 tensor(15.7169, device='cuda:0')\n",
      "\n",
      "1 23259 tensor(15.5356, device='cuda:0')\n",
      "20\n",
      "164\n",
      "1 23259 tensor(15.8471, device='cuda:0')\n",
      "1 23259 tensor(16.1310, device='cuda:0')\n",
      "\n",
      "1 20189 tensor(16.2954, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 20189 tensor(15.8486, device='cuda:0')\n",
      "1 20189 tensor(17.1131, device='cuda:0')\n",
      "\n",
      "1 45790 tensor(15.5139, device='cuda:0')\n",
      "20\n",
      "210\n",
      "1 45790 tensor(16.2846, device='cuda:0')\n",
      "1 45790 tensor(16.4870, device='cuda:0')\n",
      "\n",
      "1 29927 tensor(16.1407, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 29927 tensor(15.7981, device='cuda:0')\n",
      "1 29927 tensor(16.7414, device='cuda:0')\n",
      "\n",
      "1 46312 tensor(15.6938, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 46312 tensor(15.3948, device='cuda:0')\n",
      "1 46312 tensor(15.7140, device='cuda:0')\n",
      "\n",
      "1 31465 tensor(15.6636, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 31465 tensor(16.4116, device='cuda:0')\n",
      "1 31465 tensor(15.7018, device='cuda:0')\n",
      "\n",
      "1 46831 tensor(15.7689, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 46831 tensor(15.1687, device='cuda:0')\n",
      "1 46831 tensor(16.5930, device='cuda:0')\n",
      "\n",
      "1 31472 tensor(15.6724, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 31472 tensor(16.2115, device='cuda:0')\n",
      "1 31472 tensor(16.5359, device='cuda:0')\n",
      "\n",
      "1 29936 tensor(15.6651, device='cuda:0')\n",
      "20\n",
      "118\n",
      "1 29936 tensor(16.3777, device='cuda:0')\n",
      "1 29936 tensor(16.3777, device='cuda:0')\n",
      "\n",
      "1 26355 tensor(14.9800, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 26355 tensor(15.1279, device='cuda:0')\n",
      "1 26355 tensor(15.3907, device='cuda:0')\n",
      "\n",
      "1 6393 tensor(14.3200, device='cuda:0')\n",
      "20\n",
      "224\n",
      "1 6393 tensor(15.1956, device='cuda:0')\n",
      "1 6393 tensor(14.6268, device='cuda:0')\n",
      "\n",
      "1 26876 tensor(15.2676, device='cuda:0')\n",
      "20\n",
      "174\n",
      "1 26876 tensor(14.7577, device='cuda:0')\n",
      "1 26876 tensor(15.7584, device='cuda:0')\n",
      "\n",
      "1 8444 tensor(13.7794, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 8444 tensor(14.4685, device='cuda:0')\n",
      "1 8444 tensor(14.4685, device='cuda:0')\n",
      "\n",
      "1 26878 tensor(16.5050, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 26878 tensor(16.4519, device='cuda:0')\n",
      "1 26878 tensor(16.4520, device='cuda:0')\n",
      "\n",
      "1 6911 tensor(15.1405, device='cuda:0')\n",
      "20\n",
      "162\n",
      "1 6911 tensor(16.2840, device='cuda:0')\n",
      "1 6911 tensor(14.8533, device='cuda:0')\n",
      "\n",
      "1 25856 tensor(15.9203, device='cuda:0')\n",
      "20\n",
      "128\n",
      "1 25856 tensor(16.1798, device='cuda:0')\n",
      "1 25856 tensor(16.0398, device='cuda:0')\n",
      "\n",
      "1 21249 tensor(14.9521, device='cuda:0')\n",
      "20\n",
      "158\n",
      "1 21249 tensor(15.7201, device='cuda:0')\n",
      "1 21249 tensor(15.7201, device='cuda:0')\n",
      "\n",
      "1 19717 tensor(15.0450, device='cuda:0')\n",
      "20\n",
      "158\n",
      "1 19717 tensor(16.0011, device='cuda:0')\n",
      "1 19717 tensor(15.2024, device='cuda:0')\n",
      "\n",
      "1 8966 tensor(15.7492, device='cuda:0')\n",
      "20\n",
      "192\n",
      "1 8966 tensor(16.4950, device='cuda:0')\n",
      "1 8966 tensor(16.6421, device='cuda:0')\n",
      "\n",
      "1 38150 tensor(15.8248, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 38150 tensor(15.3894, device='cuda:0')\n",
      "1 38150 tensor(15.6767, device='cuda:0')\n",
      "\n",
      "1 26888 tensor(15.8087, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 26888 tensor(15.1262, device='cuda:0')\n",
      "1 26888 tensor(16.6847, device='cuda:0')\n",
      "\n",
      "1 27917 tensor(15.7817, device='cuda:0')\n",
      "20\n",
      "254\n",
      "1 27917 tensor(15.9347, device='cuda:0')\n",
      "1 27917 tensor(16.4367, device='cuda:0')\n",
      "\n",
      "1 39184 tensor(14.8729, device='cuda:0')\n",
      "20\n",
      "174\n",
      "1 39184 tensor(13.6736, device='cuda:0')\n",
      "1 39184 tensor(12.7051, device='cuda:0')\n",
      "\n",
      "1 48401 tensor(15.7629, device='cuda:0')\n",
      "20\n",
      "216\n",
      "1 48401 tensor(16.4348, device='cuda:0')\n",
      "1 48401 tensor(16.6368, device='cuda:0')\n",
      "\n",
      "1 24336 tensor(16.0766, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 24336 tensor(15.5764, device='cuda:0')\n",
      "1 24336 tensor(16.7060, device='cuda:0')\n",
      "\n",
      "1 6416 tensor(14.8286, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 6416 tensor(15.2773, device='cuda:0')\n",
      "1 6416 tensor(15.6775, device='cuda:0')\n",
      "\n",
      "1 23316 tensor(15.3875, device='cuda:0')\n",
      "20\n",
      "174\n",
      "1 23316 tensor(15.7147, device='cuda:0')\n",
      "1 23316 tensor(16.3953, device='cuda:0')\n",
      "\n",
      "1 37144 tensor(15.7829, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 37144 tensor(15.5775, device='cuda:0')\n",
      "1 37144 tensor(15.8052, device='cuda:0')\n",
      "\n",
      "1 31513 tensor(14.9628, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 31513 tensor(14.3669, device='cuda:0')\n",
      "1 31513 tensor(14.3669, device='cuda:0')\n",
      "\n",
      "1 42266 tensor(15.6460, device='cuda:0')\n",
      "20\n",
      "122\n",
      "1 42266 tensor(15.1210, device='cuda:0')\n",
      "1 42266 tensor(15.2089, device='cuda:0')\n",
      "\n",
      "1 29989 tensor(15.7444, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 29989 tensor(16.0318, device='cuda:0')\n",
      "1 29989 tensor(16.1903, device='cuda:0')\n",
      "\n",
      "1 27434 tensor(16.2788, device='cuda:0')\n",
      "20\n",
      "202\n",
      "1 27434 tensor(16.0359, device='cuda:0')\n",
      "1 27434 tensor(16.0359, device='cuda:0')\n",
      "\n",
      "1 45867 tensor(15.8440, device='cuda:0')\n",
      "20\n",
      "170\n",
      "1 45867 tensor(14.9055, device='cuda:0')\n",
      "1 45867 tensor(15.5798, device='cuda:0')\n",
      "\n",
      "1 36139 tensor(15.9463, device='cuda:0')\n",
      "20\n",
      "224\n",
      "1 36139 tensor(16.6305, device='cuda:0')\n",
      "1 36139 tensor(15.1182, device='cuda:0')\n",
      "\n",
      "1 29489 tensor(15.6783, device='cuda:0')\n",
      "20\n",
      "192\n",
      "1 29489 tensor(15.8427, device='cuda:0')\n",
      "1 29489 tensor(16.0139, device='cuda:0')\n",
      "\n",
      "1 27443 tensor(15.3448, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 27443 tensor(16.3444, device='cuda:0')\n",
      "1 27443 tensor(15.9511, device='cuda:0')\n",
      "\n",
      "1 27955 tensor(15.8246, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 27955 tensor(15.8436, device='cuda:0')\n",
      "1 27955 tensor(16.7534, device='cuda:0')\n",
      "\n",
      "1 22838 tensor(15.7237, device='cuda:0')\n",
      "20\n",
      "186\n",
      "1 22838 tensor(16.6076, device='cuda:0')\n",
      "1 22838 tensor(16.1994, device='cuda:0')\n",
      "\n",
      "1 7993 tensor(15.0867, device='cuda:0')\n",
      "20\n",
      "184\n",
      "1 7993 tensor(14.9394, device='cuda:0')\n",
      "1 7993 tensor(15.9982, device='cuda:0')\n",
      "\n",
      "1 13114 tensor(15.9793, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 13114 tensor(15.9124, device='cuda:0')\n",
      "1 13114 tensor(16.8245, device='cuda:0')\n",
      "\n",
      "1 13629 tensor(15.3702, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 13629 tensor(14.9577, device='cuda:0')\n",
      "1 13629 tensor(16.2333, device='cuda:0')\n",
      "\n",
      "1 28991 tensor(15.5514, device='cuda:0')\n",
      "20\n",
      "162\n",
      "1 28991 tensor(15.9481, device='cuda:0')\n",
      "1 28991 tensor(15.9481, device='cuda:0')\n",
      "\n",
      "1 40771 tensor(15.8351, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 40771 tensor(16.5202, device='cuda:0')\n",
      "1 40771 tensor(16.7430, device='cuda:0')\n",
      "\n",
      "1 25413 tensor(15.3287, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 25413 tensor(15.1134, device='cuda:0')\n",
      "1 25413 tensor(15.6632, device='cuda:0')\n",
      "\n",
      "1 44870 tensor(15.8824, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 44870 tensor(15.4818, device='cuda:0')\n",
      "1 44870 tensor(16.1317, device='cuda:0')\n",
      "\n",
      "1 18247 tensor(15.7295, device='cuda:0')\n",
      "20\n",
      "168\n",
      "1 18247 tensor(16.4273, device='cuda:0')\n",
      "1 18247 tensor(16.6584, device='cuda:0')\n",
      "\n",
      "1 47944 tensor(15.3815, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 47944 tensor(15.1232, device='cuda:0')\n",
      "1 47944 tensor(15.7301, device='cuda:0')\n",
      "\n",
      "1 35657 tensor(16.5817, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 35657 tensor(17.0345, device='cuda:0')\n",
      "1 35657 tensor(16.4876, device='cuda:0')\n",
      "\n",
      "1 26953 tensor(16.1912, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 26953 tensor(17.4672, device='cuda:0')\n",
      "1 26953 tensor(16.6245, device='cuda:0')\n",
      "\n",
      "1 13651 tensor(14.6432, device='cuda:0')\n",
      "20\n",
      "164\n",
      "1 13651 tensor(16.4905, device='cuda:0')\n",
      "1 13651 tensor(12.9937, device='cuda:0')\n",
      "\n",
      "1 27991 tensor(15.7175, device='cuda:0')\n",
      "20\n",
      "226\n",
      "1 27991 tensor(15.9466, device='cuda:0')\n",
      "1 27991 tensor(16.3622, device='cuda:0')\n",
      "\n",
      "1 26456 tensor(15.6743, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 26456 tensor(15.8847, device='cuda:0')\n",
      "1 26456 tensor(15.8847, device='cuda:0')\n",
      "\n",
      "1 48990 tensor(16.2221, device='cuda:0')\n",
      "20\n",
      "170\n",
      "1 48990 tensor(16.8305, device='cuda:0')\n",
      "1 48990 tensor(16.4937, device='cuda:0')\n",
      "\n",
      "1 34655 tensor(16.2296, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 34655 tensor(17.3423, device='cuda:0')\n",
      "1 34655 tensor(17.3423, device='cuda:0')\n",
      "\n",
      "1 16225 tensor(14.4860, device='cuda:0')\n",
      "20\n",
      "186\n",
      "1 16225 tensor(14.8133, device='cuda:0')\n",
      "1 16225 tensor(16.0248, device='cuda:0')\n",
      "\n",
      "1 28518 tensor(16.4949, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 28518 tensor(17.2781, device='cuda:0')\n",
      "1 28518 tensor(17.2904, device='cuda:0')\n",
      "\n",
      "1 20839 tensor(14.5389, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 20839 tensor(13.9388, device='cuda:0')\n",
      "1 20839 tensor(15.1566, device='cuda:0')\n",
      "\n",
      "1 43367 tensor(16.4256, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 43367 tensor(17.2750, device='cuda:0')\n",
      "1 43367 tensor(16.7796, device='cuda:0')\n",
      "\n",
      "1 10092 tensor(14.5704, device='cuda:0')\n",
      "20\n",
      "192\n",
      "1 10092 tensor(14.2835, device='cuda:0')\n",
      "1 10092 tensor(14.5991, device='cuda:0')\n",
      "\n",
      "1 11116 tensor(15.2133, device='cuda:0')\n",
      "20\n",
      "164\n",
      "1 11116 tensor(16.1418, device='cuda:0')\n",
      "1 11116 tensor(15.6044, device='cuda:0')\n",
      "\n",
      "1 31086 tensor(15.3876, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 31086 tensor(15.9495, device='cuda:0')\n",
      "1 31086 tensor(15.4706, device='cuda:0')\n",
      "\n",
      "1 29040 tensor(16.0898, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 29040 tensor(15.8347, device='cuda:0')\n",
      "1 29040 tensor(15.8347, device='cuda:0')\n",
      "\n",
      "1 50033 tensor(15.9076, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 50033 tensor(15.9797, device='cuda:0')\n",
      "1 50033 tensor(16.3896, device='cuda:0')\n",
      "\n",
      "1 5490 tensor(14.5660, device='cuda:0')\n",
      "20\n",
      "228\n",
      "1 5490 tensor(15.8681, device='cuda:0')\n",
      "1 5490 tensor(15.0807, device='cuda:0')\n",
      "\n",
      "1 39795 tensor(15.9999, device='cuda:0')\n",
      "20\n",
      "156\n",
      "1 39795 tensor(16.3575, device='cuda:0')\n",
      "1 39795 tensor(16.2746, device='cuda:0')\n",
      "\n",
      "1 48505 tensor(15.7713, device='cuda:0')\n",
      "20\n",
      "168\n",
      "1 48505 tensor(15.1353, device='cuda:0')\n",
      "1 48505 tensor(15.7428, device='cuda:0')\n",
      "\n",
      "1 40316 tensor(15.5743, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 40316 tensor(16.2970, device='cuda:0')\n",
      "1 40316 tensor(16.5755, device='cuda:0')\n",
      "\n",
      "1 24958 tensor(14.8738, device='cuda:0')\n",
      "20\n",
      "136\n",
      "1 24958 tensor(15.4100, device='cuda:0')\n",
      "1 24958 tensor(15.4100, device='cuda:0')\n",
      "\n",
      "1 38783 tensor(15.1988, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 38783 tensor(16.2793, device='cuda:0')\n",
      "1 38783 tensor(16.6827, device='cuda:0')\n",
      "\n",
      "1 19838 tensor(16.4154, device='cuda:0')\n",
      "20\n",
      "210\n",
      "1 19838 tensor(16.9570, device='cuda:0')\n",
      "1 19838 tensor(16.5006, device='cuda:0')\n",
      "\n",
      "1 23425 tensor(15.6889, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 23425 tensor(17.1115, device='cuda:0')\n",
      "1 23425 tensor(14.9262, device='cuda:0')\n",
      "\n",
      "1 24962 tensor(15.2278, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 24962 tensor(16.0251, device='cuda:0')\n",
      "1 24962 tensor(16.0343, device='cuda:0')\n",
      "\n",
      "1 13187 tensor(14.6310, device='cuda:0')\n",
      "20\n",
      "198\n",
      "1 13187 tensor(15.0033, device='cuda:0')\n",
      "1 13187 tensor(15.6368, device='cuda:0')\n",
      "\n",
      "1 49028 tensor(15.0600, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 49028 tensor(15.8209, device='cuda:0')\n",
      "1 49028 tensor(15.9436, device='cuda:0')\n",
      "\n",
      "1 12167 tensor(14.7295, device='cuda:0')\n",
      "20\n",
      "214\n",
      "1 12167 tensor(15.2925, device='cuda:0')\n",
      "1 12167 tensor(14.2555, device='cuda:0')\n",
      "\n",
      "1 43406 tensor(15.2562, device='cuda:0')\n",
      "20\n",
      "232\n",
      "1 43406 tensor(16.1534, device='cuda:0')\n",
      "1 43406 tensor(16.3047, device='cuda:0')\n",
      "\n",
      "1 14737 tensor(15.3453, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 14737 tensor(16.2795, device='cuda:0')\n",
      "1 14737 tensor(13.5682, device='cuda:0')\n",
      "\n",
      "1 18322 tensor(15.0890, device='cuda:0')\n",
      "20\n",
      "154\n",
      "1 18322 tensor(16.4490, device='cuda:0')\n",
      "1 18322 tensor(16.4490, device='cuda:0')\n",
      "\n",
      "1 43921 tensor(15.7794, device='cuda:0')\n",
      "20\n",
      "202\n",
      "1 43921 tensor(15.2304, device='cuda:0')\n",
      "1 43921 tensor(16.4376, device='cuda:0')\n",
      "\n",
      "1 12694 tensor(14.9134, device='cuda:0')\n",
      "20\n",
      "192\n",
      "1 12694 tensor(15.5206, device='cuda:0')\n",
      "1 12694 tensor(15.5206, device='cuda:0')\n",
      "\n",
      "1 16286 tensor(16.1322, device='cuda:0')\n",
      "20\n",
      "156\n",
      "1 16286 tensor(17.0677, device='cuda:0')\n",
      "1 16286 tensor(16.9400, device='cuda:0')\n",
      "\n",
      "1 48545 tensor(16.7478, device='cuda:0')\n",
      "20\n",
      "152\n",
      "1 48545 tensor(17.4584, device='cuda:0')\n",
      "1 48545 tensor(17.2560, device='cuda:0')\n",
      "\n",
      "1 29092 tensor(15.4415, device='cuda:0')\n",
      "20\n",
      "226\n",
      "1 29092 tensor(16.3317, device='cuda:0')\n",
      "1 29092 tensor(16.4489, device='cuda:0')\n",
      "\n",
      "1 15273 tensor(15.2380, device='cuda:0')\n",
      "20\n",
      "180\n",
      "1 15273 tensor(14.5829, device='cuda:0')\n",
      "1 15273 tensor(15.2164, device='cuda:0')\n",
      "\n",
      "1 16809 tensor(15.8510, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 16809 tensor(16.4744, device='cuda:0')\n",
      "1 16809 tensor(15.0937, device='cuda:0')\n",
      "\n",
      "1 22455 tensor(16.0443, device='cuda:0')\n",
      "20\n",
      "172\n",
      "1 22455 tensor(16.8328, device='cuda:0')\n",
      "1 22455 tensor(15.6104, device='cuda:0')\n",
      "\n",
      "1 24504 tensor(16.0494, device='cuda:0')\n",
      "20\n",
      "166\n",
      "1 24504 tensor(16.1406, device='cuda:0')\n",
      "1 24504 tensor(16.0703, device='cuda:0')\n",
      "\n",
      "1 30140 tensor(15.9227, device='cuda:0')\n",
      "20\n",
      "218\n",
      "1 30140 tensor(17.0283, device='cuda:0')\n",
      "1 30140 tensor(15.9809, device='cuda:0')\n",
      "\n",
      "1 27581 tensor(16.2392, device='cuda:0')\n",
      "20\n",
      "178\n",
      "1 27581 tensor(15.9468, device='cuda:0')\n",
      "1 27581 tensor(16.1117, device='cuda:0')\n",
      "\n",
      "1 21438 tensor(15.6996, device='cuda:0')\n",
      "20\n",
      "188\n",
      "1 21438 tensor(16.7135, device='cuda:0')\n",
      "1 21438 tensor(16.5907, device='cuda:0')\n",
      "\n",
      "1 35262 tensor(16.5704, device='cuda:0')\n",
      "20\n",
      "150\n",
      "1 35262 tensor(17.1456, device='cuda:0')\n",
      "1 35262 tensor(15.9963, device='cuda:0')\n",
      "\n",
      "1 36292 tensor(15.1472, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 36292 tensor(16.4379, device='cuda:0')\n",
      "1 36292 tensor(15.6331, device='cuda:0')\n",
      "\n",
      "1 6086 tensor(14.9196, device='cuda:0')\n",
      "20\n",
      "172\n",
      "1 6086 tensor(14.9052, device='cuda:0')\n",
      "1 6086 tensor(15.3622, device='cuda:0')\n",
      "\n",
      "1 21960 tensor(16.2627, device='cuda:0')\n",
      "20\n",
      "166\n",
      "1 21960 tensor(15.8349, device='cuda:0')\n",
      "1 21960 tensor(15.4861, device='cuda:0')\n",
      "\n",
      "1 20428 tensor(15.1250, device='cuda:0')\n",
      "20\n",
      "190\n",
      "1 20428 tensor(15.9056, device='cuda:0')\n",
      "1 20428 tensor(15.0850, device='cuda:0')\n",
      "\n",
      "1 17361 tensor(15.6876, device='cuda:0')\n",
      "20\n",
      "136\n",
      "1 17361 tensor(17.6480, device='cuda:0')\n",
      "1 17361 tensor(13.1893, device='cuda:0')\n",
      "\n",
      "1 33747 tensor(16.1422, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 33747 tensor(16.3109, device='cuda:0')\n",
      "1 33747 tensor(16.2287, device='cuda:0')\n",
      "\n",
      "1 2516 tensor(14.0254, device='cuda:0')\n",
      "20\n",
      "232\n",
      "1 2516 tensor(13.4327, device='cuda:0')\n",
      "1 2516 tensor(15.3727, device='cuda:0')\n",
      "\n",
      "1 13268 tensor(15.7037, device='cuda:0')\n",
      "20\n",
      "376\n",
      "1 13268 tensor(16.8005, device='cuda:0')\n",
      "1 13268 tensor(14.1730, device='cuda:0')\n",
      "\n",
      "1 45014 tensor(16.2805, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 45014 tensor(16.3372, device='cuda:0')\n",
      "1 45014 tensor(16.7377, device='cuda:0')\n",
      "\n",
      "1 25556 tensor(14.4124, device='cuda:0')\n",
      "20\n",
      "194\n",
      "1 25556 tensor(16.3900, device='cuda:0')\n",
      "1 25556 tensor(14.1188, device='cuda:0')\n",
      "\n",
      "1 33240 tensor(15.7804, device='cuda:0')\n",
      "20\n",
      "204\n",
      "1 33240 tensor(16.8432, device='cuda:0')\n",
      "1 33240 tensor(15.5643, device='cuda:0')\n",
      "\n",
      "1 36312 tensor(15.6359, device='cuda:0')\n",
      "20\n",
      "246\n",
      "1 36312 tensor(15.5736, device='cuda:0')\n",
      "1 36312 tensor(15.8973, device='cuda:0')\n",
      "\n",
      "1 16863 tensor(15.9662, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 16863 tensor(14.9851, device='cuda:0')\n",
      "1 16863 tensor(16.4141, device='cuda:0')\n",
      "\n",
      "1 28642 tensor(15.1849, device='cuda:0')\n",
      "20\n",
      "208\n",
      "1 28642 tensor(16.0892, device='cuda:0')\n",
      "1 28642 tensor(15.3804, device='cuda:0')\n",
      "\n",
      "1 10213 tensor(15.7225, device='cuda:0')\n",
      "20\n",
      "196\n",
      "1 10213 tensor(15.8441, device='cuda:0')\n",
      "1 10213 tensor(16.6004, device='cuda:0')\n",
      "\n",
      "1 16358 tensor(15.2835, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 16358 tensor(15.8138, device='cuda:0')\n",
      "1 16358 tensor(15.6897, device='cuda:0')\n",
      "\n",
      "1 25062 tensor(15.8594, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 25062 tensor(16.2548, device='cuda:0')\n",
      "1 25062 tensor(16.3861, device='cuda:0')\n",
      "\n",
      "1 23528 tensor(17.0467, device='cuda:0')\n",
      "20\n",
      "206\n",
      "1 23528 tensor(17.4164, device='cuda:0')\n",
      "1 23528 tensor(17.2045, device='cuda:0')\n",
      "\n",
      "1 35307 tensor(15.5514, device='cuda:0')\n",
      "20\n",
      "212\n",
      "1 35307 tensor(15.4003, device='cuda:0')\n",
      "1 35307 tensor(15.5513, device='cuda:0')\n",
      "\n",
      "1 19436 tensor(15.3875, device='cuda:0')\n",
      "20\n",
      "168\n",
      "1 19436 tensor(16.6002, device='cuda:0')\n",
      "1 19436 tensor(16.6002, device='cuda:0')\n",
      "\n",
      "1 25579 tensor(15.1827, device='cuda:0')\n",
      "20\n",
      "234\n",
      "1 25579 tensor(16.3617, device='cuda:0')\n",
      "1 25579 tensor(16.3617, device='cuda:0')\n",
      "\n",
      "1 15859 tensor(15.6321, device='cuda:0')\n",
      "20\n",
      "200\n",
      "1 15859 tensor(16.0694, device='cuda:0')\n",
      "1 15859 tensor(16.7443, device='cuda:0')\n",
      "\n",
      "1 38900 tensor(15.0885, device='cuda:0')\n",
      "20\n",
      "232\n",
      "1 38900 tensor(14.6974, device='cuda:0')\n",
      "1 38900 tensor(14.8748, device='cuda:0')\n",
      "\n",
      "1 7670 tensor(12.7100, device='cuda:0')\n",
      "20\n",
      "162\n",
      "1 7670 tensor(13.1538, device='cuda:0')\n",
      "1 7670 tensor(13.8842, device='cuda:0')\n",
      "\n",
      "1 8698 tensor(15.4278, device='cuda:0')\n",
      "20\n",
      "228\n",
      "1 8698 tensor(16.4569, device='cuda:0')\n",
      "1 8698 tensor(14.1622, device='cuda:0')\n",
      "\n",
      "1 12284 tensor(14.9555, device='cuda:0')\n",
      "20\n",
      "246\n",
      "1 12284 tensor(15.8764, device='cuda:0')\n",
      "1 12284 tensor(15.1250, device='cuda:0')\n",
      "\n",
      "1 44542 tensor(15.5844, device='cuda:0')\n",
      "20\n",
      "182\n",
      "1 44542 tensor(15.6561, device='cuda:0')\n",
      "1 44542 tensor(16.0732, device='cuda:0')\n",
      "\n",
      "1 31231 tensor(15.8711, device='cuda:0')\n",
      "20\n",
      "176\n",
      "1 31231 tensor(16.5346, device='cuda:0')\n",
      "1 31231 tensor(16.3580, device='cuda:0')\n",
      "\n",
      "2 50178 tensor(14.0708, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 50178 tensor(14.1910, device='cuda:0')\n",
      "2 50178 tensor(14.1910, device='cuda:0')\n",
      "\n",
      "2 46600 tensor(13.8219, device='cuda:0')\n",
      "20\n",
      "186\n",
      "2 46600 tensor(14.2281, device='cuda:0')\n",
      "2 46600 tensor(14.2825, device='cuda:0')\n",
      "\n",
      "2 31755 tensor(14.4516, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 31755 tensor(15.1031, device='cuda:0')\n",
      "2 31755 tensor(14.9529, device='cuda:0')\n",
      "\n",
      "2 46604 tensor(13.8597, device='cuda:0')\n",
      "20\n",
      "214\n",
      "2 46604 tensor(13.6086, device='cuda:0')\n",
      "2 46604 tensor(13.8584, device='cuda:0')\n",
      "\n",
      "2 10765 tensor(14.0841, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 10765 tensor(15.0822, device='cuda:0')\n",
      "2 10765 tensor(13.8945, device='cuda:0')\n",
      "\n",
      "2 11276 tensor(14.0197, device='cuda:0')\n",
      "20\n",
      "160\n",
      "2 11276 tensor(14.0914, device='cuda:0')\n",
      "2 11276 tensor(14.9094, device='cuda:0')\n",
      "\n",
      "2 33811 tensor(13.7397, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 33811 tensor(14.5606, device='cuda:0')\n",
      "2 33811 tensor(14.3694, device='cuda:0')\n",
      "\n",
      "2 46612 tensor(14.2519, device='cuda:0')\n",
      "20\n",
      "236\n",
      "2 46612 tensor(14.9976, device='cuda:0')\n",
      "2 46612 tensor(14.9999, device='cuda:0')\n",
      "\n",
      "2 16916 tensor(13.9896, device='cuda:0')\n",
      "20\n",
      "264\n",
      "2 16916 tensor(14.5292, device='cuda:0')\n",
      "2 16916 tensor(14.5292, device='cuda:0')\n",
      "\n",
      "2 18966 tensor(14.1797, device='cuda:0')\n",
      "20\n",
      "214\n",
      "2 18966 tensor(14.2454, device='cuda:0')\n",
      "2 18966 tensor(14.9869, device='cuda:0')\n",
      "\n",
      "2 12824 tensor(12.8813, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 12824 tensor(13.6531, device='cuda:0')\n",
      "2 12824 tensor(13.5610, device='cuda:0')\n",
      "\n",
      "2 32794 tensor(13.2189, device='cuda:0')\n",
      "20\n",
      "234\n",
      "2 32794 tensor(13.3441, device='cuda:0')\n",
      "2 32794 tensor(13.9803, device='cuda:0')\n",
      "\n",
      "2 7195 tensor(13.1370, device='cuda:0')\n",
      "20\n",
      "166\n",
      "2 7195 tensor(13.5370, device='cuda:0')\n",
      "2 7195 tensor(13.1399, device='cuda:0')\n",
      "\n",
      "2 33821 tensor(13.8706, device='cuda:0')\n",
      "20\n",
      "190\n",
      "2 33821 tensor(14.5438, device='cuda:0')\n",
      "2 33821 tensor(14.1179, device='cuda:0')\n",
      "\n",
      "2 37921 tensor(13.8887, device='cuda:0')\n",
      "20\n",
      "210\n",
      "2 37921 tensor(13.9650, device='cuda:0')\n",
      "2 37921 tensor(14.1958, device='cuda:0')\n",
      "\n",
      "2 33313 tensor(14.3440, device='cuda:0')\n",
      "20\n",
      "202\n",
      "2 33313 tensor(15.0639, device='cuda:0')\n",
      "2 33313 tensor(15.3198, device='cuda:0')\n",
      "\n",
      "2 31270 tensor(13.9938, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 31270 tensor(14.1237, device='cuda:0')\n",
      "2 31270 tensor(14.5788, device='cuda:0')\n",
      "\n",
      "2 29222 tensor(13.4345, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 29222 tensor(14.4593, device='cuda:0')\n",
      "2 29222 tensor(13.4928, device='cuda:0')\n",
      "\n",
      "2 28712 tensor(13.6470, device='cuda:0')\n",
      "20\n",
      "212\n",
      "2 28712 tensor(13.6227, device='cuda:0')\n",
      "2 28712 tensor(14.2150, device='cuda:0')\n",
      "\n",
      "2 18985 tensor(13.3522, device='cuda:0')\n",
      "20\n",
      "214\n",
      "2 18985 tensor(14.0923, device='cuda:0')\n",
      "2 18985 tensor(13.4355, device='cuda:0')\n",
      "\n",
      "2 37930 tensor(13.7451, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 37930 tensor(14.1599, device='cuda:0')\n",
      "2 37930 tensor(14.1725, device='cuda:0')\n",
      "\n",
      "2 28200 tensor(13.5604, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 28200 tensor(13.9379, device='cuda:0')\n",
      "2 28200 tensor(14.1842, device='cuda:0')\n",
      "\n",
      "2 7727 tensor(13.6869, device='cuda:0')\n",
      "20\n",
      "154\n",
      "2 7727 tensor(13.8579, device='cuda:0')\n",
      "2 7727 tensor(13.2597, device='cuda:0')\n",
      "\n",
      "2 24112 tensor(14.2739, device='cuda:0')\n",
      "20\n",
      "184\n",
      "2 24112 tensor(14.5175, device='cuda:0')\n",
      "2 24112 tensor(14.8232, device='cuda:0')\n",
      "\n",
      "2 36400 tensor(13.8657, device='cuda:0')\n",
      "20\n",
      "220\n",
      "2 36400 tensor(14.3250, device='cuda:0')\n",
      "2 36400 tensor(14.3913, device='cuda:0')\n",
      "\n",
      "2 32817 tensor(14.0983, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 32817 tensor(14.2502, device='cuda:0')\n",
      "2 32817 tensor(14.5582, device='cuda:0')\n",
      "\n",
      "2 5171 tensor(13.2062, device='cuda:0')\n",
      "20\n",
      "192\n",
      "2 5171 tensor(13.2351, device='cuda:0')\n",
      "2 5171 tensor(13.7287, device='cuda:0')\n",
      "\n",
      "2 44085 tensor(13.6733, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 44085 tensor(14.4718, device='cuda:0')\n",
      "2 44085 tensor(13.7192, device='cuda:0')\n",
      "\n",
      "2 35382 tensor(13.9199, device='cuda:0')\n",
      "20\n",
      "176\n",
      "2 35382 tensor(14.5301, device='cuda:0')\n",
      "2 35382 tensor(14.4497, device='cuda:0')\n",
      "\n",
      "2 14912 tensor(13.9578, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 14912 tensor(14.3912, device='cuda:0')\n",
      "2 14912 tensor(14.3660, device='cuda:0')\n",
      "\n",
      "2 30274 tensor(13.7036, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 30274 tensor(14.2372, device='cuda:0')\n",
      "2 30274 tensor(13.7876, device='cuda:0')\n",
      "\n",
      "2 20554 tensor(13.6105, device='cuda:0')\n",
      "20\n",
      "160\n",
      "2 20554 tensor(14.4422, device='cuda:0')\n",
      "2 20554 tensor(14.1462, device='cuda:0')\n",
      "\n",
      "2 15435 tensor(13.8187, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 15435 tensor(14.3082, device='cuda:0')\n",
      "2 15435 tensor(14.3624, device='cuda:0')\n",
      "\n",
      "2 33357 tensor(13.7650, device='cuda:0')\n",
      "20\n",
      "172\n",
      "2 33357 tensor(14.9191, device='cuda:0')\n",
      "2 33357 tensor(14.9191, device='cuda:0')\n",
      "\n",
      "2 49231 tensor(14.7001, device='cuda:0')\n",
      "20\n",
      "136\n",
      "2 49231 tensor(15.0058, device='cuda:0')\n",
      "2 49231 tensor(14.7774, device='cuda:0')\n",
      "\n",
      "2 38994 tensor(13.8069, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 38994 tensor(14.2684, device='cuda:0')\n",
      "2 38994 tensor(14.6654, device='cuda:0')\n",
      "\n",
      "2 21587 tensor(13.4945, device='cuda:0')\n",
      "20\n",
      "222\n",
      "2 21587 tensor(14.0891, device='cuda:0')\n",
      "2 21587 tensor(13.3355, device='cuda:0')\n",
      "\n",
      "2 7252 tensor(13.2451, device='cuda:0')\n",
      "20\n",
      "182\n",
      "2 7252 tensor(14.0354, device='cuda:0')\n",
      "2 7252 tensor(13.3101, device='cuda:0')\n",
      "\n",
      "2 40537 tensor(13.8075, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 40537 tensor(14.1064, device='cuda:0')\n",
      "2 40537 tensor(15.0806, device='cuda:0')\n",
      "\n",
      "2 27738 tensor(14.3834, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 27738 tensor(14.8218, device='cuda:0')\n",
      "2 27738 tensor(14.6997, device='cuda:0')\n",
      "\n",
      "2 44123 tensor(13.6650, device='cuda:0')\n",
      "20\n",
      "152\n",
      "2 44123 tensor(13.6050, device='cuda:0')\n",
      "2 44123 tensor(14.1791, device='cuda:0')\n",
      "\n",
      "2 44124 tensor(14.6608, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 44124 tensor(15.1619, device='cuda:0')\n",
      "2 44124 tensor(14.4818, device='cuda:0')\n",
      "\n",
      "2 14943 tensor(13.8680, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 14943 tensor(14.5984, device='cuda:0')\n",
      "2 14943 tensor(14.7436, device='cuda:0')\n",
      "\n",
      "2 45664 tensor(14.0220, device='cuda:0')\n",
      "20\n",
      "158\n",
      "2 45664 tensor(14.8613, device='cuda:0')\n",
      "2 45664 tensor(14.3089, device='cuda:0')\n",
      "\n",
      "2 15458 tensor(13.4738, device='cuda:0')\n",
      "20\n",
      "252\n",
      "2 15458 tensor(13.6343, device='cuda:0')\n",
      "2 15458 tensor(14.0732, device='cuda:0')\n",
      "\n",
      "2 49765 tensor(13.4787, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 49765 tensor(12.7116, device='cuda:0')\n",
      "2 49765 tensor(12.8405, device='cuda:0')\n",
      "\n",
      "2 19046 tensor(13.8715, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 19046 tensor(14.4158, device='cuda:0')\n",
      "2 19046 tensor(13.7801, device='cuda:0')\n",
      "\n",
      "2 35944 tensor(13.7066, device='cuda:0')\n",
      "20\n",
      "210\n",
      "2 35944 tensor(14.0159, device='cuda:0')\n",
      "2 35944 tensor(14.3603, device='cuda:0')\n",
      "\n",
      "2 29804 tensor(14.0008, device='cuda:0')\n",
      "20\n",
      "192\n",
      "2 29804 tensor(14.2622, device='cuda:0')\n",
      "2 29804 tensor(14.2622, device='cuda:0')\n",
      "\n",
      "2 23662 tensor(12.9864, device='cuda:0')\n",
      "20\n",
      "170\n",
      "2 23662 tensor(12.9151, device='cuda:0')\n",
      "2 23662 tensor(13.5916, device='cuda:0')\n",
      "\n",
      "2 37497 tensor(14.0943, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 37497 tensor(14.7561, device='cuda:0')\n",
      "2 37497 tensor(14.6232, device='cuda:0')\n",
      "\n",
      "2 22138 tensor(13.6952, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 22138 tensor(13.6933, device='cuda:0')\n",
      "2 22138 tensor(14.3977, device='cuda:0')\n",
      "\n",
      "2 27773 tensor(14.1240, device='cuda:0')\n",
      "20\n",
      "240\n",
      "2 27773 tensor(14.5294, device='cuda:0')\n",
      "2 27773 tensor(14.7956, device='cuda:0')\n",
      "\n",
      "2 28798 tensor(13.8652, device='cuda:0')\n",
      "20\n",
      "152\n",
      "2 28798 tensor(14.2338, device='cuda:0')\n",
      "2 28798 tensor(14.1438, device='cuda:0')\n",
      "\n",
      "2 33407 tensor(14.2508, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 33407 tensor(14.4114, device='cuda:0')\n",
      "2 33407 tensor(14.5303, device='cuda:0')\n",
      "\n",
      "2 27264 tensor(13.8818, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 27264 tensor(13.8197, device='cuda:0')\n",
      "2 27264 tensor(14.1966, device='cuda:0')\n",
      "\n",
      "2 9857 tensor(14.0097, device='cuda:0')\n",
      "20\n",
      "240\n",
      "2 9857 tensor(14.5421, device='cuda:0')\n",
      "2 9857 tensor(14.3594, device='cuda:0')\n",
      "\n",
      "2 14468 tensor(13.5641, device='cuda:0')\n",
      "20\n",
      "162\n",
      "2 14468 tensor(14.5822, device='cuda:0')\n",
      "2 14468 tensor(14.0001, device='cuda:0')\n",
      "\n",
      "2 6277 tensor(13.0716, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 6277 tensor(13.4245, device='cuda:0')\n",
      "2 6277 tensor(13.5775, device='cuda:0')\n",
      "\n",
      "2 35972 tensor(14.0204, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 35972 tensor(14.6332, device='cuda:0')\n",
      "2 35972 tensor(14.3950, device='cuda:0')\n",
      "\n",
      "2 4744 tensor(12.7518, device='cuda:0')\n",
      "20\n",
      "208\n",
      "2 4744 tensor(13.3866, device='cuda:0')\n",
      "2 4744 tensor(13.5297, device='cuda:0')\n",
      "\n",
      "2 32905 tensor(13.4231, device='cuda:0')\n",
      "20\n",
      "184\n",
      "2 32905 tensor(14.1735, device='cuda:0')\n",
      "2 32905 tensor(14.1735, device='cuda:0')\n",
      "\n",
      "2 32393 tensor(13.6988, device='cuda:0')\n",
      "20\n",
      "204\n",
      "2 32393 tensor(13.9779, device='cuda:0')\n",
      "2 32393 tensor(14.1501, device='cuda:0')\n",
      "\n",
      "2 22671 tensor(14.2554, device='cuda:0')\n",
      "20\n",
      "210\n",
      "2 22671 tensor(14.7686, device='cuda:0')\n",
      "2 22671 tensor(14.6177, device='cuda:0')\n",
      "\n",
      "2 20628 tensor(13.7093, device='cuda:0')\n",
      "20\n",
      "172\n",
      "2 20628 tensor(14.0508, device='cuda:0')\n",
      "2 20628 tensor(13.6458, device='cuda:0')\n",
      "\n",
      "2 32920 tensor(14.2567, device='cuda:0')\n",
      "20\n",
      "388\n",
      "2 32920 tensor(14.8701, device='cuda:0')\n",
      "2 32920 tensor(14.9849, device='cuda:0')\n",
      "\n",
      "2 17560 tensor(13.7095, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 17560 tensor(14.4533, device='cuda:0')\n",
      "2 17560 tensor(14.0688, device='cuda:0')\n",
      "\n",
      "2 5119 tensor(13.1031, device='cuda:0')\n",
      "20\n",
      "172\n",
      "2 5119 tensor(14.0023, device='cuda:0')\n",
      "2 5119 tensor(13.7351, device='cuda:0')\n",
      "\n",
      "2 21661 tensor(14.3329, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 21661 tensor(15.0142, device='cuda:0')\n",
      "2 21661 tensor(14.5306, device='cuda:0')\n",
      "\n",
      "2 16543 tensor(13.6567, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 16543 tensor(14.2263, device='cuda:0')\n",
      "2 16543 tensor(13.8069, device='cuda:0')\n",
      "\n",
      "2 31903 tensor(13.7329, device='cuda:0')\n",
      "20\n",
      "212\n",
      "2 31903 tensor(14.2494, device='cuda:0')\n",
      "2 31903 tensor(14.5570, device='cuda:0')\n",
      "\n",
      "2 18089 tensor(13.7410, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 18089 tensor(14.5113, device='cuda:0')\n",
      "2 18089 tensor(14.6928, device='cuda:0')\n",
      "\n",
      "2 16553 tensor(13.5496, device='cuda:0')\n",
      "20\n",
      "158\n",
      "2 16553 tensor(14.2814, device='cuda:0')\n",
      "2 16553 tensor(14.1998, device='cuda:0')\n",
      "\n",
      "2 28331 tensor(13.7757, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 28331 tensor(14.1581, device='cuda:0')\n",
      "2 28331 tensor(14.1298, device='cuda:0')\n",
      "\n",
      "2 41131 tensor(14.2137, device='cuda:0')\n",
      "20\n",
      "220\n",
      "2 41131 tensor(14.3536, device='cuda:0')\n",
      "2 41131 tensor(14.5731, device='cuda:0')\n",
      "\n",
      "2 20145 tensor(13.8264, device='cuda:0')\n",
      "20\n",
      "150\n",
      "2 20145 tensor(14.9357, device='cuda:0')\n",
      "2 20145 tensor(14.3013, device='cuda:0')\n",
      "\n",
      "2 46262 tensor(14.2808, device='cuda:0')\n",
      "20\n",
      "210\n",
      "2 46262 tensor(14.6151, device='cuda:0')\n",
      "2 46262 tensor(14.8844, device='cuda:0')\n",
      "\n",
      "2 30397 tensor(14.1955, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 30397 tensor(15.1911, device='cuda:0')\n",
      "2 30397 tensor(14.3512, device='cuda:0')\n",
      "\n",
      "2 41151 tensor(13.6732, device='cuda:0')\n",
      "20\n",
      "226\n",
      "2 41151 tensor(14.2463, device='cuda:0')\n",
      "2 41151 tensor(14.4497, device='cuda:0')\n",
      "\n",
      "2 22723 tensor(13.5063, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 22723 tensor(13.9623, device='cuda:0')\n",
      "2 22723 tensor(13.9593, device='cuda:0')\n",
      "\n",
      "2 23239 tensor(13.3519, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 23239 tensor(13.5808, device='cuda:0')\n",
      "2 23239 tensor(13.3843, device='cuda:0')\n",
      "\n",
      "2 14538 tensor(13.7691, device='cuda:0')\n",
      "20\n",
      "184\n",
      "2 14538 tensor(14.2401, device='cuda:0')\n",
      "2 14538 tensor(14.1259, device='cuda:0')\n",
      "\n",
      "2 17100 tensor(13.3233, device='cuda:0')\n",
      "20\n",
      "182\n",
      "2 17100 tensor(14.0539, device='cuda:0')\n",
      "2 17100 tensor(14.1519, device='cuda:0')\n",
      "\n",
      "2 37073 tensor(13.9122, device='cuda:0')\n",
      "20\n",
      "180\n",
      "2 37073 tensor(14.5048, device='cuda:0')\n",
      "2 37073 tensor(14.5879, device='cuda:0')\n",
      "\n",
      "2 22739 tensor(14.0924, device='cuda:0')\n",
      "20\n",
      "228\n",
      "2 22739 tensor(14.3172, device='cuda:0')\n",
      "2 22739 tensor(14.3172, device='cuda:0')\n",
      "\n",
      "2 49365 tensor(13.5664, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 49365 tensor(13.5062, device='cuda:0')\n",
      "2 49365 tensor(13.5536, device='cuda:0')\n",
      "\n",
      "2 16598 tensor(14.1277, device='cuda:0')\n",
      "20\n",
      "186\n",
      "2 16598 tensor(14.1903, device='cuda:0')\n",
      "2 16598 tensor(14.5068, device='cuda:0')\n",
      "\n",
      "2 47831 tensor(13.8091, device='cuda:0')\n",
      "20\n",
      "238\n",
      "2 47831 tensor(14.6095, device='cuda:0')\n",
      "2 47831 tensor(13.8667, device='cuda:0')\n",
      "\n",
      "2 31959 tensor(13.9630, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 31959 tensor(14.3254, device='cuda:0')\n",
      "2 31959 tensor(14.6315, device='cuda:0')\n",
      "\n",
      "2 22234 tensor(13.4241, device='cuda:0')\n",
      "20\n",
      "212\n",
      "2 22234 tensor(14.2180, device='cuda:0')\n",
      "2 22234 tensor(14.1623, device='cuda:0')\n",
      "\n",
      "2 23259 tensor(13.4777, device='cuda:0')\n",
      "20\n",
      "162\n",
      "2 23259 tensor(14.1383, device='cuda:0')\n",
      "2 23259 tensor(13.5648, device='cuda:0')\n",
      "\n",
      "2 20189 tensor(14.5482, device='cuda:0')\n",
      "20\n",
      "238\n",
      "2 20189 tensor(15.2071, device='cuda:0')\n",
      "2 20189 tensor(14.9683, device='cuda:0')\n",
      "\n",
      "2 45790 tensor(13.6376, device='cuda:0')\n",
      "20\n",
      "198\n",
      "2 45790 tensor(14.4039, device='cuda:0')\n",
      "2 45790 tensor(14.3817, device='cuda:0')\n",
      "\n",
      "2 29927 tensor(14.1199, device='cuda:0')\n",
      "20\n",
      "258\n",
      "2 29927 tensor(15.2780, device='cuda:0')\n",
      "2 29927 tensor(14.6064, device='cuda:0')\n",
      "\n",
      "2 46312 tensor(13.4745, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 46312 tensor(13.4757, device='cuda:0')\n",
      "2 46312 tensor(14.2325, device='cuda:0')\n",
      "\n",
      "2 31465 tensor(14.5122, device='cuda:0')\n",
      "20\n",
      "144\n",
      "2 31465 tensor(15.8025, device='cuda:0')\n",
      "2 31465 tensor(15.4782, device='cuda:0')\n",
      "\n",
      "2 46831 tensor(14.3177, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 46831 tensor(14.2228, device='cuda:0')\n",
      "2 46831 tensor(14.6680, device='cuda:0')\n",
      "\n",
      "2 31472 tensor(13.1578, device='cuda:0')\n",
      "20\n",
      "230\n",
      "2 31472 tensor(13.9726, device='cuda:0')\n",
      "2 31472 tensor(14.1876, device='cuda:0')\n",
      "\n",
      "2 29936 tensor(13.8348, device='cuda:0')\n",
      "20\n",
      "182\n",
      "2 29936 tensor(14.2055, device='cuda:0')\n",
      "2 29936 tensor(14.9513, device='cuda:0')\n",
      "\n",
      "2 26355 tensor(13.4259, device='cuda:0')\n",
      "20\n",
      "248\n",
      "2 26355 tensor(13.8231, device='cuda:0')\n",
      "2 26355 tensor(14.0709, device='cuda:0')\n",
      "\n",
      "2 6393 tensor(13.0564, device='cuda:0')\n",
      "20\n",
      "150\n",
      "2 6393 tensor(14.2176, device='cuda:0')\n",
      "2 6393 tensor(13.8257, device='cuda:0')\n",
      "\n",
      "2 26876 tensor(13.4937, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 26876 tensor(13.8719, device='cuda:0')\n",
      "2 26876 tensor(13.7288, device='cuda:0')\n",
      "\n",
      "2 8444 tensor(12.7850, device='cuda:0')\n",
      "20\n",
      "208\n",
      "2 8444 tensor(13.6397, device='cuda:0')\n",
      "2 8444 tensor(12.4853, device='cuda:0')\n",
      "\n",
      "2 26878 tensor(14.6022, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 26878 tensor(15.3495, device='cuda:0')\n",
      "2 26878 tensor(14.7732, device='cuda:0')\n",
      "\n",
      "2 6911 tensor(13.2610, device='cuda:0')\n",
      "20\n",
      "220\n",
      "2 6911 tensor(13.5387, device='cuda:0')\n",
      "2 6911 tensor(13.4780, device='cuda:0')\n",
      "\n",
      "2 25856 tensor(13.5780, device='cuda:0')\n",
      "20\n",
      "192\n",
      "2 25856 tensor(14.0250, device='cuda:0')\n",
      "2 25856 tensor(13.9556, device='cuda:0')\n",
      "\n",
      "2 21249 tensor(14.1935, device='cuda:0')\n",
      "20\n",
      "186\n",
      "2 21249 tensor(14.9645, device='cuda:0')\n",
      "2 21249 tensor(14.6813, device='cuda:0')\n",
      "\n",
      "2 19717 tensor(13.3925, device='cuda:0')\n",
      "20\n",
      "152\n",
      "2 19717 tensor(13.0560, device='cuda:0')\n",
      "2 19717 tensor(13.8390, device='cuda:0')\n",
      "\n",
      "2 8966 tensor(13.8393, device='cuda:0')\n",
      "20\n",
      "134\n",
      "2 8966 tensor(14.3261, device='cuda:0')\n",
      "2 8966 tensor(14.5375, device='cuda:0')\n",
      "\n",
      "2 38150 tensor(13.9168, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 38150 tensor(14.7379, device='cuda:0')\n",
      "2 38150 tensor(14.2337, device='cuda:0')\n",
      "\n",
      "2 26888 tensor(14.4961, device='cuda:0')\n",
      "20\n",
      "190\n",
      "2 26888 tensor(15.7015, device='cuda:0')\n",
      "2 26888 tensor(14.5929, device='cuda:0')\n",
      "\n",
      "2 27917 tensor(13.7341, device='cuda:0')\n",
      "20\n",
      "134\n",
      "2 27917 tensor(14.0239, device='cuda:0')\n",
      "2 27917 tensor(14.6852, device='cuda:0')\n",
      "\n",
      "2 39184 tensor(13.7941, device='cuda:0')\n",
      "20\n",
      "142\n",
      "2 39184 tensor(14.3639, device='cuda:0')\n",
      "2 39184 tensor(13.8593, device='cuda:0')\n",
      "\n",
      "2 48401 tensor(13.6590, device='cuda:0')\n",
      "20\n",
      "180\n",
      "2 48401 tensor(13.9145, device='cuda:0')\n",
      "2 48401 tensor(14.5188, device='cuda:0')\n",
      "\n",
      "2 24336 tensor(13.8534, device='cuda:0')\n",
      "20\n",
      "176\n",
      "2 24336 tensor(13.5472, device='cuda:0')\n",
      "2 24336 tensor(14.6621, device='cuda:0')\n",
      "\n",
      "2 6416 tensor(13.2400, device='cuda:0')\n",
      "20\n",
      "212\n",
      "2 6416 tensor(13.5865, device='cuda:0')\n",
      "2 6416 tensor(13.6610, device='cuda:0')\n",
      "\n",
      "2 23316 tensor(13.3522, device='cuda:0')\n",
      "20\n",
      "150\n",
      "2 23316 tensor(13.6391, device='cuda:0')\n",
      "2 23316 tensor(13.6906, device='cuda:0')\n",
      "\n",
      "2 37144 tensor(13.6446, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 37144 tensor(14.0184, device='cuda:0')\n",
      "2 37144 tensor(13.7753, device='cuda:0')\n",
      "\n",
      "2 31513 tensor(13.3491, device='cuda:0')\n",
      "20\n",
      "198\n",
      "2 31513 tensor(13.3281, device='cuda:0')\n",
      "2 31513 tensor(14.2453, device='cuda:0')\n",
      "\n",
      "2 42266 tensor(13.9024, device='cuda:0')\n",
      "20\n",
      "230\n",
      "2 42266 tensor(13.9419, device='cuda:0')\n",
      "2 42266 tensor(15.3233, device='cuda:0')\n",
      "\n",
      "2 29989 tensor(13.9528, device='cuda:0')\n",
      "20\n",
      "134\n",
      "2 29989 tensor(14.1520, device='cuda:0')\n",
      "2 29989 tensor(14.2981, device='cuda:0')\n",
      "\n",
      "2 27434 tensor(14.4759, device='cuda:0')\n",
      "20\n",
      "154\n",
      "2 27434 tensor(14.9627, device='cuda:0')\n",
      "2 27434 tensor(14.7168, device='cuda:0')\n",
      "\n",
      "2 45867 tensor(13.6243, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 45867 tensor(14.4369, device='cuda:0')\n",
      "2 45867 tensor(14.1750, device='cuda:0')\n",
      "\n",
      "2 36139 tensor(14.0174, device='cuda:0')\n",
      "20\n",
      "250\n",
      "2 36139 tensor(14.6039, device='cuda:0')\n",
      "2 36139 tensor(14.1914, device='cuda:0')\n",
      "\n",
      "2 29489 tensor(13.3559, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 29489 tensor(13.3985, device='cuda:0')\n",
      "2 29489 tensor(13.6817, device='cuda:0')\n",
      "\n",
      "2 27443 tensor(13.7498, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 27443 tensor(13.9145, device='cuda:0')\n",
      "2 27443 tensor(13.9506, device='cuda:0')\n",
      "\n",
      "2 27955 tensor(14.4696, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 27955 tensor(14.9232, device='cuda:0')\n",
      "2 27955 tensor(15.1902, device='cuda:0')\n",
      "\n",
      "2 22838 tensor(13.7472, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 22838 tensor(14.8727, device='cuda:0')\n",
      "2 22838 tensor(14.4486, device='cuda:0')\n",
      "\n",
      "2 7993 tensor(13.0984, device='cuda:0')\n",
      "20\n",
      "230\n",
      "2 7993 tensor(14.3241, device='cuda:0')\n",
      "2 7993 tensor(13.3737, device='cuda:0')\n",
      "\n",
      "2 13114 tensor(13.3362, device='cuda:0')\n",
      "20\n",
      "172\n",
      "2 13114 tensor(14.1468, device='cuda:0')\n",
      "2 13114 tensor(13.6826, device='cuda:0')\n",
      "\n",
      "2 13629 tensor(13.6063, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 13629 tensor(14.6684, device='cuda:0')\n",
      "2 13629 tensor(14.5377, device='cuda:0')\n",
      "\n",
      "2 28991 tensor(13.8195, device='cuda:0')\n",
      "20\n",
      "204\n",
      "2 28991 tensor(13.7090, device='cuda:0')\n",
      "2 28991 tensor(14.0837, device='cuda:0')\n",
      "\n",
      "2 40771 tensor(13.8908, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 40771 tensor(14.6479, device='cuda:0')\n",
      "2 40771 tensor(14.9097, device='cuda:0')\n",
      "\n",
      "2 25413 tensor(13.4600, device='cuda:0')\n",
      "20\n",
      "224\n",
      "2 25413 tensor(13.8302, device='cuda:0')\n",
      "2 25413 tensor(14.0471, device='cuda:0')\n",
      "\n",
      "2 44870 tensor(13.8931, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 44870 tensor(14.0311, device='cuda:0')\n",
      "2 44870 tensor(14.2625, device='cuda:0')\n",
      "\n",
      "2 18247 tensor(13.4537, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 18247 tensor(13.7712, device='cuda:0')\n",
      "2 18247 tensor(13.6129, device='cuda:0')\n",
      "\n",
      "2 47944 tensor(13.8425, device='cuda:0')\n",
      "20\n",
      "194\n",
      "2 47944 tensor(14.4244, device='cuda:0')\n",
      "2 47944 tensor(14.4244, device='cuda:0')\n",
      "\n",
      "2 35657 tensor(14.3736, device='cuda:0')\n",
      "20\n",
      "182\n",
      "2 35657 tensor(14.4886, device='cuda:0')\n",
      "2 35657 tensor(14.7695, device='cuda:0')\n",
      "\n",
      "2 26953 tensor(13.9647, device='cuda:0')\n",
      "20\n",
      "190\n",
      "2 26953 tensor(14.6228, device='cuda:0')\n",
      "2 26953 tensor(14.3094, device='cuda:0')\n",
      "\n",
      "2 13651 tensor(13.2269, device='cuda:0')\n",
      "20\n",
      "182\n",
      "2 13651 tensor(13.8012, device='cuda:0')\n",
      "2 13651 tensor(13.4852, device='cuda:0')\n",
      "\n",
      "2 27991 tensor(14.0503, device='cuda:0')\n",
      "20\n",
      "154\n",
      "2 27991 tensor(14.0971, device='cuda:0')\n",
      "2 27991 tensor(14.9372, device='cuda:0')\n",
      "\n",
      "2 26456 tensor(13.7472, device='cuda:0')\n",
      "20\n",
      "156\n",
      "2 26456 tensor(14.1339, device='cuda:0')\n",
      "2 26456 tensor(14.0657, device='cuda:0')\n",
      "\n",
      "2 48990 tensor(14.0042, device='cuda:0')\n",
      "20\n",
      "158\n",
      "2 48990 tensor(13.5281, device='cuda:0')\n",
      "2 48990 tensor(14.6158, device='cuda:0')\n",
      "\n",
      "2 34655 tensor(13.9569, device='cuda:0')\n",
      "20\n",
      "214\n",
      "2 34655 tensor(14.1891, device='cuda:0')\n",
      "2 34655 tensor(13.9195, device='cuda:0')\n",
      "\n",
      "2 16225 tensor(14.0125, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 16225 tensor(14.8720, device='cuda:0')\n",
      "2 16225 tensor(14.7445, device='cuda:0')\n",
      "\n",
      "2 28518 tensor(14.1976, device='cuda:0')\n",
      "20\n",
      "162\n",
      "2 28518 tensor(14.3492, device='cuda:0')\n",
      "2 28518 tensor(14.6761, device='cuda:0')\n",
      "\n",
      "2 20839 tensor(12.8496, device='cuda:0')\n",
      "20\n",
      "200\n",
      "2 20839 tensor(12.9769, device='cuda:0')\n",
      "2 20839 tensor(12.8226, device='cuda:0')\n",
      "\n",
      "2 43367 tensor(14.5612, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 43367 tensor(15.1393, device='cuda:0')\n",
      "2 43367 tensor(15.0564, device='cuda:0')\n",
      "\n",
      "2 10092 tensor(13.0309, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 10092 tensor(12.8620, device='cuda:0')\n",
      "2 10092 tensor(13.2260, device='cuda:0')\n",
      "\n",
      "2 11116 tensor(13.2181, device='cuda:0')\n",
      "20\n",
      "250\n",
      "2 11116 tensor(13.6292, device='cuda:0')\n",
      "2 11116 tensor(13.8785, device='cuda:0')\n",
      "\n",
      "2 31086 tensor(13.8704, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 31086 tensor(14.1703, device='cuda:0')\n",
      "2 31086 tensor(14.5652, device='cuda:0')\n",
      "\n",
      "2 29040 tensor(14.2463, device='cuda:0')\n",
      "20\n",
      "258\n",
      "2 29040 tensor(15.0254, device='cuda:0')\n",
      "2 29040 tensor(13.7948, device='cuda:0')\n",
      "\n",
      "2 50033 tensor(13.8172, device='cuda:0')\n",
      "20\n",
      "166\n",
      "2 50033 tensor(14.4693, device='cuda:0')\n",
      "2 50033 tensor(14.4693, device='cuda:0')\n",
      "\n",
      "2 5490 tensor(12.9279, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 5490 tensor(13.4715, device='cuda:0')\n",
      "2 5490 tensor(13.7623, device='cuda:0')\n",
      "\n",
      "2 39795 tensor(14.2693, device='cuda:0')\n",
      "20\n",
      "226\n",
      "2 39795 tensor(14.8323, device='cuda:0')\n",
      "2 39795 tensor(13.9062, device='cuda:0')\n",
      "\n",
      "2 48505 tensor(14.0362, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 48505 tensor(14.8613, device='cuda:0')\n",
      "2 48505 tensor(14.3733, device='cuda:0')\n",
      "\n",
      "2 40316 tensor(14.0306, device='cuda:0')\n",
      "20\n",
      "238\n",
      "2 40316 tensor(14.4377, device='cuda:0')\n",
      "2 40316 tensor(14.4041, device='cuda:0')\n",
      "\n",
      "2 24958 tensor(13.5850, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 24958 tensor(14.6764, device='cuda:0')\n",
      "2 24958 tensor(14.4047, device='cuda:0')\n",
      "\n",
      "2 38783 tensor(14.1782, device='cuda:0')\n",
      "20\n",
      "188\n",
      "2 38783 tensor(14.1767, device='cuda:0')\n",
      "2 38783 tensor(14.2587, device='cuda:0')\n",
      "\n",
      "2 19838 tensor(14.3671, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 19838 tensor(15.3636, device='cuda:0')\n",
      "2 19838 tensor(15.2252, device='cuda:0')\n",
      "\n",
      "2 23425 tensor(13.9259, device='cuda:0')\n",
      "20\n",
      "190\n",
      "2 23425 tensor(13.9019, device='cuda:0')\n",
      "2 23425 tensor(14.3541, device='cuda:0')\n",
      "\n",
      "2 24962 tensor(13.7084, device='cuda:0')\n",
      "20\n",
      "172\n",
      "2 24962 tensor(14.5897, device='cuda:0')\n",
      "2 24962 tensor(14.0837, device='cuda:0')\n",
      "\n",
      "2 13187 tensor(13.2884, device='cuda:0')\n",
      "20\n",
      "212\n",
      "2 13187 tensor(14.1430, device='cuda:0')\n",
      "2 13187 tensor(14.3346, device='cuda:0')\n",
      "\n",
      "2 49028 tensor(13.5540, device='cuda:0')\n",
      "20\n",
      "222\n",
      "2 49028 tensor(14.5540, device='cuda:0')\n",
      "2 49028 tensor(14.1566, device='cuda:0')\n",
      "\n",
      "2 12167 tensor(13.3670, device='cuda:0')\n",
      "20\n",
      "192\n",
      "2 12167 tensor(13.6009, device='cuda:0')\n",
      "2 12167 tensor(14.1893, device='cuda:0')\n",
      "\n",
      "2 43406 tensor(13.5505, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 43406 tensor(14.2483, device='cuda:0')\n",
      "2 43406 tensor(13.8879, device='cuda:0')\n",
      "\n",
      "2 14737 tensor(13.6087, device='cuda:0')\n",
      "20\n",
      "198\n",
      "2 14737 tensor(14.0385, device='cuda:0')\n",
      "2 14737 tensor(14.0929, device='cuda:0')\n",
      "\n",
      "2 18322 tensor(13.1392, device='cuda:0')\n",
      "20\n",
      "184\n",
      "2 18322 tensor(13.5224, device='cuda:0')\n",
      "2 18322 tensor(14.4515, device='cuda:0')\n",
      "\n",
      "2 43921 tensor(13.8826, device='cuda:0')\n",
      "20\n",
      "170\n",
      "2 43921 tensor(14.2019, device='cuda:0')\n",
      "2 43921 tensor(14.4944, device='cuda:0')\n",
      "\n",
      "2 12694 tensor(13.4059, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 12694 tensor(14.0678, device='cuda:0')\n",
      "2 12694 tensor(14.5189, device='cuda:0')\n",
      "\n",
      "2 16286 tensor(13.6626, device='cuda:0')\n",
      "20\n",
      "208\n",
      "2 16286 tensor(13.1575, device='cuda:0')\n",
      "2 16286 tensor(14.4117, device='cuda:0')\n",
      "\n",
      "2 48545 tensor(14.5620, device='cuda:0')\n",
      "20\n",
      "180\n",
      "2 48545 tensor(15.8059, device='cuda:0')\n",
      "2 48545 tensor(15.0824, device='cuda:0')\n",
      "\n",
      "2 29092 tensor(13.7698, device='cuda:0')\n",
      "20\n",
      "168\n",
      "2 29092 tensor(14.3413, device='cuda:0')\n",
      "2 29092 tensor(14.5553, device='cuda:0')\n",
      "\n",
      "2 15273 tensor(13.3045, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 15273 tensor(13.6791, device='cuda:0')\n",
      "2 15273 tensor(14.2158, device='cuda:0')\n",
      "\n",
      "2 16809 tensor(13.8380, device='cuda:0')\n",
      "20\n",
      "154\n",
      "2 16809 tensor(14.7876, device='cuda:0')\n",
      "2 16809 tensor(14.5792, device='cuda:0')\n",
      "\n",
      "2 22455 tensor(14.2114, device='cuda:0')\n",
      "20\n",
      "162\n",
      "2 22455 tensor(14.7831, device='cuda:0')\n",
      "2 22455 tensor(15.3181, device='cuda:0')\n",
      "\n",
      "2 24504 tensor(13.7333, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 24504 tensor(14.2453, device='cuda:0')\n",
      "2 24504 tensor(13.8700, device='cuda:0')\n",
      "\n",
      "2 30140 tensor(14.0910, device='cuda:0')\n",
      "20\n",
      "218\n",
      "2 30140 tensor(13.8450, device='cuda:0')\n",
      "2 30140 tensor(14.9538, device='cuda:0')\n",
      "\n",
      "2 27581 tensor(13.7040, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 27581 tensor(13.9938, device='cuda:0')\n",
      "2 27581 tensor(14.5147, device='cuda:0')\n",
      "\n",
      "2 21438 tensor(13.8060, device='cuda:0')\n",
      "20\n",
      "206\n",
      "2 21438 tensor(14.4613, device='cuda:0')\n",
      "2 21438 tensor(15.3011, device='cuda:0')\n",
      "\n",
      "2 35262 tensor(14.1510, device='cuda:0')\n",
      "20\n",
      "232\n",
      "2 35262 tensor(14.3621, device='cuda:0')\n",
      "2 35262 tensor(14.8239, device='cuda:0')\n",
      "\n",
      "2 36292 tensor(13.4905, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 36292 tensor(14.8110, device='cuda:0')\n",
      "2 36292 tensor(14.1767, device='cuda:0')\n",
      "\n",
      "2 6086 tensor(13.2845, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 6086 tensor(13.9009, device='cuda:0')\n",
      "2 6086 tensor(14.0030, device='cuda:0')\n",
      "\n",
      "2 21960 tensor(14.0382, device='cuda:0')\n",
      "20\n",
      "124\n",
      "2 21960 tensor(14.4405, device='cuda:0')\n",
      "2 21960 tensor(14.2576, device='cuda:0')\n",
      "\n",
      "2 20428 tensor(13.4850, device='cuda:0')\n",
      "20\n",
      "214\n",
      "2 20428 tensor(14.1540, device='cuda:0')\n",
      "2 20428 tensor(14.3047, device='cuda:0')\n",
      "\n",
      "2 17361 tensor(14.5758, device='cuda:0')\n",
      "20\n",
      "204\n",
      "2 17361 tensor(15.5050, device='cuda:0')\n",
      "2 17361 tensor(14.1710, device='cuda:0')\n",
      "\n",
      "2 33747 tensor(13.9404, device='cuda:0')\n",
      "20\n",
      "198\n",
      "2 33747 tensor(14.1474, device='cuda:0')\n",
      "2 33747 tensor(14.3669, device='cuda:0')\n",
      "\n",
      "2 2516 tensor(12.5068, device='cuda:0')\n",
      "20\n",
      "124\n",
      "2 2516 tensor(12.7838, device='cuda:0')\n",
      "2 2516 tensor(12.7978, device='cuda:0')\n",
      "\n",
      "2 13268 tensor(13.8380, device='cuda:0')\n",
      "20\n",
      "338\n",
      "2 13268 tensor(13.9171, device='cuda:0')\n",
      "2 13268 tensor(13.3720, device='cuda:0')\n",
      "\n",
      "2 45014 tensor(13.9200, device='cuda:0')\n",
      "20\n",
      "236\n",
      "2 45014 tensor(14.3232, device='cuda:0')\n",
      "2 45014 tensor(14.2942, device='cuda:0')\n",
      "\n",
      "2 25556 tensor(14.3233, device='cuda:0')\n",
      "20\n",
      "158\n",
      "2 25556 tensor(13.9698, device='cuda:0')\n",
      "2 25556 tensor(14.8711, device='cuda:0')\n",
      "\n",
      "2 33240 tensor(14.1759, device='cuda:0')\n",
      "20\n",
      "158\n",
      "2 33240 tensor(14.6469, device='cuda:0')\n",
      "2 33240 tensor(14.3745, device='cuda:0')\n",
      "\n",
      "2 36312 tensor(13.9816, device='cuda:0')\n",
      "20\n",
      "166\n",
      "2 36312 tensor(14.3853, device='cuda:0')\n",
      "2 36312 tensor(14.2009, device='cuda:0')\n",
      "\n",
      "2 16863 tensor(14.1196, device='cuda:0')\n",
      "20\n",
      "178\n",
      "2 16863 tensor(14.5096, device='cuda:0')\n",
      "2 16863 tensor(13.4936, device='cuda:0')\n",
      "\n",
      "2 28642 tensor(13.9122, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 28642 tensor(14.5892, device='cuda:0')\n",
      "2 28642 tensor(14.5892, device='cuda:0')\n",
      "\n",
      "2 10213 tensor(13.6834, device='cuda:0')\n",
      "20\n",
      "186\n",
      "2 10213 tensor(14.4339, device='cuda:0')\n",
      "2 10213 tensor(14.3592, device='cuda:0')\n",
      "\n",
      "2 16358 tensor(13.5923, device='cuda:0')\n",
      "20\n",
      "190\n",
      "2 16358 tensor(13.4701, device='cuda:0')\n",
      "2 16358 tensor(13.7547, device='cuda:0')\n",
      "\n",
      "2 25062 tensor(14.0888, device='cuda:0')\n",
      "20\n",
      "176\n",
      "2 25062 tensor(14.5844, device='cuda:0')\n",
      "2 25062 tensor(14.8481, device='cuda:0')\n",
      "\n",
      "2 23528 tensor(14.8694, device='cuda:0')\n",
      "20\n",
      "160\n",
      "2 23528 tensor(15.6967, device='cuda:0')\n",
      "2 23528 tensor(15.2026, device='cuda:0')\n",
      "\n",
      "2 35307 tensor(13.9831, device='cuda:0')\n",
      "20\n",
      "166\n",
      "2 35307 tensor(14.3913, device='cuda:0')\n",
      "2 35307 tensor(14.2880, device='cuda:0')\n",
      "\n",
      "2 19436 tensor(13.6068, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 19436 tensor(14.1520, device='cuda:0')\n",
      "2 19436 tensor(14.2919, device='cuda:0')\n",
      "\n",
      "2 25579 tensor(14.1739, device='cuda:0')\n",
      "20\n",
      "196\n",
      "2 25579 tensor(14.7616, device='cuda:0')\n",
      "2 25579 tensor(15.2825, device='cuda:0')\n",
      "\n",
      "2 15859 tensor(14.0576, device='cuda:0')\n",
      "20\n",
      "174\n",
      "2 15859 tensor(14.8021, device='cuda:0')\n",
      "2 15859 tensor(14.6365, device='cuda:0')\n",
      "\n",
      "2 38900 tensor(13.3968, device='cuda:0')\n",
      "20\n",
      "210\n",
      "2 38900 tensor(13.4974, device='cuda:0')\n",
      "2 38900 tensor(14.3435, device='cuda:0')\n",
      "\n",
      "2 7670 tensor(12.1271, device='cuda:0')\n",
      "20\n",
      "202\n",
      "2 7670 tensor(12.6101, device='cuda:0')\n",
      "2 7670 tensor(13.0524, device='cuda:0')\n",
      "\n",
      "2 8698 tensor(13.8175, device='cuda:0')\n",
      "20\n",
      "164\n",
      "2 8698 tensor(14.8483, device='cuda:0')\n",
      "2 8698 tensor(15.0202, device='cuda:0')\n",
      "\n",
      "2 12284 tensor(13.2751, device='cuda:0')\n",
      "20\n",
      "186\n",
      "2 12284 tensor(14.0718, device='cuda:0')\n",
      "2 12284 tensor(13.2523, device='cuda:0')\n",
      "\n",
      "2 44542 tensor(13.5724, device='cuda:0')\n",
      "20\n",
      "216\n",
      "2 44542 tensor(13.7540, device='cuda:0')\n",
      "2 44542 tensor(13.8409, device='cuda:0')\n",
      "\n",
      "2 31231 tensor(13.8665, device='cuda:0')\n",
      "20\n",
      "238\n",
      "2 31231 tensor(13.7719, device='cuda:0')\n",
      "2 31231 tensor(14.3703, device='cuda:0')\n",
      "\n",
      "3 50178 tensor(17.1973, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 50178 tensor(18.2997, device='cuda:0')\n",
      "3 50178 tensor(17.0849, device='cuda:0')\n",
      "\n",
      "3 46600 tensor(17.0992, device='cuda:0')\n",
      "20\n",
      "178\n",
      "3 46600 tensor(17.1846, device='cuda:0')\n",
      "3 46600 tensor(16.9256, device='cuda:0')\n",
      "\n",
      "3 31755 tensor(17.6957, device='cuda:0')\n",
      "20\n",
      "192\n",
      "3 31755 tensor(18.1614, device='cuda:0')\n",
      "3 31755 tensor(17.7271, device='cuda:0')\n",
      "\n",
      "3 46604 tensor(17.2492, device='cuda:0')\n",
      "20\n",
      "200\n",
      "3 46604 tensor(17.4047, device='cuda:0')\n",
      "3 46604 tensor(17.7901, device='cuda:0')\n",
      "\n",
      "3 10765 tensor(17.6116, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 10765 tensor(18.1177, device='cuda:0')\n",
      "3 10765 tensor(17.8086, device='cuda:0')\n",
      "\n",
      "3 11276 tensor(17.8999, device='cuda:0')\n",
      "20\n",
      "218\n",
      "3 11276 tensor(17.9299, device='cuda:0')\n",
      "3 11276 tensor(18.7246, device='cuda:0')\n",
      "\n",
      "3 33811 tensor(17.1989, device='cuda:0')\n",
      "20\n",
      "198\n",
      "3 33811 tensor(17.7487, device='cuda:0')\n",
      "3 33811 tensor(16.6974, device='cuda:0')\n",
      "\n",
      "3 46612 tensor(17.1393, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 46612 tensor(17.9258, device='cuda:0')\n",
      "3 46612 tensor(18.2961, device='cuda:0')\n",
      "\n",
      "3 16916 tensor(17.4316, device='cuda:0')\n",
      "20\n",
      "192\n",
      "3 16916 tensor(17.4924, device='cuda:0')\n",
      "3 16916 tensor(17.9802, device='cuda:0')\n",
      "\n",
      "3 18966 tensor(17.7615, device='cuda:0')\n",
      "20\n",
      "142\n",
      "3 18966 tensor(17.9220, device='cuda:0')\n",
      "3 18966 tensor(18.1570, device='cuda:0')\n",
      "\n",
      "3 12824 tensor(16.6450, device='cuda:0')\n",
      "20\n",
      "216\n",
      "3 12824 tensor(17.1621, device='cuda:0')\n",
      "3 12824 tensor(17.3933, device='cuda:0')\n",
      "\n",
      "3 32794 tensor(16.6482, device='cuda:0')\n",
      "20\n",
      "180\n",
      "3 32794 tensor(16.6247, device='cuda:0')\n",
      "3 32794 tensor(17.0725, device='cuda:0')\n",
      "\n",
      "3 7195 tensor(17.2091, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 7195 tensor(17.8513, device='cuda:0')\n",
      "3 7195 tensor(18.0797, device='cuda:0')\n",
      "\n",
      "3 33821 tensor(17.0381, device='cuda:0')\n",
      "20\n",
      "180\n",
      "3 33821 tensor(17.1760, device='cuda:0')\n",
      "3 33821 tensor(17.1543, device='cuda:0')\n",
      "\n",
      "3 37921 tensor(17.4741, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 37921 tensor(18.6376, device='cuda:0')\n",
      "3 37921 tensor(17.7308, device='cuda:0')\n",
      "\n",
      "3 33313 tensor(17.6376, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 33313 tensor(18.8854, device='cuda:0')\n",
      "3 33313 tensor(18.8854, device='cuda:0')\n",
      "\n",
      "3 31270 tensor(16.7878, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 31270 tensor(17.2079, device='cuda:0')\n",
      "3 31270 tensor(17.4090, device='cuda:0')\n",
      "\n",
      "3 29222 tensor(16.9454, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 29222 tensor(17.4239, device='cuda:0')\n",
      "3 29222 tensor(17.2634, device='cuda:0')\n",
      "\n",
      "3 28712 tensor(17.5080, device='cuda:0')\n",
      "20\n",
      "160\n",
      "3 28712 tensor(17.3027, device='cuda:0')\n",
      "3 28712 tensor(17.7097, device='cuda:0')\n",
      "\n",
      "3 18985 tensor(16.8513, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 18985 tensor(17.4742, device='cuda:0')\n",
      "3 18985 tensor(17.4674, device='cuda:0')\n",
      "\n",
      "3 37930 tensor(17.2371, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 37930 tensor(17.3441, device='cuda:0')\n",
      "3 37930 tensor(17.8510, device='cuda:0')\n",
      "\n",
      "3 28200 tensor(17.2260, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 28200 tensor(17.6926, device='cuda:0')\n",
      "3 28200 tensor(17.1772, device='cuda:0')\n",
      "\n",
      "3 7727 tensor(17.1459, device='cuda:0')\n",
      "20\n",
      "126\n",
      "3 7727 tensor(17.0976, device='cuda:0')\n",
      "3 7727 tensor(17.8170, device='cuda:0')\n",
      "\n",
      "3 24112 tensor(17.1621, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 24112 tensor(18.0033, device='cuda:0')\n",
      "3 24112 tensor(16.7845, device='cuda:0')\n",
      "\n",
      "3 36400 tensor(17.2575, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 36400 tensor(17.8197, device='cuda:0')\n",
      "3 36400 tensor(17.3070, device='cuda:0')\n",
      "\n",
      "3 32817 tensor(17.3386, device='cuda:0')\n",
      "20\n",
      "240\n",
      "3 32817 tensor(18.4130, device='cuda:0')\n",
      "3 32817 tensor(17.9088, device='cuda:0')\n",
      "\n",
      "3 5171 tensor(17.0476, device='cuda:0')\n",
      "20\n",
      "156\n",
      "3 5171 tensor(17.7419, device='cuda:0')\n",
      "3 5171 tensor(17.8416, device='cuda:0')\n",
      "\n",
      "3 44085 tensor(17.0153, device='cuda:0')\n",
      "20\n",
      "220\n",
      "3 44085 tensor(17.7581, device='cuda:0')\n",
      "3 44085 tensor(17.4144, device='cuda:0')\n",
      "\n",
      "3 35382 tensor(17.2768, device='cuda:0')\n",
      "20\n",
      "190\n",
      "3 35382 tensor(17.5501, device='cuda:0')\n",
      "3 35382 tensor(17.8951, device='cuda:0')\n",
      "\n",
      "3 14912 tensor(17.3394, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 14912 tensor(17.3372, device='cuda:0')\n",
      "3 14912 tensor(17.4622, device='cuda:0')\n",
      "\n",
      "3 30274 tensor(16.9862, device='cuda:0')\n",
      "20\n",
      "178\n",
      "3 30274 tensor(16.6598, device='cuda:0')\n",
      "3 30274 tensor(16.8473, device='cuda:0')\n",
      "\n",
      "3 20554 tensor(17.1973, device='cuda:0')\n",
      "20\n",
      "140\n",
      "3 20554 tensor(17.5472, device='cuda:0')\n",
      "3 20554 tensor(17.8023, device='cuda:0')\n",
      "\n",
      "3 15435 tensor(17.2641, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 15435 tensor(17.6520, device='cuda:0')\n",
      "3 15435 tensor(17.1931, device='cuda:0')\n",
      "\n",
      "3 33357 tensor(17.2582, device='cuda:0')\n",
      "20\n",
      "166\n",
      "3 33357 tensor(17.3946, device='cuda:0')\n",
      "3 33357 tensor(17.4959, device='cuda:0')\n",
      "\n",
      "3 49231 tensor(17.5707, device='cuda:0')\n",
      "20\n",
      "184\n",
      "3 49231 tensor(18.3745, device='cuda:0')\n",
      "3 49231 tensor(17.7638, device='cuda:0')\n",
      "\n",
      "3 38994 tensor(17.2002, device='cuda:0')\n",
      "20\n",
      "172\n",
      "3 38994 tensor(18.1830, device='cuda:0')\n",
      "3 38994 tensor(17.3276, device='cuda:0')\n",
      "\n",
      "3 21587 tensor(17.2311, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 21587 tensor(18.3826, device='cuda:0')\n",
      "3 21587 tensor(17.0084, device='cuda:0')\n",
      "\n",
      "3 7252 tensor(16.6873, device='cuda:0')\n",
      "20\n",
      "156\n",
      "3 7252 tensor(17.1833, device='cuda:0')\n",
      "3 7252 tensor(16.6655, device='cuda:0')\n",
      "\n",
      "3 40537 tensor(17.1811, device='cuda:0')\n",
      "20\n",
      "196\n",
      "3 40537 tensor(17.4343, device='cuda:0')\n",
      "3 40537 tensor(17.4877, device='cuda:0')\n",
      "\n",
      "3 27738 tensor(17.1853, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 27738 tensor(17.6447, device='cuda:0')\n",
      "3 27738 tensor(17.5774, device='cuda:0')\n",
      "\n",
      "3 44123 tensor(17.2187, device='cuda:0')\n",
      "20\n",
      "160\n",
      "3 44123 tensor(17.0682, device='cuda:0')\n",
      "3 44123 tensor(17.5019, device='cuda:0')\n",
      "\n",
      "3 44124 tensor(17.9296, device='cuda:0')\n",
      "20\n",
      "236\n",
      "3 44124 tensor(18.1662, device='cuda:0')\n",
      "3 44124 tensor(18.3367, device='cuda:0')\n",
      "\n",
      "3 14943 tensor(17.2130, device='cuda:0')\n",
      "20\n",
      "156\n",
      "3 14943 tensor(17.5972, device='cuda:0')\n",
      "3 14943 tensor(17.9999, device='cuda:0')\n",
      "\n",
      "3 45664 tensor(17.4383, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 45664 tensor(17.1240, device='cuda:0')\n",
      "3 45664 tensor(18.0828, device='cuda:0')\n",
      "\n",
      "3 15458 tensor(17.3288, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 15458 tensor(17.4258, device='cuda:0')\n",
      "3 15458 tensor(16.8764, device='cuda:0')\n",
      "\n",
      "3 49765 tensor(17.4507, device='cuda:0')\n",
      "20\n",
      "192\n",
      "3 49765 tensor(17.7417, device='cuda:0')\n",
      "3 49765 tensor(17.8917, device='cuda:0')\n",
      "\n",
      "3 19046 tensor(17.1766, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 19046 tensor(17.4263, device='cuda:0')\n",
      "3 19046 tensor(17.9416, device='cuda:0')\n",
      "\n",
      "3 35944 tensor(16.8927, device='cuda:0')\n",
      "20\n",
      "216\n",
      "3 35944 tensor(17.4792, device='cuda:0')\n",
      "3 35944 tensor(17.7122, device='cuda:0')\n",
      "\n",
      "3 29804 tensor(17.0970, device='cuda:0')\n",
      "20\n",
      "198\n",
      "3 29804 tensor(17.4834, device='cuda:0')\n",
      "3 29804 tensor(18.1947, device='cuda:0')\n",
      "\n",
      "3 23662 tensor(16.8823, device='cuda:0')\n",
      "20\n",
      "218\n",
      "3 23662 tensor(17.1038, device='cuda:0')\n",
      "3 23662 tensor(17.5673, device='cuda:0')\n",
      "\n",
      "3 37497 tensor(17.1941, device='cuda:0')\n",
      "20\n",
      "220\n",
      "3 37497 tensor(17.2130, device='cuda:0')\n",
      "3 37497 tensor(17.2130, device='cuda:0')\n",
      "\n",
      "3 22138 tensor(16.9838, device='cuda:0')\n",
      "20\n",
      "184\n",
      "3 22138 tensor(17.3887, device='cuda:0')\n",
      "3 22138 tensor(17.8810, device='cuda:0')\n",
      "\n",
      "3 27773 tensor(17.1993, device='cuda:0')\n",
      "20\n",
      "176\n",
      "3 27773 tensor(17.7868, device='cuda:0')\n",
      "3 27773 tensor(17.3940, device='cuda:0')\n",
      "\n",
      "3 28798 tensor(16.9767, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 28798 tensor(17.7851, device='cuda:0')\n",
      "3 28798 tensor(17.1566, device='cuda:0')\n",
      "\n",
      "3 33407 tensor(17.9232, device='cuda:0')\n",
      "20\n",
      "226\n",
      "3 33407 tensor(17.7244, device='cuda:0')\n",
      "3 33407 tensor(18.7338, device='cuda:0')\n",
      "\n",
      "3 27264 tensor(16.1607, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 27264 tensor(17.2080, device='cuda:0')\n",
      "3 27264 tensor(16.5949, device='cuda:0')\n",
      "\n",
      "3 9857 tensor(17.7846, device='cuda:0')\n",
      "20\n",
      "208\n",
      "3 9857 tensor(18.6850, device='cuda:0')\n",
      "3 9857 tensor(18.0582, device='cuda:0')\n",
      "\n",
      "3 14468 tensor(16.6425, device='cuda:0')\n",
      "20\n",
      "198\n",
      "3 14468 tensor(17.1813, device='cuda:0')\n",
      "3 14468 tensor(17.0600, device='cuda:0')\n",
      "\n",
      "3 6277 tensor(16.8423, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 6277 tensor(17.2894, device='cuda:0')\n",
      "3 6277 tensor(16.7600, device='cuda:0')\n",
      "\n",
      "3 35972 tensor(17.5101, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 35972 tensor(17.6087, device='cuda:0')\n",
      "3 35972 tensor(17.4312, device='cuda:0')\n",
      "\n",
      "3 4744 tensor(16.6675, device='cuda:0')\n",
      "20\n",
      "146\n",
      "3 4744 tensor(17.1632, device='cuda:0')\n",
      "3 4744 tensor(16.6996, device='cuda:0')\n",
      "\n",
      "3 32905 tensor(17.0702, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 32905 tensor(17.6121, device='cuda:0')\n",
      "3 32905 tensor(18.2648, device='cuda:0')\n",
      "\n",
      "3 32393 tensor(17.0624, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 32393 tensor(17.7467, device='cuda:0')\n",
      "3 32393 tensor(17.0253, device='cuda:0')\n",
      "\n",
      "3 22671 tensor(17.5532, device='cuda:0')\n",
      "20\n",
      "176\n",
      "3 22671 tensor(17.6812, device='cuda:0')\n",
      "3 22671 tensor(18.8773, device='cuda:0')\n",
      "\n",
      "3 20628 tensor(16.6636, device='cuda:0')\n",
      "20\n",
      "218\n",
      "3 20628 tensor(18.0138, device='cuda:0')\n",
      "3 20628 tensor(17.4971, device='cuda:0')\n",
      "\n",
      "3 32920 tensor(17.6388, device='cuda:0')\n",
      "20\n",
      "362\n",
      "3 32920 tensor(18.3946, device='cuda:0')\n",
      "3 32920 tensor(17.8543, device='cuda:0')\n",
      "\n",
      "3 17560 tensor(16.6856, device='cuda:0')\n",
      "20\n",
      "164\n",
      "3 17560 tensor(16.9399, device='cuda:0')\n",
      "3 17560 tensor(17.1245, device='cuda:0')\n",
      "\n",
      "3 5119 tensor(16.8737, device='cuda:0')\n",
      "20\n",
      "140\n",
      "3 5119 tensor(16.9543, device='cuda:0')\n",
      "3 5119 tensor(15.5182, device='cuda:0')\n",
      "\n",
      "3 21661 tensor(18.0723, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 21661 tensor(18.7484, device='cuda:0')\n",
      "3 21661 tensor(17.9885, device='cuda:0')\n",
      "\n",
      "3 16543 tensor(17.2879, device='cuda:0')\n",
      "20\n",
      "172\n",
      "3 16543 tensor(17.1985, device='cuda:0')\n",
      "3 16543 tensor(18.2140, device='cuda:0')\n",
      "\n",
      "3 31903 tensor(17.0226, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 31903 tensor(17.0511, device='cuda:0')\n",
      "3 31903 tensor(17.0724, device='cuda:0')\n",
      "\n",
      "3 18089 tensor(17.3140, device='cuda:0')\n",
      "20\n",
      "184\n",
      "3 18089 tensor(17.9053, device='cuda:0')\n",
      "3 18089 tensor(18.6055, device='cuda:0')\n",
      "\n",
      "3 16553 tensor(16.9536, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 16553 tensor(16.7959, device='cuda:0')\n",
      "3 16553 tensor(17.4995, device='cuda:0')\n",
      "\n",
      "3 28331 tensor(17.0581, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 28331 tensor(16.9385, device='cuda:0')\n",
      "3 28331 tensor(17.0081, device='cuda:0')\n",
      "\n",
      "3 41131 tensor(17.4024, device='cuda:0')\n",
      "20\n",
      "178\n",
      "3 41131 tensor(17.7505, device='cuda:0')\n",
      "3 41131 tensor(17.0158, device='cuda:0')\n",
      "\n",
      "3 20145 tensor(16.7207, device='cuda:0')\n",
      "20\n",
      "174\n",
      "3 20145 tensor(16.7095, device='cuda:0')\n",
      "3 20145 tensor(16.8415, device='cuda:0')\n",
      "\n",
      "3 46262 tensor(17.5420, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 46262 tensor(17.7598, device='cuda:0')\n",
      "3 46262 tensor(17.7598, device='cuda:0')\n",
      "\n",
      "3 30397 tensor(17.2118, device='cuda:0')\n",
      "20\n",
      "200\n",
      "3 30397 tensor(18.2369, device='cuda:0')\n",
      "3 30397 tensor(17.7783, device='cuda:0')\n",
      "\n",
      "3 41151 tensor(16.7074, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 41151 tensor(17.1565, device='cuda:0')\n",
      "3 41151 tensor(16.7834, device='cuda:0')\n",
      "\n",
      "3 22723 tensor(17.0843, device='cuda:0')\n",
      "20\n",
      "210\n",
      "3 22723 tensor(17.0463, device='cuda:0')\n",
      "3 22723 tensor(17.2925, device='cuda:0')\n",
      "\n",
      "3 23239 tensor(16.9730, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 23239 tensor(16.9143, device='cuda:0')\n",
      "3 23239 tensor(16.9143, device='cuda:0')\n",
      "\n",
      "3 14538 tensor(17.3748, device='cuda:0')\n",
      "20\n",
      "174\n",
      "3 14538 tensor(18.7375, device='cuda:0')\n",
      "3 14538 tensor(19.5172, device='cuda:0')\n",
      "\n",
      "3 17100 tensor(17.0303, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 17100 tensor(17.5777, device='cuda:0')\n",
      "3 17100 tensor(17.5777, device='cuda:0')\n",
      "\n",
      "3 37073 tensor(17.1083, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 37073 tensor(17.5042, device='cuda:0')\n",
      "3 37073 tensor(17.4023, device='cuda:0')\n",
      "\n",
      "3 22739 tensor(17.5402, device='cuda:0')\n",
      "20\n",
      "238\n",
      "3 22739 tensor(18.1044, device='cuda:0')\n",
      "3 22739 tensor(17.6337, device='cuda:0')\n",
      "\n",
      "3 49365 tensor(17.3839, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 49365 tensor(17.6252, device='cuda:0')\n",
      "3 49365 tensor(17.9929, device='cuda:0')\n",
      "\n",
      "3 16598 tensor(18.0518, device='cuda:0')\n",
      "20\n",
      "152\n",
      "3 16598 tensor(17.9506, device='cuda:0')\n",
      "3 16598 tensor(18.1730, device='cuda:0')\n",
      "\n",
      "3 47831 tensor(17.2449, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 47831 tensor(17.7296, device='cuda:0')\n",
      "3 47831 tensor(17.7013, device='cuda:0')\n",
      "\n",
      "3 31959 tensor(17.1397, device='cuda:0')\n",
      "20\n",
      "232\n",
      "3 31959 tensor(17.3975, device='cuda:0')\n",
      "3 31959 tensor(17.1025, device='cuda:0')\n",
      "\n",
      "3 22234 tensor(16.7251, device='cuda:0')\n",
      "20\n",
      "252\n",
      "3 22234 tensor(16.6591, device='cuda:0')\n",
      "3 22234 tensor(16.7252, device='cuda:0')\n",
      "\n",
      "3 23259 tensor(17.1412, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 23259 tensor(17.6296, device='cuda:0')\n",
      "3 23259 tensor(17.8709, device='cuda:0')\n",
      "\n",
      "3 20189 tensor(18.0141, device='cuda:0')\n",
      "20\n",
      "176\n",
      "3 20189 tensor(17.8093, device='cuda:0')\n",
      "3 20189 tensor(18.7819, device='cuda:0')\n",
      "\n",
      "3 45790 tensor(17.2313, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 45790 tensor(17.6165, device='cuda:0')\n",
      "3 45790 tensor(18.3123, device='cuda:0')\n",
      "\n",
      "3 29927 tensor(17.1032, device='cuda:0')\n",
      "20\n",
      "226\n",
      "3 29927 tensor(18.2494, device='cuda:0')\n",
      "3 29927 tensor(17.9099, device='cuda:0')\n",
      "\n",
      "3 46312 tensor(17.1807, device='cuda:0')\n",
      "20\n",
      "210\n",
      "3 46312 tensor(17.8692, device='cuda:0')\n",
      "3 46312 tensor(18.4829, device='cuda:0')\n",
      "\n",
      "3 31465 tensor(18.1697, device='cuda:0')\n",
      "20\n",
      "176\n",
      "3 31465 tensor(19.2221, device='cuda:0')\n",
      "3 31465 tensor(18.6080, device='cuda:0')\n",
      "\n",
      "3 46831 tensor(17.4941, device='cuda:0')\n",
      "20\n",
      "158\n",
      "3 46831 tensor(17.7538, device='cuda:0')\n",
      "3 46831 tensor(18.1041, device='cuda:0')\n",
      "\n",
      "3 31472 tensor(16.7316, device='cuda:0')\n",
      "20\n",
      "162\n",
      "3 31472 tensor(16.8648, device='cuda:0')\n",
      "3 31472 tensor(17.3573, device='cuda:0')\n",
      "\n",
      "3 29936 tensor(17.1912, device='cuda:0')\n",
      "20\n",
      "150\n",
      "3 29936 tensor(16.6935, device='cuda:0')\n",
      "3 29936 tensor(16.9325, device='cuda:0')\n",
      "\n",
      "3 26355 tensor(17.0871, device='cuda:0')\n",
      "20\n",
      "136\n",
      "3 26355 tensor(17.1544, device='cuda:0')\n",
      "3 26355 tensor(17.3182, device='cuda:0')\n",
      "\n",
      "3 6393 tensor(16.6373, device='cuda:0')\n",
      "20\n",
      "150\n",
      "3 6393 tensor(17.1188, device='cuda:0')\n",
      "3 6393 tensor(17.0296, device='cuda:0')\n",
      "\n",
      "3 26876 tensor(17.2504, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 26876 tensor(18.0622, device='cuda:0')\n",
      "3 26876 tensor(17.7308, device='cuda:0')\n",
      "\n",
      "3 8444 tensor(16.7551, device='cuda:0')\n",
      "20\n",
      "152\n",
      "3 8444 tensor(17.6767, device='cuda:0')\n",
      "3 8444 tensor(17.2256, device='cuda:0')\n",
      "\n",
      "3 26878 tensor(17.7676, device='cuda:0')\n",
      "20\n",
      "216\n",
      "3 26878 tensor(18.0301, device='cuda:0')\n",
      "3 26878 tensor(17.7057, device='cuda:0')\n",
      "\n",
      "3 6911 tensor(16.8114, device='cuda:0')\n",
      "20\n",
      "162\n",
      "3 6911 tensor(17.0480, device='cuda:0')\n",
      "3 6911 tensor(17.4136, device='cuda:0')\n",
      "\n",
      "3 25856 tensor(16.6836, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 25856 tensor(16.8055, device='cuda:0')\n",
      "3 25856 tensor(16.8165, device='cuda:0')\n",
      "\n",
      "3 21249 tensor(19.1456, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 21249 tensor(19.8635, device='cuda:0')\n",
      "3 21249 tensor(18.8460, device='cuda:0')\n",
      "\n",
      "3 19717 tensor(17.1864, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 19717 tensor(17.9607, device='cuda:0')\n",
      "3 19717 tensor(17.8551, device='cuda:0')\n",
      "\n",
      "3 8966 tensor(17.0771, device='cuda:0')\n",
      "20\n",
      "166\n",
      "3 8966 tensor(17.9519, device='cuda:0')\n",
      "3 8966 tensor(17.5214, device='cuda:0')\n",
      "\n",
      "3 38150 tensor(17.3242, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 38150 tensor(17.1789, device='cuda:0')\n",
      "3 38150 tensor(18.0734, device='cuda:0')\n",
      "\n",
      "3 26888 tensor(16.6885, device='cuda:0')\n",
      "20\n",
      "210\n",
      "3 26888 tensor(16.9196, device='cuda:0')\n",
      "3 26888 tensor(16.7323, device='cuda:0')\n",
      "\n",
      "3 27917 tensor(17.4306, device='cuda:0')\n",
      "20\n",
      "214\n",
      "3 27917 tensor(18.4713, device='cuda:0')\n",
      "3 27917 tensor(17.2069, device='cuda:0')\n",
      "\n",
      "3 39184 tensor(17.9376, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 39184 tensor(18.9651, device='cuda:0')\n",
      "3 39184 tensor(18.9651, device='cuda:0')\n",
      "\n",
      "3 48401 tensor(17.0456, device='cuda:0')\n",
      "20\n",
      "148\n",
      "3 48401 tensor(17.4651, device='cuda:0')\n",
      "3 48401 tensor(17.4651, device='cuda:0')\n",
      "\n",
      "3 24336 tensor(17.3323, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 24336 tensor(18.2614, device='cuda:0')\n",
      "3 24336 tensor(17.3988, device='cuda:0')\n",
      "\n",
      "3 6416 tensor(17.3396, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 6416 tensor(17.4247, device='cuda:0')\n",
      "3 6416 tensor(18.0124, device='cuda:0')\n",
      "\n",
      "3 23316 tensor(17.1351, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 23316 tensor(17.5511, device='cuda:0')\n",
      "3 23316 tensor(16.9708, device='cuda:0')\n",
      "\n",
      "3 37144 tensor(17.2635, device='cuda:0')\n",
      "20\n",
      "146\n",
      "3 37144 tensor(17.2634, device='cuda:0')\n",
      "3 37144 tensor(17.7167, device='cuda:0')\n",
      "\n",
      "3 31513 tensor(17.0061, device='cuda:0')\n",
      "20\n",
      "222\n",
      "3 31513 tensor(16.9085, device='cuda:0')\n",
      "3 31513 tensor(17.6538, device='cuda:0')\n",
      "\n",
      "3 42266 tensor(16.8232, device='cuda:0')\n",
      "20\n",
      "178\n",
      "3 42266 tensor(17.4882, device='cuda:0')\n",
      "3 42266 tensor(16.8773, device='cuda:0')\n",
      "\n",
      "3 29989 tensor(17.1497, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 29989 tensor(18.1717, device='cuda:0')\n",
      "3 29989 tensor(18.1717, device='cuda:0')\n",
      "\n",
      "3 27434 tensor(17.9000, device='cuda:0')\n",
      "20\n",
      "222\n",
      "3 27434 tensor(18.9185, device='cuda:0')\n",
      "3 27434 tensor(17.6370, device='cuda:0')\n",
      "\n",
      "3 45867 tensor(17.1889, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 45867 tensor(17.4729, device='cuda:0')\n",
      "3 45867 tensor(18.0508, device='cuda:0')\n",
      "\n",
      "3 36139 tensor(17.0290, device='cuda:0')\n",
      "20\n",
      "242\n",
      "3 36139 tensor(17.9872, device='cuda:0')\n",
      "3 36139 tensor(17.2153, device='cuda:0')\n",
      "\n",
      "3 29489 tensor(17.5120, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 29489 tensor(17.7269, device='cuda:0')\n",
      "3 29489 tensor(17.1751, device='cuda:0')\n",
      "\n",
      "3 27443 tensor(16.9904, device='cuda:0')\n",
      "20\n",
      "200\n",
      "3 27443 tensor(17.1069, device='cuda:0')\n",
      "3 27443 tensor(17.8947, device='cuda:0')\n",
      "\n",
      "3 27955 tensor(17.8844, device='cuda:0')\n",
      "20\n",
      "216\n",
      "3 27955 tensor(20.0715, device='cuda:0')\n",
      "3 27955 tensor(18.0302, device='cuda:0')\n",
      "\n",
      "3 22838 tensor(17.3829, device='cuda:0')\n",
      "20\n",
      "152\n",
      "3 22838 tensor(17.0930, device='cuda:0')\n",
      "3 22838 tensor(18.0435, device='cuda:0')\n",
      "\n",
      "3 7993 tensor(17.4136, device='cuda:0')\n",
      "20\n",
      "174\n",
      "3 7993 tensor(17.5592, device='cuda:0')\n",
      "3 7993 tensor(17.2758, device='cuda:0')\n",
      "\n",
      "3 13114 tensor(17.3373, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 13114 tensor(18.1833, device='cuda:0')\n",
      "3 13114 tensor(18.1442, device='cuda:0')\n",
      "\n",
      "3 13629 tensor(17.2410, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 13629 tensor(17.6555, device='cuda:0')\n",
      "3 13629 tensor(17.2184, device='cuda:0')\n",
      "\n",
      "3 28991 tensor(17.4447, device='cuda:0')\n",
      "20\n",
      "200\n",
      "3 28991 tensor(18.0293, device='cuda:0')\n",
      "3 28991 tensor(18.1585, device='cuda:0')\n",
      "\n",
      "3 40771 tensor(17.1014, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 40771 tensor(17.0598, device='cuda:0')\n",
      "3 40771 tensor(17.4139, device='cuda:0')\n",
      "\n",
      "3 25413 tensor(16.8587, device='cuda:0')\n",
      "20\n",
      "230\n",
      "3 25413 tensor(16.9734, device='cuda:0')\n",
      "3 25413 tensor(17.5929, device='cuda:0')\n",
      "\n",
      "3 44870 tensor(17.3432, device='cuda:0')\n",
      "20\n",
      "168\n",
      "3 44870 tensor(17.8610, device='cuda:0')\n",
      "3 44870 tensor(17.7628, device='cuda:0')\n",
      "\n",
      "3 18247 tensor(17.0453, device='cuda:0')\n",
      "20\n",
      "230\n",
      "3 18247 tensor(16.9418, device='cuda:0')\n",
      "3 18247 tensor(16.7204, device='cuda:0')\n",
      "\n",
      "3 47944 tensor(17.0697, device='cuda:0')\n",
      "20\n",
      "208\n",
      "3 47944 tensor(17.5838, device='cuda:0')\n",
      "3 47944 tensor(17.4025, device='cuda:0')\n",
      "\n",
      "3 35657 tensor(17.1188, device='cuda:0')\n",
      "20\n",
      "192\n",
      "3 35657 tensor(17.6343, device='cuda:0')\n",
      "3 35657 tensor(17.8354, device='cuda:0')\n",
      "\n",
      "3 26953 tensor(17.5129, device='cuda:0')\n",
      "20\n",
      "196\n",
      "3 26953 tensor(17.9278, device='cuda:0')\n",
      "3 26953 tensor(17.2422, device='cuda:0')\n",
      "\n",
      "3 13651 tensor(17.3861, device='cuda:0')\n",
      "20\n",
      "226\n",
      "3 13651 tensor(17.4696, device='cuda:0')\n",
      "3 13651 tensor(18.4552, device='cuda:0')\n",
      "\n",
      "3 27991 tensor(17.1643, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 27991 tensor(17.7380, device='cuda:0')\n",
      "3 27991 tensor(18.0311, device='cuda:0')\n",
      "\n",
      "3 26456 tensor(17.1757, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 26456 tensor(17.5140, device='cuda:0')\n",
      "3 26456 tensor(17.5813, device='cuda:0')\n",
      "\n",
      "3 48990 tensor(17.0131, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 48990 tensor(16.5261, device='cuda:0')\n",
      "3 48990 tensor(17.8499, device='cuda:0')\n",
      "\n",
      "3 34655 tensor(17.2030, device='cuda:0')\n",
      "20\n",
      "190\n",
      "3 34655 tensor(16.8413, device='cuda:0')\n",
      "3 34655 tensor(18.5067, device='cuda:0')\n",
      "\n",
      "3 16225 tensor(17.7966, device='cuda:0')\n",
      "20\n",
      "132\n",
      "3 16225 tensor(18.5499, device='cuda:0')\n",
      "3 16225 tensor(18.2831, device='cuda:0')\n",
      "\n",
      "3 28518 tensor(17.5362, device='cuda:0')\n",
      "20\n",
      "148\n",
      "3 28518 tensor(18.2826, device='cuda:0')\n",
      "3 28518 tensor(18.0054, device='cuda:0')\n",
      "\n",
      "3 20839 tensor(17.1404, device='cuda:0')\n",
      "20\n",
      "192\n",
      "3 20839 tensor(16.9317, device='cuda:0')\n",
      "3 20839 tensor(17.3449, device='cuda:0')\n",
      "\n",
      "3 43367 tensor(17.3565, device='cuda:0')\n",
      "20\n",
      "256\n",
      "3 43367 tensor(17.8717, device='cuda:0')\n",
      "3 43367 tensor(17.6452, device='cuda:0')\n",
      "\n",
      "3 10092 tensor(16.9190, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 10092 tensor(16.5616, device='cuda:0')\n",
      "3 10092 tensor(18.2907, device='cuda:0')\n",
      "\n",
      "3 11116 tensor(16.8912, device='cuda:0')\n",
      "20\n",
      "154\n",
      "3 11116 tensor(17.7727, device='cuda:0')\n",
      "3 11116 tensor(17.1618, device='cuda:0')\n",
      "\n",
      "3 31086 tensor(16.6419, device='cuda:0')\n",
      "20\n",
      "226\n",
      "3 31086 tensor(17.0466, device='cuda:0')\n",
      "3 31086 tensor(17.0311, device='cuda:0')\n",
      "\n",
      "3 29040 tensor(17.1842, device='cuda:0')\n",
      "20\n",
      "180\n",
      "3 29040 tensor(17.7155, device='cuda:0')\n",
      "3 29040 tensor(17.1756, device='cuda:0')\n",
      "\n",
      "3 50033 tensor(17.3265, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 50033 tensor(18.1553, device='cuda:0')\n",
      "3 50033 tensor(17.6150, device='cuda:0')\n",
      "\n",
      "3 5490 tensor(16.8878, device='cuda:0')\n",
      "20\n",
      "196\n",
      "3 5490 tensor(17.0794, device='cuda:0')\n",
      "3 5490 tensor(18.0686, device='cuda:0')\n",
      "\n",
      "3 39795 tensor(17.3735, device='cuda:0')\n",
      "20\n",
      "176\n",
      "3 39795 tensor(17.7635, device='cuda:0')\n",
      "3 39795 tensor(17.3016, device='cuda:0')\n",
      "\n",
      "3 48505 tensor(17.0733, device='cuda:0')\n",
      "20\n",
      "166\n",
      "3 48505 tensor(16.6425, device='cuda:0')\n",
      "3 48505 tensor(17.9484, device='cuda:0')\n",
      "\n",
      "3 40316 tensor(17.3587, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 40316 tensor(17.2122, device='cuda:0')\n",
      "3 40316 tensor(17.0215, device='cuda:0')\n",
      "\n",
      "3 24958 tensor(16.9292, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 24958 tensor(17.4186, device='cuda:0')\n",
      "3 24958 tensor(17.0771, device='cuda:0')\n",
      "\n",
      "3 38783 tensor(17.6346, device='cuda:0')\n",
      "20\n",
      "164\n",
      "3 38783 tensor(18.1086, device='cuda:0')\n",
      "3 38783 tensor(18.1086, device='cuda:0')\n",
      "\n",
      "3 19838 tensor(18.2674, device='cuda:0')\n",
      "20\n",
      "216\n",
      "3 19838 tensor(18.6874, device='cuda:0')\n",
      "3 19838 tensor(18.7389, device='cuda:0')\n",
      "\n",
      "3 23425 tensor(17.3427, device='cuda:0')\n",
      "20\n",
      "172\n",
      "3 23425 tensor(17.9093, device='cuda:0')\n",
      "3 23425 tensor(17.7102, device='cuda:0')\n",
      "\n",
      "3 24962 tensor(17.2097, device='cuda:0')\n",
      "20\n",
      "172\n",
      "3 24962 tensor(17.6120, device='cuda:0')\n",
      "3 24962 tensor(17.9182, device='cuda:0')\n",
      "\n",
      "3 13187 tensor(16.8087, device='cuda:0')\n",
      "20\n",
      "170\n",
      "3 13187 tensor(16.8933, device='cuda:0')\n",
      "3 13187 tensor(16.9958, device='cuda:0')\n",
      "\n",
      "3 49028 tensor(17.1909, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 49028 tensor(17.3317, device='cuda:0')\n",
      "3 49028 tensor(17.9423, device='cuda:0')\n",
      "\n",
      "3 12167 tensor(16.8197, device='cuda:0')\n",
      "20\n",
      "218\n",
      "3 12167 tensor(17.0471, device='cuda:0')\n",
      "3 12167 tensor(17.5345, device='cuda:0')\n",
      "\n",
      "3 43406 tensor(16.8036, device='cuda:0')\n",
      "20\n",
      "178\n",
      "3 43406 tensor(16.5084, device='cuda:0')\n",
      "3 43406 tensor(17.9674, device='cuda:0')\n",
      "\n",
      "3 14737 tensor(16.5955, device='cuda:0')\n",
      "20\n",
      "218\n",
      "3 14737 tensor(17.7030, device='cuda:0')\n",
      "3 14737 tensor(17.3460, device='cuda:0')\n",
      "\n",
      "3 18322 tensor(16.9629, device='cuda:0')\n",
      "20\n",
      "152\n",
      "3 18322 tensor(17.4828, device='cuda:0')\n",
      "3 18322 tensor(17.2325, device='cuda:0')\n",
      "\n",
      "3 43921 tensor(17.2458, device='cuda:0')\n",
      "20\n",
      "236\n",
      "3 43921 tensor(17.7385, device='cuda:0')\n",
      "3 43921 tensor(18.3696, device='cuda:0')\n",
      "\n",
      "3 12694 tensor(16.6917, device='cuda:0')\n",
      "20\n",
      "224\n",
      "3 12694 tensor(17.7508, device='cuda:0')\n",
      "3 12694 tensor(16.6148, device='cuda:0')\n",
      "\n",
      "3 16286 tensor(17.5758, device='cuda:0')\n",
      "20\n",
      "204\n",
      "3 16286 tensor(18.1021, device='cuda:0')\n",
      "3 16286 tensor(17.6474, device='cuda:0')\n",
      "\n",
      "3 48545 tensor(17.2365, device='cuda:0')\n",
      "20\n",
      "190\n",
      "3 48545 tensor(17.6869, device='cuda:0')\n",
      "3 48545 tensor(17.1804, device='cuda:0')\n",
      "\n",
      "3 29092 tensor(17.0237, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 29092 tensor(17.8472, device='cuda:0')\n",
      "3 29092 tensor(16.0580, device='cuda:0')\n",
      "\n",
      "3 15273 tensor(16.8278, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 15273 tensor(16.1221, device='cuda:0')\n",
      "3 15273 tensor(16.0415, device='cuda:0')\n",
      "\n",
      "3 16809 tensor(17.6645, device='cuda:0')\n",
      "20\n",
      "182\n",
      "3 16809 tensor(17.9873, device='cuda:0')\n",
      "3 16809 tensor(18.7470, device='cuda:0')\n",
      "\n",
      "3 22455 tensor(17.6437, device='cuda:0')\n",
      "20\n",
      "128\n",
      "3 22455 tensor(18.1996, device='cuda:0')\n",
      "3 22455 tensor(17.7752, device='cuda:0')\n",
      "\n",
      "3 24504 tensor(16.9805, device='cuda:0')\n",
      "20\n",
      "190\n",
      "3 24504 tensor(17.3800, device='cuda:0')\n",
      "3 24504 tensor(16.9061, device='cuda:0')\n",
      "\n",
      "3 30140 tensor(17.1969, device='cuda:0')\n",
      "20\n",
      "210\n",
      "3 30140 tensor(17.4394, device='cuda:0')\n",
      "3 30140 tensor(17.9524, device='cuda:0')\n",
      "\n",
      "3 27581 tensor(17.3899, device='cuda:0')\n",
      "20\n",
      "180\n",
      "3 27581 tensor(18.3033, device='cuda:0')\n",
      "3 27581 tensor(17.5663, device='cuda:0')\n",
      "\n",
      "3 21438 tensor(17.4138, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 21438 tensor(17.3048, device='cuda:0')\n",
      "3 21438 tensor(17.5399, device='cuda:0')\n",
      "\n",
      "3 35262 tensor(17.7640, device='cuda:0')\n",
      "20\n",
      "166\n",
      "3 35262 tensor(17.9297, device='cuda:0')\n",
      "3 35262 tensor(17.7432, device='cuda:0')\n",
      "\n",
      "3 36292 tensor(17.0051, device='cuda:0')\n",
      "20\n",
      "196\n",
      "3 36292 tensor(17.4944, device='cuda:0')\n",
      "3 36292 tensor(17.3902, device='cuda:0')\n",
      "\n",
      "3 6086 tensor(16.7027, device='cuda:0')\n",
      "20\n",
      "166\n",
      "3 6086 tensor(16.3146, device='cuda:0')\n",
      "3 6086 tensor(16.2940, device='cuda:0')\n",
      "\n",
      "3 21960 tensor(17.2946, device='cuda:0')\n",
      "20\n",
      "174\n",
      "3 21960 tensor(17.6588, device='cuda:0')\n",
      "3 21960 tensor(17.9002, device='cuda:0')\n",
      "\n",
      "3 20428 tensor(16.8031, device='cuda:0')\n",
      "20\n",
      "234\n",
      "3 20428 tensor(17.6147, device='cuda:0')\n",
      "3 20428 tensor(17.5650, device='cuda:0')\n",
      "\n",
      "3 17361 tensor(18.0182, device='cuda:0')\n",
      "20\n",
      "212\n",
      "3 17361 tensor(19.6219, device='cuda:0')\n",
      "3 17361 tensor(17.5654, device='cuda:0')\n",
      "\n",
      "3 33747 tensor(17.6554, device='cuda:0')\n",
      "20\n",
      "144\n",
      "3 33747 tensor(18.3375, device='cuda:0')\n",
      "3 33747 tensor(18.4608, device='cuda:0')\n",
      "\n",
      "3 2516 tensor(16.2886, device='cuda:0')\n",
      "20\n",
      "246\n",
      "3 2516 tensor(16.5139, device='cuda:0')\n",
      "3 2516 tensor(16.5335, device='cuda:0')\n",
      "\n",
      "3 13268 tensor(17.4504, device='cuda:0')\n",
      "20\n",
      "432\n",
      "3 13268 tensor(17.5236, device='cuda:0')\n",
      "3 13268 tensor(17.8045, device='cuda:0')\n",
      "\n",
      "3 45014 tensor(17.5379, device='cuda:0')\n",
      "20\n",
      "186\n",
      "3 45014 tensor(18.3516, device='cuda:0')\n",
      "3 45014 tensor(18.6247, device='cuda:0')\n",
      "\n",
      "3 25556 tensor(17.4650, device='cuda:0')\n",
      "20\n",
      "214\n",
      "3 25556 tensor(18.4529, device='cuda:0')\n",
      "3 25556 tensor(17.9245, device='cuda:0')\n",
      "\n",
      "3 33240 tensor(17.6620, device='cuda:0')\n",
      "20\n",
      "200\n",
      "3 33240 tensor(17.6144, device='cuda:0')\n",
      "3 33240 tensor(19.1741, device='cuda:0')\n",
      "\n",
      "3 36312 tensor(17.3838, device='cuda:0')\n",
      "20\n",
      "234\n",
      "3 36312 tensor(17.0763, device='cuda:0')\n",
      "3 36312 tensor(17.7958, device='cuda:0')\n",
      "\n",
      "3 16863 tensor(17.8759, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 16863 tensor(18.4257, device='cuda:0')\n",
      "3 16863 tensor(18.0466, device='cuda:0')\n",
      "\n",
      "3 28642 tensor(16.9590, device='cuda:0')\n",
      "20\n",
      "194\n",
      "3 28642 tensor(16.7262, device='cuda:0')\n",
      "3 28642 tensor(17.4393, device='cuda:0')\n",
      "\n",
      "3 10213 tensor(17.6111, device='cuda:0')\n",
      "20\n",
      "188\n",
      "3 10213 tensor(18.1895, device='cuda:0')\n",
      "3 10213 tensor(17.7066, device='cuda:0')\n",
      "\n",
      "3 16358 tensor(17.0034, device='cuda:0')\n",
      "20\n",
      "222\n",
      "3 16358 tensor(17.6756, device='cuda:0')\n",
      "3 16358 tensor(16.9280, device='cuda:0')\n",
      "\n",
      "3 25062 tensor(16.9434, device='cuda:0')\n",
      "20\n",
      "164\n",
      "3 25062 tensor(17.1917, device='cuda:0')\n",
      "3 25062 tensor(17.3588, device='cuda:0')\n",
      "\n",
      "3 23528 tensor(18.4194, device='cuda:0')\n",
      "20\n",
      "206\n",
      "3 23528 tensor(20.4810, device='cuda:0')\n",
      "3 23528 tensor(18.3467, device='cuda:0')\n",
      "\n",
      "3 35307 tensor(17.3344, device='cuda:0')\n",
      "20\n",
      "238\n",
      "3 35307 tensor(17.5295, device='cuda:0')\n",
      "3 35307 tensor(17.2576, device='cuda:0')\n",
      "\n",
      "3 19436 tensor(16.7108, device='cuda:0')\n",
      "20\n",
      "162\n",
      "3 19436 tensor(17.6525, device='cuda:0')\n",
      "3 19436 tensor(16.4212, device='cuda:0')\n",
      "\n",
      "3 25579 tensor(17.8147, device='cuda:0')\n",
      "20\n",
      "224\n",
      "3 25579 tensor(18.6637, device='cuda:0')\n",
      "3 25579 tensor(18.3329, device='cuda:0')\n",
      "\n",
      "3 15859 tensor(17.4743, device='cuda:0')\n",
      "20\n",
      "208\n",
      "3 15859 tensor(17.8919, device='cuda:0')\n",
      "3 15859 tensor(17.7421, device='cuda:0')\n",
      "\n",
      "3 38900 tensor(17.3649, device='cuda:0')\n",
      "20\n",
      "130\n",
      "3 38900 tensor(17.8627, device='cuda:0')\n",
      "3 38900 tensor(17.6117, device='cuda:0')\n",
      "\n",
      "3 7670 tensor(16.8521, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 7670 tensor(16.7230, device='cuda:0')\n",
      "3 7670 tensor(17.5212, device='cuda:0')\n",
      "\n",
      "3 8698 tensor(17.3556, device='cuda:0')\n",
      "20\n",
      "202\n",
      "3 8698 tensor(17.5290, device='cuda:0')\n",
      "3 8698 tensor(17.5290, device='cuda:0')\n",
      "\n",
      "3 12284 tensor(17.0931, device='cuda:0')\n",
      "20\n",
      "174\n",
      "3 12284 tensor(17.4681, device='cuda:0')\n",
      "3 12284 tensor(17.3382, device='cuda:0')\n",
      "\n",
      "3 44542 tensor(17.1254, device='cuda:0')\n",
      "20\n",
      "214\n",
      "3 44542 tensor(17.6231, device='cuda:0')\n",
      "3 44542 tensor(17.3217, device='cuda:0')\n",
      "\n",
      "3 31231 tensor(17.0916, device='cuda:0')\n",
      "20\n",
      "184\n",
      "3 31231 tensor(17.1865, device='cuda:0')\n",
      "3 31231 tensor(16.9916, device='cuda:0')\n",
      "\n",
      "4 50178 tensor(16.9806, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 50178 tensor(17.4023, device='cuda:0')\n",
      "4 50178 tensor(17.4738, device='cuda:0')\n",
      "\n",
      "4 46600 tensor(17.1445, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 46600 tensor(18.0372, device='cuda:0')\n",
      "4 46600 tensor(16.9792, device='cuda:0')\n",
      "\n",
      "4 31755 tensor(17.5021, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 31755 tensor(18.4366, device='cuda:0')\n",
      "4 31755 tensor(17.7975, device='cuda:0')\n",
      "\n",
      "4 46604 tensor(16.9537, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 46604 tensor(17.6456, device='cuda:0')\n",
      "4 46604 tensor(16.8113, device='cuda:0')\n",
      "\n",
      "4 10765 tensor(16.5159, device='cuda:0')\n",
      "20\n",
      "246\n",
      "4 10765 tensor(17.8146, device='cuda:0')\n",
      "4 10765 tensor(17.3658, device='cuda:0')\n",
      "\n",
      "4 11276 tensor(17.2815, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 11276 tensor(17.5725, device='cuda:0')\n",
      "4 11276 tensor(18.4010, device='cuda:0')\n",
      "\n",
      "4 33811 tensor(16.9574, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 33811 tensor(17.2995, device='cuda:0')\n",
      "4 33811 tensor(17.3172, device='cuda:0')\n",
      "\n",
      "4 46612 tensor(17.1879, device='cuda:0')\n",
      "20\n",
      "238\n",
      "4 46612 tensor(17.9984, device='cuda:0')\n",
      "4 46612 tensor(17.2658, device='cuda:0')\n",
      "\n",
      "4 16916 tensor(17.0395, device='cuda:0')\n",
      "20\n",
      "232\n",
      "4 16916 tensor(18.3587, device='cuda:0')\n",
      "4 16916 tensor(17.4850, device='cuda:0')\n",
      "\n",
      "4 18966 tensor(17.0526, device='cuda:0')\n",
      "20\n",
      "224\n",
      "4 18966 tensor(17.1445, device='cuda:0')\n",
      "4 18966 tensor(17.2699, device='cuda:0')\n",
      "\n",
      "4 12824 tensor(16.2737, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 12824 tensor(16.1129, device='cuda:0')\n",
      "4 12824 tensor(17.4546, device='cuda:0')\n",
      "\n",
      "4 32794 tensor(16.5465, device='cuda:0')\n",
      "20\n",
      "232\n",
      "4 32794 tensor(16.9963, device='cuda:0')\n",
      "4 32794 tensor(17.3764, device='cuda:0')\n",
      "\n",
      "4 7195 tensor(16.5275, device='cuda:0')\n",
      "20\n",
      "182\n",
      "4 7195 tensor(17.0152, device='cuda:0')\n",
      "4 7195 tensor(17.1859, device='cuda:0')\n",
      "\n",
      "4 33821 tensor(16.8049, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 33821 tensor(17.9364, device='cuda:0')\n",
      "4 33821 tensor(16.3653, device='cuda:0')\n",
      "\n",
      "4 37921 tensor(17.0854, device='cuda:0')\n",
      "20\n",
      "206\n",
      "4 37921 tensor(17.0717, device='cuda:0')\n",
      "4 37921 tensor(17.3068, device='cuda:0')\n",
      "\n",
      "4 33313 tensor(17.0954, device='cuda:0')\n",
      "20\n",
      "230\n",
      "4 33313 tensor(18.0334, device='cuda:0')\n",
      "4 33313 tensor(17.4304, device='cuda:0')\n",
      "\n",
      "4 31270 tensor(16.4435, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 31270 tensor(16.8290, device='cuda:0')\n",
      "4 31270 tensor(16.8009, device='cuda:0')\n",
      "\n",
      "4 29222 tensor(16.5596, device='cuda:0')\n",
      "20\n",
      "148\n",
      "4 29222 tensor(17.6688, device='cuda:0')\n",
      "4 29222 tensor(17.1204, device='cuda:0')\n",
      "\n",
      "4 28712 tensor(16.7048, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 28712 tensor(17.3360, device='cuda:0')\n",
      "4 28712 tensor(17.3360, device='cuda:0')\n",
      "\n",
      "4 18985 tensor(16.4908, device='cuda:0')\n",
      "20\n",
      "222\n",
      "4 18985 tensor(17.7662, device='cuda:0')\n",
      "4 18985 tensor(17.7662, device='cuda:0')\n",
      "\n",
      "4 37930 tensor(16.9680, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 37930 tensor(17.2937, device='cuda:0')\n",
      "4 37930 tensor(16.5158, device='cuda:0')\n",
      "\n",
      "4 28200 tensor(16.4685, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 28200 tensor(16.6309, device='cuda:0')\n",
      "4 28200 tensor(17.2105, device='cuda:0')\n",
      "\n",
      "4 7727 tensor(16.8043, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 7727 tensor(17.4721, device='cuda:0')\n",
      "4 7727 tensor(17.3740, device='cuda:0')\n",
      "\n",
      "4 24112 tensor(16.8835, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 24112 tensor(16.5494, device='cuda:0')\n",
      "4 24112 tensor(17.1194, device='cuda:0')\n",
      "\n",
      "4 36400 tensor(16.4508, device='cuda:0')\n",
      "20\n",
      "224\n",
      "4 36400 tensor(16.4365, device='cuda:0')\n",
      "4 36400 tensor(16.6966, device='cuda:0')\n",
      "\n",
      "4 32817 tensor(17.0109, device='cuda:0')\n",
      "20\n",
      "204\n",
      "4 32817 tensor(17.6501, device='cuda:0')\n",
      "4 32817 tensor(16.6234, device='cuda:0')\n",
      "\n",
      "4 5171 tensor(16.6329, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 5171 tensor(17.2269, device='cuda:0')\n",
      "4 5171 tensor(17.2264, device='cuda:0')\n",
      "\n",
      "4 44085 tensor(17.0273, device='cuda:0')\n",
      "20\n",
      "204\n",
      "4 44085 tensor(17.2252, device='cuda:0')\n",
      "4 44085 tensor(17.2075, device='cuda:0')\n",
      "\n",
      "4 35382 tensor(16.9787, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 35382 tensor(16.8288, device='cuda:0')\n",
      "4 35382 tensor(17.0906, device='cuda:0')\n",
      "\n",
      "4 14912 tensor(16.7944, device='cuda:0')\n",
      "20\n",
      "156\n",
      "4 14912 tensor(16.6773, device='cuda:0')\n",
      "4 14912 tensor(16.3365, device='cuda:0')\n",
      "\n",
      "4 30274 tensor(16.1431, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 30274 tensor(17.0472, device='cuda:0')\n",
      "4 30274 tensor(17.1682, device='cuda:0')\n",
      "\n",
      "4 20554 tensor(16.7943, device='cuda:0')\n",
      "20\n",
      "160\n",
      "4 20554 tensor(17.4301, device='cuda:0')\n",
      "4 20554 tensor(16.5411, device='cuda:0')\n",
      "\n",
      "4 15435 tensor(16.8897, device='cuda:0')\n",
      "20\n",
      "156\n",
      "4 15435 tensor(16.7200, device='cuda:0')\n",
      "4 15435 tensor(16.3640, device='cuda:0')\n",
      "\n",
      "4 33357 tensor(16.8477, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 33357 tensor(17.4583, device='cuda:0')\n",
      "4 33357 tensor(17.4903, device='cuda:0')\n",
      "\n",
      "4 49231 tensor(17.5542, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 49231 tensor(18.1494, device='cuda:0')\n",
      "4 49231 tensor(17.6199, device='cuda:0')\n",
      "\n",
      "4 38994 tensor(17.0890, device='cuda:0')\n",
      "20\n",
      "202\n",
      "4 38994 tensor(16.9499, device='cuda:0')\n",
      "4 38994 tensor(17.5359, device='cuda:0')\n",
      "\n",
      "4 21587 tensor(16.8261, device='cuda:0')\n",
      "20\n",
      "216\n",
      "4 21587 tensor(17.0769, device='cuda:0')\n",
      "4 21587 tensor(17.6862, device='cuda:0')\n",
      "\n",
      "4 7252 tensor(16.2119, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 7252 tensor(17.0806, device='cuda:0')\n",
      "4 7252 tensor(16.9526, device='cuda:0')\n",
      "\n",
      "4 40537 tensor(16.9692, device='cuda:0')\n",
      "20\n",
      "176\n",
      "4 40537 tensor(17.7589, device='cuda:0')\n",
      "4 40537 tensor(17.7829, device='cuda:0')\n",
      "\n",
      "4 27738 tensor(17.0927, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 27738 tensor(17.2732, device='cuda:0')\n",
      "4 27738 tensor(17.0747, device='cuda:0')\n",
      "\n",
      "4 44123 tensor(16.8898, device='cuda:0')\n",
      "20\n",
      "158\n",
      "4 44123 tensor(17.2205, device='cuda:0')\n",
      "4 44123 tensor(17.9864, device='cuda:0')\n",
      "\n",
      "4 44124 tensor(17.1543, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 44124 tensor(17.9622, device='cuda:0')\n",
      "4 44124 tensor(17.0476, device='cuda:0')\n",
      "\n",
      "4 14943 tensor(17.2316, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 14943 tensor(17.8116, device='cuda:0')\n",
      "4 14943 tensor(17.9897, device='cuda:0')\n",
      "\n",
      "4 45664 tensor(17.0437, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 45664 tensor(17.4828, device='cuda:0')\n",
      "4 45664 tensor(17.7883, device='cuda:0')\n",
      "\n",
      "4 15458 tensor(16.9388, device='cuda:0')\n",
      "20\n",
      "240\n",
      "4 15458 tensor(17.5925, device='cuda:0')\n",
      "4 15458 tensor(16.9251, device='cuda:0')\n",
      "\n",
      "4 49765 tensor(16.4585, device='cuda:0')\n",
      "20\n",
      "214\n",
      "4 49765 tensor(17.2426, device='cuda:0')\n",
      "4 49765 tensor(17.2426, device='cuda:0')\n",
      "\n",
      "4 19046 tensor(16.5728, device='cuda:0')\n",
      "20\n",
      "228\n",
      "4 19046 tensor(16.4731, device='cuda:0')\n",
      "4 19046 tensor(16.7333, device='cuda:0')\n",
      "\n",
      "4 35944 tensor(16.7388, device='cuda:0')\n",
      "20\n",
      "230\n",
      "4 35944 tensor(17.5684, device='cuda:0')\n",
      "4 35944 tensor(16.4816, device='cuda:0')\n",
      "\n",
      "4 29804 tensor(17.1020, device='cuda:0')\n",
      "20\n",
      "158\n",
      "4 29804 tensor(17.4946, device='cuda:0')\n",
      "4 29804 tensor(17.3031, device='cuda:0')\n",
      "\n",
      "4 23662 tensor(16.8098, device='cuda:0')\n",
      "20\n",
      "166\n",
      "4 23662 tensor(16.8679, device='cuda:0')\n",
      "4 23662 tensor(17.1427, device='cuda:0')\n",
      "\n",
      "4 37497 tensor(16.5984, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 37497 tensor(16.8282, device='cuda:0')\n",
      "4 37497 tensor(17.1344, device='cuda:0')\n",
      "\n",
      "4 22138 tensor(16.8631, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 22138 tensor(16.9348, device='cuda:0')\n",
      "4 22138 tensor(16.9103, device='cuda:0')\n",
      "\n",
      "4 27773 tensor(17.2142, device='cuda:0')\n",
      "20\n",
      "258\n",
      "4 27773 tensor(18.1593, device='cuda:0')\n",
      "4 27773 tensor(16.6901, device='cuda:0')\n",
      "\n",
      "4 28798 tensor(16.9987, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 28798 tensor(17.8463, device='cuda:0')\n",
      "4 28798 tensor(17.9563, device='cuda:0')\n",
      "\n",
      "4 33407 tensor(17.2801, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 33407 tensor(18.4940, device='cuda:0')\n",
      "4 33407 tensor(17.3686, device='cuda:0')\n",
      "\n",
      "4 27264 tensor(17.0417, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 27264 tensor(16.9604, device='cuda:0')\n",
      "4 27264 tensor(17.3989, device='cuda:0')\n",
      "\n",
      "4 9857 tensor(16.9474, device='cuda:0')\n",
      "20\n",
      "208\n",
      "4 9857 tensor(17.6064, device='cuda:0')\n",
      "4 9857 tensor(16.6875, device='cuda:0')\n",
      "\n",
      "4 14468 tensor(16.6929, device='cuda:0')\n",
      "20\n",
      "134\n",
      "4 14468 tensor(16.4244, device='cuda:0')\n",
      "4 14468 tensor(17.6430, device='cuda:0')\n",
      "\n",
      "4 6277 tensor(16.6165, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 6277 tensor(17.3643, device='cuda:0')\n",
      "4 6277 tensor(17.2692, device='cuda:0')\n",
      "\n",
      "4 35972 tensor(16.9996, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 35972 tensor(17.9860, device='cuda:0')\n",
      "4 35972 tensor(17.0673, device='cuda:0')\n",
      "\n",
      "4 4744 tensor(16.3616, device='cuda:0')\n",
      "20\n",
      "212\n",
      "4 4744 tensor(16.6872, device='cuda:0')\n",
      "4 4744 tensor(16.6341, device='cuda:0')\n",
      "\n",
      "4 32905 tensor(16.0120, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 32905 tensor(17.0610, device='cuda:0')\n",
      "4 32905 tensor(16.4830, device='cuda:0')\n",
      "\n",
      "4 32393 tensor(16.8913, device='cuda:0')\n",
      "20\n",
      "222\n",
      "4 32393 tensor(17.0827, device='cuda:0')\n",
      "4 32393 tensor(16.6550, device='cuda:0')\n",
      "\n",
      "4 22671 tensor(17.0973, device='cuda:0')\n",
      "20\n",
      "196\n",
      "4 22671 tensor(17.2438, device='cuda:0')\n",
      "4 22671 tensor(18.0707, device='cuda:0')\n",
      "\n",
      "4 20628 tensor(16.5693, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 20628 tensor(18.0358, device='cuda:0')\n",
      "4 20628 tensor(17.1159, device='cuda:0')\n",
      "\n",
      "4 32920 tensor(17.1745, device='cuda:0')\n",
      "20\n",
      "348\n",
      "4 32920 tensor(17.2506, device='cuda:0')\n",
      "4 32920 tensor(17.7536, device='cuda:0')\n",
      "\n",
      "4 17560 tensor(16.7767, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 17560 tensor(16.5668, device='cuda:0')\n",
      "4 17560 tensor(17.8957, device='cuda:0')\n",
      "\n",
      "4 5119 tensor(16.6098, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 5119 tensor(16.6658, device='cuda:0')\n",
      "4 5119 tensor(18.1501, device='cuda:0')\n",
      "\n",
      "4 21661 tensor(17.1139, device='cuda:0')\n",
      "20\n",
      "210\n",
      "4 21661 tensor(17.6879, device='cuda:0')\n",
      "4 21661 tensor(17.1808, device='cuda:0')\n",
      "\n",
      "4 16543 tensor(16.8505, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 16543 tensor(15.5487, device='cuda:0')\n",
      "4 16543 tensor(16.9144, device='cuda:0')\n",
      "\n",
      "4 31903 tensor(16.7044, device='cuda:0')\n",
      "20\n",
      "230\n",
      "4 31903 tensor(16.1549, device='cuda:0')\n",
      "4 31903 tensor(17.6791, device='cuda:0')\n",
      "\n",
      "4 18089 tensor(16.5903, device='cuda:0')\n",
      "20\n",
      "154\n",
      "4 18089 tensor(16.4771, device='cuda:0')\n",
      "4 18089 tensor(16.9648, device='cuda:0')\n",
      "\n",
      "4 16553 tensor(16.8930, device='cuda:0')\n",
      "20\n",
      "190\n",
      "4 16553 tensor(17.3299, device='cuda:0')\n",
      "4 16553 tensor(16.8636, device='cuda:0')\n",
      "\n",
      "4 28331 tensor(16.6516, device='cuda:0')\n",
      "20\n",
      "216\n",
      "4 28331 tensor(17.3258, device='cuda:0')\n",
      "4 28331 tensor(17.3095, device='cuda:0')\n",
      "\n",
      "4 41131 tensor(17.1445, device='cuda:0')\n",
      "20\n",
      "196\n",
      "4 41131 tensor(16.7716, device='cuda:0')\n",
      "4 41131 tensor(17.1977, device='cuda:0')\n",
      "\n",
      "4 20145 tensor(16.4757, device='cuda:0')\n",
      "20\n",
      "138\n",
      "4 20145 tensor(16.4291, device='cuda:0')\n",
      "4 20145 tensor(17.3871, device='cuda:0')\n",
      "\n",
      "4 46262 tensor(16.8239, device='cuda:0')\n",
      "20\n",
      "214\n",
      "4 46262 tensor(17.2250, device='cuda:0')\n",
      "4 46262 tensor(16.8925, device='cuda:0')\n",
      "\n",
      "4 30397 tensor(17.2250, device='cuda:0')\n",
      "20\n",
      "226\n",
      "4 30397 tensor(17.8228, device='cuda:0')\n",
      "4 30397 tensor(18.1338, device='cuda:0')\n",
      "\n",
      "4 41151 tensor(16.5573, device='cuda:0')\n",
      "20\n",
      "230\n",
      "4 41151 tensor(15.8959, device='cuda:0')\n",
      "4 41151 tensor(17.2418, device='cuda:0')\n",
      "\n",
      "4 22723 tensor(16.9757, device='cuda:0')\n",
      "20\n",
      "236\n",
      "4 22723 tensor(16.7727, device='cuda:0')\n",
      "4 22723 tensor(16.9578, device='cuda:0')\n",
      "\n",
      "4 23239 tensor(16.9286, device='cuda:0')\n",
      "20\n",
      "190\n",
      "4 23239 tensor(17.0682, device='cuda:0')\n",
      "4 23239 tensor(16.7592, device='cuda:0')\n",
      "\n",
      "4 14538 tensor(16.7423, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 14538 tensor(16.9853, device='cuda:0')\n",
      "4 14538 tensor(17.2636, device='cuda:0')\n",
      "\n",
      "4 17100 tensor(16.7674, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 17100 tensor(16.5386, device='cuda:0')\n",
      "4 17100 tensor(16.9668, device='cuda:0')\n",
      "\n",
      "4 37073 tensor(16.7228, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 37073 tensor(16.5621, device='cuda:0')\n",
      "4 37073 tensor(18.0508, device='cuda:0')\n",
      "\n",
      "4 22739 tensor(17.1007, device='cuda:0')\n",
      "20\n",
      "206\n",
      "4 22739 tensor(17.1715, device='cuda:0')\n",
      "4 22739 tensor(16.9896, device='cuda:0')\n",
      "\n",
      "4 49365 tensor(16.6298, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 49365 tensor(17.0356, device='cuda:0')\n",
      "4 49365 tensor(16.8073, device='cuda:0')\n",
      "\n",
      "4 16598 tensor(16.6810, device='cuda:0')\n",
      "20\n",
      "156\n",
      "4 16598 tensor(16.9248, device='cuda:0')\n",
      "4 16598 tensor(17.0191, device='cuda:0')\n",
      "\n",
      "4 47831 tensor(16.6788, device='cuda:0')\n",
      "20\n",
      "234\n",
      "4 47831 tensor(17.0673, device='cuda:0')\n",
      "4 47831 tensor(16.6749, device='cuda:0')\n",
      "\n",
      "4 31959 tensor(16.8944, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 31959 tensor(18.0440, device='cuda:0')\n",
      "4 31959 tensor(18.0440, device='cuda:0')\n",
      "\n",
      "4 22234 tensor(16.5578, device='cuda:0')\n",
      "20\n",
      "212\n",
      "4 22234 tensor(16.4496, device='cuda:0')\n",
      "4 22234 tensor(17.5851, device='cuda:0')\n",
      "\n",
      "4 23259 tensor(16.8629, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 23259 tensor(17.6560, device='cuda:0')\n",
      "4 23259 tensor(17.5082, device='cuda:0')\n",
      "\n",
      "4 20189 tensor(17.0976, device='cuda:0')\n",
      "20\n",
      "248\n",
      "4 20189 tensor(17.2669, device='cuda:0')\n",
      "4 20189 tensor(17.2669, device='cuda:0')\n",
      "\n",
      "4 45790 tensor(16.7226, device='cuda:0')\n",
      "20\n",
      "210\n",
      "4 45790 tensor(17.2217, device='cuda:0')\n",
      "4 45790 tensor(16.8258, device='cuda:0')\n",
      "\n",
      "4 29927 tensor(16.8394, device='cuda:0')\n",
      "20\n",
      "248\n",
      "4 29927 tensor(17.5100, device='cuda:0')\n",
      "4 29927 tensor(17.1672, device='cuda:0')\n",
      "\n",
      "4 46312 tensor(16.5277, device='cuda:0')\n",
      "20\n",
      "202\n",
      "4 46312 tensor(16.0791, device='cuda:0')\n",
      "4 46312 tensor(16.9057, device='cuda:0')\n",
      "\n",
      "4 31465 tensor(17.5052, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 31465 tensor(18.6442, device='cuda:0')\n",
      "4 31465 tensor(17.4212, device='cuda:0')\n",
      "\n",
      "4 46831 tensor(16.8408, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 46831 tensor(17.1201, device='cuda:0')\n",
      "4 46831 tensor(18.2358, device='cuda:0')\n",
      "\n",
      "4 31472 tensor(16.7210, device='cuda:0')\n",
      "20\n",
      "232\n",
      "4 31472 tensor(16.6785, device='cuda:0')\n",
      "4 31472 tensor(16.9140, device='cuda:0')\n",
      "\n",
      "4 29936 tensor(16.5526, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 29936 tensor(16.8253, device='cuda:0')\n",
      "4 29936 tensor(17.2434, device='cuda:0')\n",
      "\n",
      "4 26355 tensor(16.7987, device='cuda:0')\n",
      "20\n",
      "262\n",
      "4 26355 tensor(17.1011, device='cuda:0')\n",
      "4 26355 tensor(17.5923, device='cuda:0')\n",
      "\n",
      "4 6393 tensor(16.5037, device='cuda:0')\n",
      "20\n",
      "204\n",
      "4 6393 tensor(16.2560, device='cuda:0')\n",
      "4 6393 tensor(16.9500, device='cuda:0')\n",
      "\n",
      "4 26876 tensor(16.4632, device='cuda:0')\n",
      "20\n",
      "214\n",
      "4 26876 tensor(16.9069, device='cuda:0')\n",
      "4 26876 tensor(17.5328, device='cuda:0')\n",
      "\n",
      "4 8444 tensor(16.3011, device='cuda:0')\n",
      "20\n",
      "182\n",
      "4 8444 tensor(17.0838, device='cuda:0')\n",
      "4 8444 tensor(17.0838, device='cuda:0')\n",
      "\n",
      "4 26878 tensor(17.3063, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 26878 tensor(18.1398, device='cuda:0')\n",
      "4 26878 tensor(18.4423, device='cuda:0')\n",
      "\n",
      "4 6911 tensor(16.5453, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 6911 tensor(17.0750, device='cuda:0')\n",
      "4 6911 tensor(17.0184, device='cuda:0')\n",
      "\n",
      "4 25856 tensor(16.6474, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 25856 tensor(17.9348, device='cuda:0')\n",
      "4 25856 tensor(17.2182, device='cuda:0')\n",
      "\n",
      "4 21249 tensor(17.1046, device='cuda:0')\n",
      "20\n",
      "202\n",
      "4 21249 tensor(17.8486, device='cuda:0')\n",
      "4 21249 tensor(16.9214, device='cuda:0')\n",
      "\n",
      "4 19717 tensor(16.4756, device='cuda:0')\n",
      "20\n",
      "148\n",
      "4 19717 tensor(16.6793, device='cuda:0')\n",
      "4 19717 tensor(16.6992, device='cuda:0')\n",
      "\n",
      "4 8966 tensor(16.7430, device='cuda:0')\n",
      "20\n",
      "160\n",
      "4 8966 tensor(17.3722, device='cuda:0')\n",
      "4 8966 tensor(17.4279, device='cuda:0')\n",
      "\n",
      "4 38150 tensor(17.0897, device='cuda:0')\n",
      "20\n",
      "196\n",
      "4 38150 tensor(16.6687, device='cuda:0')\n",
      "4 38150 tensor(16.6687, device='cuda:0')\n",
      "\n",
      "4 26888 tensor(16.9404, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 26888 tensor(17.6389, device='cuda:0')\n",
      "4 26888 tensor(17.2525, device='cuda:0')\n",
      "\n",
      "4 27917 tensor(17.1142, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 27917 tensor(17.8806, device='cuda:0')\n",
      "4 27917 tensor(17.8806, device='cuda:0')\n",
      "\n",
      "4 39184 tensor(17.0829, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 39184 tensor(17.5626, device='cuda:0')\n",
      "4 39184 tensor(16.9554, device='cuda:0')\n",
      "\n",
      "4 48401 tensor(16.3287, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 48401 tensor(17.9291, device='cuda:0')\n",
      "4 48401 tensor(16.3723, device='cuda:0')\n",
      "\n",
      "4 24336 tensor(16.7824, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 24336 tensor(17.0381, device='cuda:0')\n",
      "4 24336 tensor(17.3670, device='cuda:0')\n",
      "\n",
      "4 6416 tensor(16.7885, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 6416 tensor(16.5114, device='cuda:0')\n",
      "4 6416 tensor(17.0241, device='cuda:0')\n",
      "\n",
      "4 23316 tensor(16.7547, device='cuda:0')\n",
      "20\n",
      "156\n",
      "4 23316 tensor(16.8225, device='cuda:0')\n",
      "4 23316 tensor(17.1217, device='cuda:0')\n",
      "\n",
      "4 37144 tensor(16.7538, device='cuda:0')\n",
      "20\n",
      "176\n",
      "4 37144 tensor(17.2288, device='cuda:0')\n",
      "4 37144 tensor(16.5769, device='cuda:0')\n",
      "\n",
      "4 31513 tensor(16.5106, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 31513 tensor(17.5989, device='cuda:0')\n",
      "4 31513 tensor(16.1859, device='cuda:0')\n",
      "\n",
      "4 42266 tensor(16.3584, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 42266 tensor(17.5415, device='cuda:0')\n",
      "4 42266 tensor(16.4459, device='cuda:0')\n",
      "\n",
      "4 29989 tensor(16.5234, device='cuda:0')\n",
      "20\n",
      "136\n",
      "4 29989 tensor(16.7325, device='cuda:0')\n",
      "4 29989 tensor(16.2242, device='cuda:0')\n",
      "\n",
      "4 27434 tensor(17.5034, device='cuda:0')\n",
      "20\n",
      "160\n",
      "4 27434 tensor(17.6725, device='cuda:0')\n",
      "4 27434 tensor(17.9584, device='cuda:0')\n",
      "\n",
      "4 45867 tensor(17.0943, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 45867 tensor(17.2206, device='cuda:0')\n",
      "4 45867 tensor(17.2206, device='cuda:0')\n",
      "\n",
      "4 36139 tensor(16.9474, device='cuda:0')\n",
      "20\n",
      "234\n",
      "4 36139 tensor(17.7759, device='cuda:0')\n",
      "4 36139 tensor(17.1153, device='cuda:0')\n",
      "\n",
      "4 29489 tensor(17.1553, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 29489 tensor(17.2103, device='cuda:0')\n",
      "4 29489 tensor(16.6350, device='cuda:0')\n",
      "\n",
      "4 27443 tensor(16.6497, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 27443 tensor(17.4646, device='cuda:0')\n",
      "4 27443 tensor(17.4454, device='cuda:0')\n",
      "\n",
      "4 27955 tensor(16.9808, device='cuda:0')\n",
      "20\n",
      "176\n",
      "4 27955 tensor(16.9727, device='cuda:0')\n",
      "4 27955 tensor(17.4772, device='cuda:0')\n",
      "\n",
      "4 22838 tensor(16.8490, device='cuda:0')\n",
      "20\n",
      "202\n",
      "4 22838 tensor(16.8979, device='cuda:0')\n",
      "4 22838 tensor(17.2859, device='cuda:0')\n",
      "\n",
      "4 7993 tensor(16.8200, device='cuda:0')\n",
      "20\n",
      "220\n",
      "4 7993 tensor(17.5102, device='cuda:0')\n",
      "4 7993 tensor(17.4782, device='cuda:0')\n",
      "\n",
      "4 13114 tensor(16.8477, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 13114 tensor(18.1160, device='cuda:0')\n",
      "4 13114 tensor(18.4109, device='cuda:0')\n",
      "\n",
      "4 13629 tensor(16.6012, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 13629 tensor(17.2001, device='cuda:0')\n",
      "4 13629 tensor(17.2001, device='cuda:0')\n",
      "\n",
      "4 28991 tensor(16.3053, device='cuda:0')\n",
      "20\n",
      "182\n",
      "4 28991 tensor(16.5552, device='cuda:0')\n",
      "4 28991 tensor(17.3727, device='cuda:0')\n",
      "\n",
      "4 40771 tensor(17.1108, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 40771 tensor(17.0577, device='cuda:0')\n",
      "4 40771 tensor(17.7302, device='cuda:0')\n",
      "\n",
      "4 25413 tensor(16.7292, device='cuda:0')\n",
      "20\n",
      "214\n",
      "4 25413 tensor(17.8747, device='cuda:0')\n",
      "4 25413 tensor(17.0002, device='cuda:0')\n",
      "\n",
      "4 44870 tensor(16.9762, device='cuda:0')\n",
      "20\n",
      "208\n",
      "4 44870 tensor(16.6782, device='cuda:0')\n",
      "4 44870 tensor(17.8953, device='cuda:0')\n",
      "\n",
      "4 18247 tensor(16.7647, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 18247 tensor(17.3860, device='cuda:0')\n",
      "4 18247 tensor(17.3956, device='cuda:0')\n",
      "\n",
      "4 47944 tensor(16.7887, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 47944 tensor(17.3776, device='cuda:0')\n",
      "4 47944 tensor(18.0996, device='cuda:0')\n",
      "\n",
      "4 35657 tensor(16.8920, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 35657 tensor(17.1842, device='cuda:0')\n",
      "4 35657 tensor(17.9381, device='cuda:0')\n",
      "\n",
      "4 26953 tensor(17.0774, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 26953 tensor(17.6554, device='cuda:0')\n",
      "4 26953 tensor(18.1275, device='cuda:0')\n",
      "\n",
      "4 13651 tensor(16.5051, device='cuda:0')\n",
      "20\n",
      "158\n",
      "4 13651 tensor(16.6627, device='cuda:0')\n",
      "4 13651 tensor(17.6104, device='cuda:0')\n",
      "\n",
      "4 27991 tensor(16.7709, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 27991 tensor(17.5004, device='cuda:0')\n",
      "4 27991 tensor(17.0828, device='cuda:0')\n",
      "\n",
      "4 26456 tensor(16.6740, device='cuda:0')\n",
      "20\n",
      "166\n",
      "4 26456 tensor(17.4102, device='cuda:0')\n",
      "4 26456 tensor(16.9773, device='cuda:0')\n",
      "\n",
      "4 48990 tensor(16.9026, device='cuda:0')\n",
      "20\n",
      "144\n",
      "4 48990 tensor(17.6449, device='cuda:0')\n",
      "4 48990 tensor(17.6449, device='cuda:0')\n",
      "\n",
      "4 34655 tensor(16.8402, device='cuda:0')\n",
      "20\n",
      "214\n",
      "4 34655 tensor(17.4355, device='cuda:0')\n",
      "4 34655 tensor(16.7894, device='cuda:0')\n",
      "\n",
      "4 16225 tensor(16.7891, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 16225 tensor(18.2994, device='cuda:0')\n",
      "4 16225 tensor(18.2994, device='cuda:0')\n",
      "\n",
      "4 28518 tensor(17.3829, device='cuda:0')\n",
      "20\n",
      "144\n",
      "4 28518 tensor(17.9985, device='cuda:0')\n",
      "4 28518 tensor(17.8168, device='cuda:0')\n",
      "\n",
      "4 20839 tensor(16.4552, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 20839 tensor(17.5653, device='cuda:0')\n",
      "4 20839 tensor(15.9654, device='cuda:0')\n",
      "\n",
      "4 43367 tensor(17.0008, device='cuda:0')\n",
      "20\n",
      "206\n",
      "4 43367 tensor(17.4583, device='cuda:0')\n",
      "4 43367 tensor(17.6423, device='cuda:0')\n",
      "\n",
      "4 10092 tensor(16.4748, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 10092 tensor(15.6300, device='cuda:0')\n",
      "4 10092 tensor(17.6000, device='cuda:0')\n",
      "\n",
      "4 11116 tensor(16.4616, device='cuda:0')\n",
      "20\n",
      "216\n",
      "4 11116 tensor(17.3191, device='cuda:0')\n",
      "4 11116 tensor(16.5850, device='cuda:0')\n",
      "\n",
      "4 31086 tensor(16.6277, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 31086 tensor(17.2138, device='cuda:0')\n",
      "4 31086 tensor(16.0267, device='cuda:0')\n",
      "\n",
      "4 29040 tensor(17.3219, device='cuda:0')\n",
      "20\n",
      "252\n",
      "4 29040 tensor(17.2739, device='cuda:0')\n",
      "4 29040 tensor(17.5354, device='cuda:0')\n",
      "\n",
      "4 50033 tensor(16.7806, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 50033 tensor(17.9938, device='cuda:0')\n",
      "4 50033 tensor(16.5770, device='cuda:0')\n",
      "\n",
      "4 5490 tensor(16.5037, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 5490 tensor(16.8125, device='cuda:0')\n",
      "4 5490 tensor(16.0336, device='cuda:0')\n",
      "\n",
      "4 39795 tensor(16.7212, device='cuda:0')\n",
      "20\n",
      "204\n",
      "4 39795 tensor(16.7677, device='cuda:0')\n",
      "4 39795 tensor(16.7677, device='cuda:0')\n",
      "\n",
      "4 48505 tensor(16.5148, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 48505 tensor(17.2317, device='cuda:0')\n",
      "4 48505 tensor(17.0327, device='cuda:0')\n",
      "\n",
      "4 40316 tensor(16.4917, device='cuda:0')\n",
      "20\n",
      "208\n",
      "4 40316 tensor(16.7275, device='cuda:0')\n",
      "4 40316 tensor(17.5440, device='cuda:0')\n",
      "\n",
      "4 24958 tensor(16.6529, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 24958 tensor(17.4585, device='cuda:0')\n",
      "4 24958 tensor(16.6717, device='cuda:0')\n",
      "\n",
      "4 38783 tensor(16.6326, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 38783 tensor(17.2940, device='cuda:0')\n",
      "4 38783 tensor(16.9925, device='cuda:0')\n",
      "\n",
      "4 19838 tensor(17.0370, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 19838 tensor(17.1654, device='cuda:0')\n",
      "4 19838 tensor(16.9161, device='cuda:0')\n",
      "\n",
      "4 23425 tensor(16.7710, device='cuda:0')\n",
      "20\n",
      "198\n",
      "4 23425 tensor(17.3764, device='cuda:0')\n",
      "4 23425 tensor(17.3764, device='cuda:0')\n",
      "\n",
      "4 24962 tensor(16.7497, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 24962 tensor(17.2860, device='cuda:0')\n",
      "4 24962 tensor(17.2586, device='cuda:0')\n",
      "\n",
      "4 13187 tensor(16.7572, device='cuda:0')\n",
      "20\n",
      "228\n",
      "4 13187 tensor(18.1718, device='cuda:0')\n",
      "4 13187 tensor(18.1718, device='cuda:0')\n",
      "\n",
      "4 49028 tensor(16.7291, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 49028 tensor(17.2628, device='cuda:0')\n",
      "4 49028 tensor(16.9093, device='cuda:0')\n",
      "\n",
      "4 12167 tensor(16.3885, device='cuda:0')\n",
      "20\n",
      "174\n",
      "4 12167 tensor(17.5848, device='cuda:0')\n",
      "4 12167 tensor(16.5890, device='cuda:0')\n",
      "\n",
      "4 43406 tensor(16.6856, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 43406 tensor(17.2956, device='cuda:0')\n",
      "4 43406 tensor(17.2799, device='cuda:0')\n",
      "\n",
      "4 14737 tensor(16.7687, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 14737 tensor(17.6683, device='cuda:0')\n",
      "4 14737 tensor(17.4956, device='cuda:0')\n",
      "\n",
      "4 18322 tensor(16.3427, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 18322 tensor(16.8686, device='cuda:0')\n",
      "4 18322 tensor(16.7214, device='cuda:0')\n",
      "\n",
      "4 43921 tensor(16.5194, device='cuda:0')\n",
      "20\n",
      "130\n",
      "4 43921 tensor(17.9190, device='cuda:0')\n",
      "4 43921 tensor(16.3714, device='cuda:0')\n",
      "\n",
      "4 12694 tensor(16.4316, device='cuda:0')\n",
      "20\n",
      "162\n",
      "4 12694 tensor(16.7399, device='cuda:0')\n",
      "4 12694 tensor(17.2297, device='cuda:0')\n",
      "\n",
      "4 16286 tensor(16.7514, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 16286 tensor(17.7025, device='cuda:0')\n",
      "4 16286 tensor(17.3236, device='cuda:0')\n",
      "\n",
      "4 48545 tensor(17.2775, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 48545 tensor(17.5000, device='cuda:0')\n",
      "4 48545 tensor(17.7628, device='cuda:0')\n",
      "\n",
      "4 29092 tensor(16.5354, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 29092 tensor(16.4750, device='cuda:0')\n",
      "4 29092 tensor(16.9248, device='cuda:0')\n",
      "\n",
      "4 15273 tensor(16.5296, device='cuda:0')\n",
      "20\n",
      "152\n",
      "4 15273 tensor(16.6474, device='cuda:0')\n",
      "4 15273 tensor(17.1445, device='cuda:0')\n",
      "\n",
      "4 16809 tensor(17.1826, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 16809 tensor(16.6544, device='cuda:0')\n",
      "4 16809 tensor(17.5593, device='cuda:0')\n",
      "\n",
      "4 22455 tensor(17.0528, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 22455 tensor(18.5422, device='cuda:0')\n",
      "4 22455 tensor(17.4651, device='cuda:0')\n",
      "\n",
      "4 24504 tensor(16.8639, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 24504 tensor(17.6208, device='cuda:0')\n",
      "4 24504 tensor(16.9752, device='cuda:0')\n",
      "\n",
      "4 30140 tensor(16.8900, device='cuda:0')\n",
      "20\n",
      "236\n",
      "4 30140 tensor(18.2565, device='cuda:0')\n",
      "4 30140 tensor(16.7198, device='cuda:0')\n",
      "\n",
      "4 27581 tensor(16.8714, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 27581 tensor(17.7435, device='cuda:0')\n",
      "4 27581 tensor(16.6930, device='cuda:0')\n",
      "\n",
      "4 21438 tensor(16.6599, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 21438 tensor(17.0848, device='cuda:0')\n",
      "4 21438 tensor(17.0372, device='cuda:0')\n",
      "\n",
      "4 35262 tensor(17.3906, device='cuda:0')\n",
      "20\n",
      "184\n",
      "4 35262 tensor(17.4645, device='cuda:0')\n",
      "4 35262 tensor(17.9176, device='cuda:0')\n",
      "\n",
      "4 36292 tensor(16.5194, device='cuda:0')\n",
      "20\n",
      "190\n",
      "4 36292 tensor(17.0897, device='cuda:0')\n",
      "4 36292 tensor(17.0326, device='cuda:0')\n",
      "\n",
      "4 6086 tensor(16.4280, device='cuda:0')\n",
      "20\n",
      "216\n",
      "4 6086 tensor(17.8904, device='cuda:0')\n",
      "4 6086 tensor(16.5046, device='cuda:0')\n",
      "\n",
      "4 21960 tensor(17.2356, device='cuda:0')\n",
      "20\n",
      "130\n",
      "4 21960 tensor(16.8711, device='cuda:0')\n",
      "4 21960 tensor(17.2914, device='cuda:0')\n",
      "\n",
      "4 20428 tensor(16.5865, device='cuda:0')\n",
      "20\n",
      "200\n",
      "4 20428 tensor(17.1577, device='cuda:0')\n",
      "4 20428 tensor(17.3543, device='cuda:0')\n",
      "\n",
      "4 17361 tensor(17.1807, device='cuda:0')\n",
      "20\n",
      "178\n",
      "4 17361 tensor(17.5043, device='cuda:0')\n",
      "4 17361 tensor(18.4304, device='cuda:0')\n",
      "\n",
      "4 33747 tensor(17.4348, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 33747 tensor(18.0056, device='cuda:0')\n",
      "4 33747 tensor(17.4511, device='cuda:0')\n",
      "\n",
      "4 2516 tensor(16.3310, device='cuda:0')\n",
      "20\n",
      "166\n",
      "4 2516 tensor(17.5132, device='cuda:0')\n",
      "4 2516 tensor(17.1361, device='cuda:0')\n",
      "\n",
      "4 13268 tensor(16.9463, device='cuda:0')\n",
      "20\n",
      "342\n",
      "4 13268 tensor(17.5145, device='cuda:0')\n",
      "4 13268 tensor(16.3564, device='cuda:0')\n",
      "\n",
      "4 45014 tensor(17.0467, device='cuda:0')\n",
      "20\n",
      "204\n",
      "4 45014 tensor(17.6844, device='cuda:0')\n",
      "4 45014 tensor(17.8717, device='cuda:0')\n",
      "\n",
      "4 25556 tensor(17.3067, device='cuda:0')\n",
      "20\n",
      "164\n",
      "4 25556 tensor(17.9846, device='cuda:0')\n",
      "4 25556 tensor(16.2968, device='cuda:0')\n",
      "\n",
      "4 33240 tensor(16.9463, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 33240 tensor(17.2419, device='cuda:0')\n",
      "4 33240 tensor(16.7694, device='cuda:0')\n",
      "\n",
      "4 36312 tensor(16.8825, device='cuda:0')\n",
      "20\n",
      "168\n",
      "4 36312 tensor(17.2395, device='cuda:0')\n",
      "4 36312 tensor(17.2395, device='cuda:0')\n",
      "\n",
      "4 16863 tensor(16.8465, device='cuda:0')\n",
      "20\n",
      "196\n",
      "4 16863 tensor(16.9617, device='cuda:0')\n",
      "4 16863 tensor(16.9724, device='cuda:0')\n",
      "\n",
      "4 28642 tensor(16.8109, device='cuda:0')\n",
      "20\n",
      "188\n",
      "4 28642 tensor(16.5918, device='cuda:0')\n",
      "4 28642 tensor(16.4916, device='cuda:0')\n",
      "\n",
      "4 10213 tensor(16.9994, device='cuda:0')\n",
      "20\n",
      "196\n",
      "4 10213 tensor(17.3928, device='cuda:0')\n",
      "4 10213 tensor(17.2169, device='cuda:0')\n",
      "\n",
      "4 16358 tensor(16.4285, device='cuda:0')\n",
      "20\n",
      "194\n",
      "4 16358 tensor(16.1710, device='cuda:0')\n",
      "4 16358 tensor(16.7045, device='cuda:0')\n",
      "\n",
      "4 25062 tensor(16.8426, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 25062 tensor(17.4301, device='cuda:0')\n",
      "4 25062 tensor(17.2572, device='cuda:0')\n",
      "\n",
      "4 23528 tensor(17.3810, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 23528 tensor(17.8498, device='cuda:0')\n",
      "4 23528 tensor(18.0543, device='cuda:0')\n",
      "\n",
      "4 35307 tensor(16.7369, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 35307 tensor(17.3492, device='cuda:0')\n",
      "4 35307 tensor(16.9511, device='cuda:0')\n",
      "\n",
      "4 19436 tensor(16.5964, device='cuda:0')\n",
      "20\n",
      "180\n",
      "4 19436 tensor(17.7034, device='cuda:0')\n",
      "4 19436 tensor(16.9775, device='cuda:0')\n",
      "\n",
      "4 25579 tensor(17.1939, device='cuda:0')\n",
      "20\n",
      "228\n",
      "4 25579 tensor(17.9771, device='cuda:0')\n",
      "4 25579 tensor(18.0562, device='cuda:0')\n",
      "\n",
      "4 15859 tensor(17.0210, device='cuda:0')\n",
      "20\n",
      "186\n",
      "4 15859 tensor(17.4674, device='cuda:0')\n",
      "4 15859 tensor(17.4217, device='cuda:0')\n",
      "\n",
      "4 38900 tensor(16.8629, device='cuda:0')\n",
      "20\n",
      "242\n",
      "4 38900 tensor(17.2877, device='cuda:0')\n",
      "4 38900 tensor(17.3116, device='cuda:0')\n",
      "\n",
      "4 7670 tensor(16.2687, device='cuda:0')\n",
      "20\n",
      "170\n",
      "4 7670 tensor(16.8835, device='cuda:0')\n",
      "4 7670 tensor(16.4513, device='cuda:0')\n",
      "\n",
      "4 8698 tensor(16.6881, device='cuda:0')\n",
      "20\n",
      "172\n",
      "4 8698 tensor(17.1818, device='cuda:0')\n",
      "4 8698 tensor(17.8189, device='cuda:0')\n",
      "\n",
      "4 12284 tensor(16.8805, device='cuda:0')\n",
      "20\n",
      "212\n",
      "4 12284 tensor(16.8258, device='cuda:0')\n",
      "4 12284 tensor(17.5692, device='cuda:0')\n",
      "\n",
      "4 44542 tensor(16.4063, device='cuda:0')\n",
      "20\n",
      "192\n",
      "4 44542 tensor(17.2938, device='cuda:0')\n",
      "4 44542 tensor(17.0585, device='cuda:0')\n",
      "\n",
      "4 31231 tensor(16.7062, device='cuda:0')\n",
      "20\n",
      "218\n",
      "4 31231 tensor(16.8727, device='cuda:0')\n",
      "4 31231 tensor(16.9133, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "random.seed(27)\n",
    "for name_i in range(len(name_positions)):\n",
    "    for name_tok in list(name_averages[name_i].keys()):\n",
    "        print()\n",
    "        print(name_i, name_tok, torch.linalg.norm(name_averages[name_i][name_tok], ord=2))\n",
    "        print(len(name_choices[name_i][name_tok]))\n",
    "        print(counts[name_i][name_tok])\n",
    "        print(name_i, name_tok, torch.linalg.norm(random.choice(name_choices[name_i][name_tok]), ord=2))\n",
    "        print(name_i, name_tok, torch.linalg.norm(random.choice(name_choices[name_i][name_tok]), ord=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8cba178a-3688-4632-be14-0445f634da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "\n",
    "DO_DIFF = True\n",
    "\n",
    "model_kwargs = {\"fast_ssm\": True, \"fast_conv\": True}\n",
    "\n",
    "original_corrects = {}\n",
    "original_replaces = {}\n",
    "replace_corrects = {}\n",
    "replace_replaces = {}\n",
    "patched_corrects = {}\n",
    "patched_replaces = {}\n",
    "\n",
    "for position_1 in range(3):\n",
    "    for position_2 in range(5):\n",
    "        print(position_1, position_2)\n",
    "        original_correct = []\n",
    "        original_replace = []\n",
    "        replace_correct = []\n",
    "        replace_replace = []\n",
    "        patched_correct = []\n",
    "        patched_replace = []\n",
    "\n",
    "        original_corrects[(position_1, position_2)] = original_correct\n",
    "        original_replaces[(position_1, position_2)] = original_replace\n",
    "        replace_corrects[(position_1, position_2)] = replace_correct\n",
    "        replace_replaces[(position_1, position_2)] = replace_replace\n",
    "        patched_corrects[(position_1, position_2)] = patched_correct\n",
    "        patched_replaces[(position_1, position_2)] = patched_replace\n",
    "\n",
    "        batched_inputs = []\n",
    "        batched_corrupted_inputs = []\n",
    "        num_found = 0\n",
    "        hooks = []\n",
    "        corrupted_hooks = []\n",
    "        last_token_positions = []\n",
    "        replace_toks = []\n",
    "        answer_toks = []\n",
    "        batch_i = 0\n",
    "        while True:\n",
    "            data_i = random.choice(list(range(data.data.size()[0])))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i]\n",
    "            corrupted_tokens = data.data[patched_i]\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            \n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                replace_vec,\n",
    "                replace_add_vec,\n",
    "                batch_i,\n",
    "            ):\n",
    "                if not replace_vec is None:\n",
    "                    x[batch_i, position] = replace_vec\n",
    "                if not replace_add_vec is None:\n",
    "                    x[batch_i, position] += replace_add_vec\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(name_positions)):\n",
    "                position = name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                    break\n",
    "                \n",
    "                name_i = position_2\n",
    "                replace_vec = random.choice(name_choices[name_i][replace_tok])\n",
    "                # two ways to do it\n",
    "                # diff(name) = avg - name\n",
    "                # if we add this it should \"erase\" name\n",
    "                # if we subtract this it should \"add\" name\n",
    "                # so we can do\n",
    "                # replace_add_vec = diff(answer) - diff(replace)\n",
    "                #diff_answer = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][answer_tok]\n",
    "                #diff_replace = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][replace_tok]\n",
    "                #replace_add_vec = diff_answer - diff_replace\n",
    "                # this is (avg-a) - (avg-r) = r-a\n",
    "                # in other words the average doesn't matter for this\n",
    "                # and it's just subtract avg for a and add average for b\n",
    "                replace_add_vec = name_averages[name_i][replace_tok] - name_averages[name_i][answer_tok]\n",
    "                # then we do\n",
    "                # replace_vec\n",
    "                # we have x\n",
    "                # we want y\n",
    "                # we can do\n",
    "                # x-y\n",
    "                # and apply it to y\n",
    "                #replace_diff = name_averages[name_i][TOTAL_AVG_NAME]\n",
    "        \n",
    "                if DO_DIFF:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            batched_inputs.append(data_tokens.view(1, -1))\n",
    "            #logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            batched_corrupted_inputs.append(corrupted_tokens.view(1, -1))\n",
    "            for name_i, position in answer_positions:\n",
    "                name_i = position_2\n",
    "                replace_vec = name_averages[name_i][answer_tok]\n",
    "                replace_add_vec = name_averages[name_i][answer_tok] - name_averages[name_i][replace_tok]            \n",
    "                if DO_DIFF:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "            last_token_positions.append(last_token_pos)\n",
    "            replace_toks.append(replace_tok)\n",
    "            answer_toks.append(answer_tok)\n",
    "\n",
    "            \n",
    "            batch_i += 1\n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 100:\n",
    "                break\n",
    "\n",
    "        batched_inputs = torch.cat(batched_inputs, dim=0)\n",
    "        batched_corrupted_inputs = torch.cat(batched_corrupted_inputs, dim=0)\n",
    "        \n",
    "        logits_modified = model.run_with_hooks(batched_inputs, fwd_hooks=hooks, **model_kwargs)\n",
    "        #print(logits_modified.size())\n",
    "        #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "        #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "        for i in range(batched_inputs.size()[0]):\n",
    "            replace_correct.append(logits_modified[i,last_token_positions[i],answer_toks[i]].item())\n",
    "            replace_replace.append(logits_modified[i,last_token_positions[i],replace_toks[i]].item())        \n",
    "        del logits_modified\n",
    "        logits_modified_corrupted = model.run_with_hooks(batched_corrupted_inputs, fwd_hooks=corrupted_hooks, **model_kwargs)\n",
    "        for i in range(batched_inputs.size()[0]):\n",
    "            replace_correct.append(logits_modified_corrupted[i,last_token_positions[i],replace_toks[i]].item())\n",
    "            replace_replace.append(logits_modified_corrupted[i,last_token_positions[i],answer_toks[i]].item())\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de9db7-907d-41d4-a4c3-1814720177d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a963471-2615-44aa-8be8-64f3e274530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_correct_matrix = torch.zeros([3,5])\n",
    "\n",
    "for pos1 in range(3):\n",
    "    for pos2 in range(5):\n",
    "        #original_diff = -torch.tensor(original_correct) + torch.tensor(original_replace)\n",
    "        replace_diff = -torch.tensor(replace_corrects[(pos1,pos2)]) + torch.tensor(replace_replaces[(pos1,pos2)])\n",
    "        #patched_diff = -torch.tensor(patched_correct) + torch.tensor(patched_replace)\n",
    "        \n",
    "        #print(f'original min diff {torch.min(original_diff)} max diff {torch.max(original_diff)} avg diff {torch.mean(original_diff)}')\n",
    "        #print(f'replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "        #print(f'patch min diff {torch.min(patched_diff)} max diff {torch.max(patched_diff)} avg diff {torch.mean(patched_diff)}')\n",
    "\n",
    "        n_correct_matrix[pos1, pos2] = torch.sum(replace_diff > 0)/replace_diff.size()[0]\n",
    "        #print(f'original n correct {torch.sum(original_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'replace n correct {torch.sum(replace_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'patch n correct {torch.sum(patched_diff < 0)} / {original_diff.size()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8637d98c-498d-4ad2-bd9f-1f23265ab475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "y": [
          0,
          1,
          2
         ],
         "yaxis": "y",
         "z": [
          [
           0.9851484894752502,
           0.9851484894752502,
           0.9851484894752502,
           0.6485148668289185,
           0.5544554591178894
          ],
          [
           0.9801980257034302,
           0.9950494766235352,
           0.9653465151786804,
           0.7079207897186279,
           0.6089109182357788
          ],
          [
           1,
           1,
           0.9900990128517151,
           0.9108911156654358,
           0.7722772359848022
          ]
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "replacing with subtract and add average"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.21209213051823417,
          0.7879078694817658
         ],
         "range": [
          -0.5,
          4.5
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          2.5,
          -0.5
         ],
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"e55473c8-4e4c-42a8-81c7-7ac8ab8b37f5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e55473c8-4e4c-42a8-81c7-7ac8ab8b37f5\")) {                    Plotly.newPlot(                        \"e55473c8-4e4c-42a8-81c7-7ac8ab8b37f5\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"y\":[0,1,2],\"z\":[[0.9851484894752502,0.9851484894752502,0.9851484894752502,0.6485148668289185,0.5544554591178894],[0.9801980257034302,0.9950494766235352,0.9653465151786804,0.7079207897186279,0.6089109182357788],[1.0,1.0,0.9900990128517151,0.9108911156654358,0.7722772359848022]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"title\":{\"text\":\"replacing with subtract and add average\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e55473c8-4e4c-42a8-81c7-7ac8ab8b37f5');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# modified from neel nanda's examples\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", font_size=None, show=True, color_continuous_midpoint=0.0, fix_size=False, **kwargs):\n",
    "    import plotly.express as px\n",
    "    import transformer_lens.utils as utils\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=color_continuous_midpoint, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show()\n",
    "\n",
    "imshow(n_correct_matrix, color_continuous_midpoint=None, y=[0,1,2], title='replacing with subtract and add average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c750123a-7369-4ef9-a872-2855db55a66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "69\n",
      "[' John', ' Mark', ' David', ' Paul', ' James', ' George', ' Michael', ' Mary', ' Christian', ' Robert', ' Thomas', ' William', ' Jesus', ' Richard', ' Peter', ' Charles', ' Martin', ' Henry', ' Jackson', ' Joseph', ' Daniel', ' Francisco', ' Andrew', ' Taylor', ' Stephen', ' Eric', ' Elizabeth', ' Edward', ' Ryan', ' Adam', ' Jordan', ' Grant', ' Alexander', ' Brian', ' Jacob', ' Diego', ' Kelly', ' Kevin', ' Patrick', ' Sarah', ' Cooper', ' Victoria', ' Morgan', ' Anthony', ' Anna', ' Jason', ' Kennedy', ' Cole', ' Carter', ' Austin', ' Maria', ' Sydney', ' Alan', ' Antonio', ' Luke', ' Matthew', ' Grace', ' Jonathan', ' Benjamin', ' Steven', ' Christopher', ' Parker', ' Margaret', ' Hunter', ' Kate', ' Oliver', ' Samuel', ' Justin', ' Brooklyn']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffc278fc1b04514a4497e5b4e2ccb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "\n",
    "DO_DIFF = True\n",
    "\n",
    "model_kwargs = {\"fast_ssm\": True, \"fast_conv\": True}\n",
    "\n",
    "original_corrects = {}\n",
    "original_replaces = {}\n",
    "replace_corrects = {}\n",
    "replace_replaces = {}\n",
    "patched_corrects = {}\n",
    "patched_replaces = {}\n",
    "import itertools\n",
    "name_toks = sorted(list(name_tokens))[:70]\n",
    "print(len(name_toks))\n",
    "for forbidden_name in ['Summer']:\n",
    "    name_tok = model.to_tokens(' ' + forbidden_name)[0][1].item()\n",
    "    name_toks = [t for t in name_toks if not t == name_tok]\n",
    "    print(len(name_toks))\n",
    "\n",
    "name_toks_strs = [model.to_str_tokens(torch.tensor([t]))[0] for t in name_toks]\n",
    "print(name_toks_strs)\n",
    "\n",
    "for position_1, name_tok_1, name_tok_2 in tqdm(list(itertools.product(*[range(1), name_toks, name_toks]))):\n",
    "        original_correct = []\n",
    "        original_replace = []\n",
    "        replace_correct = []\n",
    "        replace_replace = []\n",
    "        patched_correct = []\n",
    "        patched_replace = []\n",
    "         \n",
    "        key = (position_1, name_tok_1, name_tok_2)\n",
    "        original_corrects[key] = original_correct\n",
    "        original_replaces[key] = original_replace\n",
    "        replace_corrects[key] = replace_correct\n",
    "        replace_replaces[key] = replace_replace\n",
    "        patched_corrects[key] = patched_correct\n",
    "        patched_replaces[key] = patched_replace\n",
    "\n",
    "\n",
    "        batched_inputs = []\n",
    "        batched_corrupted_inputs = []\n",
    "        num_found = 0\n",
    "        hooks = []\n",
    "        corrupted_hooks = []\n",
    "        last_token_positions = []\n",
    "        replace_toks = []\n",
    "        answer_toks = []\n",
    "        batch_i = 0\n",
    "        while True:\n",
    "            data_i = random.choice(list(range(data.data.size()[0])))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i].clone()\n",
    "            corrupted_tokens = data.data[patched_i].clone()\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            \n",
    "            all_names = set([x.item() for x in data.incorrect[data_i]]) | set([answer_tok]) | set([replace_tok])\n",
    "            if name_tok_1 in all_names or name_tok_2 in all_names:\n",
    "                continue\n",
    "\n",
    "        \n",
    "            \n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                replace_vec,\n",
    "                replace_add_vec,\n",
    "                batch_i,\n",
    "            ):\n",
    "                if not replace_vec is None:\n",
    "                    x[batch_i, position] = replace_vec\n",
    "                if not replace_add_vec is None:\n",
    "                    x[batch_i, position] += replace_add_vec\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(name_positions)):\n",
    "                position = name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    data_tokens[position] = name_tok_1\n",
    "                    corrupted_tokens[position] = name_tok_2\n",
    "                    answer_positions.append((name_i, position))\n",
    "\n",
    "            answer_tok = name_tok_1\n",
    "            replace_tok = name_tok_2\n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                    break\n",
    "                \n",
    "                name_i = position_1\n",
    "                replace_vec = random.choice(name_choices[name_i][replace_tok])\n",
    "                # two ways to do it\n",
    "                # diff(name) = avg - name\n",
    "                # if we add this it should \"erase\" name\n",
    "                # if we subtract this it should \"add\" name\n",
    "                # so we can do\n",
    "                # replace_add_vec = diff(answer) - diff(replace)\n",
    "                #diff_answer = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][answer_tok]\n",
    "                #diff_replace = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][replace_tok]\n",
    "                #replace_add_vec = diff_answer - diff_replace\n",
    "                # this is (avg-a) - (avg-r) = r-a\n",
    "                # in other words the average doesn't matter for this\n",
    "                # and it's just subtract avg for a and add average for b\n",
    "                replace_add_vec = name_averages[name_i][replace_tok] - name_averages[name_i][answer_tok]\n",
    "                # then we do\n",
    "                # replace_vec\n",
    "                # we have x\n",
    "                # we want y\n",
    "                # we can do\n",
    "                # x-y\n",
    "                # and apply it to y\n",
    "                #replace_diff = name_averages[name_i][TOTAL_AVG_NAME]\n",
    "        \n",
    "                if DO_DIFF:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "\n",
    "            batched_inputs.append(data_tokens.view(1, -1))\n",
    "            #logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            '''\n",
    "            batched_corrupted_inputs.append(corrupted_tokens.view(1, -1))\n",
    "            for name_i, position in answer_positions:\n",
    "                name_i = position_2\n",
    "                replace_vec = name_averages[name_i][answer_tok]\n",
    "                replace_add_vec = name_averages[name_i][answer_tok] - name_averages[name_i][replace_tok]            \n",
    "                if DO_DIFF:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "            '''\n",
    "            last_token_positions.append(last_token_pos)\n",
    "            replace_toks.append(replace_tok)\n",
    "            answer_toks.append(answer_tok)\n",
    "\n",
    "            \n",
    "            batch_i += 1\n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 10:\n",
    "                break\n",
    "\n",
    "        batched_inputs = torch.cat(batched_inputs, dim=0)\n",
    "        #batched_corrupted_inputs = torch.cat(batched_corrupted_inputs, dim=0)\n",
    "        \n",
    "        logits_modified = model.run_with_hooks(batched_inputs, fwd_hooks=hooks, **model_kwargs)\n",
    "        #print(logits_modified.size())\n",
    "        #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "        #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "        for i in range(batched_inputs.size()[0]):\n",
    "            replace_correct.append(logits_modified[i,last_token_positions[i],answer_toks[i]].item())\n",
    "            replace_replace.append(logits_modified[i,last_token_positions[i],replace_toks[i]].item())        \n",
    "        del logits_modified\n",
    "        #logits_modified_corrupted = model.run_with_hooks(batched_corrupted_inputs, fwd_hooks=corrupted_hooks, **model_kwargs)\n",
    "        #for i in range(batched_inputs.size()[0]):\n",
    "        #    replace_correct.append(logits_modified_corrupted[i,last_token_positions[i],replace_toks[i]].item())\n",
    "        #    replace_replace.append(logits_modified_corrupted[i,last_token_positions[i],answer_toks[i]].item())\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "831bcefc-f11c-4a43-a7cb-257ef74cc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_correct_matrix = torch.zeros([len(name_toks),len(name_toks)])\n",
    "\n",
    "for position_1, name_tok_1, name_tok_2 in list(itertools.product(*[range(1), name_toks, name_toks])):\n",
    "        \n",
    "        key = (position_1, name_tok_1, name_tok_2)\n",
    "        pos1 = name_toks.index(name_tok_1)\n",
    "        pos2 = name_toks.index(name_tok_2)\n",
    "        #original_diff = -torch.tensor(original_correct) + torch.tensor(original_replace)\n",
    "        replace_diff = -torch.tensor(replace_corrects[key]) + torch.tensor(replace_replaces[key])\n",
    "        #patched_diff = -torch.tensor(patched_correct) + torch.tensor(patched_replace)\n",
    "        \n",
    "        #print(f'original min diff {torch.min(original_diff)} max diff {torch.max(original_diff)} avg diff {torch.mean(original_diff)}')\n",
    "        #print(f'replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "        #print(f'patch min diff {torch.min(patched_diff)} max diff {torch.max(patched_diff)} avg diff {torch.mean(patched_diff)}')\n",
    "\n",
    "        n_correct_matrix[pos1, pos2] = torch.sum(replace_diff > 0)/replace_diff.size()[0]\n",
    "        if pos1 == pos2:\n",
    "            n_correct_matrix[pos1, pos2] = 1.0 # ez\n",
    "        #print(f'original n correct {torch.sum(original_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'replace n correct {torch.sum(replace_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'patch n correct {torch.sum(patched_diff < 0)} / {original_diff.size()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2f6eca2c-0491-4557-b8fb-df3c099b1bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam",
          " Jordan",
          " Grant",
          " Alexander",
          " Brian",
          " Jacob",
          " Diego",
          " Kelly",
          " Kevin",
          " Patrick",
          " Sarah",
          " Cooper",
          " Victoria",
          " Morgan",
          " Anthony",
          " Anna",
          " Jason",
          " Kennedy",
          " Cole",
          " Carter",
          " Austin",
          " Maria",
          " Sydney",
          " Alan",
          " Antonio",
          " Luke",
          " Matthew",
          " Grace",
          " Jonathan",
          " Benjamin",
          " Steven",
          " Christopher",
          " Parker",
          " Margaret",
          " Hunter",
          " Kate",
          " Oliver",
          " Samuel",
          " Justin"
         ],
         "xaxis": "x",
         "y": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam",
          " Jordan",
          " Grant",
          " Alexander",
          " Brian",
          " Jacob",
          " Diego",
          " Kelly",
          " Kevin",
          " Patrick",
          " Sarah",
          " Cooper",
          " Victoria",
          " Morgan",
          " Anthony",
          " Anna",
          " Jason",
          " Kennedy",
          " Cole",
          " Carter",
          " Austin",
          " Maria",
          " Sydney",
          " Alan",
          " Antonio",
          " Luke",
          " Matthew",
          " Grace",
          " Jonathan",
          " Benjamin",
          " Steven",
          " Christopher",
          " Parker",
          " Margaret",
          " Hunter",
          " Kate",
          " Oliver",
          " Samuel",
          " Justin"
         ],
         "yaxis": "y",
         "z": [
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.8181818127632141,
           0.9090909361839294,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.7272727489471436,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           0.8181818127632141,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           0.9090909361839294,
           0.7272727489471436,
           0.9090909361839294,
           0.7272727489471436,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.8181818127632141,
           0.9090909361839294,
           1,
           0.7272727489471436,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.6363636255264282,
           0.8181818127632141,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           1,
           0.8181818127632141,
           0.9090909361839294,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           0.6363636255264282,
           1,
           1,
           0.8181818127632141,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           0.7272727489471436,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.8181818127632141,
           0.7272727489471436,
           0.7272727489471436,
           0.9090909361839294,
           0.7272727489471436,
           1,
           0.7272727489471436,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           0.9090909361839294,
           0.8181818127632141,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           0.8181818127632141,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1
          ],
          [
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.6363636255264282,
           0.8181818127632141,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.7272727489471436,
           0.9090909361839294,
           0.8181818127632141,
           0.8181818127632141,
           1,
           1,
           1,
           0.7272727489471436,
           0.8181818127632141,
           0.8181818127632141,
           0.9090909361839294,
           0.9090909361839294,
           0.8181818127632141,
           0.7272727489471436,
           1,
           0.7272727489471436,
           0.7272727489471436,
           0.9090909361839294,
           0.7272727489471436,
           1,
           0.8181818127632141,
           0.8181818127632141,
           0.9090909361839294,
           0.7272727489471436,
           1,
           1,
           0.7272727489471436,
           0.9090909361839294,
           0.9090909361839294,
           1,
           0.9090909361839294,
           0.8181818127632141,
           0.8181818127632141,
           0.9090909361839294,
           0.5454545617103577,
           0.9090909361839294,
           0.5454545617103577,
           0.9090909361839294,
           0.7272727489471436,
           0.9090909361839294,
           0.8181818127632141,
           1,
           0.9090909361839294,
           0.8181818127632141,
           1,
           0.7272727489471436,
           0.9090909361839294,
           1,
           0.8181818127632141,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.7272727489471436,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.7272727489471436,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.7272727489471436,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           0.8181818127632141,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           0.9090909361839294,
           1,
           0.8181818127632141,
           1,
           0.9090909361839294,
           0.8181818127632141,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           0.9090909361839294,
           1,
           0.9090909361839294,
           0.8181818127632141,
           0.8181818127632141,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           0.8181818127632141,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.6363636255264282,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.7272727489471436,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           0.8181818127632141,
           0.9090909361839294,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           0.8181818127632141,
           1,
           0.9090909361839294,
           1,
           0.7272727489471436,
           1,
           1,
           0.8181818127632141,
           0.9090909361839294,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.8181818127632141,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.7272727489471436,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           0.9090909361839294,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           0.9090909361839294
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.7272727489471436,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           0.8181818127632141,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0.9090909361839294,
           1,
           0.9090909361839294,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ]
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "font": {
         "color": "black",
         "size": 9
        },
        "height": 600,
        "legend": {
         "x": 0.01,
         "xanchor": "left",
         "y": 0.99,
         "yanchor": "top"
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 100
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "replacing with subtract and add average"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.1926345609065156,
          0.8073654390934843
         ],
         "range": [
          -0.5,
          67.5
         ],
         "scaleanchor": "y",
         "tickmode": "array",
         "ticktext": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam",
          " Jordan",
          " Grant",
          " Alexander",
          " Brian",
          " Jacob",
          " Diego",
          " Kelly",
          " Kevin",
          " Patrick",
          " Sarah",
          " Cooper",
          " Victoria",
          " Morgan",
          " Anthony",
          " Anna",
          " Jason",
          " Kennedy",
          " Cole",
          " Carter",
          " Austin",
          " Maria",
          " Sydney",
          " Alan",
          " Antonio",
          " Luke",
          " Matthew",
          " Grace",
          " Jonathan",
          " Benjamin",
          " Steven",
          " Christopher",
          " Parker",
          " Margaret",
          " Hunter",
          " Kate",
          " Oliver",
          " Samuel",
          " Justin"
         ],
         "tickvals": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam",
          " Jordan",
          " Grant",
          " Alexander",
          " Brian",
          " Jacob",
          " Diego",
          " Kelly",
          " Kevin",
          " Patrick",
          " Sarah",
          " Cooper",
          " Victoria",
          " Morgan",
          " Anthony",
          " Anna",
          " Jason",
          " Kennedy",
          " Cole",
          " Carter",
          " Austin",
          " Maria",
          " Sydney",
          " Alan",
          " Antonio",
          " Luke",
          " Matthew",
          " Grace",
          " Jonathan",
          " Benjamin",
          " Steven",
          " Christopher",
          " Parker",
          " Margaret",
          " Hunter",
          " Kate",
          " Oliver",
          " Samuel",
          " Justin"
         ],
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          67.5,
          -0.5
         ],
         "tickmode": "array",
         "ticktext": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam",
          " Jordan",
          " Grant",
          " Alexander",
          " Brian",
          " Jacob",
          " Diego",
          " Kelly",
          " Kevin",
          " Patrick",
          " Sarah",
          " Cooper",
          " Victoria",
          " Morgan",
          " Anthony",
          " Anna",
          " Jason",
          " Kennedy",
          " Cole",
          " Carter",
          " Austin",
          " Maria",
          " Sydney",
          " Alan",
          " Antonio",
          " Luke",
          " Matthew",
          " Grace",
          " Jonathan",
          " Benjamin",
          " Steven",
          " Christopher",
          " Parker",
          " Margaret",
          " Hunter",
          " Kate",
          " Oliver",
          " Samuel",
          " Justin"
         ],
         "tickvals": [
          " John",
          " Mark",
          " David",
          " Paul",
          " James",
          " George",
          " Michael",
          " Mary",
          " Christian",
          " Robert",
          " Thomas",
          " William",
          " Jesus",
          " Richard",
          " Peter",
          " Charles",
          " Martin",
          " Henry",
          " Jackson",
          " Joseph",
          " Daniel",
          " Francisco",
          " Andrew",
          " Taylor",
          " Stephen",
          " Eric",
          " Elizabeth",
          " Edward",
          " Ryan",
          " Adam",
          " Jordan",
          " Grant",
          " Alexander",
          " Brian",
          " Jacob",
          " Diego",
          " Kelly",
          " Kevin",
          " Patrick",
          " Sarah",
          " Cooper",
          " Victoria",
          " Morgan",
          " Anthony",
          " Anna",
          " Jason",
          " Kennedy",
          " Cole",
          " Carter",
          " Austin",
          " Maria",
          " Sydney",
          " Alan",
          " Antonio",
          " Luke",
          " Matthew",
          " Grace",
          " Jonathan",
          " Benjamin",
          " Steven",
          " Christopher",
          " Parker",
          " Margaret",
          " Hunter",
          " Kate",
          " Oliver",
          " Samuel",
          " Justin"
         ],
         "type": "category"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"7f568ea0-21db-4330-b9b8-5f0608a69061\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7f568ea0-21db-4330-b9b8-5f0608a69061\")) {                    Plotly.newPlot(                        \"7f568ea0-21db-4330-b9b8-5f0608a69061\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\",\" Jordan\",\" Grant\",\" Alexander\",\" Brian\",\" Jacob\",\" Diego\",\" Kelly\",\" Kevin\",\" Patrick\",\" Sarah\",\" Cooper\",\" Victoria\",\" Morgan\",\" Anthony\",\" Anna\",\" Jason\",\" Kennedy\",\" Cole\",\" Carter\",\" Austin\",\" Maria\",\" Sydney\",\" Alan\",\" Antonio\",\" Luke\",\" Matthew\",\" Grace\",\" Jonathan\",\" Benjamin\",\" Steven\",\" Christopher\",\" Parker\",\" Margaret\",\" Hunter\",\" Kate\",\" Oliver\",\" Samuel\",\" Justin\"],\"y\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\",\" Jordan\",\" Grant\",\" Alexander\",\" Brian\",\" Jacob\",\" Diego\",\" Kelly\",\" Kevin\",\" Patrick\",\" Sarah\",\" Cooper\",\" Victoria\",\" Morgan\",\" Anthony\",\" Anna\",\" Jason\",\" Kennedy\",\" Cole\",\" Carter\",\" Austin\",\" Maria\",\" Sydney\",\" Alan\",\" Antonio\",\" Luke\",\" Matthew\",\" Grace\",\" Jonathan\",\" Benjamin\",\" Steven\",\" Christopher\",\" Parker\",\" Margaret\",\" Hunter\",\" Kate\",\" Oliver\",\" Samuel\",\" Justin\"],\"z\":[[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.8181818127632141,0.9090909361839294,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.7272727489471436,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,0.8181818127632141,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,0.9090909361839294,0.7272727489471436,0.9090909361839294,0.7272727489471436,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.8181818127632141,0.9090909361839294,1.0,0.7272727489471436,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.6363636255264282,0.8181818127632141,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,1.0,1.0,0.8181818127632141,0.9090909361839294,0.9090909361839294,1.0,0.9090909361839294,1.0,0.9090909361839294,0.6363636255264282,1.0,1.0,0.8181818127632141,0.9090909361839294,1.0,1.0,0.9090909361839294,0.7272727489471436,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.8181818127632141,0.7272727489471436,0.7272727489471436,0.9090909361839294,0.7272727489471436,1.0,0.7272727489471436,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,0.9090909361839294,0.8181818127632141,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,0.8181818127632141,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0],[0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.6363636255264282,0.8181818127632141,0.9090909361839294,1.0,1.0,1.0,1.0,0.7272727489471436,0.9090909361839294,0.8181818127632141,0.8181818127632141,1.0,1.0,1.0,0.7272727489471436,0.8181818127632141,0.8181818127632141,0.9090909361839294,0.9090909361839294,0.8181818127632141,0.7272727489471436,1.0,0.7272727489471436,0.7272727489471436,0.9090909361839294,0.7272727489471436,1.0,0.8181818127632141,0.8181818127632141,0.9090909361839294,0.7272727489471436,1.0,1.0,0.7272727489471436,0.9090909361839294,0.9090909361839294,1.0,0.9090909361839294,0.8181818127632141,0.8181818127632141,0.9090909361839294,0.5454545617103577,0.9090909361839294,0.5454545617103577,0.9090909361839294,0.7272727489471436,0.9090909361839294,0.8181818127632141,1.0,0.9090909361839294,0.8181818127632141,1.0,0.7272727489471436,0.9090909361839294,1.0,0.8181818127632141,1.0,0.9090909361839294,1.0,0.9090909361839294],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.7272727489471436,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.8181818127632141,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,0.7272727489471436,1.0,1.0,0.9090909361839294,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.7272727489471436,1.0,0.9090909361839294,0.9090909361839294,1.0,0.8181818127632141,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,0.9090909361839294,1.0,0.8181818127632141,1.0,0.9090909361839294,0.8181818127632141,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,0.9090909361839294,1.0,0.9090909361839294,0.8181818127632141,0.8181818127632141,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,0.8181818127632141,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.6363636255264282,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.7272727489471436,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,0.8181818127632141,0.9090909361839294,0.8181818127632141,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,0.8181818127632141,1.0,0.9090909361839294,1.0,0.7272727489471436,1.0,1.0,0.8181818127632141,0.9090909361839294,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.8181818127632141,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.7272727489471436,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,0.9090909361839294,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,0.9090909361839294],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.7272727489471436,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,0.8181818127632141,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9090909361839294,1.0,0.9090909361839294,1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"tickmode\":\"array\",\"tickvals\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\",\" Jordan\",\" Grant\",\" Alexander\",\" Brian\",\" Jacob\",\" Diego\",\" Kelly\",\" Kevin\",\" Patrick\",\" Sarah\",\" Cooper\",\" Victoria\",\" Morgan\",\" Anthony\",\" Anna\",\" Jason\",\" Kennedy\",\" Cole\",\" Carter\",\" Austin\",\" Maria\",\" Sydney\",\" Alan\",\" Antonio\",\" Luke\",\" Matthew\",\" Grace\",\" Jonathan\",\" Benjamin\",\" Steven\",\" Christopher\",\" Parker\",\" Margaret\",\" Hunter\",\" Kate\",\" Oliver\",\" Samuel\",\" Justin\"],\"ticktext\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\",\" Jordan\",\" Grant\",\" Alexander\",\" Brian\",\" Jacob\",\" Diego\",\" Kelly\",\" Kevin\",\" Patrick\",\" Sarah\",\" Cooper\",\" Victoria\",\" Morgan\",\" Anthony\",\" Anna\",\" Jason\",\" Kennedy\",\" Cole\",\" Carter\",\" Austin\",\" Maria\",\" Sydney\",\" Alan\",\" Antonio\",\" Luke\",\" Matthew\",\" Grace\",\" Jonathan\",\" Benjamin\",\" Steven\",\" Christopher\",\" Parker\",\" Margaret\",\" Hunter\",\" Kate\",\" Oliver\",\" Samuel\",\" Justin\"]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"tickmode\":\"array\",\"tickvals\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\",\" Jordan\",\" Grant\",\" Alexander\",\" Brian\",\" Jacob\",\" Diego\",\" Kelly\",\" Kevin\",\" Patrick\",\" Sarah\",\" Cooper\",\" Victoria\",\" Morgan\",\" Anthony\",\" Anna\",\" Jason\",\" Kennedy\",\" Cole\",\" Carter\",\" Austin\",\" Maria\",\" Sydney\",\" Alan\",\" Antonio\",\" Luke\",\" Matthew\",\" Grace\",\" Jonathan\",\" Benjamin\",\" Steven\",\" Christopher\",\" Parker\",\" Margaret\",\" Hunter\",\" Kate\",\" Oliver\",\" Samuel\",\" Justin\"],\"ticktext\":[\" John\",\" Mark\",\" David\",\" Paul\",\" James\",\" George\",\" Michael\",\" Mary\",\" Christian\",\" Robert\",\" Thomas\",\" William\",\" Jesus\",\" Richard\",\" Peter\",\" Charles\",\" Martin\",\" Henry\",\" Jackson\",\" Joseph\",\" Daniel\",\" Francisco\",\" Andrew\",\" Taylor\",\" Stephen\",\" Eric\",\" Elizabeth\",\" Edward\",\" Ryan\",\" Adam\",\" Jordan\",\" Grant\",\" Alexander\",\" Brian\",\" Jacob\",\" Diego\",\" Kelly\",\" Kevin\",\" Patrick\",\" Sarah\",\" Cooper\",\" Victoria\",\" Morgan\",\" Anthony\",\" Anna\",\" Jason\",\" Kennedy\",\" Cole\",\" Carter\",\" Austin\",\" Maria\",\" Sydney\",\" Alan\",\" Antonio\",\" Luke\",\" Matthew\",\" Grace\",\" Jonathan\",\" Benjamin\",\" Steven\",\" Christopher\",\" Parker\",\" Margaret\",\" Hunter\",\" Kate\",\" Oliver\",\" Samuel\",\" Justin\"]},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"title\":{\"text\":\"replacing with subtract and add average\"},\"font\":{\"size\":9,\"color\":\"black\"},\"margin\":{\"l\":0,\"r\":0,\"t\":100,\"b\":0},\"width\":800,\"height\":600,\"autosize\":false,\"showlegend\":true,\"legend\":{\"yanchor\":\"top\",\"y\":0.99,\"xanchor\":\"left\",\"x\":0.01}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7f568ea0-21db-4330-b9b8-5f0608a69061');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", font_size=None, show=True, color_continuous_midpoint=0.0, **kwargs):\n",
    "    import plotly.express as px\n",
    "    import transformer_lens.utils as utils\n",
    "    fig = px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=color_continuous_midpoint, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs)\n",
    "    if not font_size is None:\n",
    "        if 'x' in kwargs:\n",
    "            fig.update_layout(\n",
    "              xaxis = dict(\n",
    "                tickmode='array',\n",
    "                tickvals = kwargs['x'],\n",
    "                ticktext = kwargs['x'], \n",
    "                ),\n",
    "               font=dict(size=font_size, color=\"black\"))\n",
    "        if 'y' in kwargs:\n",
    "            fig.update_layout(\n",
    "              yaxis = dict(\n",
    "                tickmode='array',\n",
    "                tickvals = kwargs['y'],\n",
    "                ticktext = kwargs['y'], \n",
    "                ),\n",
    "               font=dict(size=font_size, color=\"black\"))\n",
    "    plot_args = {\n",
    "        'width': 800,\n",
    "        'height': 600,\n",
    "        \"autosize\": False,\n",
    "        'showlegend': True,\n",
    "        'margin': {\"l\":0,\"r\":0,\"t\":100,\"b\":0}\n",
    "    }\n",
    "    \n",
    "    fig.update_layout(**plot_args)\n",
    "    fig.update_layout(legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    ))\n",
    "    if show:\n",
    "        fig.show(renderer)\n",
    "    else:\n",
    "        return fig\n",
    "\n",
    "imshow(n_correct_matrix[:-1,:-1], color_continuous_midpoint=None, y=name_toks_strs[:-1], x=name_toks_strs[:-1], title='replacing with subtract and add average', font_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ba32f2c-2128-463f-9979-48b48b813d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 0 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 0 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 0 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 0 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 1 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 1 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 1 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 1 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 1 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 2 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 2 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 2 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 2 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 2 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 3 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 3 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 3 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 3 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 3 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 4 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0 4 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 197\u001b[0m\n\u001b[1;32m    195\u001b[0m         logits_modified_corrupted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mrun_with_hooks(batched_corrupted_inputs, fwd_hooks\u001b[38;5;241m=\u001b[39mcorrupted_hooks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batched_inputs\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m--> 197\u001b[0m             replace_correct\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlogits_modified_corrupted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlast_token_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreplace_tok\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    198\u001b[0m             replace_replace\u001b[38;5;241m.\u001b[39mappend(logits_modified_corrupted[i,last_token_pos,answer_tok]\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar_chart\u001b[39m(data, x_labels, y_label, title, font_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "\n",
    "DO_DIFF = True\n",
    "\n",
    "model_kwargs = {\"fast_ssm\": True, \"fast_conv\": True}\n",
    "\n",
    "original_corrects = {}\n",
    "original_replaces = {}\n",
    "replace_corrects = {}\n",
    "replace_replaces = {}\n",
    "patched_corrects = {}\n",
    "patched_replaces = {}\n",
    "\n",
    "for position_1 in range(3):\n",
    "  for name_tok_1 in list(name_tokens):\n",
    "     for name_tok_2 in list(name_tokens):\n",
    "        print(position_1, name_tok_1, name_tok_2)\n",
    "        original_correct = []\n",
    "        original_replace = []\n",
    "        replace_correct = []\n",
    "        replace_replace = []\n",
    "        patched_correct = []\n",
    "        patched_replace = []\n",
    "\n",
    "        key = (position_1, name_tok_1, name_tok_2)\n",
    "        original_corrects[key] = original_correct\n",
    "        original_replaces[key] = original_replace\n",
    "        replace_corrects[key] = replace_correct\n",
    "        replace_replaces[key] = replace_replace\n",
    "        patched_corrects[key] = patched_correct\n",
    "        patched_replaces[key] = patched_replace\n",
    "\n",
    "        batched_inputs = []\n",
    "        batched_corrupted_inputs = []\n",
    "        num_found = 0\n",
    "        hooks = []\n",
    "        corrupted_hooks = []\n",
    "        last_token_positions = []\n",
    "        replace_toks = []\n",
    "        answer_toks = []\n",
    "        while True:\n",
    "            batch_i = 0\n",
    "            data_i = random.choice(list(range(data.data.size()[0])))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i].clone()\n",
    "            corrupted_tokens = data.data[patched_i].clone()\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "\n",
    "\n",
    "            all_names = set([x.item() for x in data.incorrect[data_i]]) | set([answer_tok]) | set([replace_tok])\n",
    "            if name_tok_1 in all_names or name_tok_2 in all_names:\n",
    "                continue\n",
    "\n",
    "            answer_tok = name_tok_1\n",
    "            replace_tok = name_tok_2\n",
    "            \n",
    "            \n",
    "            replace_toks.append(replace_tok)\n",
    "            answer_toks.append(answer_tok)\n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            last_token_positions.append(last_token_pos)\n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                replace_vec,\n",
    "                replace_add_vec,\n",
    "                batch_i,\n",
    "            ):\n",
    "                if not replace_vec is None:\n",
    "                    x[batch_i, position] = replace_vec\n",
    "                if not replace_add_vec is None:\n",
    "                    x[batch_i, position] += replace_add_vec\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(name_positions)):\n",
    "                position = name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "                    data_tokens[position] = name_tok_1\n",
    "                    corrupted_tokens[position] = name_tok_2\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                    break\n",
    "\n",
    "                \n",
    "                \n",
    "                name_i = position_2\n",
    "                replace_vec = random.choice(name_choices[name_i][replace_tok])\n",
    "                # two ways to do it\n",
    "                # diff(name) = avg - name\n",
    "                # if we add this it should \"erase\" name\n",
    "                # if we subtract this it should \"add\" name\n",
    "                # so we can do\n",
    "                # replace_add_vec = diff(answer) - diff(replace)\n",
    "                #diff_answer = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][answer_tok]\n",
    "                #diff_replace = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][replace_tok]\n",
    "                #replace_add_vec = diff_answer - diff_replace\n",
    "                # this is (avg-a) - (avg-r) = r-a\n",
    "                # in other words the average doesn't matter for this\n",
    "                # and it's just subtract avg for a and add average for b\n",
    "                replace_add_vec = random.choice(name_choices[name_i][replace_tok]) - name_averages[name_i][answer_tok]\n",
    "                # then we do\n",
    "                # replace_vec\n",
    "                # we have x\n",
    "                # we want y\n",
    "                # we can do\n",
    "                # x-y\n",
    "                # and apply it to y\n",
    "                #replace_diff = name_averages[name_i][TOTAL_AVG_NAME]\n",
    "        \n",
    "                if DO_DIFF:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            batched_inputs.append(data_tokens.view(1, -1))\n",
    "            #logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            batched_corrupted_inputs.append(corrupted_tokens.view(1, -1))\n",
    "            for name_i, position in answer_positions:\n",
    "                name_i = position_2\n",
    "                replace_vec = name_averages[name_i][answer_tok]\n",
    "                replace_add_vec = name_averages[name_i][answer_tok] - name_averages[name_i][replace_tok]            \n",
    "                if DO_DIFF:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec, batch_i=batch_i)))\n",
    "                else:\n",
    "                    corrupted_hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None, batch_i=batch_i)))\n",
    "\n",
    "            \n",
    "    \n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 50:\n",
    "                break\n",
    "\n",
    "        batched_inputs = torch.cat(batched_inputs, dim=0)\n",
    "        batched_corrupted_inputs = torch.cat(batched_corrupted_inputs, dim=0)\n",
    "        \n",
    "        logits_modified = model.run_with_hooks(batched_inputs, fwd_hooks=hooks, **model_kwargs)\n",
    "        #print(logits_modified.size())\n",
    "        #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "        #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "        for i in range(batched_inputs.size()[0]):\n",
    "            replace_correct.append(logits_modified[i,last_token_positions[i],answer_toks[i]].item())\n",
    "            replace_replace.append(logits_modified[i,last_token_positions[i],replace_toks[i]].item())        \n",
    "        del logits_modified\n",
    "        logits_modified_corrupted = model.run_with_hooks(batched_corrupted_inputs, fwd_hooks=corrupted_hooks, **model_kwargs)\n",
    "        for i in range(batched_inputs.size()[0]):\n",
    "            replace_correct.append(logits_modified_corrupted[i,last_token_pos,replace_tok].item())\n",
    "            replace_replace.append(logits_modified_corrupted[i,last_token_pos,answer_tok].item())\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd58f192-1209-4e50-91ed-6fae7bc1b021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9901, 0.9901, 1.0000, 0.4752, 0.4752],\n",
       "        [1.0000, 1.0000, 0.9901, 0.6040, 0.5842],\n",
       "        [0.9802, 1.0000, 0.9901, 0.4455, 0.3861]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_correct_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "88a02596-53c9-4a4c-a6bf-512407cd28b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 120000/120000 [00:21<00:00, 5619.17it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 120000/120000 [00:21<00:00, 5499.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 400/400 [07:01<00:00,  1.05s/it]\n",
      "  1%|▌                                                                                  | 3/400 [00:04<08:54,  1.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 149\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#del X\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m#del Y\u001b[39;00m\n\u001b[1;32m    148\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m--> 149\u001b[0m vX, vY \u001b[38;5;241m=\u001b[39m \u001b[43mget_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvdata_name_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m pY \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mpredict(vX)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# we want cosine similarity to actual embedding vectors\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m#avg_sim = cosine_similarity(pY, vY).mean().item()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[89], line 133\u001b[0m, in \u001b[0;36mget_training_data\u001b[0;34m(dat, name_positions, batch_size)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_end\u001b[38;5;241m-\u001b[39mbatch_start):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m#print(ssm_inputs[batch_i, position].size())\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     position \u001b[38;5;241m=\u001b[39m positions[batch_i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# +1 because conv\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     bX \u001b[38;5;241m=\u001b[39m \u001b[43mget_linear_classification_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(bX)\n\u001b[1;32m    135\u001b[0m     Y\u001b[38;5;241m.\u001b[39mappend(name_tokens[batch_i]\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[89], line 102\u001b[0m, in \u001b[0;36mget_linear_classification_X\u001b[0;34m(activations, layer, batch_i, position_x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_linear_classification_X\u001b[39m(activations, layer, batch_i, position_x):\n\u001b[0;32m--> 102\u001b[0m     vec \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblocks.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.hook_ssm_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43mposition_x\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m#vec = vec / torch.linalg.norm(vec, ord=2) / divTerm\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vec\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "# we want to predict the name from the representation\n",
    "# there are two ways to do this:\n",
    "# 1. Predict the probability of a rep being a name (output logits for each name)\n",
    "# 2. Output the name embedding\n",
    "# we'll start with the second one because it is more general, if that doesn't work we can try the first one\n",
    "\n",
    "\n",
    "# we're basically doing a tuned lens sorta? idk\n",
    "# lets start with not batched\n",
    "\n",
    "# okay so say we are trying to output the name embedding\n",
    "# on layer i, that could mean:\n",
    "#    predict emb after it's projected into E space (which is after norm, but before conv)\n",
    "#    predict emb after conv\n",
    "#    predict emb after conv and silu\n",
    "#    predict emb from hidden state or some other internal rep\n",
    "# the point is that we train this linear map for some specific thing, then how well it performs suggests how well that thing encodes our data,\n",
    "# so we can try it for lots of intermediate stuff\n",
    "# some of the maps won't work, that's ok\n",
    "from mamba_lens.input_dependent_hooks import clean_hooks\n",
    "import torch\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from jaxtyping import Float\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "# this is useful because sometimes if you spam ctrl-c too many times some hooks will stay around\n",
    "clean_hooks(model)\n",
    "\n",
    "# make sure we have no overlap\n",
    "#joined_data = torch.cat([data.data, data.valid_data], dim=0)\n",
    "#torch.sort(joined_data, dim=0)\n",
    "#unique = torch.unique(joined_data, dim=0)\n",
    "#torch.manual_seed(27)\n",
    "# shuffle data\n",
    "#unique = unique[torch.randperm(unique.size()[0])]\n",
    "#B = unique.size()[0]//3\n",
    "# split into train valid and test\n",
    "#dataset, vdataset, tdataset = unique[:B], unique[B:2*B], unique[2*B:3*B]\n",
    "dataset = data.data\n",
    "vdataset = data.valid_data\n",
    "\n",
    "\n",
    "\n",
    "from acdc.data.ioi import good_names\n",
    "from collections import defaultdict\n",
    "name_tokens = set([model.to_single_token(\" \" + name) for name in good_names])\n",
    "\n",
    "\n",
    "name_tok_to_class = {}\n",
    "for i, tok in enumerate(sorted(list(name_tokens))):\n",
    "    name_tok_to_class[tok] = i\n",
    "\n",
    "def get_name_positions(dat):\n",
    "    name_positions = defaultdict(lambda: [])\n",
    "    for i in tqdm(list(range(dat.size()[0]))):\n",
    "        prompt_tokens = dat[i]\n",
    "        name_pos = 0\n",
    "        for i, tok in enumerate(prompt_tokens):\n",
    "            if tok.item() in name_tokens:\n",
    "                name_positions[name_pos].append(i)\n",
    "                name_pos += 1\n",
    "        if name_pos != 5: raise ValueError(f\"data point {model.to_str_tokens(data)} does not have 5 names\")\n",
    "    return name_positions\n",
    "\n",
    "data_name_positions, vdata_name_positions = get_name_positions(dataset), get_name_positions(vdataset)\n",
    "\n",
    "model_kwargs = {\n",
    "    \"fast_ssm\": True,\n",
    "    \"fast_conv\": True,\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 300\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "B,L = dataset.size()\n",
    "\n",
    "# for each position that varies, for each other position, fit a linear model\n",
    "\n",
    "global probing_dataset_X\n",
    "probing_dataset_X = []\n",
    "def dataset_gathering_hook(\n",
    "    x: Float[torch.Tensor, \"B L D\"],\n",
    "    hook: HookPoint,\n",
    "    position: int\n",
    "):\n",
    "    global probing_dataset_X\n",
    "    probing_dataset_X.append(x[:,position,:].cpu())\n",
    "    return x\n",
    "\n",
    "layer = 39\n",
    "\n",
    "linear_models = []\n",
    "E = model.cfg.E\n",
    "divTerm = float(math.sqrt(math.sqrt(float(E))*E))\n",
    "for name_i in range(5):\n",
    "    \n",
    "    # make dataset\n",
    "    \n",
    "    def get_linear_classification_X(activations, layer, batch_i, position_x):\n",
    "        vec = activations[f'blocks.{layer}.hook_ssm_input'][batch_i,position_x].view(-1)\n",
    "        #vec = vec / torch.linalg.norm(vec, ord=2) / divTerm\n",
    "        return vec.view(1,-1).detach().cpu().numpy()\n",
    "\n",
    "    def get_linear_classification_Y(labels):\n",
    "        B = labels.size()[0]\n",
    "        Y = np.zeros([B,len(name_tokens)])\n",
    "        #Y = model.embedding.weight[input_data[:,position_y]]\n",
    "        #return Y.detach().cpu().numpy()\n",
    "        Y[:] = -1 # predict a vector with -1 for incorrect class and 1 for correct class\n",
    "        for i in range(B):\n",
    "            value = labels[i].item()\n",
    "            Y[i,name_tok_to_class[value]] = 1\n",
    "        return Y#/math.sqrt(float(model.cfg.E))\n",
    "    \n",
    "    names_filter = [f'blocks.{layer}.hook_ssm_input']\n",
    "    \n",
    "    print(f\"collecting data...\")\n",
    "\n",
    "    def get_training_data(dat, name_positions, batch_size):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for batch_start in tqdm(list(range(0, dat.size()[0], batch_size))):\n",
    "            batch_end = min(batch_start + batch_size, dataset.size()[0])\n",
    "            data_batch = dat[batch_start:batch_end]\n",
    "            positions = torch.tensor(name_positions[name_i][batch_start:batch_end], device=model.cfg.device)\n",
    "            name_tokens = data_batch[torch.arange(batch_end-batch_start),positions]\n",
    "            logits, activations = model.run_with_cache(data_batch, names_filter=names_filter, **model_kwargs)\n",
    "            for batch_i in range(batch_end-batch_start):\n",
    "                #print(ssm_inputs[batch_i, position].size())\n",
    "                position = positions[batch_i] + 1 # +1 because conv\n",
    "                bX = get_linear_classification_X(activations=activations, layer=layer, batch_i=batch_i, position_x=position)\n",
    "                X.append(bX)\n",
    "                Y.append(name_tokens[batch_i].item())\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        Y = torch.tensor(Y)\n",
    "        Y = get_linear_classification_Y(labels=Y)\n",
    "        return X, Y\n",
    "\n",
    "    X, Y = get_training_data(dat=dataset, name_positions=data_name_positions, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X, Y)\n",
    "    linear_models.append(linear_model)\n",
    "    #del X\n",
    "    #del Y\n",
    "    torch.cuda.empty_cache()\n",
    "    vX, vY = get_training_data(dat=vdataset, name_positions=vdata_name_positions, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    pY = linear_model.predict(vX)\n",
    "    # we want cosine similarity to actual embedding vectors\n",
    "    #avg_sim = cosine_similarity(pY, vY).mean().item()\n",
    "    predicted_inds = np.argmax(pY, axis=1)\n",
    "    actual_inds = np.argmax(vY, axis=1)\n",
    "    acc = np.sum(predicted_inds==actual_inds)/float(predicted_inds.shape[0])\n",
    "    print(f\"position {name_i} layer {layer} acc {acc}\")\n",
    "    #outpaut_accuracies[position_i, layer, other_position] = avg_sim\n",
    "\n",
    "print(f\"these token positions vary their value: {positions_that_vary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e19606-dde4-49fc-840e-8cd3c035e560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_fit',\n",
       " '_fit_full',\n",
       " '_fit_svd_solver',\n",
       " '_fit_truncated',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_n_features_out',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sklearn_auto_wrap_output_keys',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " 'components_',\n",
       " 'copy',\n",
       " 'explained_variance_',\n",
       " 'explained_variance_ratio_',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_covariance',\n",
       " 'get_feature_names_out',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'get_precision',\n",
       " 'inverse_transform',\n",
       " 'iterated_power',\n",
       " 'mean_',\n",
       " 'n_components',\n",
       " 'n_components_',\n",
       " 'n_features_in_',\n",
       " 'n_oversamples',\n",
       " 'n_samples_',\n",
       " 'noise_variance_',\n",
       " 'power_iteration_normalizer',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'set_output',\n",
       " 'set_params',\n",
       " 'singular_values_',\n",
       " 'svd_solver',\n",
       " 'tol',\n",
       " 'transform',\n",
       " 'whiten']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "470a3314-2d8d-4337-9f01-28af455ab120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div term 304.4370214406966\n",
      "worst case mag 5.129492386402035e-10\n",
      "div term 304.4370214406966\n",
      "worst case mag 5.129643376733384e-10\n",
      "div term 304.4370214406966\n",
      "worst case mag 5.129641711398847e-10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "np.random.seed(27)\n",
    "\n",
    "class NameBasis(object):\n",
    "    def __init__(self, linear_model):\n",
    "        self.linear_model = linear_model\n",
    "        #       [C,E] [E,1] [C] [C]\n",
    "        # we have A  @  x  + b = y which is -1 for not name and 1 for name\n",
    "        # we want a V s.t.\n",
    "        #       [E,E] [E,1] [E]  [E]\n",
    "        #         V  @  x  + d =  y\n",
    "        # where V is invertible so\n",
    "        #        [E]   [E,E]    [E] [E]\n",
    "        #         x  = V^-1  @  (y - d)\n",
    "        # and\n",
    "        #          [C,E]    [E,1]     [C]\n",
    "        #        V[:C,:]  @   x   +  d[:C] =\n",
    "        #            A                 b\n",
    "        # the simplest way to do this is to set those extra bias terms to zero\n",
    "        # and those extra rows to normally distributed random values\n",
    "        # (with high pr the matrix should be invertible as long as first C aren't linearly dependent)\n",
    "        A = linear_model.coef_\n",
    "        b = linear_model.intercept_\n",
    "        C,E = A.shape\n",
    "        self.E = E\n",
    "        d = np.zeros([E])\n",
    "        d[:C] = b\n",
    "        V = np.random.randn(E,E)\n",
    "        V[:C] = A\n",
    "        # normalize rows to help it be more well behaved\n",
    "        # actually if they are normalized, the input is normalized so output values\n",
    "        # go from -1 to 1\n",
    "        # but that's too big, that means output norm is sqrt(E)\n",
    "        # what we want is norm of result is 1\n",
    "        # each row should be magnitude 1/sqrt(E)\n",
    "        # if input is also size 1/sqrt(E) then dot product gives us\n",
    "        # ((-1,1)*1/sqrt(E)*1/sqrt(E) which is (-1/E,1/E)\n",
    "        # which would give us sqrt(E*E^2) = E^3/2 which is not unit\n",
    "        # we have mag1 mag2 and dot product gives\n",
    "        # mag1*mag2\n",
    "        # and magnitude gives\n",
    "        # sqrt(E*mag1^2*mag2^2) = sqrt(E)*mag1*mag2\n",
    "        # we want this to be 1, so\n",
    "        # 1 = sqrt(E)*mag1*mag2\n",
    "        # assume mag=mag1=mag2\n",
    "        # 1 = sqrt(E)*mag^2\n",
    "        # 1/sqrt(E) = mag^2\n",
    "        # 1/sqrt(sqrt(E)) = mag\n",
    "        # lets double check that\n",
    "        # consider 111111 vector\n",
    "        # when we divide by 1/sqrt(sqrt(E)) we get lots of terms of \n",
    "        # we have two vectors each full of 1/sqrt(sqrt(E)) terms\n",
    "        # dot product will give lots of\n",
    "        # E*(1/sqrt(sqrt(E)))*(1/sqrt(sqrt(E)))\n",
    "        # E*1/sqrt(E)\n",
    "        # The magnitude of that is\n",
    "        # sqrt(E*(E^2/E)) = E\n",
    "        # not what we want\n",
    "        # okay so we have a matrix full of 1/v\n",
    "        # we dot product each row with another vector full of 1/v\n",
    "        # each entry in result is E*1/v^2\n",
    "        # So total magnitude is\n",
    "        # sqrt(E*(E^2/v^4))\n",
    "        # = sqrt(E)*E/v^2\n",
    "        # we want this to be 1\n",
    "        # thus\n",
    "        # 1 = sqrt(E)*E/v^2\n",
    "        # v^2 = sqrt(E)*E\n",
    "        # v = sqrt(sqrt(E)*E)\n",
    "        # lets double check that\n",
    "        # E*1/sqrt(sqrt(E)*E)*1/sqrt(sqrt(E)*E) is each term\n",
    "        # E*1/sqrt(E)*1/E\n",
    "        # 1/sqrt(E) is each term in the result\n",
    "        # sqrt(E*1/E) = sqrt(1) nice!\n",
    "        self.divTerm = float(math.sqrt(math.sqrt(float(E))*E))\n",
    "        print(\"div term\", self.divTerm)\n",
    "        for row in range(C,E):\n",
    "            vrow = V[row]\n",
    "            V[row] = vrow / np.linalg.norm(vrow, ord=2) / self.divTerm\n",
    "        V_inv = np.linalg.inv(V)\n",
    "        \n",
    "        self.d = torch.tensor(d, device=model.cfg.device, dtype=torch.double)\n",
    "        self.V = torch.tensor(V, device=model.cfg.device, dtype=torch.double)\n",
    "        self.V_inv = torch.tensor(V_inv, device=model.cfg.device, dtype=torch.double)\n",
    "        # test to make sure it's invertible\n",
    "        mags = []\n",
    "        for i in range(200):\n",
    "            x = torch.tensor(vX[i] / np.linalg.norm(vX[i], ord=2) / self.divTerm, device=model.cfg.device)\n",
    "            coords = self.map_to_coords(x)\n",
    "            backx = self.map_from_coords(coords)\n",
    "            mags.append(torch.linalg.norm(x-backx, dim=0, ord=2))\n",
    "        print(f\"worst case mag {torch.max(torch.tensor(mags))}\")\n",
    "    \n",
    "    def map_to_coords(self, vec):\n",
    "        vec = vec.double() / torch.linalg.norm(vec, ord=2) / self.divTerm\n",
    "        return ((self.V @ vec.view(self.E, 1))[:,0] + self.d)\n",
    "\n",
    "    def map_from_coords(self, coords):\n",
    "        return (self.V_inv @ (coords - self.d).view(self.E, 1))[:,0].float()        \n",
    "\n",
    "\n",
    "name_bases = [NameBasis(linear_model) for linear_model in linear_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db46432-3422-47fc-9698-78ccba2ddf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                               | 1/20 [00:19<06:17, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                           | 2/20 [00:39<05:51, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▌                                                                       | 3/20 [00:59<05:38, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 4/20 [01:19<05:21, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████                                                               | 5/20 [01:39<04:57, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▏                                                          | 6/20 [01:59<04:39, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████▍                                                      | 7/20 [02:18<04:15, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 8/20 [02:38<03:55, 19.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▊                                              | 9/20 [02:58<03:37, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 10/20 [03:18<03:19, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████▋                                     | 11/20 [03:38<02:59, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 12/20 [03:59<02:42, 20.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▉                             | 13/20 [04:20<02:23, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 14/20 [04:41<02:03, 20.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████▎                    | 15/20 [05:02<01:43, 20.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 16/20 [05:21<01:21, 20.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████████████████▌            | 17/20 [05:41<01:00, 20.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 18/20 [06:02<00:40, 20.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████████████████▊    | 19/20 [06:21<00:20, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fb5f8629f60>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dev/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 20/20 [06:42<00:00, 20.11s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "replace_corrects = []\n",
    "replace_replaces = []\n",
    "pca_sizes = []\n",
    "X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "print(X_proj[:,-1])\n",
    "\n",
    "for n_components in tqdm(list(range(1, 100, 5))):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_proj)\n",
    "    pca_sizes.append(n_components)\n",
    "    replace_correct = []\n",
    "    replace_replace = []\n",
    "    print(f\"layer {layer}\")\n",
    "    name_bases = [0]\n",
    "    for position_1, name_basis in enumerate(name_bases):\n",
    "        num_found = 0\n",
    "        while True:            \n",
    "            data_i = random.choice(list(range(10000)))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i]\n",
    "            corrupted_tokens = data.data[data_i+1]\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            \n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                answer_name_tok,\n",
    "                replace_name_tok,\n",
    "                name_basis\n",
    "            ):\n",
    "                B,L,E = x.size()\n",
    "                for b in range(B):\n",
    "                    vec = x[b,position]\n",
    "                    add_ones = np.concatenate([vec.detach().cpu().numpy(), np.array([1.0])], axis=0).reshape(1,-1)\n",
    "                    pcad = pca.transform(add_ones)\n",
    "                    x[b,position] = torch.tensor(pca.inverse_transform(pcad), device=model.cfg.device).reshape(-1)[:-1]\n",
    "                    '''\n",
    "                    coords = name_basis.map_to_coords(vec/torch.linalg.norm(vec, ord=2))\n",
    "                    C = len(name_tok_to_class)\n",
    "                    sorted = torch.argsort(coords[:C])\n",
    "                    print(coords[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"predict {maxi} {coords[maxi]}\")\n",
    "                    print(f\"answer {name_tok_to_class[answer_name_tok]} replace {name_tok_to_class[replace_name_tok]}\")\n",
    "                    coords[name_tok_to_class[answer_name_tok]] = -0.0692\n",
    "                    coords[name_tok_to_class[replace_name_tok]] = 0.0692\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"now predict {maxi} {coords[maxi]}\")\n",
    "                    patched_vec = name_basis.map_from_coords(coords)\n",
    "                    print(f\"orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    patched_veco = patched_vec / torch.linalg.norm(patched_vec, ord=2) * torch.linalg.norm(vec, ord=2)\n",
    "                    print(f\"now orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    coords2 = name_basis.map_to_coords(patched_vec)\n",
    "                    sorted = torch.argsort(coords2[:C])\n",
    "                    print(\"predict2\", coords2[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords2[:C])\n",
    "                    print(f\"predict2 {maxi} {coords2[maxi]}\")\n",
    "                    '''\n",
    "                    #x[b,position] = patched_veco\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(data_name_positions)):\n",
    "                position = data_name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            hooks = []\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                \n",
    "                hooks.append((\n",
    "                    f'blocks.{layer}.hook_ssm_input', \n",
    "                    partial(replace_hook,\n",
    "                            position=position+1,\n",
    "                            answer_name_tok=answer_tok,\n",
    "                            replace_name_tok=replace_tok,\n",
    "                            name_basis=name_basis\n",
    "                    )\n",
    "                ))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            \n",
    "            logits_modified = model.run_with_hooks(corrupted_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 100:\n",
    "                break\n",
    "        break\n",
    "    replace_corrects.append(replace_correct)\n",
    "    replace_replaces.append(replace_replace)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aae9b467-00ca-41a5-b319-5d67412fd57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca 1 replace min diff -6.385058403015137 max diff 3.271770477294922 avg diff -1.354062795639038\n",
      "pca 6 replace min diff -5.725831985473633 max diff 2.4847850799560547 avg diff -1.5583744049072266\n",
      "pca 11 replace min diff -6.683233261108398 max diff 2.3404159545898438 avg diff -1.9905790090560913\n",
      "pca 16 replace min diff -7.113604545593262 max diff 3.5367918014526367 avg diff -2.205662965774536\n",
      "pca 21 replace min diff -9.534707069396973 max diff 1.856553077697754 avg diff -2.4536325931549072\n",
      "pca 26 replace min diff -8.919142723083496 max diff 1.7314033508300781 avg diff -2.710315704345703\n",
      "pca 31 replace min diff -7.971835136413574 max diff 1.7389650344848633 avg diff -2.910799741744995\n",
      "pca 36 replace min diff -7.82713508605957 max diff 1.1897377967834473 avg diff -2.9427006244659424\n",
      "pca 41 replace min diff -8.441636085510254 max diff 1.600846290588379 avg diff -3.3408656120300293\n",
      "pca 46 replace min diff -9.645776748657227 max diff 1.5369129180908203 avg diff -3.474529504776001\n",
      "pca 51 replace min diff -10.496797561645508 max diff 0.248779296875 avg diff -3.81083083152771\n",
      "pca 56 replace min diff -8.755396842956543 max diff 0.24278831481933594 avg diff -3.885650873184204\n",
      "pca 61 replace min diff -11.150490760803223 max diff 0.4462156295776367 avg diff -4.142153263092041\n",
      "pca 66 replace min diff -9.073711395263672 max diff 0.8152923583984375 avg diff -4.223395824432373\n",
      "pca 71 replace min diff -8.688760757446289 max diff 0.28945446014404297 avg diff -4.340442180633545\n",
      "pca 76 replace min diff -9.15414810180664 max diff -0.8808870315551758 avg diff -4.480126857757568\n",
      "pca 81 replace min diff -9.430322647094727 max diff -0.569371223449707 avg diff -4.623082637786865\n",
      "pca 86 replace min diff -11.85174560546875 max diff -0.02276611328125 avg diff -4.782935619354248\n",
      "pca 91 replace min diff -9.480352401733398 max diff -0.3169670104980469 avg diff -4.726596832275391\n",
      "pca 96 replace min diff -9.863895416259766 max diff -0.45804882049560547 avg diff -5.036709308624268\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "x=%{x}<br>num incorrect=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1,
          6,
          11,
          16,
          21,
          26,
          31,
          36,
          41,
          46,
          51,
          56,
          61,
          66,
          71,
          76,
          81,
          86,
          91,
          96
         ],
         "xaxis": "x",
         "y": [
          46,
          35,
          26,
          25,
          21,
          14,
          10,
          5,
          6,
          5,
          1,
          2,
          1,
          2,
          2,
          0,
          0,
          0,
          0,
          0
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": true,
        "barmode": "relative",
        "font": {
         "color": "black",
         "size": 10
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "projective pca reduction num incorrect / 202"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -1.5,
          98.5
         ],
         "tickmode": "array",
         "ticktext": [
          1,
          6,
          11,
          16,
          21,
          26,
          31,
          36,
          41,
          46,
          51,
          56,
          61,
          66,
          71,
          76,
          81,
          86,
          91,
          96
         ],
         "tickvals": [
          1,
          6,
          11,
          16,
          21,
          26,
          31,
          36,
          41,
          46,
          51,
          56,
          61,
          66,
          71,
          76,
          81,
          86,
          91,
          96
         ],
         "title": {
          "text": "x"
         },
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          48.421052631578945
         ],
         "title": {
          "text": "num incorrect"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"a35b1e48-9602-4f04-9fed-02cafa87a37a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a35b1e48-9602-4f04-9fed-02cafa87a37a\")) {                    Plotly.newPlot(                        \"a35b1e48-9602-4f04-9fed-02cafa87a37a\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}\\u003cbr\\u003enum incorrect=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[1,6,11,16,21,26,31,36,41,46,51,56,61,66,71,76,81,86,91,96],\"xaxis\":\"x\",\"y\":[46,35,26,25,21,14,10,5,6,5,1,2,1,2,2,0,0,0,0,0],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"},\"tickmode\":\"array\",\"tickvals\":[1,6,11,16,21,26,31,36,41,46,51,56,61,66,71,76,81,86,91,96],\"ticktext\":[1,6,11,16,21,26,31,36,41,46,51,56,61,66,71,76,81,86,91,96]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"num incorrect\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"projective pca reduction num incorrect \\u002f 202\"},\"barmode\":\"relative\",\"font\":{\"size\":10,\"color\":\"black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a35b1e48-9602-4f04-9fed-02cafa87a37a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.82138442993164 11.173883438110352\n",
      "12.736701965332031 10.217185974121094\n",
      "8.846115112304688 6.645937442779541\n",
      "7.833235740661621 6.569667816162109\n",
      "11.275167465209961 9.637931823730469\n",
      "11.706157684326172 10.110433578491211\n",
      "10.820472717285156 9.33121109008789\n",
      "9.343393325805664 9.4407377243042\n",
      "7.741237640380859 5.295808792114258\n",
      "11.029853820800781 7.26798152923584\n",
      "9.24068832397461 8.79992389678955\n",
      "12.335310935974121 7.3508076667785645\n",
      "11.4617919921875 10.812494277954102\n",
      "12.249700546264648 9.514029502868652\n",
      "9.796886444091797 9.914495468139648\n",
      "10.353769302368164 8.812589645385742\n",
      "13.758966445922852 9.780296325683594\n",
      "11.305784225463867 10.323810577392578\n",
      "7.346553325653076 5.561267852783203\n",
      "6.7610931396484375 6.760856628417969\n",
      "12.463811874389648 11.240272521972656\n",
      "11.58830738067627 11.424102783203125\n",
      "11.935590744018555 9.477813720703125\n",
      "10.57258415222168 9.6211519241333\n",
      "12.906749725341797 9.574055671691895\n",
      "12.236769676208496 10.673309326171875\n",
      "8.085566520690918 9.532452583312988\n",
      "11.367392539978027 7.331670761108398\n",
      "9.44795036315918 5.439880847930908\n",
      "8.970124244689941 7.604208469390869\n",
      "9.568976402282715 10.046334266662598\n",
      "10.426973342895508 7.972574710845947\n",
      "11.153364181518555 6.23821496963501\n",
      "9.093563079833984 9.273422241210938\n",
      "9.705839157104492 8.230713844299316\n",
      "9.845163345336914 9.030946731567383\n",
      "8.61175537109375 6.784881591796875\n",
      "8.1769437789917 5.850738048553467\n",
      "13.15955924987793 10.660138130187988\n",
      "11.52824592590332 13.080982208251953\n",
      "9.138144493103027 7.357149600982666\n",
      "9.617812156677246 6.641775131225586\n",
      "7.178480625152588 7.275465965270996\n",
      "7.993780136108398 5.953423976898193\n",
      "11.678421020507812 10.713802337646484\n",
      "12.163931846618652 10.626363754272461\n",
      "8.071128845214844 6.695095539093018\n",
      "8.767404556274414 6.991397857666016\n",
      "10.45274829864502 9.172473907470703\n",
      "10.720008850097656 9.83204460144043\n",
      "10.372379302978516 6.889727592468262\n",
      "7.009171009063721 7.680910587310791\n",
      "8.584653854370117 2.1995954513549805\n",
      "6.501134872436523 6.687055587768555\n",
      "10.292490005493164 8.57479476928711\n",
      "10.871880531311035 11.175724983215332\n",
      "10.157279968261719 5.042340278625488\n",
      "8.931731224060059 8.045745849609375\n",
      "7.343886375427246 8.759236335754395\n",
      "9.946905136108398 7.241683006286621\n",
      "8.011834144592285 5.217484474182129\n",
      "7.777530193328857 8.136749267578125\n",
      "7.854931831359863 6.8462324142456055\n",
      "7.600063323974609 5.9740190505981445\n",
      "9.880928993225098 10.607848167419434\n",
      "11.441099166870117 8.816179275512695\n",
      "10.102273941040039 8.818135261535645\n",
      "10.355039596557617 8.35733699798584\n",
      "10.02355670928955 10.525150299072266\n",
      "9.980942726135254 8.55744743347168\n",
      "8.919565200805664 7.377824306488037\n",
      "8.014500617980957 7.8161821365356445\n",
      "8.082802772521973 6.254266262054443\n",
      "11.87661075592041 8.519800186157227\n",
      "10.36467456817627 10.137242317199707\n",
      "11.525394439697266 9.578553199768066\n",
      "11.112127304077148 10.043296813964844\n",
      "9.942113876342773 10.388795852661133\n",
      "10.340627670288086 10.38489818572998\n",
      "11.189665794372559 8.554141998291016\n",
      "10.482337951660156 9.6416015625\n",
      "11.092926025390625 8.462176322937012\n",
      "9.085617065429688 6.455327033996582\n",
      "9.882442474365234 8.481016159057617\n",
      "9.939321517944336 10.563427925109863\n",
      "12.193060874938965 9.030574798583984\n",
      "9.368901252746582 11.42994499206543\n",
      "12.560968399047852 8.981766700744629\n",
      "8.631667137145996 9.08941650390625\n",
      "9.766006469726562 7.052516937255859\n",
      "12.750507354736328 11.585031509399414\n",
      "13.86790657043457 11.32711410522461\n",
      "8.767786979675293 9.437551498413086\n",
      "11.291702270507812 6.035971641540527\n",
      "8.143950462341309 6.657054901123047\n",
      "8.331369400024414 5.593354225158691\n",
      "9.006256103515625 6.433910846710205\n",
      "7.76837158203125 7.088249206542969\n",
      "13.209383964538574 6.946290969848633\n",
      "11.771954536437988 10.52676010131836\n",
      "6.604437828063965 5.945704936981201\n",
      "9.604927062988281 4.239669322967529\n",
      "6.498605728149414 7.74258279800415\n",
      "8.063379287719727 6.335928916931152\n",
      "11.245794296264648 10.385636329650879\n",
      "9.274681091308594 8.268399238586426\n",
      "12.649630546569824 9.217443466186523\n",
      "11.596834182739258 11.266002655029297\n",
      "10.577555656433105 10.347478866577148\n",
      "10.874801635742188 8.240960121154785\n",
      "9.705839157104492 8.230713844299316\n",
      "9.845163345336914 9.030946731567383\n",
      "10.976018905639648 10.999357223510742\n",
      "7.618655204772949 5.923557758331299\n",
      "7.740528583526611 6.883609771728516\n",
      "8.456459045410156 5.746333599090576\n",
      "9.757234573364258 9.329662322998047\n",
      "11.488872528076172 10.028802871704102\n",
      "9.333450317382812 10.927244186401367\n",
      "10.560724258422852 7.579588890075684\n",
      "13.225317001342773 7.90593147277832\n",
      "10.331476211547852 13.603246688842773\n",
      "10.820472717285156 9.33121109008789\n",
      "9.343393325805664 9.4407377243042\n",
      "11.19087028503418 8.692405700683594\n",
      "10.086915016174316 10.87360954284668\n",
      "10.202108383178711 8.780006408691406\n",
      "9.685901641845703 9.203184127807617\n",
      "10.121858596801758 11.52665901184082\n",
      "11.293508529663086 9.64724349975586\n",
      "10.143451690673828 10.562411308288574\n",
      "11.752883911132812 9.691624641418457\n",
      "6.5698041915893555 5.4159440994262695\n",
      "6.250579833984375 5.271914482116699\n",
      "11.442590713500977 7.242542266845703\n",
      "9.511819839477539 10.050323486328125\n",
      "10.38708209991455 11.03580379486084\n",
      "10.666099548339844 7.358905792236328\n",
      "9.636833190917969 5.889793395996094\n",
      "10.958550453186035 8.762382507324219\n",
      "11.237150192260742 9.311643600463867\n",
      "10.727337837219238 8.99577522277832\n",
      "10.913508415222168 9.263092041015625\n",
      "10.930493354797363 10.362013816833496\n",
      "11.06956672668457 7.510549545288086\n",
      "8.053606033325195 10.21324634552002\n",
      "11.883007049560547 8.593852996826172\n",
      "10.630781173706055 9.921819686889648\n",
      "10.55055046081543 11.06204891204834\n",
      "10.363893508911133 8.861485481262207\n",
      "11.81227970123291 11.460952758789062\n",
      "12.305299758911133 9.944406509399414\n",
      "11.917722702026367 12.092464447021484\n",
      "13.397371292114258 11.019512176513672\n",
      "10.808452606201172 11.301603317260742\n",
      "12.303353309631348 9.940918922424316\n",
      "8.465506553649902 8.433185577392578\n",
      "10.081113815307617 8.19450569152832\n",
      "7.7534074783325195 8.943455696105957\n",
      "10.605315208435059 8.789491653442383\n",
      "10.19941520690918 9.749045372009277\n",
      "11.231992721557617 8.155952453613281\n",
      "8.325687408447266 8.213493347167969\n",
      "9.075226783752441 8.483946800231934\n",
      "11.569820404052734 10.559743881225586\n",
      "11.743306159973145 10.061901092529297\n",
      "10.482376098632812 10.617559432983398\n",
      "11.359151840209961 10.052759170532227\n",
      "7.7663164138793945 8.385099411010742\n",
      "9.129294395446777 7.348080158233643\n",
      "10.865220069885254 8.130353927612305\n",
      "8.043354988098145 9.080892562866211\n",
      "9.403135299682617 11.191118240356445\n",
      "12.229394912719727 9.155508995056152\n",
      "5.430807590484619 4.843462944030762\n",
      "5.57808780670166 1.9580473899841309\n",
      "10.483532905578613 9.353864669799805\n",
      "11.181320190429688 11.00922679901123\n",
      "8.289859771728516 7.422601699829102\n",
      "8.618532180786133 7.104608535766602\n",
      "11.890957832336426 8.626033782958984\n",
      "10.324531555175781 10.76175308227539\n",
      "11.185176849365234 9.262042045593262\n",
      "7.4928975105285645 6.53530216217041\n",
      "12.649630546569824 9.217443466186523\n",
      "11.596834182739258 11.266002655029297\n",
      "9.368901252746582 11.42994499206543\n",
      "12.560968399047852 8.981766700744629\n",
      "9.819631576538086 9.461490631103516\n",
      "11.687419891357422 9.635668754577637\n",
      "9.666617393493652 9.291219711303711\n",
      "10.80374813079834 8.969524383544922\n",
      "8.709712028503418 9.432348251342773\n",
      "9.512109756469727 6.584179878234863\n",
      "9.898179054260254 6.0724334716796875\n",
      "7.772026062011719 8.70802116394043\n",
      "9.348716735839844 8.872407913208008\n",
      "8.064765930175781 8.2152099609375\n",
      "10.178813934326172 9.813162803649902\n",
      "9.68673324584961 9.201980590820312\n",
      "12.302922248840332 9.306802749633789\n",
      "11.566715240478516 11.800349235534668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_x = pca_sizes[:len(replace_corrects)]\n",
    "data_y = []\n",
    "for i in range(len(replace_corrects)):\n",
    "    replace_diff = -torch.tensor(replace_corrects[i]) + torch.tensor(replace_replaces[i])\n",
    "    n_correct = torch.sum(replace_diff > 0)\n",
    "    data_y.append(n_correct)\n",
    "    print(f'pca {data_x[i]} replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "\n",
    "data_y = torch.tensor(data_y, device=model.cfg.device)\n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "bar_chart(data_y, x_labels=data_x, y_label='num incorrect', title=f'projective pca reduction num incorrect / {len(replace_replaces[0])}', font_size=10)\n",
    "\n",
    "for i in range(len(replace_corrects[0])):\n",
    "    print(replace_corrects[0][i], replace_replaces[0][i])\n",
    "#patched_diff = -torch.tensor(patched_correct) + torch.tensor(patched_replace)\n",
    "\n",
    "#print(n_correct_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f369477e-4828-477e-b16b-d882309f5184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(len(name_tokens))\n",
    "pca = PCA(n_components=pca_dim)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d78207-1556-4aaf-bffb-b609de24f15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4854c-42c7-4696-a92b-b3401d460bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79a7ebf1-7fc4-473c-9ebc-3a4542f0ca63",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m answer_tok \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcorrect[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     17\u001b[0m template \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdata[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 18\u001b[0m components \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_proj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m grouped_by_answers[answer_tok]\u001b[38;5;241m.\u001b[39mappend((components[component_1], components[component_2]))\n\u001b[1;32m     20\u001b[0m grouped_by_template[template]\u001b[38;5;241m.\u001b[39mappend((components[component_1], components[component_2]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/decomposition/_base.py:145\u001b[0m, in \u001b[0;36m_BasePCA.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    141\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    143\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1049\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:121\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    122\u001b[0m     first_pass_isfinite \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misfinite(xp\u001b[38;5;241m.\u001b[39msum(X))\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:431\u001b[0m, in \u001b[0;36merrstate.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldstate \u001b[38;5;241m=\u001b[39m \u001b[43mseterr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Unspecified:\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldcall \u001b[38;5;241m=\u001b[39m seterrcall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:111\u001b[0m, in \u001b[0;36mseterr\u001b[0;34m(all, divide, over, under, invalid)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mSet how floating-point errors are handled.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m pyvals \u001b[38;5;241m=\u001b[39m umath\u001b[38;5;241m.\u001b[39mgeterrobj()\n\u001b[0;32m--> 111\u001b[0m old \u001b[38;5;241m=\u001b[39m \u001b[43mgeterr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m divide \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     divide \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m old[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivide\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:168\u001b[0m, in \u001b[0;36mgeterr\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgeterr\u001b[39m():\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    Get the current way of handling floating-point errors.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     maskvalue \u001b[38;5;241m=\u001b[39m \u001b[43mumath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeterrobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    169\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[1;32m    170\u001b[0m     res \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name_points = []\n",
    "pca_dim = 90\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "\n",
    "\n",
    "for component_1 in range(0, pca_dim, 2):\n",
    "    component_2 = component_1 + 1\n",
    "    grouped_by_answers = defaultdict(lambda: [])\n",
    "    grouped_by_template = defaultdict(lambda: [])\n",
    "        \n",
    "    for i in range(X.shape[0]):\n",
    "        answer_tok = data.correct[i][0].item()\n",
    "        template = data.data[i][1].item()\n",
    "        components = pca.transform(X_proj[i].reshape(1, -1)).reshape(-1)\n",
    "        grouped_by_answers[answer_tok].append((components[component_1], components[component_2]))\n",
    "        grouped_by_template[template].append((components[component_1], components[component_2]))\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    grouped_by_answers = sorted(list(grouped_by_answers.items()))[:20]\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(grouped_by_answers)))\n",
    "    \n",
    "    for (answer_i, points), c in zip(grouped_by_answers, colors):\n",
    "        x = np.array([point[0] for point in points])\n",
    "        y = np.array([point[1] for point in points])\n",
    "        plt.scatter(x, y, color=c)\n",
    "    plt.title(f'components {component_1} {component_2} colored by name')\n",
    "    plt.savefig(f'{component_1} {component_2} name.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    grouped_by_template = sorted(list(grouped_by_template.items()))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(grouped_by_template)))\n",
    "    \n",
    "    for (answer_i, points), c in zip(grouped_by_template, colors):\n",
    "        x = np.array([point[0] for point in points])\n",
    "        y = np.array([point[1] for point in points])\n",
    "        plt.scatter(x, y, color=c)\n",
    "    plt.title(f'components {component_1} {component_2} colored by template')\n",
    "    plt.savefig(f'{component_1} {component_2} template.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "862073d2-6a9f-410a-bc91-071871ac0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then, [NAME], [NAME] and [NAME] went to the [PLACE]. [NAME] and [NAME] gave a [OBJECT] to\n",
      "Afterwards [NAME], [NAME] and [NAME] went to the [PLACE]. [NAME] and [NAME] gave a [OBJECT] to\n",
      "When [NAME], [NAME] and [NAME] arrived at the [PLACE], [NAME] and [NAME] gave a [OBJECT] to\n",
      "Friends [NAME], [NAME] and [NAME] went to the [PLACE]. [NAME] and [NAME] gave a [OBJECT] to\n"
     ]
    }
   ],
   "source": [
    "for x in ABC_TEMPLATES:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b3da994c-a396-498d-80f4-542563c2580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get positive examples\n",
      "get negative examples\n",
      "shuffle data\n",
      "training erasers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/209 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                  | 1/209 [00:00<02:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1176, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                  | 2/209 [00:01<01:57,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                 | 3/209 [00:01<01:54,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                 | 4/209 [00:02<01:52,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                 | 5/209 [00:02<01:52,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                | 6/209 [00:03<01:51,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                | 7/209 [00:03<01:54,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                               | 8/209 [00:04<01:52,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                               | 9/209 [00:05<01:55,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1300, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                              | 10/209 [00:05<01:55,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1220, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                             | 11/209 [00:06<01:54,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                             | 12/209 [00:06<01:51,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                             | 13/209 [00:07<01:51,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                            | 14/209 [00:07<01:53,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▉                                                                            | 15/209 [00:08<01:51,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▎                                                                           | 16/209 [00:09<01:49,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                           | 17/209 [00:09<01:48,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████                                                                           | 18/209 [00:10<01:47,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1152, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▍                                                                          | 19/209 [00:10<01:46,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▊                                                                          | 20/209 [00:11<01:45,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▏                                                                         | 21/209 [00:11<01:44,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1192, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▋                                                                         | 22/209 [00:12<01:48,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1244, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████                                                                         | 23/209 [00:13<01:51,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▍                                                                        | 24/209 [00:13<01:48,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▊                                                                        | 25/209 [00:14<01:47,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▏                                                                       | 26/209 [00:14<01:45,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1220, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▌                                                                       | 27/209 [00:15<01:44,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▉                                                                       | 28/209 [00:15<01:43,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▍                                                                      | 29/209 [00:16<01:42,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▊                                                                      | 30/209 [00:17<01:40,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▏                                                                     | 31/209 [00:17<01:40,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1080, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▌                                                                     | 32/209 [00:18<01:43,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▉                                                                     | 33/209 [00:18<01:41,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▎                                                                    | 34/209 [00:19<01:40,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▋                                                                    | 35/209 [00:19<01:40,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████                                                                    | 36/209 [00:20<01:41,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                   | 37/209 [00:21<01:41,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1236, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▉                                                                   | 38/209 [00:21<01:39,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▎                                                                  | 39/209 [00:22<01:38,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1152, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▋                                                                  | 40/209 [00:22<01:37,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1240, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████                                                                  | 41/209 [00:23<01:38,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▍                                                                 | 42/209 [00:24<01:36,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▊                                                                 | 43/209 [00:24<01:35,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████▎                                                                | 44/209 [00:25<01:35,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1280, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▋                                                                | 45/209 [00:25<01:39,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████                                                                | 46/209 [00:26<01:36,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▍                                                               | 47/209 [00:27<01:37,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▊                                                               | 48/209 [00:27<01:36,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▏                                                              | 49/209 [00:28<01:34,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▌                                                              | 50/209 [00:28<01:31,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████                                                              | 51/209 [00:29<01:29,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▍                                                             | 52/209 [00:29<01:28,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                             | 53/209 [00:30<01:28,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████▏                                                            | 54/209 [00:30<01:26,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████▌                                                            | 55/209 [00:31<01:25,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([996, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▉                                                            | 56/209 [00:32<01:23,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████▎                                                           | 57/209 [00:32<01:24,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▊                                                           | 58/209 [00:33<01:23,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1292, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████▏                                                          | 59/209 [00:33<01:24,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▌                                                          | 60/209 [00:34<01:23,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1060, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▉                                                          | 61/209 [00:34<01:21,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1100, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▎                                                         | 62/209 [00:35<01:20,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▋                                                         | 63/209 [00:35<01:20,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████                                                         | 64/209 [00:36<01:20,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▌                                                        | 65/209 [00:37<01:19,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████▉                                                        | 66/209 [00:37<01:18,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████▎                                                       | 67/209 [00:38<01:17,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████▋                                                       | 68/209 [00:38<01:17,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1244, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████                                                       | 69/209 [00:39<01:17,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████▍                                                      | 70/209 [00:39<01:16,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1292, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▊                                                      | 71/209 [00:40<01:19,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████▏                                                     | 72/209 [00:41<01:18,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1328, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████▋                                                     | 73/209 [00:41<01:18,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                     | 74/209 [00:42<01:24,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▍                                                    | 75/209 [00:42<01:20,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▊                                                    | 76/209 [00:43<01:18,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████▏                                                   | 77/209 [00:44<01:16,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████▌                                                   | 78/209 [00:44<01:16,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1176, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▉                                                   | 79/209 [00:45<01:15,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▍                                                  | 80/209 [00:45<01:13,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████▊                                                  | 81/209 [00:46<01:13,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████▏                                                 | 82/209 [00:46<01:11,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▌                                                 | 83/209 [00:47<01:10,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▉                                                 | 84/209 [00:47<01:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████▎                                                | 85/209 [00:48<01:09,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████▋                                                | 86/209 [00:49<01:09,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▏                                               | 87/209 [00:49<01:07,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▌                                               | 88/209 [00:50<01:08,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▉                                               | 89/209 [00:50<01:09,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████▎                                              | 90/209 [00:51<01:08,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1100, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████▋                                              | 91/209 [00:51<01:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████                                              | 92/209 [00:52<01:08,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████▍                                             | 93/209 [00:53<01:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1056, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████▉                                             | 94/209 [00:53<01:04,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1080, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                            | 95/209 [00:54<01:06,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▋                                            | 96/209 [00:54<01:05,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████                                            | 97/209 [00:55<01:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████▍                                           | 98/209 [00:55<01:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████▊                                           | 99/209 [00:56<01:01,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▊                                          | 100/209 [00:57<01:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████▏                                         | 101/209 [00:57<01:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████▌                                         | 102/209 [00:58<01:06,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████▉                                         | 103/209 [00:58<01:03,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▎                                        | 104/209 [00:59<01:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1224, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▋                                        | 105/209 [01:00<01:01,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([976, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████                                        | 106/209 [01:00<00:59,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1044, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████▍                                       | 107/209 [01:01<01:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████▊                                       | 108/209 [01:01<01:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████▏                                      | 109/209 [01:02<01:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████▋                                      | 110/209 [01:03<01:01,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1244, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████████████████████████████                                      | 111/209 [01:03<00:59,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████▍                                     | 112/209 [01:04<00:58,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████▊                                     | 113/209 [01:04<00:56,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1224, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████▏                                    | 114/209 [01:05<00:55,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████▌                                    | 115/209 [01:06<00:54,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▉                                    | 116/209 [01:06<00:53,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████▎                                   | 117/209 [01:07<00:53,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1036, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████▋                                   | 118/209 [01:07<00:53,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████                                   | 119/209 [01:08<00:53,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1280, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████▌                                  | 120/209 [01:08<00:52,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████▉                                  | 121/209 [01:09<00:51,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████▎                                 | 122/209 [01:10<00:50,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████▋                                 | 123/209 [01:10<00:49,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████████████                                 | 124/209 [01:11<00:48,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1060, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████▍                                | 125/209 [01:11<00:47,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1216, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████▊                                | 126/209 [01:12<00:47,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████▏                               | 127/209 [01:13<00:48,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1020, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████▌                               | 128/209 [01:13<00:46,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████▉                               | 129/209 [01:14<00:45,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████▍                              | 130/209 [01:14<00:44,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▊                              | 131/209 [01:15<00:43,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1168, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████▏                             | 132/209 [01:15<00:42,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▌                             | 133/209 [01:16<00:42,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([932, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▉                             | 134/209 [01:16<00:40,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1008, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████▎                            | 135/209 [01:17<00:40,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1084, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████▋                            | 136/209 [01:17<00:40,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████                            | 137/209 [01:18<00:40,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([980, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████▍                           | 138/209 [01:19<00:39,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1116, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████▊                           | 139/209 [01:19<00:38,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████▎                          | 140/209 [01:20<00:38,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1032, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████▋                          | 141/209 [01:20<00:37,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1260, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████                          | 142/209 [01:21<00:37,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████▍                         | 143/209 [01:21<00:38,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████▊                         | 144/209 [01:22<00:39,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1076, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████▏                        | 145/209 [01:23<00:39,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▌                        | 146/209 [01:23<00:37,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▉                        | 147/209 [01:24<00:35,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████▎                       | 148/209 [01:24<00:34,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████▋                       | 149/209 [01:25<00:34,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████▏                      | 150/209 [01:26<00:33,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████▌                      | 151/209 [01:26<00:33,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████▉                      | 152/209 [01:27<00:32,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████████████▎                     | 153/209 [01:27<00:31,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1168, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████▋                     | 154/209 [01:28<00:31,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████████████                     | 155/209 [01:28<00:31,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1260, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████▍                    | 156/209 [01:29<00:31,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1008, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████▊                    | 157/209 [01:30<00:29,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████▏                   | 158/209 [01:30<00:28,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████▌                   | 159/209 [01:31<00:28,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████████                   | 160/209 [01:31<00:27,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████████▍                  | 161/209 [01:32<00:26,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1128, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████▊                  | 162/209 [01:32<00:26,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████▏                 | 163/209 [01:33<00:26,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████▌                 | 164/209 [01:33<00:25,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████▉                 | 165/209 [01:34<00:24,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████████▎                | 166/209 [01:35<00:25,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1044, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████▋                | 167/209 [01:35<00:23,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████                | 168/209 [01:36<00:23,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████▍               | 169/209 [01:36<00:22,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████▉               | 170/209 [01:37<00:21,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1052, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████▎              | 171/209 [01:37<00:21,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1128, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████▋              | 172/209 [01:38<00:20,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1084, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████              | 173/209 [01:39<00:20,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████▍             | 174/209 [01:39<00:19,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████▊             | 175/209 [01:40<00:19,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1060, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████▏            | 176/209 [01:40<00:18,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████▌            | 177/209 [01:41<00:18,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████▉            | 178/209 [01:41<00:18,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████▎           | 179/209 [01:42<00:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([960, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████▊           | 180/209 [01:43<00:16,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████▏          | 181/209 [01:43<00:15,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████▌          | 182/209 [01:44<00:15,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1128, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████▉          | 183/209 [01:44<00:14,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1168, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████▎         | 184/209 [01:45<00:14,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████▋         | 185/209 [01:45<00:13,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1188, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████         | 186/209 [01:46<00:13,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1052, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████▍        | 187/209 [01:47<00:12,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1148, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████▊        | 188/209 [01:47<00:12,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▏       | 189/209 [01:48<00:11,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████▋       | 190/209 [01:48<00:10,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1084, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████       | 191/209 [01:49<00:10,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████▍      | 192/209 [01:49<00:09,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1028, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████▊      | 193/209 [01:50<00:08,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████▏     | 194/209 [01:50<00:08,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████▌     | 195/209 [01:51<00:07,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▉     | 196/209 [01:52<00:07,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████▎    | 197/209 [01:52<00:06,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1080, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████████▋    | 198/209 [01:53<00:06,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████    | 199/209 [01:53<00:05,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████▌   | 200/209 [01:54<00:05,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████▉   | 201/209 [01:55<00:04,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1028, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████████▎  | 202/209 [01:55<00:04,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████████▋  | 203/209 [01:56<00:03,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████  | 204/209 [01:56<00:02,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████▍ | 205/209 [01:57<00:02,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████▊ | 206/209 [01:57<00:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1252, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████▏| 207/209 [01:58<00:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1188, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████▌| 208/209 [01:59<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1036, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 209/209 [01:59<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "from concept_erasure import LeaceEraser\n",
    "from collections import defaultdict\n",
    "X_data_by_name = defaultdict(lambda: [])\n",
    "Y_data_by_name = defaultdict(lambda: [])\n",
    "X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "\n",
    "# gather positive examples\n",
    "print(\"get positive examples\")\n",
    "for i in range(X_proj.shape[0]):\n",
    "    answer_tok = data.correct[i][0].item()\n",
    "    X_data_by_name[answer_tok].append(X_proj[i])\n",
    "    Y_data_by_name[answer_tok].append([1.0,0.0])\n",
    "\n",
    "# gather negative examples\n",
    "print(\"get negative examples\")\n",
    "for answer, X_data in X_data_by_name.items():\n",
    "    num_points = len(X_data)\n",
    "    while len(X_data) < num_points*2:\n",
    "        random_data_i = random.randint(0, X_proj.shape[0]-1)\n",
    "        random_data_answer = data.correct[random_data_i][0].item()\n",
    "        if random_data_answer != answer:\n",
    "            X_data.append(X_proj[random_data_i])\n",
    "            Y_data_by_name[answer].append([0.0, 1.0])\n",
    "\n",
    "# shuffle data\n",
    "print(\"shuffle data\")\n",
    "for answer in list(X_data_by_name.keys()):\n",
    "    inds = list(range(len(X_data_by_name[answer])))\n",
    "    random.shuffle(inds)\n",
    "    X_data_by_name[answer] = [X_data_by_name[answer][i] for i in inds]\n",
    "    Y_data_by_name[answer] = [Y_data_by_name[answer][i] for i in inds]\n",
    "\n",
    "print(\"training erasers\")\n",
    "# train leace\n",
    "name_erasers = {}\n",
    "\n",
    "\n",
    "for answer in tqdm(list(X_data_by_name.keys())):\n",
    "    Xd, Yd = X_data_by_name[answer], Y_data_by_name[answer]\n",
    "    Xd = torch.tensor(Xd, device=model.cfg.device)\n",
    "    Yd = torch.tensor(Yd, device=model.cfg.device)\n",
    "    print(Xd.size())\n",
    "    name_erasers[answer] = LeaceEraser.fit(Xd, Yd)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e8d4940a-afa0-42a5-b71a-fc3878dd24b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "replace_corrects = []\n",
    "replace_replaces = []\n",
    "original_corrects = []\n",
    "original_replaces = []\n",
    "#pca_sizes = []\n",
    "#X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "#print(X_proj[:,-1])\n",
    "\n",
    "# subtract to erase\n",
    "# add to add\n",
    "def apply_eraser(eraser, x):\n",
    "    delta = x - eraser.bias\n",
    "    diff = (delta @ eraser.proj_right.mH) @ eraser.proj_left.mH\n",
    "    return x - diff\n",
    "\n",
    "def invert_eraser(eraser, x):\n",
    "    # (AB)^-1 = B^-1 A^-1\n",
    "    eye = torch.eye(x.size()[0], device=model.cfg.device, dtype=eraser.proj_left.dtype)\n",
    "    \n",
    "    #Inv = torch.linalg.inv(eraser.proj_right.mH @ eraser.proj_left.mH)\n",
    "    #Inv = torch.linalg.pinv(eye-eraser.proj_right.mH @ eraser.proj_left.mH)\n",
    "    # approximation to the inverse\n",
    "    res = eye\n",
    "    prod = eraser.proj_right.mH @ eraser.proj_left.mH\n",
    "    for i in range(40):\n",
    "        res += prod\n",
    "        prod = prod @ eraser.proj_right.mH @ eraser.proj_left.mH\n",
    "    #print(f\"inverse {Inv}\")\n",
    "    bA = (eraser.bias @ eraser.proj_right.mH) @ eraser.proj_left.mH\n",
    "    return (x-bA)@res\n",
    "\n",
    "for _ in range(1):\n",
    "    original_correct = []\n",
    "    original_replace = []\n",
    "    replace_correct = []\n",
    "    replace_replace = []\n",
    "    print(f\"layer {layer}\")\n",
    "    name_bases = [0]\n",
    "    for position_1, name_basis in enumerate(name_bases):\n",
    "        num_found = 0\n",
    "        while True:            \n",
    "            data_i = random.choice(list(range(10000)))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i]\n",
    "            corrupted_tokens = data.data[data_i+1]\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            \n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                answer_name_tok,\n",
    "                replace_name_tok,\n",
    "            ):\n",
    "                B,L,E = x.size()\n",
    "                for b in range(B):\n",
    "                    veco = torch.concatenate([x[b,position], torch.tensor([1.0], device=model.cfg.device)])\n",
    "                    vec = apply_eraser(name_erasers[answer_name_tok], veco)\n",
    "                    vec2 = invert_eraser(name_erasers[replace_name_tok], vec)\n",
    "                    invert_diff = vec2 - vec\n",
    "                    vec = vec + invert_diff*100\n",
    "                    # we can do vec + diff to get vec2\n",
    "                    # instead we will do vec - diff to do inverse\n",
    "                    #vec = vec2\n",
    "                    \n",
    "                    #print(vec)\n",
    "                    #print(\"done\")\n",
    "                    x[b,position] = vec[:-1]\n",
    "\n",
    "                    #add_ones = np.concatenate([vec.detach().cpu().numpy(), np.array([1.0])], axis=0).reshape(1,-1)\n",
    "                    #pcad = pca.transform(add_ones)\n",
    "                    #x[b,position] = torch.tensor(pca.inverse_transform(pcad), device=model.cfg.device).reshape(-1)[:-1]\n",
    "                    '''\n",
    "                    coords = name_basis.map_to_coords(vec/torch.linalg.norm(vec, ord=2))\n",
    "                    C = len(name_tok_to_class)\n",
    "                    sorted = torch.argsort(coords[:C])\n",
    "                    print(coords[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"predict {maxi} {coords[maxi]}\")\n",
    "                    print(f\"answer {name_tok_to_class[answer_name_tok]} replace {name_tok_to_class[replace_name_tok]}\")\n",
    "                    coords[name_tok_to_class[answer_name_tok]] = -0.0692\n",
    "                    coords[name_tok_to_class[replace_name_tok]] = 0.0692\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"now predict {maxi} {coords[maxi]}\")\n",
    "                    patched_vec = name_basis.map_from_coords(coords)\n",
    "                    print(f\"orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    patched_veco = patched_vec / torch.linalg.norm(patched_vec, ord=2) * torch.linalg.norm(vec, ord=2)\n",
    "                    print(f\"now orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    coords2 = name_basis.map_to_coords(patched_vec)\n",
    "                    sorted = torch.argsort(coords2[:C])\n",
    "                    print(\"predict2\", coords2[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords2[:C])\n",
    "                    print(f\"predict2 {maxi} {coords2[maxi]}\")\n",
    "                    '''\n",
    "                    #x[b,position] = patched_veco\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(data_name_positions)):\n",
    "                position = data_name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            hooks = []\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                \n",
    "                hooks.append((\n",
    "                    f'blocks.{layer}.hook_ssm_input', \n",
    "                    partial(replace_hook,\n",
    "                            position=position+1,\n",
    "                            answer_name_tok=answer_tok,\n",
    "                            replace_name_tok=replace_tok,\n",
    "                    )\n",
    "                ))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            hooks = []\n",
    "            for name_i, position in answer_positions:\n",
    "                hooks.append((\n",
    "                    f'blocks.{layer}.hook_ssm_input', \n",
    "                    partial(replace_hook,\n",
    "                            position=position+1,\n",
    "                            answer_name_tok=replace_tok,\n",
    "                            replace_name_tok=answer_tok,\n",
    "                    )\n",
    "                ))\n",
    "            \n",
    "            logits = model(corrupted_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            original_correct.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            original_replace.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            \n",
    "            logits_modified = model.run_with_hooks(corrupted_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 100:\n",
    "                break\n",
    "        break\n",
    "    original_corrects.append(original_correct)\n",
    "    original_replaces.append(original_replace)\n",
    "    replace_corrects.append(replace_correct)\n",
    "    replace_replaces.append(replace_replace)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1aca3665-2d22-4db2-9cda-852e1f55761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/202\n",
      "replace min diff -68.55792999267578 max diff 69.87189483642578 avg diff -0.19875283539295197\n",
      "h\n",
      "16.470701217651367 9.71561050415039\n",
      "-5.661073684692383 -22.156082153320312\n",
      "h\n",
      "14.580031394958496 9.408432006835938\n",
      "0.48569345474243164 6.747767448425293\n",
      "h\n",
      "14.380048751831055 7.109065055847168\n",
      "-2.442127227783203 -24.21950912475586\n",
      "h\n",
      "16.272052764892578 7.420269966125488\n",
      "-7.698086738586426 62.173805236816406\n",
      "h\n",
      "14.879524230957031 9.761422157287598\n",
      "-3.2463455200195312 25.89336395263672\n",
      "h\n",
      "14.439093589782715 5.619184970855713\n",
      "8.848220825195312 -33.423301696777344\n",
      "h\n",
      "14.669663429260254 8.600264549255371\n",
      "2.081355094909668 -1.9556349515914917\n",
      "h\n",
      "15.520383834838867 7.870769500732422\n",
      "1.4222896099090576 22.22512435913086\n",
      "h\n",
      "17.11648941040039 11.07115650177002\n",
      "-10.067371368408203 -39.855567932128906\n",
      "h\n",
      "14.599285125732422 9.929826736450195\n",
      "-6.593348979949951 -6.830587863922119\n",
      "h\n",
      "16.378326416015625 11.30602741241455\n",
      "5.956884860992432 -38.610435485839844\n",
      "h\n",
      "17.24477195739746 12.21163272857666\n",
      "4.230982780456543 8.75568675994873\n",
      "h\n",
      "17.055301666259766 9.792766571044922\n",
      "-6.7681660652160645 -40.46263122558594\n",
      "h\n",
      "15.095385551452637 8.833169937133789\n",
      "-8.643159866333008 9.353684425354004\n",
      "h\n",
      "17.705638885498047 10.347694396972656\n",
      "-1.1137534379959106 36.980987548828125\n",
      "h\n",
      "17.70909881591797 12.46829891204834\n",
      "4.278864860534668 10.1322021484375\n",
      "h\n",
      "13.674509048461914 2.729785203933716\n",
      "8.848783493041992 14.957258224487305\n",
      "h\n",
      "11.015439987182617 7.332038879394531\n",
      "-0.40244436264038086 6.306756973266602\n",
      "h\n",
      "17.063003540039062 9.478687286376953\n",
      "-0.5124579668045044 -10.10653018951416\n",
      "h\n",
      "17.016000747680664 9.74824333190918\n",
      "-0.053635597229003906 28.03034210205078\n",
      "h\n",
      "14.829706192016602 5.538116931915283\n",
      "0.1917802095413208 50.553794860839844\n",
      "h\n",
      "15.466934204101562 10.313305854797363\n",
      "1.0343191623687744 -2.2826528549194336\n",
      "h\n",
      "12.930335998535156 5.6602678298950195\n",
      "0.40245652198791504 -49.356834411621094\n",
      "h\n",
      "13.753924369812012 6.906387805938721\n",
      "14.573183059692383 40.302452087402344\n",
      "h\n",
      "15.272117614746094 7.513121128082275\n",
      "-1.9908170700073242 25.334665298461914\n",
      "h\n",
      "14.374013900756836 5.310833930969238\n",
      "2.037912368774414 61.625709533691406\n",
      "h\n",
      "13.430246353149414 6.389962196350098\n",
      "-3.8849401473999023 30.17223358154297\n",
      "h\n",
      "12.919710159301758 7.869196891784668\n",
      "-4.0385966300964355 8.03372573852539\n",
      "h\n",
      "17.368846893310547 10.586111068725586\n",
      "-8.072798728942871 5.658577919006348\n",
      "h\n",
      "17.00928497314453 11.611640930175781\n",
      "1.7490825653076172 18.310752868652344\n",
      "h\n",
      "15.7691011428833 6.738853931427002\n",
      "1.6175341606140137 10.121139526367188\n",
      "h\n",
      "14.03289794921875 6.293128967285156\n",
      "-2.97029447555542 -35.81845474243164\n",
      "h\n",
      "14.218904495239258 9.513717651367188\n",
      "5.595700263977051 -18.34531593322754\n",
      "h\n",
      "16.62076187133789 8.895003318786621\n",
      "5.766347885131836 -42.54839324951172\n",
      "h\n",
      "12.203004837036133 6.083037853240967\n",
      "-1.0008347034454346 23.98700714111328\n",
      "h\n",
      "14.704365730285645 7.946584701538086\n",
      "-0.016435742378234863 -14.676387786865234\n",
      "h\n",
      "8.897337913513184 1.077894687652588\n",
      "-3.877026319503784 19.058242797851562\n",
      "h\n",
      "8.121967315673828 -1.0396852493286133\n",
      "-3.933058261871338 47.77484130859375\n",
      "h\n",
      "15.813190460205078 10.41125774383545\n",
      "-4.233362674713135 51.51629638671875\n",
      "h\n",
      "17.074491500854492 8.385383605957031\n",
      "1.612729549407959 9.170707702636719\n",
      "h\n",
      "15.585822105407715 11.576179504394531\n",
      "2.741321325302124 -5.563211441040039\n",
      "h\n",
      "16.00225257873535 8.32889175415039\n",
      "-3.1251511573791504 -39.8695068359375\n",
      "h\n",
      "18.544811248779297 11.8841552734375\n",
      "-2.204787015914917 -15.113668441772461\n",
      "h\n",
      "18.548494338989258 13.399232864379883\n",
      "1.0070135593414307 37.28767776489258\n",
      "h\n",
      "16.36518669128418 10.43846321105957\n",
      "-2.407611608505249 -0.21759843826293945\n",
      "h\n",
      "16.766250610351562 9.270914077758789\n",
      "-3.3712310791015625 30.524829864501953\n",
      "h\n",
      "14.669663429260254 8.600264549255371\n",
      "2.081355094909668 -1.9556349515914917\n",
      "h\n",
      "15.520383834838867 7.870769500732422\n",
      "1.4222896099090576 22.22512435913086\n",
      "h\n",
      "16.39776039123535 7.390601634979248\n",
      "0.17546308040618896 -40.02701187133789\n",
      "h\n",
      "16.6684513092041 10.163793563842773\n",
      "9.735057830810547 -4.866774559020996\n",
      "h\n",
      "14.380048751831055 7.109065055847168\n",
      "-2.442127227783203 -24.21950912475586\n",
      "h\n",
      "16.272052764892578 7.420269966125488\n",
      "-7.698086738586426 62.173805236816406\n",
      "h\n",
      "10.861021041870117 4.524538516998291\n",
      "-0.8411014080047607 32.92559051513672\n",
      "h\n",
      "11.794175148010254 3.1382973194122314\n",
      "6.587797164916992 -3.79280948638916\n",
      "h\n",
      "16.336885452270508 6.245671272277832\n",
      "-9.842906951904297 -47.97581481933594\n",
      "h\n",
      "15.646645545959473 7.008029460906982\n",
      "1.6293400526046753 61.09855651855469\n",
      "h\n",
      "16.299503326416016 9.718326568603516\n",
      "3.4221134185791016 -28.932390213012695\n",
      "h\n",
      "14.449541091918945 11.833253860473633\n",
      "-3.2021055221557617 -35.85157012939453\n",
      "h\n",
      "15.406458854675293 10.657981872558594\n",
      "2.1399261951446533 49.92259979248047\n",
      "h\n",
      "17.072769165039062 11.170125961303711\n",
      "-7.728151798248291 -31.958995819091797\n",
      "h\n",
      "14.30941390991211 7.718364715576172\n",
      "-0.0828852653503418 -27.250425338745117\n",
      "h\n",
      "16.768972396850586 11.284313201904297\n",
      "3.9116079807281494 -54.83154296875\n",
      "h\n",
      "14.224660873413086 6.028111457824707\n",
      "3.5183351039886475 -8.583236694335938\n",
      "h\n",
      "14.157243728637695 4.108088493347168\n",
      "-2.8067798614501953 48.64846420288086\n",
      "h\n",
      "19.83786392211914 12.366390228271484\n",
      "7.711895942687988 0.3670095205307007\n",
      "h\n",
      "18.613697052001953 12.455986022949219\n",
      "-5.930981159210205 30.85239028930664\n",
      "h\n",
      "14.095074653625488 6.3821611404418945\n",
      "9.584667205810547 -30.38941192626953\n",
      "h\n",
      "15.425775527954102 10.400848388671875\n",
      "4.956835746765137 -10.735883712768555\n",
      "h\n",
      "16.855308532714844 9.954970359802246\n",
      "-0.8591716289520264 -7.199571132659912\n",
      "h\n",
      "17.992345809936523 10.363795280456543\n",
      "9.615142822265625 12.433926582336426\n",
      "h\n",
      "11.22191047668457 3.653398275375366\n",
      "1.8061182498931885 -20.239566802978516\n",
      "h\n",
      "9.185664176940918 4.289755821228027\n",
      "0.4170109033584595 -19.251052856445312\n",
      "h\n",
      "16.299503326416016 9.718326568603516\n",
      "3.4221134185791016 -28.932390213012695\n",
      "h\n",
      "14.449541091918945 11.833253860473633\n",
      "-3.2021055221557617 -35.85157012939453\n",
      "h\n",
      "14.052519798278809 9.695889472961426\n",
      "7.987891674041748 -15.997453689575195\n",
      "h\n",
      "14.83008861541748 7.414546489715576\n",
      "-3.505863666534424 -47.1068229675293\n",
      "h\n",
      "16.48956298828125 9.136743545532227\n",
      "-2.1396608352661133 -3.536954402923584\n",
      "h\n",
      "15.77269172668457 9.213828086853027\n",
      "-8.737995147705078 -11.788990020751953\n",
      "h\n",
      "17.51837158203125 9.624862670898438\n",
      "4.503121376037598 -41.50974655151367\n",
      "h\n",
      "16.068586349487305 9.978069305419922\n",
      "1.532455563545227 -15.997509002685547\n",
      "h\n",
      "15.161977767944336 4.8690667152404785\n",
      "2.584624767303467 -13.022727966308594\n",
      "h\n",
      "14.288325309753418 10.116472244262695\n",
      "7.917823314666748 -60.640106201171875\n",
      "h\n",
      "15.050782203674316 10.455619812011719\n",
      "3.980501890182495 9.842601776123047\n",
      "h\n",
      "13.355952262878418 8.135208129882812\n",
      "-3.7414815425872803 12.320381164550781\n",
      "h\n",
      "14.79833984375 10.084672927856445\n",
      "6.437402248382568 55.108848571777344\n",
      "h\n",
      "10.920382499694824 1.7902164459228516\n",
      "-0.6614793539047241 -12.868444442749023\n",
      "h\n",
      "13.344636917114258 7.28670597076416\n",
      "-0.513707160949707 46.30146026611328\n",
      "h\n",
      "16.567476272583008 9.052946090698242\n",
      "2.6877522468566895 20.682714462280273\n",
      "h\n",
      "15.591033935546875 11.579273223876953\n",
      "-6.953457832336426 4.992960453033447\n",
      "h\n",
      "15.871563911437988 8.972944259643555\n",
      "-1.3056917190551758 -16.025474548339844\n",
      "h\n",
      "15.332590103149414 8.09166145324707\n",
      "-1.4696078300476074 9.947774887084961\n",
      "h\n",
      "15.952951431274414 9.328046798706055\n",
      "-8.466363906860352 -33.127723693847656\n",
      "h\n",
      "12.545150756835938 6.543041229248047\n",
      "3.718639850616455 -31.48052406311035\n",
      "h\n",
      "11.745452880859375 4.749141693115234\n",
      "-4.059512615203857 -31.17159652709961\n",
      "h\n",
      "14.710734367370605 7.189019203186035\n",
      "-8.113587379455566 16.371967315673828\n",
      "h\n",
      "15.396932601928711 9.213991165161133\n",
      "-2.7745323181152344 6.283504962921143\n",
      "h\n",
      "15.46364974975586 7.662905693054199\n",
      "-5.817660331726074 -4.512526035308838\n",
      "h\n",
      "15.516579627990723 8.438018798828125\n",
      "7.574199199676514 -40.14968490600586\n",
      "h\n",
      "18.00779914855957 11.00239086151123\n",
      "-3.845308303833008 -25.69446563720703\n",
      "h\n",
      "16.74390411376953 11.326934814453125\n",
      "-5.264564514160156 23.29741859436035\n",
      "h\n",
      "15.607980728149414 8.785783767700195\n",
      "4.279184341430664 21.17559242248535\n",
      "h\n",
      "15.31121826171875 10.23464584350586\n",
      "-1.3506779670715332 35.27305603027344\n",
      "h\n",
      "16.545787811279297 9.748418807983398\n",
      "5.1703362464904785 -14.891695022583008\n",
      "h\n",
      "15.641013145446777 12.105112075805664\n",
      "-4.339848518371582 -2.8296098709106445\n",
      "h\n",
      "17.89249610900879 9.464522361755371\n",
      "2.066053867340088 38.74785232543945\n",
      "h\n",
      "16.218936920166016 9.47114086151123\n",
      "-5.354866027832031 16.037155151367188\n",
      "h\n",
      "14.24139404296875 8.756010055541992\n",
      "4.923202991485596 41.001220703125\n",
      "h\n",
      "14.029823303222656 6.8785505294799805\n",
      "6.097702980041504 43.89731979370117\n",
      "h\n",
      "17.364980697631836 8.91641616821289\n",
      "-0.628294825553894 36.6123161315918\n",
      "h\n",
      "18.27509307861328 12.241517066955566\n",
      "3.087888240814209 -33.56169128417969\n",
      "h\n",
      "14.829706192016602 5.538116931915283\n",
      "0.1917802095413208 50.553794860839844\n",
      "h\n",
      "15.466934204101562 10.313305854797363\n",
      "1.0343191623687744 -2.2826528549194336\n",
      "h\n",
      "16.935216903686523 7.608884811401367\n",
      "-2.2093348503112793 -3.8333492279052734\n",
      "h\n",
      "17.26114273071289 10.614680290222168\n",
      "4.5497636795043945 -34.496795654296875\n",
      "h\n",
      "15.367265701293945 7.916478157043457\n",
      "0.17589432001113892 5.268338203430176\n",
      "h\n",
      "16.1202335357666 7.427145957946777\n",
      "6.865468978881836 32.02280807495117\n",
      "h\n",
      "14.906461715698242 7.238569736480713\n",
      "1.9232205152511597 34.59309768676758\n",
      "h\n",
      "14.982187271118164 10.453558921813965\n",
      "-3.2551188468933105 -41.273555755615234\n",
      "h\n",
      "15.953706741333008 9.514832496643066\n",
      "-11.219736099243164 27.329790115356445\n",
      "h\n",
      "16.191654205322266 11.261881828308105\n",
      "-25.088703155517578 -26.26083755493164\n",
      "h\n",
      "12.981090545654297 4.800163745880127\n",
      "6.47797966003418 -29.343719482421875\n",
      "h\n",
      "12.702577590942383 5.3510541915893555\n",
      "0.045181989669799805 27.955537796020508\n",
      "h\n",
      "18.05076026916504 8.262930870056152\n",
      "-26.727258682250977 -20.908039093017578\n",
      "h\n",
      "13.114811897277832 8.236100196838379\n",
      "6.163795471191406 -10.405448913574219\n",
      "h\n",
      "11.184981346130371 5.477569580078125\n",
      "-0.823401689529419 -37.131561279296875\n",
      "h\n",
      "12.11019515991211 5.487217426300049\n",
      "6.398008823394775 1.1598834991455078\n",
      "h\n",
      "13.631156921386719 5.005945205688477\n",
      "-1.3013010025024414 -35.36598205566406\n",
      "h\n",
      "14.353663444519043 9.097090721130371\n",
      "-4.851175785064697 35.707313537597656\n",
      "h\n",
      "17.855365753173828 8.765284538269043\n",
      "-5.845831871032715 34.547393798828125\n",
      "h\n",
      "14.91015911102295 8.219558715820312\n",
      "-26.652511596679688 -9.593456268310547\n",
      "h\n",
      "13.329482078552246 9.186090469360352\n",
      "-2.7445895671844482 -38.9617805480957\n",
      "h\n",
      "12.575907707214355 3.318831443786621\n",
      "-2.0611305236816406 -0.8795684576034546\n",
      "h\n",
      "15.52709674835205 7.9920525550842285\n",
      "-2.611707925796509 28.657346725463867\n",
      "h\n",
      "15.117034912109375 8.496362686157227\n",
      "0.487715482711792 -22.42041778564453\n",
      "h\n",
      "16.837112426757812 9.816349029541016\n",
      "-7.890166282653809 -30.835987091064453\n",
      "h\n",
      "15.798788070678711 9.763764381408691\n",
      "3.669558525085449 22.46722984313965\n",
      "h\n",
      "16.238201141357422 7.920373439788818\n",
      "-2.11696195602417 36.563568115234375\n",
      "h\n",
      "14.977234840393066 7.65087366104126\n",
      "-13.844106674194336 51.51967239379883\n",
      "h\n",
      "13.773504257202148 8.524214744567871\n",
      "2.0446596145629883 5.833892822265625\n",
      "h\n",
      "13.961038589477539 9.59559440612793\n",
      "-16.38018798828125 -35.64924621582031\n",
      "h\n",
      "13.866863250732422 10.403433799743652\n",
      "0.18948078155517578 -5.849045276641846\n",
      "h\n",
      "16.57666015625 6.441707611083984\n",
      "4.734696388244629 52.837406158447266\n",
      "h\n",
      "14.015767097473145 7.827755928039551\n",
      "-5.012124061584473 -50.24174880981445\n",
      "h\n",
      "14.888607025146484 8.124990463256836\n",
      "-4.5537614822387695 27.047649383544922\n",
      "h\n",
      "13.07066535949707 5.752313613891602\n",
      "-13.06021499633789 7.693819522857666\n",
      "h\n",
      "14.98537826538086 8.10573959350586\n",
      "4.445674419403076 -6.269136428833008\n",
      "h\n",
      "16.95366859436035 10.334005355834961\n",
      "3.146125316619873 -22.511152267456055\n",
      "h\n",
      "17.195240020751953 10.66891098022461\n",
      "-5.892423152923584 0.8991451263427734\n",
      "h\n",
      "17.33126449584961 12.410531044006348\n",
      "-11.9546480178833 -55.83887481689453\n",
      "h\n",
      "16.502975463867188 12.980813026428223\n",
      "0.5605758428573608 -28.651676177978516\n",
      "h\n",
      "14.320621490478516 5.762042045593262\n",
      "-5.752760887145996 -46.874881744384766\n",
      "h\n",
      "12.848661422729492 6.104880332946777\n",
      "-10.425561904907227 -18.884552001953125\n",
      "h\n",
      "16.39776039123535 7.390601634979248\n",
      "0.17546308040618896 -40.02701187133789\n",
      "h\n",
      "16.6684513092041 10.163793563842773\n",
      "9.735057830810547 -4.866774559020996\n",
      "h\n",
      "14.368732452392578 7.548228740692139\n",
      "-4.609913349151611 -36.13181686401367\n",
      "h\n",
      "15.064282417297363 8.308619499206543\n",
      "2.828176498413086 -43.8228874206543\n",
      "h\n",
      "15.272117614746094 7.513121128082275\n",
      "-1.9908170700073242 25.334665298461914\n",
      "h\n",
      "14.374013900756836 5.310833930969238\n",
      "2.037912368774414 61.625709533691406\n",
      "h\n",
      "15.859074592590332 8.208483695983887\n",
      "-5.304727554321289 3.60602068901062\n",
      "h\n",
      "17.013866424560547 8.498764038085938\n",
      "3.4107937812805176 -12.180163383483887\n",
      "h\n",
      "11.89676284790039 7.33900260925293\n",
      "3.0724446773529053 35.774662017822266\n",
      "h\n",
      "14.052923202514648 5.363186359405518\n",
      "-1.5547268390655518 47.63958740234375\n",
      "h\n",
      "19.005756378173828 13.246550559997559\n",
      "1.1653929948806763 6.207075595855713\n",
      "h\n",
      "17.389223098754883 13.453790664672852\n",
      "1.821940302848816 -13.385778427124023\n",
      "h\n",
      "17.68056869506836 5.611257553100586\n",
      "9.42885971069336 9.587654113769531\n",
      "h\n",
      "14.44775104522705 10.439446449279785\n",
      "29.327693939208984 18.844890594482422\n",
      "h\n",
      "11.746161460876465 5.573391914367676\n",
      "-5.846700191497803 -9.517237663269043\n",
      "h\n",
      "11.99139404296875 7.325329780578613\n",
      "-10.146591186523438 -25.697967529296875\n",
      "h\n",
      "16.178407669067383 9.0160551071167\n",
      "6.311351776123047 6.120110034942627\n",
      "h\n",
      "17.384723663330078 8.490104675292969\n",
      "3.763883590698242 -19.53798484802246\n",
      "h\n",
      "14.345429420471191 8.967655181884766\n",
      "-0.42703962326049805 -25.33700180053711\n",
      "h\n",
      "14.806262016296387 4.610994338989258\n",
      "-1.4173917770385742 5.9518938064575195\n",
      "h\n",
      "16.100406646728516 10.995957374572754\n",
      "-1.6567704677581787 10.212364196777344\n",
      "h\n",
      "17.979389190673828 7.976305961608887\n",
      "1.6969459056854248 -45.14743423461914\n",
      "h\n",
      "12.717581748962402 5.667555332183838\n",
      "3.310988187789917 17.849430084228516\n",
      "h\n",
      "13.893537521362305 5.038000583648682\n",
      "-3.183180332183838 -8.53040885925293\n",
      "h\n",
      "15.307296752929688 7.891786575317383\n",
      "5.204636573791504 -19.465051651000977\n",
      "h\n",
      "12.196322441101074 3.679227828979492\n",
      "0.5914669036865234 -50.718353271484375\n",
      "h\n",
      "13.329482078552246 9.186090469360352\n",
      "-2.7445895671844482 -38.9617805480957\n",
      "h\n",
      "12.575907707214355 3.318831443786621\n",
      "-2.0611305236816406 -0.8795684576034546\n",
      "h\n",
      "12.203004837036133 6.083037853240967\n",
      "-1.0008347034454346 23.98700714111328\n",
      "h\n",
      "14.704365730285645 7.946584701538086\n",
      "-0.016435742378234863 -14.676387786865234\n",
      "h\n",
      "15.698116302490234 6.560624122619629\n",
      "4.125256061553955 2.9740285873413086\n",
      "h\n",
      "14.413520812988281 7.559412956237793\n",
      "-18.824169158935547 36.48233413696289\n",
      "h\n",
      "15.054311752319336 7.013485431671143\n",
      "-0.33341383934020996 32.88636016845703\n",
      "h\n",
      "14.400745391845703 8.226999282836914\n",
      "-2.319897174835205 16.9798583984375\n",
      "h\n",
      "16.742595672607422 9.596820831298828\n",
      "-4.120171070098877 -10.617629051208496\n",
      "h\n",
      "14.751602172851562 6.340147018432617\n",
      "12.920976638793945 5.698291778564453\n",
      "h\n",
      "14.489692687988281 5.523256778717041\n",
      "-6.964242935180664 15.203484535217285\n",
      "h\n",
      "14.315783500671387 6.335674285888672\n",
      "7.384576320648193 -5.65513277053833\n",
      "h\n",
      "12.951492309570312 4.968156337738037\n",
      "-0.3871188163757324 15.705499649047852\n",
      "h\n",
      "13.207586288452148 4.612159729003906\n",
      "-23.842777252197266 -11.337262153625488\n",
      "h\n",
      "16.299503326416016 9.718326568603516\n",
      "3.4221134185791016 -28.932390213012695\n",
      "h\n",
      "14.449541091918945 11.833253860473633\n",
      "-3.2021055221557617 -35.85157012939453\n",
      "h\n",
      "15.706313133239746 6.989566326141357\n",
      "4.806384086608887 -6.323780059814453\n",
      "h\n",
      "15.175418853759766 8.616482734680176\n",
      "-1.0566871166229248 -21.671432495117188\n",
      "h\n",
      "15.926142692565918 9.8261137008667\n",
      "2.6988489627838135 15.621175765991211\n",
      "h\n",
      "17.27912712097168 11.191543579101562\n",
      "5.8326616287231445 -13.644901275634766\n",
      "h\n",
      "16.545787811279297 9.748418807983398\n",
      "5.1703362464904785 -14.891695022583008\n",
      "h\n",
      "15.641013145446777 12.105112075805664\n",
      "-4.339848518371582 -2.8296098709106445\n",
      "h\n",
      "15.317859649658203 9.43427848815918\n",
      "0.5738344192504883 15.901336669921875\n",
      "h\n",
      "13.300771713256836 7.8972930908203125\n",
      "0.8151917457580566 -12.686817169189453\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(len(replace_corrects)):\n",
    "    replace_diff = -torch.tensor(replace_corrects[i]) + torch.tensor(replace_replaces[i])\n",
    "    n_correct = torch.sum(replace_diff > 0)\n",
    "    print(f\"{n_correct}/{len(replace_corrects[i])}\")\n",
    "    print(f'replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "\n",
    "    for j in range(len(replace_corrects[i])):\n",
    "        print(\"h\")\n",
    "        print(original_corrects[i][j], original_replaces[i][j])\n",
    "        print(replace_corrects[i][j], replace_replaces[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd4e2e-ae43-403d-9410-ad374a7ce622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
