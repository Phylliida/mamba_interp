{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2150298-45a8-4a12-84ef-a4a42ccb7b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fb5f85ebc40>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requires\n",
    "# pip install git+https://github.com/Phylliida/MambaLens.git\n",
    "\n",
    "# do PCA (and projective PCA?)\n",
    "# todo: for each name look at its PCA (make a colored graph for different components?)\n",
    "# train projection from PCA space to classifier space?\n",
    "\n",
    "from mamba_lens import HookedMamba # this will take a little while to import\n",
    "import torch\n",
    "model_path = \"state-spaces/mamba-370m\"\n",
    "model = HookedMamba.from_pretrained(model_path, device='cuda')\n",
    "torch.set_grad_enabled(False)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29eba0c2-102b-4450-ad2f-7c9fce14cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to do\n",
    "# pip install -e .\n",
    "# in the root directory of this repo\n",
    "# also\n",
    "# to install graphviz:\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install graphviz xdg-utils\n",
    "\n",
    "from acdc.data.ioi import ioi_data_generator, ABC_TEMPLATES, get_all_single_name_abc_patching_formats\n",
    "from acdc.data.utils import generate_dataset\n",
    "\n",
    "num_patching_pairs = 30000\n",
    "seed = 27\n",
    "valid_seed = 28\n",
    "constrain_to_answers = True\n",
    "has_symmetric_patching = True\n",
    "\n",
    "templates = ABC_TEMPLATES\n",
    "patching_formats = list(get_all_single_name_abc_patching_formats())\n",
    "\n",
    "data = generate_dataset(model=model,\n",
    "                  data_generator=ioi_data_generator,\n",
    "                  num_patching_pairs=num_patching_pairs,\n",
    "                  seed=seed,\n",
    "                  valid_seed=valid_seed,\n",
    "                  constrain_to_answers=constrain_to_answers,\n",
    "                  has_symmetric_patching=has_symmetric_patching, \n",
    "                  varying_data_lengths=True,\n",
    "                  templates=templates,\n",
    "                  patching_formats=patching_formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6302f3-c007-4fa7-b405-f998a00a700b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{50178, 46600, 31755, 11276, 10765, 46604, 33811, 46612, 16916, 18966, 12824, 32794, 7195, 33821, 33313, 37921, 29222, 31270, 28712, 28200, 37930, 18985, 7727, 24112, 36400, 32817, 5171, 44085, 35382, 14912, 30274, 20554, 15435, 33357, 49231, 38994, 21587, 7252, 40537, 27738, 44123, 44124, 14943, 45664, 15458, 49765, 19046, 35944, 29804, 23662, 37497, 22138, 27773, 28798, 33407, 27264, 9857, 14468, 35972, 6277, 4744, 32905, 32393, 22671, 20628, 32920, 17560, 21661, 16543, 31903, 18089, 16553, 28331, 41131, 20145, 46262, 30397, 41151, 22723, 23239, 14538, 17100, 37073, 22739, 49365, 16598, 31959, 47831, 22234, 23259, 20189, 45790, 29927, 46312, 31465, 46831, 31472, 29936, 26355, 6393, 26876, 8444, 26878, 6911, 25856, 21249, 19717, 8966, 38150, 26888, 27917, 39184, 48401, 24336, 6416, 23316, 37144, 31513, 42266, 29989, 27434, 45867, 36139, 29489, 27955, 27443, 22838, 7993, 13114, 13629, 28991, 40771, 25413, 44870, 18247, 47944, 35657, 26953, 13651, 27991, 26456, 48990, 34655, 16225, 28518, 43367, 20839, 11116, 10092, 31086, 29040, 50033, 5490, 39795, 48505, 40316, 19838, 24958, 38783, 23425, 24962, 13187, 49028, 12167, 43406, 43921, 18322, 14737, 12694, 16286, 48545, 29092, 16809, 15273, 22455, 24504, 30140, 27581, 21438, 35262, 36292, 6086, 21960, 31231, 20428, 17361, 33747, 13268, 2516, 45014, 25556, 33240, 36312, 16863, 28642, 10213, 16358, 25062, 23528, 35307, 19436, 25579, 15859, 38900, 7670, 8698, 12284, 44542, 5119}\n",
      "torch.Size([120000, 20])\n"
     ]
    }
   ],
   "source": [
    "from acdc.data.ioi import good_names\n",
    "from collections import defaultdict\n",
    "name_tokens = set([model.to_single_token(\" \" + name) for name in good_names])\n",
    "print(name_tokens)\n",
    "print(data.data.size())\n",
    "name_positions = defaultdict(lambda: [])\n",
    "for i in range(data.data.size()[0]):\n",
    "    prompt_tokens = data.data[i]\n",
    "    name_pos = 0\n",
    "    for i, tok in enumerate(prompt_tokens):\n",
    "        if tok.item() in name_tokens:\n",
    "            name_positions[name_pos].append(i) # +1 because conv\n",
    "            name_pos += 1\n",
    "    if name_pos != 5: raise ValueError(f\"data point {model.to_str_tokens(data)} does not have 5 names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "969917bf-e5cc-4b9c-b12c-c16a3fa6d3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808d1465fe464f54bbad8fae1f1ae63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7f973116f490>, {0: {50178: 238, 46600: 172, 31755: 186, 46604: 184, 10765: 176, 11276: 202, 33811: 158, 46612: 210, 16916: 172, 18966: 188, 12824: 196, 32794: 202, 7195: 164, 33821: 196, 37921: 232, 33313: 226, 31270: 184, 29222: 188, 28712: 180, 18985: 180, 37930: 170, 28200: 178, 7727: 174, 24112: 186, 36400: 222, 32817: 188, 5171: 188, 44085: 176, 35382: 192, 14912: 174, 30274: 200, 20554: 180, 15435: 156, 33357: 146, 49231: 172, 38994: 214, 21587: 172, 7252: 180, 40537: 202, 27738: 212, 44123: 166, 44124: 202, 14943: 182, 45664: 118, 15458: 188, 49765: 190, 19046: 194, 35944: 226, 29804: 170, 23662: 162, 37497: 198, 22138: 168, 27773: 240, 28798: 232, 33407: 226, 27264: 218, 9857: 214, 14468: 180, 6277: 144, 35972: 214, 4744: 192, 32905: 160, 32393: 202, 22671: 218, 20628: 168, 32920: 344, 17560: 204, 5119: 138, 21661: 184, 16543: 144, 31903: 266, 18089: 186, 16553: 154, 28331: 184, 41131: 196, 20145: 186, 46262: 188, 30397: 184, 41151: 254, 22723: 186, 23239: 218, 14538: 168, 17100: 166, 37073: 184, 22739: 234, 49365: 226, 16598: 204, 47831: 210, 31959: 242, 22234: 192, 23259: 178, 20189: 208, 45790: 200, 29927: 196, 46312: 206, 31465: 166, 46831: 176, 31472: 186, 29936: 136, 26355: 198, 6393: 156, 26876: 170, 8444: 252, 26878: 236, 6911: 170, 25856: 158, 21249: 168, 19717: 188, 8966: 152, 38150: 140, 26888: 218, 27917: 200, 39184: 166, 48401: 250, 24336: 172, 6416: 228, 23316: 174, 37144: 220, 31513: 200, 42266: 152, 29989: 188, 27434: 188, 45867: 206, 36139: 274, 29489: 224, 27443: 198, 27955: 194, 22838: 186, 7993: 226, 13114: 174, 13629: 188, 28991: 164, 40771: 190, 25413: 228, 44870: 198, 18247: 164, 47944: 164, 35657: 182, 26953: 156, 13651: 174, 27991: 200, 26456: 148, 48990: 224, 34655: 182, 16225: 210, 28518: 166, 20839: 208, 43367: 184, 10092: 226, 11116: 212, 31086: 214, 29040: 208, 50033: 180, 5490: 216, 39795: 190, 48505: 174, 40316: 202, 24958: 158, 38783: 198, 19838: 192, 23425: 200, 24962: 210, 13187: 184, 49028: 162, 12167: 250, 43406: 192, 14737: 216, 18322: 150, 43921: 212, 12694: 150, 16286: 170, 48545: 174, 29092: 188, 15273: 160, 16809: 176, 22455: 130, 24504: 132, 30140: 234, 27581: 152, 21438: 164, 35262: 200, 36292: 212, 6086: 156, 21960: 146, 20428: 204, 17361: 170, 33747: 210, 2516: 188, 13268: 368, 45014: 210, 25556: 196, 33240: 172, 36312: 216, 16863: 198, 28642: 172, 10213: 186, 16358: 200, 25062: 156, 23528: 174, 35307: 212, 19436: 158, 25579: 194, 15859: 216, 38900: 182, 7670: 192, 8698: 202, 12284: 210, 44542: 172, 31231: 214}, 1: {50178: 194, 46600: 182, 31755: 184, 46604: 192, 10765: 224, 11276: 176, 33811: 186, 46612: 232, 16916: 238, 18966: 220, 12824: 182, 32794: 212, 7195: 178, 33821: 170, 37921: 176, 33313: 208, 31270: 176, 29222: 146, 28712: 182, 18985: 240, 37930: 220, 28200: 188, 7727: 168, 24112: 186, 36400: 246, 32817: 214, 5171: 192, 44085: 242, 35382: 172, 14912: 194, 30274: 150, 20554: 144, 15435: 190, 33357: 182, 49231: 168, 38994: 192, 21587: 210, 7252: 164, 40537: 160, 27738: 196, 44123: 154, 44124: 186, 14943: 178, 45664: 192, 15458: 266, 49765: 222, 19046: 222, 35944: 190, 29804: 170, 23662: 172, 37497: 164, 22138: 178, 27773: 220, 28798: 156, 33407: 172, 27264: 182, 9857: 212, 14468: 152, 6277: 192, 35972: 180, 4744: 186, 32905: 170, 32393: 234, 22671: 172, 20628: 200, 32920: 382, 17560: 164, 5119: 166, 21661: 244, 16543: 206, 31903: 198, 18089: 138, 16553: 198, 28331: 232, 41131: 186, 20145: 138, 46262: 196, 30397: 228, 41151: 206, 22723: 246, 23239: 166, 14538: 190, 17100: 200, 37073: 178, 22739: 210, 49365: 136, 16598: 148, 47831: 210, 31959: 184, 22234: 208, 23259: 162, 20189: 224, 45790: 216, 29927: 262, 46312: 218, 31465: 160, 46831: 170, 31472: 204, 29936: 158, 26355: 248, 6393: 206, 26876: 210, 8444: 172, 26878: 172, 6911: 198, 25856: 176, 21249: 188, 19717: 130, 8966: 158, 38150: 204, 26888: 168, 27917: 148, 39184: 158, 48401: 142, 24336: 184, 6416: 194, 23316: 148, 37144: 200, 31513: 202, 42266: 222, 29989: 146, 27434: 158, 45867: 158, 36139: 234, 29489: 170, 27443: 172, 27955: 210, 22838: 202, 7993: 196, 13114: 182, 13629: 186, 28991: 182, 40771: 180, 25413: 188, 44870: 198, 18247: 202, 47944: 196, 35657: 178, 26953: 186, 13651: 154, 27991: 170, 26456: 200, 48990: 126, 34655: 234, 16225: 196, 28518: 140, 20839: 184, 43367: 216, 10092: 168, 11116: 216, 31086: 216, 29040: 244, 50033: 188, 5490: 196, 39795: 190, 48505: 182, 40316: 218, 24958: 184, 38783: 198, 19838: 194, 23425: 198, 24962: 168, 13187: 220, 49028: 196, 12167: 158, 43406: 204, 14737: 200, 18322: 190, 43921: 172, 12694: 180, 16286: 182, 48545: 180, 29092: 198, 15273: 174, 16809: 178, 22455: 190, 24504: 202, 30140: 240, 27581: 178, 21438: 224, 35262: 172, 36292: 164, 6086: 210, 21960: 152, 20428: 206, 17361: 182, 33747: 170, 2516: 162, 13268: 332, 45014: 206, 25556: 166, 33240: 184, 36312: 192, 16863: 222, 28642: 200, 10213: 184, 16358: 196, 25062: 184, 23528: 174, 35307: 186, 19436: 204, 25579: 230, 15859: 186, 38900: 238, 7670: 174, 8698: 170, 12284: 222, 44542: 208, 31231: 196}, 2: {50178: 144, 46600: 180, 31755: 164, 46604: 210, 10765: 192, 11276: 210, 33811: 164, 46612: 238, 16916: 188, 18966: 222, 12824: 194, 32794: 162, 7195: 174, 33821: 182, 37921: 174, 33313: 206, 31270: 200, 29222: 134, 28712: 168, 18985: 150, 37930: 176, 28200: 208, 7727: 126, 24112: 222, 36400: 178, 32817: 222, 5171: 170, 44085: 208, 35382: 218, 14912: 192, 30274: 214, 20554: 152, 15435: 210, 33357: 144, 49231: 210, 38994: 198, 21587: 204, 7252: 158, 40537: 222, 27738: 238, 44123: 196, 44124: 232, 14943: 184, 45664: 198, 15458: 214, 49765: 194, 19046: 200, 35944: 220, 29804: 194, 23662: 198, 37497: 198, 22138: 220, 27773: 184, 28798: 166, 33407: 160, 27264: 168, 9857: 138, 14468: 208, 6277: 196, 35972: 158, 4744: 200, 32905: 218, 32393: 166, 22671: 212, 20628: 194, 32920: 372, 17560: 184, 5119: 116, 21661: 212, 16543: 190, 31903: 182, 18089: 196, 16553: 190, 28331: 170, 41131: 188, 20145: 198, 46262: 198, 30397: 190, 41151: 198, 22723: 164, 23239: 192, 14538: 188, 17100: 228, 37073: 180, 22739: 236, 49365: 160, 16598: 178, 47831: 186, 31959: 184, 22234: 196, 23259: 228, 20189: 158, 45790: 206, 29927: 216, 46312: 206, 31465: 206, 46831: 186, 31472: 222, 29936: 164, 26355: 130, 6393: 154, 26876: 194, 8444: 162, 26878: 180, 6911: 150, 25856: 152, 21249: 152, 19717: 176, 8966: 190, 38150: 182, 26888: 226, 27917: 212, 39184: 192, 48401: 152, 24336: 170, 6416: 180, 23316: 152, 37144: 168, 31513: 200, 42266: 148, 29989: 156, 27434: 220, 45867: 190, 36139: 194, 29489: 182, 27443: 218, 27955: 188, 22838: 190, 7993: 170, 13114: 164, 13629: 198, 28991: 192, 40771: 182, 25413: 258, 44870: 180, 18247: 236, 47944: 208, 35657: 198, 26953: 214, 13651: 248, 27991: 228, 26456: 214, 48990: 188, 34655: 186, 16225: 158, 28518: 158, 20839: 212, 43367: 228, 10092: 192, 11116: 166, 31086: 176, 29040: 208, 50033: 158, 5490: 198, 39795: 218, 48505: 166, 40316: 196, 24958: 210, 38783: 132, 19838: 230, 23425: 156, 24962: 210, 13187: 192, 49028: 252, 12167: 174, 43406: 226, 14737: 172, 18322: 178, 43921: 188, 12694: 192, 16286: 174, 48545: 172, 29092: 140, 15273: 210, 16809: 190, 22455: 160, 24504: 214, 30140: 154, 27581: 168, 21438: 206, 35262: 192, 36292: 178, 6086: 162, 21960: 200, 20428: 214, 17361: 202, 33747: 172, 2516: 244, 13268: 414, 45014: 174, 25556: 196, 33240: 236, 36312: 218, 16863: 140, 28642: 204, 10213: 212, 16358: 192, 25062: 206, 23528: 190, 35307: 172, 19436: 176, 25579: 168, 15859: 178, 38900: 202, 7670: 206, 8698: 212, 12284: 184, 44542: 190, 31231: 198}, 3: {50178: 238, 46600: 156, 31755: 182, 46604: 188, 10765: 196, 11276: 182, 33811: 174, 46612: 214, 16916: 218, 18966: 208, 12824: 172, 32794: 220, 7195: 162, 33821: 194, 37921: 246, 33313: 238, 31270: 172, 29222: 164, 28712: 186, 18985: 196, 37930: 180, 28200: 190, 7727: 184, 24112: 188, 36400: 226, 32817: 194, 5171: 180, 44085: 158, 35382: 202, 14912: 172, 30274: 184, 20554: 180, 15435: 148, 33357: 154, 49231: 158, 38994: 236, 21587: 200, 7252: 196, 40537: 194, 27738: 224, 44123: 154, 44124: 198, 14943: 168, 45664: 136, 15458: 222, 49765: 210, 19046: 210, 35944: 258, 29804: 176, 23662: 166, 37497: 160, 22138: 164, 27773: 270, 28798: 176, 33407: 202, 27264: 196, 9857: 216, 14468: 170, 6277: 172, 35972: 202, 4744: 216, 32905: 164, 32393: 206, 22671: 220, 20628: 176, 32920: 320, 17560: 200, 5119: 154, 21661: 174, 16543: 176, 31903: 246, 18089: 154, 16553: 158, 28331: 184, 41131: 214, 20145: 182, 46262: 210, 30397: 184, 41151: 256, 22723: 206, 23239: 212, 14538: 170, 17100: 168, 37073: 160, 22739: 228, 49365: 204, 16598: 190, 47831: 220, 31959: 218, 22234: 208, 23259: 176, 20189: 226, 45790: 194, 29927: 232, 46312: 194, 31465: 148, 46831: 174, 31472: 240, 29936: 146, 26355: 256, 6393: 146, 26876: 180, 8444: 230, 26878: 224, 6911: 176, 25856: 164, 21249: 194, 19717: 168, 8966: 146, 38150: 142, 26888: 194, 27917: 158, 39184: 148, 48401: 234, 24336: 170, 6416: 220, 23316: 176, 37144: 218, 31513: 208, 42266: 188, 29989: 168, 27434: 160, 45867: 206, 36139: 272, 29489: 208, 27443: 176, 27955: 204, 22838: 196, 7993: 246, 13114: 166, 13629: 192, 28991: 158, 40771: 204, 25413: 208, 44870: 188, 18247: 170, 47944: 164, 35657: 182, 26953: 154, 13651: 178, 27991: 200, 26456: 146, 48990: 192, 34655: 198, 16225: 222, 28518: 154, 20839: 204, 43367: 206, 10092: 216, 11116: 220, 31086: 192, 29040: 242, 50033: 182, 5490: 168, 39795: 214, 48505: 174, 40316: 196, 24958: 176, 38783: 184, 19838: 196, 23425: 178, 24962: 182, 13187: 218, 49028: 170, 12167: 224, 43406: 182, 14737: 224, 18322: 162, 43921: 170, 12694: 140, 16286: 176, 48545: 192, 29092: 172, 15273: 172, 16809: 152, 22455: 140, 24504: 150, 30140: 250, 27581: 162, 21438: 174, 35262: 208, 36292: 202, 6086: 170, 21960: 138, 20428: 206, 17361: 178, 33747: 188, 2516: 160, 13268: 340, 45014: 200, 25556: 180, 33240: 192, 36312: 180, 16863: 192, 28642: 174, 10213: 192, 16358: 200, 25062: 176, 23528: 154, 35307: 196, 19436: 176, 25579: 198, 15859: 194, 38900: 220, 7670: 188, 8698: 182, 12284: 212, 44542: 176, 31231: 228}, 4: {50178: 160, 46600: 194, 31755: 158, 46604: 180, 10765: 204, 11276: 204, 33811: 162, 46612: 240, 16916: 170, 18966: 246, 12824: 198, 32794: 164, 7195: 182, 33821: 172, 37921: 162, 33313: 220, 31270: 208, 29222: 130, 28712: 168, 18985: 172, 37930: 196, 28200: 206, 7727: 128, 24112: 204, 36400: 216, 32817: 210, 5171: 184, 44085: 232, 35382: 200, 14912: 162, 30274: 224, 20554: 150, 15435: 210, 33357: 158, 49231: 212, 38994: 212, 21587: 190, 7252: 144, 40537: 212, 27738: 236, 44123: 206, 44124: 212, 14943: 190, 45664: 208, 15458: 232, 49765: 202, 19046: 222, 35944: 198, 29804: 170, 23662: 184, 37497: 190, 22138: 220, 27773: 190, 28798: 172, 33407: 148, 27264: 190, 9857: 124, 14468: 182, 6277: 190, 35972: 166, 4744: 206, 32905: 198, 32393: 186, 22671: 208, 20628: 188, 32920: 380, 17560: 178, 5119: 108, 21661: 246, 16543: 164, 31903: 188, 18089: 180, 16553: 204, 28331: 206, 41131: 178, 20145: 168, 46262: 184, 30397: 212, 41151: 194, 22723: 202, 23239: 182, 14538: 198, 17100: 228, 37073: 192, 22739: 228, 49365: 172, 16598: 168, 47831: 188, 31959: 172, 22234: 178, 23259: 206, 20189: 162, 45790: 232, 29927: 214, 46312: 224, 31465: 214, 46831: 188, 31472: 204, 29936: 138, 26355: 160, 6393: 204, 26876: 210, 8444: 172, 26878: 158, 6911: 144, 25856: 140, 21249: 132, 19717: 154, 8966: 196, 38150: 200, 26888: 212, 27917: 198, 39184: 190, 48401: 150, 24336: 160, 6416: 176, 23316: 154, 37144: 176, 31513: 206, 42266: 142, 29989: 142, 27434: 218, 45867: 156, 36139: 210, 29489: 180, 27443: 206, 27955: 190, 22838: 210, 7993: 170, 13114: 176, 13629: 190, 28991: 182, 40771: 176, 25413: 240, 44870: 192, 18247: 214, 47944: 200, 35657: 184, 26953: 212, 13651: 194, 27991: 222, 26456: 220, 48990: 162, 34655: 202, 16225: 166, 28518: 152, 20839: 220, 43367: 194, 10092: 180, 11116: 174, 31086: 170, 29040: 220, 50033: 172, 5490: 214, 39795: 212, 48505: 154, 40316: 198, 24958: 198, 38783: 172, 19838: 204, 23425: 184, 24962: 220, 13187: 192, 49028: 226, 12167: 168, 43406: 248, 14737: 152, 18322: 206, 43921: 190, 12694: 172, 16286: 158, 48545: 154, 29092: 152, 15273: 174, 16809: 208, 22455: 184, 24504: 218, 30140: 168, 27581: 168, 21438: 206, 35262: 160, 36292: 164, 6086: 196, 21960: 202, 20428: 200, 17361: 190, 33747: 184, 2516: 250, 13268: 394, 45014: 200, 25556: 174, 33240: 220, 36312: 206, 16863: 174, 28642: 210, 10213: 218, 16358: 176, 25062: 218, 23528: 190, 35307: 184, 19436: 184, 25579: 190, 15859: 190, 38900: 242, 7670: 198, 8698: 208, 12284: 210, 44542: 196, 31231: 200}})\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "LAYER = 39\n",
    "batch_size = 40\n",
    "\n",
    "hook = f\"blocks.{LAYER}.hook_ssm_input\"\n",
    "\n",
    "name_averages = defaultdict(lambda: {})\n",
    "counts = defaultdict(lambda: {})\n",
    "\n",
    "TOTAL_AVG_NAME = \"total\"\n",
    "\n",
    "for tok in name_tokens:\n",
    "    for name_i in range(len(name_positions)):\n",
    "        name_averages[name_i][tok] = torch.zeros([model.cfg.E], device=model.cfg.device)\n",
    "        counts[name_i][tok] = 0\n",
    "\n",
    "for batch_start in tqdm(list(range(0, data.data.size()[0], batch_size))):\n",
    "    batch_end = min(data.data.size()[0], batch_start+batch_size)\n",
    "    data_batch = data.data[batch_start:batch_end]\n",
    "    logits, activations = model.run_with_cache(data_batch, names_filter=[hook], fast_ssm=True, fast_conv=True)\n",
    "    for name_i in range(len(name_positions)):\n",
    "        positions = torch.tensor(name_positions[name_i][batch_start:batch_end], device=model.cfg.device)\n",
    "        batch_name_tokens = data_batch[torch.arange(batch_end-batch_start),positions]\n",
    "        ssm_inputs = activations[hook]\n",
    "        for batch_i, name_tok in enumerate(batch_name_tokens):\n",
    "            #print(ssm_inputs[batch_i, position].size())\n",
    "            try:\n",
    "                position = positions[batch_i]+1\n",
    "                name_averages[name_i][name_tok.item()] = ssm_inputs[batch_i, position]\n",
    "                name_averages['all'][name_tok.item()] = ssm_inputs[batch_i, position]\n",
    "                #name_averages[name_i][TOTAL_AVG_NAME] += ssm_inputs[batch_i, position]\n",
    "                counts[name_i][name_tok.item()] += 1\n",
    "                #counts[name_i][TOTAL_AVG_NAME] += 1\n",
    "            except:\n",
    "                print(model.to_str_tokens([name_tok]))\n",
    "                raise\n",
    "    \n",
    "print(counts)\n",
    "for name_i in range(len(name_positions)):\n",
    "    for name_tok in list(name_averages.keys()):\n",
    "        #name_averages[name_i][name_tok] = name_averages[name_i][name_tok] / counts[name_i][name_tok]\n",
    "        pass   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cba178a-3688-4632-be14-0445f634da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "0 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "1 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 1\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 2\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 3\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "2 4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "\n",
    "DO_DIFF = False\n",
    "\n",
    "model_kwargs = {\"fast_ssm\": True, \"fast_conv\": True}\n",
    "\n",
    "original_corrects = {}\n",
    "original_replaces = {}\n",
    "replace_corrects = {}\n",
    "replace_replaces = {}\n",
    "patched_corrects = {}\n",
    "patched_replaces = {}\n",
    "\n",
    "for position_1 in range(3):\n",
    "    for position_2 in range(5):\n",
    "        print(position_1, position_2)\n",
    "        original_correct = []\n",
    "        original_replace = []\n",
    "        replace_correct = []\n",
    "        replace_replace = []\n",
    "        patched_correct = []\n",
    "        patched_replace = []\n",
    "\n",
    "        original_corrects[(position_1, position_2)] = original_correct\n",
    "        original_replaces[(position_1, position_2)] = original_replace\n",
    "        replace_corrects[(position_1, position_2)] = replace_correct\n",
    "        replace_replaces[(position_1, position_2)] = replace_replace\n",
    "        patched_corrects[(position_1, position_2)] = patched_correct\n",
    "        patched_replaces[(position_1, position_2)] = patched_replace\n",
    "        \n",
    "        num_found = 0\n",
    "        while True:\n",
    "            data_i = random.choice(list(range(data.data.size()[0])))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i]\n",
    "            answer_tok = data.correct[data_i][0]\n",
    "            answer = model.to_str_tokens(answer_tok)[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            \n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                replace_vec,\n",
    "                replace_add_vec\n",
    "            ):\n",
    "                if not replace_vec is None:\n",
    "                    x[0, position] = replace_vec\n",
    "                if not replace_add_vec is None:\n",
    "                    x[0, position] += replace_add_vec\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(name_positions)):\n",
    "                position = name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            hooks = []\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                \n",
    "                name_i = position_2\n",
    "                replace_vec = name_averages[name_i][replace_tok]\n",
    "                # two ways to do it\n",
    "                # diff(name) = avg - name\n",
    "                # if we add this it should \"erase\" name\n",
    "                # if we subtract this it should \"add\" name\n",
    "                # so we can do\n",
    "                # replace_add_vec = diff(answer) - diff(replace)\n",
    "                #diff_answer = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][answer_tok]\n",
    "                #diff_replace = name_averages[name_i][TOTAL_AVG_NAME] - name_averages[name_i][replace_tok]\n",
    "                #replace_add_vec = diff_answer - diff_replace\n",
    "                # this is (avg-a) - (avg-r) = r-a\n",
    "                # in other words the average doesn't matter for this\n",
    "                # and it's just subtract avg for a and add average for b\n",
    "                replace_add_vec = name_averages[name_i][replace_tok] - name_averages[name_i][answer_tok.item()]\n",
    "                # then we do\n",
    "                # replace_vec\n",
    "                # we have x\n",
    "                # we want y\n",
    "                # we can do\n",
    "                # x-y\n",
    "                # and apply it to y\n",
    "                #replace_diff = name_averages[name_i][TOTAL_AVG_NAME]\n",
    "        \n",
    "                if DO_DIFF:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=None, replace_add_vec=replace_add_vec)))\n",
    "                else:\n",
    "                    hooks.append((hook, partial(replace_hook, position=position+1, replace_vec=replace_vec, replace_add_vec=None)))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 100:\n",
    "                break\n",
    "    \n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a963471-2615-44aa-8be8-64f3e274530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_correct_matrix = torch.zeros([3,5])\n",
    "\n",
    "for pos1 in range(3):\n",
    "    for pos2 in range(5):\n",
    "        #original_diff = -torch.tensor(original_correct) + torch.tensor(original_replace)\n",
    "        replace_diff = -torch.tensor(replace_corrects[(pos1,pos2)]) + torch.tensor(replace_replaces[(pos1,pos2)])\n",
    "        #patched_diff = -torch.tensor(patched_correct) + torch.tensor(patched_replace)\n",
    "        \n",
    "        #print(f'original min diff {torch.min(original_diff)} max diff {torch.max(original_diff)} avg diff {torch.mean(original_diff)}')\n",
    "        #print(f'replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "        #print(f'patch min diff {torch.min(patched_diff)} max diff {torch.max(patched_diff)} avg diff {torch.mean(patched_diff)}')\n",
    "\n",
    "        n_correct_matrix[pos1, pos2] = torch.sum(replace_diff > 0)/101.0\n",
    "        #print(f'original n correct {torch.sum(original_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'replace n correct {torch.sum(replace_diff < 0)} / {original_diff.size()[0]}')\n",
    "        #print(f'patch n correct {torch.sum(patched_diff < 0)} / {original_diff.size()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8637d98c-498d-4ad2-bd9f-1f23265ab475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "y": [
          0,
          1,
          2
         ],
         "yaxis": "y",
         "z": [
          [
           0.9900990128517151,
           0.9900990128517151,
           1,
           0.4752475321292877,
           0.4752475321292877
          ],
          [
           1,
           1,
           0.9900990128517151,
           0.603960394859314,
           0.5841584205627441
          ],
          [
           0.9801980257034302,
           1,
           0.9900990128517151,
           0.4455445408821106,
           0.3861386179924011
          ]
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "replacing"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.21209213051823417,
          0.7879078694817658
         ],
         "range": [
          -0.5,
          4.5
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.008637236084452993,
          0.991362763915547
         ],
         "range": [
          2.5,
          -0.5
         ],
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"fb9184de-aad0-4157-af14-c9db66ef9d18\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fb9184de-aad0-4157-af14-c9db66ef9d18\")) {                    Plotly.newPlot(                        \"fb9184de-aad0-4157-af14-c9db66ef9d18\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"y\":[0,1,2],\"z\":[[0.9900990128517151,0.9900990128517151,1.0,0.4752475321292877,0.4752475321292877],[1.0,1.0,0.9900990128517151,0.603960394859314,0.5841584205627441],[0.9801980257034302,1.0,0.9900990128517151,0.4455445408821106,0.3861386179924011]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"title\":{\"text\":\"replacing\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fb9184de-aad0-4157-af14-c9db66ef9d18');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# modified from neel nanda's examples\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", font_size=None, show=True, color_continuous_midpoint=0.0, fix_size=False, **kwargs):\n",
    "    import plotly.express as px\n",
    "    import transformer_lens.utils as utils\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=color_continuous_midpoint, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show()\n",
    "\n",
    "imshow(n_correct_matrix, color_continuous_midpoint=None, y=[0,1,2], title='replacing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ba32f2c-2128-463f-9979-48b48b813d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {0: {50178: 238,\n",
       "              46600: 172,\n",
       "              31755: 186,\n",
       "              46604: 184,\n",
       "              10765: 176,\n",
       "              11276: 202,\n",
       "              33811: 158,\n",
       "              46612: 210,\n",
       "              16916: 172,\n",
       "              18966: 188,\n",
       "              12824: 196,\n",
       "              32794: 202,\n",
       "              7195: 164,\n",
       "              33821: 196,\n",
       "              37921: 232,\n",
       "              33313: 226,\n",
       "              31270: 184,\n",
       "              29222: 188,\n",
       "              28712: 180,\n",
       "              18985: 180,\n",
       "              37930: 170,\n",
       "              28200: 178,\n",
       "              7727: 174,\n",
       "              24112: 186,\n",
       "              36400: 222,\n",
       "              32817: 188,\n",
       "              5171: 188,\n",
       "              44085: 176,\n",
       "              35382: 192,\n",
       "              14912: 174,\n",
       "              30274: 200,\n",
       "              20554: 180,\n",
       "              15435: 156,\n",
       "              33357: 146,\n",
       "              49231: 172,\n",
       "              38994: 214,\n",
       "              21587: 172,\n",
       "              7252: 180,\n",
       "              40537: 202,\n",
       "              27738: 212,\n",
       "              44123: 166,\n",
       "              44124: 202,\n",
       "              14943: 182,\n",
       "              45664: 118,\n",
       "              15458: 188,\n",
       "              49765: 190,\n",
       "              19046: 194,\n",
       "              35944: 226,\n",
       "              29804: 170,\n",
       "              23662: 162,\n",
       "              37497: 198,\n",
       "              22138: 168,\n",
       "              27773: 240,\n",
       "              28798: 232,\n",
       "              33407: 226,\n",
       "              27264: 218,\n",
       "              9857: 214,\n",
       "              14468: 180,\n",
       "              6277: 144,\n",
       "              35972: 214,\n",
       "              4744: 192,\n",
       "              32905: 160,\n",
       "              32393: 202,\n",
       "              22671: 218,\n",
       "              20628: 168,\n",
       "              32920: 344,\n",
       "              17560: 204,\n",
       "              5119: 138,\n",
       "              21661: 184,\n",
       "              16543: 144,\n",
       "              31903: 266,\n",
       "              18089: 186,\n",
       "              16553: 154,\n",
       "              28331: 184,\n",
       "              41131: 196,\n",
       "              20145: 186,\n",
       "              46262: 188,\n",
       "              30397: 184,\n",
       "              41151: 254,\n",
       "              22723: 186,\n",
       "              23239: 218,\n",
       "              14538: 168,\n",
       "              17100: 166,\n",
       "              37073: 184,\n",
       "              22739: 234,\n",
       "              49365: 226,\n",
       "              16598: 204,\n",
       "              47831: 210,\n",
       "              31959: 242,\n",
       "              22234: 192,\n",
       "              23259: 178,\n",
       "              20189: 208,\n",
       "              45790: 200,\n",
       "              29927: 196,\n",
       "              46312: 206,\n",
       "              31465: 166,\n",
       "              46831: 176,\n",
       "              31472: 186,\n",
       "              29936: 136,\n",
       "              26355: 198,\n",
       "              6393: 156,\n",
       "              26876: 170,\n",
       "              8444: 252,\n",
       "              26878: 236,\n",
       "              6911: 170,\n",
       "              25856: 158,\n",
       "              21249: 168,\n",
       "              19717: 188,\n",
       "              8966: 152,\n",
       "              38150: 140,\n",
       "              26888: 218,\n",
       "              27917: 200,\n",
       "              39184: 166,\n",
       "              48401: 250,\n",
       "              24336: 172,\n",
       "              6416: 228,\n",
       "              23316: 174,\n",
       "              37144: 220,\n",
       "              31513: 200,\n",
       "              42266: 152,\n",
       "              29989: 188,\n",
       "              27434: 188,\n",
       "              45867: 206,\n",
       "              36139: 274,\n",
       "              29489: 224,\n",
       "              27443: 198,\n",
       "              27955: 194,\n",
       "              22838: 186,\n",
       "              7993: 226,\n",
       "              13114: 174,\n",
       "              13629: 188,\n",
       "              28991: 164,\n",
       "              40771: 190,\n",
       "              25413: 228,\n",
       "              44870: 198,\n",
       "              18247: 164,\n",
       "              47944: 164,\n",
       "              35657: 182,\n",
       "              26953: 156,\n",
       "              13651: 174,\n",
       "              27991: 200,\n",
       "              26456: 148,\n",
       "              48990: 224,\n",
       "              34655: 182,\n",
       "              16225: 210,\n",
       "              28518: 166,\n",
       "              20839: 208,\n",
       "              43367: 184,\n",
       "              10092: 226,\n",
       "              11116: 212,\n",
       "              31086: 214,\n",
       "              29040: 208,\n",
       "              50033: 180,\n",
       "              5490: 216,\n",
       "              39795: 190,\n",
       "              48505: 174,\n",
       "              40316: 202,\n",
       "              24958: 158,\n",
       "              38783: 198,\n",
       "              19838: 192,\n",
       "              23425: 200,\n",
       "              24962: 210,\n",
       "              13187: 184,\n",
       "              49028: 162,\n",
       "              12167: 250,\n",
       "              43406: 192,\n",
       "              14737: 216,\n",
       "              18322: 150,\n",
       "              43921: 212,\n",
       "              12694: 150,\n",
       "              16286: 170,\n",
       "              48545: 174,\n",
       "              29092: 188,\n",
       "              15273: 160,\n",
       "              16809: 176,\n",
       "              22455: 130,\n",
       "              24504: 132,\n",
       "              30140: 234,\n",
       "              27581: 152,\n",
       "              21438: 164,\n",
       "              35262: 200,\n",
       "              36292: 212,\n",
       "              6086: 156,\n",
       "              21960: 146,\n",
       "              20428: 204,\n",
       "              17361: 170,\n",
       "              33747: 210,\n",
       "              2516: 188,\n",
       "              13268: 368,\n",
       "              45014: 210,\n",
       "              25556: 196,\n",
       "              33240: 172,\n",
       "              36312: 216,\n",
       "              16863: 198,\n",
       "              28642: 172,\n",
       "              10213: 186,\n",
       "              16358: 200,\n",
       "              25062: 156,\n",
       "              23528: 174,\n",
       "              35307: 212,\n",
       "              19436: 158,\n",
       "              25579: 194,\n",
       "              15859: 216,\n",
       "              38900: 182,\n",
       "              7670: 192,\n",
       "              8698: 202,\n",
       "              12284: 210,\n",
       "              44542: 172,\n",
       "              31231: 214},\n",
       "             1: {50178: 194,\n",
       "              46600: 182,\n",
       "              31755: 184,\n",
       "              46604: 192,\n",
       "              10765: 224,\n",
       "              11276: 176,\n",
       "              33811: 186,\n",
       "              46612: 232,\n",
       "              16916: 238,\n",
       "              18966: 220,\n",
       "              12824: 182,\n",
       "              32794: 212,\n",
       "              7195: 178,\n",
       "              33821: 170,\n",
       "              37921: 176,\n",
       "              33313: 208,\n",
       "              31270: 176,\n",
       "              29222: 146,\n",
       "              28712: 182,\n",
       "              18985: 240,\n",
       "              37930: 220,\n",
       "              28200: 188,\n",
       "              7727: 168,\n",
       "              24112: 186,\n",
       "              36400: 246,\n",
       "              32817: 214,\n",
       "              5171: 192,\n",
       "              44085: 242,\n",
       "              35382: 172,\n",
       "              14912: 194,\n",
       "              30274: 150,\n",
       "              20554: 144,\n",
       "              15435: 190,\n",
       "              33357: 182,\n",
       "              49231: 168,\n",
       "              38994: 192,\n",
       "              21587: 210,\n",
       "              7252: 164,\n",
       "              40537: 160,\n",
       "              27738: 196,\n",
       "              44123: 154,\n",
       "              44124: 186,\n",
       "              14943: 178,\n",
       "              45664: 192,\n",
       "              15458: 266,\n",
       "              49765: 222,\n",
       "              19046: 222,\n",
       "              35944: 190,\n",
       "              29804: 170,\n",
       "              23662: 172,\n",
       "              37497: 164,\n",
       "              22138: 178,\n",
       "              27773: 220,\n",
       "              28798: 156,\n",
       "              33407: 172,\n",
       "              27264: 182,\n",
       "              9857: 212,\n",
       "              14468: 152,\n",
       "              6277: 192,\n",
       "              35972: 180,\n",
       "              4744: 186,\n",
       "              32905: 170,\n",
       "              32393: 234,\n",
       "              22671: 172,\n",
       "              20628: 200,\n",
       "              32920: 382,\n",
       "              17560: 164,\n",
       "              5119: 166,\n",
       "              21661: 244,\n",
       "              16543: 206,\n",
       "              31903: 198,\n",
       "              18089: 138,\n",
       "              16553: 198,\n",
       "              28331: 232,\n",
       "              41131: 186,\n",
       "              20145: 138,\n",
       "              46262: 196,\n",
       "              30397: 228,\n",
       "              41151: 206,\n",
       "              22723: 246,\n",
       "              23239: 166,\n",
       "              14538: 190,\n",
       "              17100: 200,\n",
       "              37073: 178,\n",
       "              22739: 210,\n",
       "              49365: 136,\n",
       "              16598: 148,\n",
       "              47831: 210,\n",
       "              31959: 184,\n",
       "              22234: 208,\n",
       "              23259: 162,\n",
       "              20189: 224,\n",
       "              45790: 216,\n",
       "              29927: 262,\n",
       "              46312: 218,\n",
       "              31465: 160,\n",
       "              46831: 170,\n",
       "              31472: 204,\n",
       "              29936: 158,\n",
       "              26355: 248,\n",
       "              6393: 206,\n",
       "              26876: 210,\n",
       "              8444: 172,\n",
       "              26878: 172,\n",
       "              6911: 198,\n",
       "              25856: 176,\n",
       "              21249: 188,\n",
       "              19717: 130,\n",
       "              8966: 158,\n",
       "              38150: 204,\n",
       "              26888: 168,\n",
       "              27917: 148,\n",
       "              39184: 158,\n",
       "              48401: 142,\n",
       "              24336: 184,\n",
       "              6416: 194,\n",
       "              23316: 148,\n",
       "              37144: 200,\n",
       "              31513: 202,\n",
       "              42266: 222,\n",
       "              29989: 146,\n",
       "              27434: 158,\n",
       "              45867: 158,\n",
       "              36139: 234,\n",
       "              29489: 170,\n",
       "              27443: 172,\n",
       "              27955: 210,\n",
       "              22838: 202,\n",
       "              7993: 196,\n",
       "              13114: 182,\n",
       "              13629: 186,\n",
       "              28991: 182,\n",
       "              40771: 180,\n",
       "              25413: 188,\n",
       "              44870: 198,\n",
       "              18247: 202,\n",
       "              47944: 196,\n",
       "              35657: 178,\n",
       "              26953: 186,\n",
       "              13651: 154,\n",
       "              27991: 170,\n",
       "              26456: 200,\n",
       "              48990: 126,\n",
       "              34655: 234,\n",
       "              16225: 196,\n",
       "              28518: 140,\n",
       "              20839: 184,\n",
       "              43367: 216,\n",
       "              10092: 168,\n",
       "              11116: 216,\n",
       "              31086: 216,\n",
       "              29040: 244,\n",
       "              50033: 188,\n",
       "              5490: 196,\n",
       "              39795: 190,\n",
       "              48505: 182,\n",
       "              40316: 218,\n",
       "              24958: 184,\n",
       "              38783: 198,\n",
       "              19838: 194,\n",
       "              23425: 198,\n",
       "              24962: 168,\n",
       "              13187: 220,\n",
       "              49028: 196,\n",
       "              12167: 158,\n",
       "              43406: 204,\n",
       "              14737: 200,\n",
       "              18322: 190,\n",
       "              43921: 172,\n",
       "              12694: 180,\n",
       "              16286: 182,\n",
       "              48545: 180,\n",
       "              29092: 198,\n",
       "              15273: 174,\n",
       "              16809: 178,\n",
       "              22455: 190,\n",
       "              24504: 202,\n",
       "              30140: 240,\n",
       "              27581: 178,\n",
       "              21438: 224,\n",
       "              35262: 172,\n",
       "              36292: 164,\n",
       "              6086: 210,\n",
       "              21960: 152,\n",
       "              20428: 206,\n",
       "              17361: 182,\n",
       "              33747: 170,\n",
       "              2516: 162,\n",
       "              13268: 332,\n",
       "              45014: 206,\n",
       "              25556: 166,\n",
       "              33240: 184,\n",
       "              36312: 192,\n",
       "              16863: 222,\n",
       "              28642: 200,\n",
       "              10213: 184,\n",
       "              16358: 196,\n",
       "              25062: 184,\n",
       "              23528: 174,\n",
       "              35307: 186,\n",
       "              19436: 204,\n",
       "              25579: 230,\n",
       "              15859: 186,\n",
       "              38900: 238,\n",
       "              7670: 174,\n",
       "              8698: 170,\n",
       "              12284: 222,\n",
       "              44542: 208,\n",
       "              31231: 196},\n",
       "             2: {50178: 144,\n",
       "              46600: 180,\n",
       "              31755: 164,\n",
       "              46604: 210,\n",
       "              10765: 192,\n",
       "              11276: 210,\n",
       "              33811: 164,\n",
       "              46612: 238,\n",
       "              16916: 188,\n",
       "              18966: 222,\n",
       "              12824: 194,\n",
       "              32794: 162,\n",
       "              7195: 174,\n",
       "              33821: 182,\n",
       "              37921: 174,\n",
       "              33313: 206,\n",
       "              31270: 200,\n",
       "              29222: 134,\n",
       "              28712: 168,\n",
       "              18985: 150,\n",
       "              37930: 176,\n",
       "              28200: 208,\n",
       "              7727: 126,\n",
       "              24112: 222,\n",
       "              36400: 178,\n",
       "              32817: 222,\n",
       "              5171: 170,\n",
       "              44085: 208,\n",
       "              35382: 218,\n",
       "              14912: 192,\n",
       "              30274: 214,\n",
       "              20554: 152,\n",
       "              15435: 210,\n",
       "              33357: 144,\n",
       "              49231: 210,\n",
       "              38994: 198,\n",
       "              21587: 204,\n",
       "              7252: 158,\n",
       "              40537: 222,\n",
       "              27738: 238,\n",
       "              44123: 196,\n",
       "              44124: 232,\n",
       "              14943: 184,\n",
       "              45664: 198,\n",
       "              15458: 214,\n",
       "              49765: 194,\n",
       "              19046: 200,\n",
       "              35944: 220,\n",
       "              29804: 194,\n",
       "              23662: 198,\n",
       "              37497: 198,\n",
       "              22138: 220,\n",
       "              27773: 184,\n",
       "              28798: 166,\n",
       "              33407: 160,\n",
       "              27264: 168,\n",
       "              9857: 138,\n",
       "              14468: 208,\n",
       "              6277: 196,\n",
       "              35972: 158,\n",
       "              4744: 200,\n",
       "              32905: 218,\n",
       "              32393: 166,\n",
       "              22671: 212,\n",
       "              20628: 194,\n",
       "              32920: 372,\n",
       "              17560: 184,\n",
       "              5119: 116,\n",
       "              21661: 212,\n",
       "              16543: 190,\n",
       "              31903: 182,\n",
       "              18089: 196,\n",
       "              16553: 190,\n",
       "              28331: 170,\n",
       "              41131: 188,\n",
       "              20145: 198,\n",
       "              46262: 198,\n",
       "              30397: 190,\n",
       "              41151: 198,\n",
       "              22723: 164,\n",
       "              23239: 192,\n",
       "              14538: 188,\n",
       "              17100: 228,\n",
       "              37073: 180,\n",
       "              22739: 236,\n",
       "              49365: 160,\n",
       "              16598: 178,\n",
       "              47831: 186,\n",
       "              31959: 184,\n",
       "              22234: 196,\n",
       "              23259: 228,\n",
       "              20189: 158,\n",
       "              45790: 206,\n",
       "              29927: 216,\n",
       "              46312: 206,\n",
       "              31465: 206,\n",
       "              46831: 186,\n",
       "              31472: 222,\n",
       "              29936: 164,\n",
       "              26355: 130,\n",
       "              6393: 154,\n",
       "              26876: 194,\n",
       "              8444: 162,\n",
       "              26878: 180,\n",
       "              6911: 150,\n",
       "              25856: 152,\n",
       "              21249: 152,\n",
       "              19717: 176,\n",
       "              8966: 190,\n",
       "              38150: 182,\n",
       "              26888: 226,\n",
       "              27917: 212,\n",
       "              39184: 192,\n",
       "              48401: 152,\n",
       "              24336: 170,\n",
       "              6416: 180,\n",
       "              23316: 152,\n",
       "              37144: 168,\n",
       "              31513: 200,\n",
       "              42266: 148,\n",
       "              29989: 156,\n",
       "              27434: 220,\n",
       "              45867: 190,\n",
       "              36139: 194,\n",
       "              29489: 182,\n",
       "              27443: 218,\n",
       "              27955: 188,\n",
       "              22838: 190,\n",
       "              7993: 170,\n",
       "              13114: 164,\n",
       "              13629: 198,\n",
       "              28991: 192,\n",
       "              40771: 182,\n",
       "              25413: 258,\n",
       "              44870: 180,\n",
       "              18247: 236,\n",
       "              47944: 208,\n",
       "              35657: 198,\n",
       "              26953: 214,\n",
       "              13651: 248,\n",
       "              27991: 228,\n",
       "              26456: 214,\n",
       "              48990: 188,\n",
       "              34655: 186,\n",
       "              16225: 158,\n",
       "              28518: 158,\n",
       "              20839: 212,\n",
       "              43367: 228,\n",
       "              10092: 192,\n",
       "              11116: 166,\n",
       "              31086: 176,\n",
       "              29040: 208,\n",
       "              50033: 158,\n",
       "              5490: 198,\n",
       "              39795: 218,\n",
       "              48505: 166,\n",
       "              40316: 196,\n",
       "              24958: 210,\n",
       "              38783: 132,\n",
       "              19838: 230,\n",
       "              23425: 156,\n",
       "              24962: 210,\n",
       "              13187: 192,\n",
       "              49028: 252,\n",
       "              12167: 174,\n",
       "              43406: 226,\n",
       "              14737: 172,\n",
       "              18322: 178,\n",
       "              43921: 188,\n",
       "              12694: 192,\n",
       "              16286: 174,\n",
       "              48545: 172,\n",
       "              29092: 140,\n",
       "              15273: 210,\n",
       "              16809: 190,\n",
       "              22455: 160,\n",
       "              24504: 214,\n",
       "              30140: 154,\n",
       "              27581: 168,\n",
       "              21438: 206,\n",
       "              35262: 192,\n",
       "              36292: 178,\n",
       "              6086: 162,\n",
       "              21960: 200,\n",
       "              20428: 214,\n",
       "              17361: 202,\n",
       "              33747: 172,\n",
       "              2516: 244,\n",
       "              13268: 414,\n",
       "              45014: 174,\n",
       "              25556: 196,\n",
       "              33240: 236,\n",
       "              36312: 218,\n",
       "              16863: 140,\n",
       "              28642: 204,\n",
       "              10213: 212,\n",
       "              16358: 192,\n",
       "              25062: 206,\n",
       "              23528: 190,\n",
       "              35307: 172,\n",
       "              19436: 176,\n",
       "              25579: 168,\n",
       "              15859: 178,\n",
       "              38900: 202,\n",
       "              7670: 206,\n",
       "              8698: 212,\n",
       "              12284: 184,\n",
       "              44542: 190,\n",
       "              31231: 198},\n",
       "             3: {50178: 238,\n",
       "              46600: 156,\n",
       "              31755: 182,\n",
       "              46604: 188,\n",
       "              10765: 196,\n",
       "              11276: 182,\n",
       "              33811: 174,\n",
       "              46612: 214,\n",
       "              16916: 218,\n",
       "              18966: 208,\n",
       "              12824: 172,\n",
       "              32794: 220,\n",
       "              7195: 162,\n",
       "              33821: 194,\n",
       "              37921: 246,\n",
       "              33313: 238,\n",
       "              31270: 172,\n",
       "              29222: 164,\n",
       "              28712: 186,\n",
       "              18985: 196,\n",
       "              37930: 180,\n",
       "              28200: 190,\n",
       "              7727: 184,\n",
       "              24112: 188,\n",
       "              36400: 226,\n",
       "              32817: 194,\n",
       "              5171: 180,\n",
       "              44085: 158,\n",
       "              35382: 202,\n",
       "              14912: 172,\n",
       "              30274: 184,\n",
       "              20554: 180,\n",
       "              15435: 148,\n",
       "              33357: 154,\n",
       "              49231: 158,\n",
       "              38994: 236,\n",
       "              21587: 200,\n",
       "              7252: 196,\n",
       "              40537: 194,\n",
       "              27738: 224,\n",
       "              44123: 154,\n",
       "              44124: 198,\n",
       "              14943: 168,\n",
       "              45664: 136,\n",
       "              15458: 222,\n",
       "              49765: 210,\n",
       "              19046: 210,\n",
       "              35944: 258,\n",
       "              29804: 176,\n",
       "              23662: 166,\n",
       "              37497: 160,\n",
       "              22138: 164,\n",
       "              27773: 270,\n",
       "              28798: 176,\n",
       "              33407: 202,\n",
       "              27264: 196,\n",
       "              9857: 216,\n",
       "              14468: 170,\n",
       "              6277: 172,\n",
       "              35972: 202,\n",
       "              4744: 216,\n",
       "              32905: 164,\n",
       "              32393: 206,\n",
       "              22671: 220,\n",
       "              20628: 176,\n",
       "              32920: 320,\n",
       "              17560: 200,\n",
       "              5119: 154,\n",
       "              21661: 174,\n",
       "              16543: 176,\n",
       "              31903: 246,\n",
       "              18089: 154,\n",
       "              16553: 158,\n",
       "              28331: 184,\n",
       "              41131: 214,\n",
       "              20145: 182,\n",
       "              46262: 210,\n",
       "              30397: 184,\n",
       "              41151: 256,\n",
       "              22723: 206,\n",
       "              23239: 212,\n",
       "              14538: 170,\n",
       "              17100: 168,\n",
       "              37073: 160,\n",
       "              22739: 228,\n",
       "              49365: 204,\n",
       "              16598: 190,\n",
       "              47831: 220,\n",
       "              31959: 218,\n",
       "              22234: 208,\n",
       "              23259: 176,\n",
       "              20189: 226,\n",
       "              45790: 194,\n",
       "              29927: 232,\n",
       "              46312: 194,\n",
       "              31465: 148,\n",
       "              46831: 174,\n",
       "              31472: 240,\n",
       "              29936: 146,\n",
       "              26355: 256,\n",
       "              6393: 146,\n",
       "              26876: 180,\n",
       "              8444: 230,\n",
       "              26878: 224,\n",
       "              6911: 176,\n",
       "              25856: 164,\n",
       "              21249: 194,\n",
       "              19717: 168,\n",
       "              8966: 146,\n",
       "              38150: 142,\n",
       "              26888: 194,\n",
       "              27917: 158,\n",
       "              39184: 148,\n",
       "              48401: 234,\n",
       "              24336: 170,\n",
       "              6416: 220,\n",
       "              23316: 176,\n",
       "              37144: 218,\n",
       "              31513: 208,\n",
       "              42266: 188,\n",
       "              29989: 168,\n",
       "              27434: 160,\n",
       "              45867: 206,\n",
       "              36139: 272,\n",
       "              29489: 208,\n",
       "              27443: 176,\n",
       "              27955: 204,\n",
       "              22838: 196,\n",
       "              7993: 246,\n",
       "              13114: 166,\n",
       "              13629: 192,\n",
       "              28991: 158,\n",
       "              40771: 204,\n",
       "              25413: 208,\n",
       "              44870: 188,\n",
       "              18247: 170,\n",
       "              47944: 164,\n",
       "              35657: 182,\n",
       "              26953: 154,\n",
       "              13651: 178,\n",
       "              27991: 200,\n",
       "              26456: 146,\n",
       "              48990: 192,\n",
       "              34655: 198,\n",
       "              16225: 222,\n",
       "              28518: 154,\n",
       "              20839: 204,\n",
       "              43367: 206,\n",
       "              10092: 216,\n",
       "              11116: 220,\n",
       "              31086: 192,\n",
       "              29040: 242,\n",
       "              50033: 182,\n",
       "              5490: 168,\n",
       "              39795: 214,\n",
       "              48505: 174,\n",
       "              40316: 196,\n",
       "              24958: 176,\n",
       "              38783: 184,\n",
       "              19838: 196,\n",
       "              23425: 178,\n",
       "              24962: 182,\n",
       "              13187: 218,\n",
       "              49028: 170,\n",
       "              12167: 224,\n",
       "              43406: 182,\n",
       "              14737: 224,\n",
       "              18322: 162,\n",
       "              43921: 170,\n",
       "              12694: 140,\n",
       "              16286: 176,\n",
       "              48545: 192,\n",
       "              29092: 172,\n",
       "              15273: 172,\n",
       "              16809: 152,\n",
       "              22455: 140,\n",
       "              24504: 150,\n",
       "              30140: 250,\n",
       "              27581: 162,\n",
       "              21438: 174,\n",
       "              35262: 208,\n",
       "              36292: 202,\n",
       "              6086: 170,\n",
       "              21960: 138,\n",
       "              20428: 206,\n",
       "              17361: 178,\n",
       "              33747: 188,\n",
       "              2516: 160,\n",
       "              13268: 340,\n",
       "              45014: 200,\n",
       "              25556: 180,\n",
       "              33240: 192,\n",
       "              36312: 180,\n",
       "              16863: 192,\n",
       "              28642: 174,\n",
       "              10213: 192,\n",
       "              16358: 200,\n",
       "              25062: 176,\n",
       "              23528: 154,\n",
       "              35307: 196,\n",
       "              19436: 176,\n",
       "              25579: 198,\n",
       "              15859: 194,\n",
       "              38900: 220,\n",
       "              7670: 188,\n",
       "              8698: 182,\n",
       "              12284: 212,\n",
       "              44542: 176,\n",
       "              31231: 228},\n",
       "             4: {50178: 160,\n",
       "              46600: 194,\n",
       "              31755: 158,\n",
       "              46604: 180,\n",
       "              10765: 204,\n",
       "              11276: 204,\n",
       "              33811: 162,\n",
       "              46612: 240,\n",
       "              16916: 170,\n",
       "              18966: 246,\n",
       "              12824: 198,\n",
       "              32794: 164,\n",
       "              7195: 182,\n",
       "              33821: 172,\n",
       "              37921: 162,\n",
       "              33313: 220,\n",
       "              31270: 208,\n",
       "              29222: 130,\n",
       "              28712: 168,\n",
       "              18985: 172,\n",
       "              37930: 196,\n",
       "              28200: 206,\n",
       "              7727: 128,\n",
       "              24112: 204,\n",
       "              36400: 216,\n",
       "              32817: 210,\n",
       "              5171: 184,\n",
       "              44085: 232,\n",
       "              35382: 200,\n",
       "              14912: 162,\n",
       "              30274: 224,\n",
       "              20554: 150,\n",
       "              15435: 210,\n",
       "              33357: 158,\n",
       "              49231: 212,\n",
       "              38994: 212,\n",
       "              21587: 190,\n",
       "              7252: 144,\n",
       "              40537: 212,\n",
       "              27738: 236,\n",
       "              44123: 206,\n",
       "              44124: 212,\n",
       "              14943: 190,\n",
       "              45664: 208,\n",
       "              15458: 232,\n",
       "              49765: 202,\n",
       "              19046: 222,\n",
       "              35944: 198,\n",
       "              29804: 170,\n",
       "              23662: 184,\n",
       "              37497: 190,\n",
       "              22138: 220,\n",
       "              27773: 190,\n",
       "              28798: 172,\n",
       "              33407: 148,\n",
       "              27264: 190,\n",
       "              9857: 124,\n",
       "              14468: 182,\n",
       "              6277: 190,\n",
       "              35972: 166,\n",
       "              4744: 206,\n",
       "              32905: 198,\n",
       "              32393: 186,\n",
       "              22671: 208,\n",
       "              20628: 188,\n",
       "              32920: 380,\n",
       "              17560: 178,\n",
       "              5119: 108,\n",
       "              21661: 246,\n",
       "              16543: 164,\n",
       "              31903: 188,\n",
       "              18089: 180,\n",
       "              16553: 204,\n",
       "              28331: 206,\n",
       "              41131: 178,\n",
       "              20145: 168,\n",
       "              46262: 184,\n",
       "              30397: 212,\n",
       "              41151: 194,\n",
       "              22723: 202,\n",
       "              23239: 182,\n",
       "              14538: 198,\n",
       "              17100: 228,\n",
       "              37073: 192,\n",
       "              22739: 228,\n",
       "              49365: 172,\n",
       "              16598: 168,\n",
       "              47831: 188,\n",
       "              31959: 172,\n",
       "              22234: 178,\n",
       "              23259: 206,\n",
       "              20189: 162,\n",
       "              45790: 232,\n",
       "              29927: 214,\n",
       "              46312: 224,\n",
       "              31465: 214,\n",
       "              46831: 188,\n",
       "              31472: 204,\n",
       "              29936: 138,\n",
       "              26355: 160,\n",
       "              6393: 204,\n",
       "              26876: 210,\n",
       "              8444: 172,\n",
       "              26878: 158,\n",
       "              6911: 144,\n",
       "              25856: 140,\n",
       "              21249: 132,\n",
       "              19717: 154,\n",
       "              8966: 196,\n",
       "              38150: 200,\n",
       "              26888: 212,\n",
       "              27917: 198,\n",
       "              39184: 190,\n",
       "              48401: 150,\n",
       "              24336: 160,\n",
       "              6416: 176,\n",
       "              23316: 154,\n",
       "              37144: 176,\n",
       "              31513: 206,\n",
       "              42266: 142,\n",
       "              29989: 142,\n",
       "              27434: 218,\n",
       "              45867: 156,\n",
       "              36139: 210,\n",
       "              29489: 180,\n",
       "              27443: 206,\n",
       "              27955: 190,\n",
       "              22838: 210,\n",
       "              7993: 170,\n",
       "              13114: 176,\n",
       "              13629: 190,\n",
       "              28991: 182,\n",
       "              40771: 176,\n",
       "              25413: 240,\n",
       "              44870: 192,\n",
       "              18247: 214,\n",
       "              47944: 200,\n",
       "              35657: 184,\n",
       "              26953: 212,\n",
       "              13651: 194,\n",
       "              27991: 222,\n",
       "              26456: 220,\n",
       "              48990: 162,\n",
       "              34655: 202,\n",
       "              16225: 166,\n",
       "              28518: 152,\n",
       "              20839: 220,\n",
       "              43367: 194,\n",
       "              10092: 180,\n",
       "              11116: 174,\n",
       "              31086: 170,\n",
       "              29040: 220,\n",
       "              50033: 172,\n",
       "              5490: 214,\n",
       "              39795: 212,\n",
       "              48505: 154,\n",
       "              40316: 198,\n",
       "              24958: 198,\n",
       "              38783: 172,\n",
       "              19838: 204,\n",
       "              23425: 184,\n",
       "              24962: 220,\n",
       "              13187: 192,\n",
       "              49028: 226,\n",
       "              12167: 168,\n",
       "              43406: 248,\n",
       "              14737: 152,\n",
       "              18322: 206,\n",
       "              43921: 190,\n",
       "              12694: 172,\n",
       "              16286: 158,\n",
       "              48545: 154,\n",
       "              29092: 152,\n",
       "              15273: 174,\n",
       "              16809: 208,\n",
       "              22455: 184,\n",
       "              24504: 218,\n",
       "              30140: 168,\n",
       "              27581: 168,\n",
       "              21438: 206,\n",
       "              35262: 160,\n",
       "              36292: 164,\n",
       "              6086: 196,\n",
       "              21960: 202,\n",
       "              20428: 200,\n",
       "              17361: 190,\n",
       "              33747: 184,\n",
       "              2516: 250,\n",
       "              13268: 394,\n",
       "              45014: 200,\n",
       "              25556: 174,\n",
       "              33240: 220,\n",
       "              36312: 206,\n",
       "              16863: 174,\n",
       "              28642: 210,\n",
       "              10213: 218,\n",
       "              16358: 176,\n",
       "              25062: 218,\n",
       "              23528: 190,\n",
       "              35307: 184,\n",
       "              19436: 184,\n",
       "              25579: 190,\n",
       "              15859: 190,\n",
       "              38900: 242,\n",
       "              7670: 198,\n",
       "              8698: 208,\n",
       "              12284: 210,\n",
       "              44542: 196,\n",
       "              31231: 200}})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd58f192-1209-4e50-91ed-6fae7bc1b021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9901, 0.9901, 1.0000, 0.4752, 0.4752],\n",
       "        [1.0000, 1.0000, 0.9901, 0.6040, 0.5842],\n",
       "        [0.9802, 1.0000, 0.9901, 0.4455, 0.3861]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_correct_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "88a02596-53c9-4a4c-a6bf-512407cd28b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 120000/120000 [00:21<00:00, 5619.17it/s]\n",
      "100%|| 120000/120000 [00:21<00:00, 5499.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [07:01<00:00,  1.05s/it]\n",
      "  1%|                                                                                  | 3/400 [00:04<08:54,  1.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 149\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#del X\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m#del Y\u001b[39;00m\n\u001b[1;32m    148\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m--> 149\u001b[0m vX, vY \u001b[38;5;241m=\u001b[39m \u001b[43mget_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvdata_name_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m pY \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mpredict(vX)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# we want cosine similarity to actual embedding vectors\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m#avg_sim = cosine_similarity(pY, vY).mean().item()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[89], line 133\u001b[0m, in \u001b[0;36mget_training_data\u001b[0;34m(dat, name_positions, batch_size)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_end\u001b[38;5;241m-\u001b[39mbatch_start):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m#print(ssm_inputs[batch_i, position].size())\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     position \u001b[38;5;241m=\u001b[39m positions[batch_i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# +1 because conv\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     bX \u001b[38;5;241m=\u001b[39m \u001b[43mget_linear_classification_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(bX)\n\u001b[1;32m    135\u001b[0m     Y\u001b[38;5;241m.\u001b[39mappend(name_tokens[batch_i]\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[89], line 102\u001b[0m, in \u001b[0;36mget_linear_classification_X\u001b[0;34m(activations, layer, batch_i, position_x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_linear_classification_X\u001b[39m(activations, layer, batch_i, position_x):\n\u001b[0;32m--> 102\u001b[0m     vec \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblocks.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.hook_ssm_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43mposition_x\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m#vec = vec / torch.linalg.norm(vec, ord=2) / divTerm\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vec\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "# we want to predict the name from the representation\n",
    "# there are two ways to do this:\n",
    "# 1. Predict the probability of a rep being a name (output logits for each name)\n",
    "# 2. Output the name embedding\n",
    "# we'll start with the second one because it is more general, if that doesn't work we can try the first one\n",
    "\n",
    "\n",
    "# we're basically doing a tuned lens sorta? idk\n",
    "# lets start with not batched\n",
    "\n",
    "# okay so say we are trying to output the name embedding\n",
    "# on layer i, that could mean:\n",
    "#    predict emb after it's projected into E space (which is after norm, but before conv)\n",
    "#    predict emb after conv\n",
    "#    predict emb after conv and silu\n",
    "#    predict emb from hidden state or some other internal rep\n",
    "# the point is that we train this linear map for some specific thing, then how well it performs suggests how well that thing encodes our data,\n",
    "# so we can try it for lots of intermediate stuff\n",
    "# some of the maps won't work, that's ok\n",
    "from mamba_lens.input_dependent_hooks import clean_hooks\n",
    "import torch\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from jaxtyping import Float\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "# this is useful because sometimes if you spam ctrl-c too many times some hooks will stay around\n",
    "clean_hooks(model)\n",
    "\n",
    "# make sure we have no overlap\n",
    "#joined_data = torch.cat([data.data, data.valid_data], dim=0)\n",
    "#torch.sort(joined_data, dim=0)\n",
    "#unique = torch.unique(joined_data, dim=0)\n",
    "#torch.manual_seed(27)\n",
    "# shuffle data\n",
    "#unique = unique[torch.randperm(unique.size()[0])]\n",
    "#B = unique.size()[0]//3\n",
    "# split into train valid and test\n",
    "#dataset, vdataset, tdataset = unique[:B], unique[B:2*B], unique[2*B:3*B]\n",
    "dataset = data.data\n",
    "vdataset = data.valid_data\n",
    "\n",
    "\n",
    "\n",
    "from acdc.data.ioi import good_names\n",
    "from collections import defaultdict\n",
    "name_tokens = set([model.to_single_token(\" \" + name) for name in good_names])\n",
    "\n",
    "\n",
    "name_tok_to_class = {}\n",
    "for i, tok in enumerate(sorted(list(name_tokens))):\n",
    "    name_tok_to_class[tok] = i\n",
    "\n",
    "def get_name_positions(dat):\n",
    "    name_positions = defaultdict(lambda: [])\n",
    "    for i in tqdm(list(range(dat.size()[0]))):\n",
    "        prompt_tokens = dat[i]\n",
    "        name_pos = 0\n",
    "        for i, tok in enumerate(prompt_tokens):\n",
    "            if tok.item() in name_tokens:\n",
    "                name_positions[name_pos].append(i)\n",
    "                name_pos += 1\n",
    "        if name_pos != 5: raise ValueError(f\"data point {model.to_str_tokens(data)} does not have 5 names\")\n",
    "    return name_positions\n",
    "\n",
    "data_name_positions, vdata_name_positions = get_name_positions(dataset), get_name_positions(vdataset)\n",
    "\n",
    "model_kwargs = {\n",
    "    \"fast_ssm\": True,\n",
    "    \"fast_conv\": True,\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 300\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "B,L = dataset.size()\n",
    "\n",
    "# for each position that varies, for each other position, fit a linear model\n",
    "\n",
    "global probing_dataset_X\n",
    "probing_dataset_X = []\n",
    "def dataset_gathering_hook(\n",
    "    x: Float[torch.Tensor, \"B L D\"],\n",
    "    hook: HookPoint,\n",
    "    position: int\n",
    "):\n",
    "    global probing_dataset_X\n",
    "    probing_dataset_X.append(x[:,position,:].cpu())\n",
    "    return x\n",
    "\n",
    "layer = 39\n",
    "\n",
    "linear_models = []\n",
    "E = model.cfg.E\n",
    "divTerm = float(math.sqrt(math.sqrt(float(E))*E))\n",
    "for name_i in range(5):\n",
    "    \n",
    "    # make dataset\n",
    "    \n",
    "    def get_linear_classification_X(activations, layer, batch_i, position_x):\n",
    "        vec = activations[f'blocks.{layer}.hook_ssm_input'][batch_i,position_x].view(-1)\n",
    "        #vec = vec / torch.linalg.norm(vec, ord=2) / divTerm\n",
    "        return vec.view(1,-1).detach().cpu().numpy()\n",
    "\n",
    "    def get_linear_classification_Y(labels):\n",
    "        B = labels.size()[0]\n",
    "        Y = np.zeros([B,len(name_tokens)])\n",
    "        #Y = model.embedding.weight[input_data[:,position_y]]\n",
    "        #return Y.detach().cpu().numpy()\n",
    "        Y[:] = -1 # predict a vector with -1 for incorrect class and 1 for correct class\n",
    "        for i in range(B):\n",
    "            value = labels[i].item()\n",
    "            Y[i,name_tok_to_class[value]] = 1\n",
    "        return Y#/math.sqrt(float(model.cfg.E))\n",
    "    \n",
    "    names_filter = [f'blocks.{layer}.hook_ssm_input']\n",
    "    \n",
    "    print(f\"collecting data...\")\n",
    "\n",
    "    def get_training_data(dat, name_positions, batch_size):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for batch_start in tqdm(list(range(0, dat.size()[0], batch_size))):\n",
    "            batch_end = min(batch_start + batch_size, dataset.size()[0])\n",
    "            data_batch = dat[batch_start:batch_end]\n",
    "            positions = torch.tensor(name_positions[name_i][batch_start:batch_end], device=model.cfg.device)\n",
    "            name_tokens = data_batch[torch.arange(batch_end-batch_start),positions]\n",
    "            logits, activations = model.run_with_cache(data_batch, names_filter=names_filter, **model_kwargs)\n",
    "            for batch_i in range(batch_end-batch_start):\n",
    "                #print(ssm_inputs[batch_i, position].size())\n",
    "                position = positions[batch_i] + 1 # +1 because conv\n",
    "                bX = get_linear_classification_X(activations=activations, layer=layer, batch_i=batch_i, position_x=position)\n",
    "                X.append(bX)\n",
    "                Y.append(name_tokens[batch_i].item())\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        Y = torch.tensor(Y)\n",
    "        Y = get_linear_classification_Y(labels=Y)\n",
    "        return X, Y\n",
    "\n",
    "    X, Y = get_training_data(dat=dataset, name_positions=data_name_positions, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X, Y)\n",
    "    linear_models.append(linear_model)\n",
    "    #del X\n",
    "    #del Y\n",
    "    torch.cuda.empty_cache()\n",
    "    vX, vY = get_training_data(dat=vdataset, name_positions=vdata_name_positions, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    pY = linear_model.predict(vX)\n",
    "    # we want cosine similarity to actual embedding vectors\n",
    "    #avg_sim = cosine_similarity(pY, vY).mean().item()\n",
    "    predicted_inds = np.argmax(pY, axis=1)\n",
    "    actual_inds = np.argmax(vY, axis=1)\n",
    "    acc = np.sum(predicted_inds==actual_inds)/float(predicted_inds.shape[0])\n",
    "    print(f\"position {name_i} layer {layer} acc {acc}\")\n",
    "    #outpaut_accuracies[position_i, layer, other_position] = avg_sim\n",
    "\n",
    "print(f\"these token positions vary their value: {positions_that_vary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e19606-dde4-49fc-840e-8cd3c035e560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_fit',\n",
       " '_fit_full',\n",
       " '_fit_svd_solver',\n",
       " '_fit_truncated',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_n_features_out',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sklearn_auto_wrap_output_keys',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " 'components_',\n",
       " 'copy',\n",
       " 'explained_variance_',\n",
       " 'explained_variance_ratio_',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_covariance',\n",
       " 'get_feature_names_out',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'get_precision',\n",
       " 'inverse_transform',\n",
       " 'iterated_power',\n",
       " 'mean_',\n",
       " 'n_components',\n",
       " 'n_components_',\n",
       " 'n_features_in_',\n",
       " 'n_oversamples',\n",
       " 'n_samples_',\n",
       " 'noise_variance_',\n",
       " 'power_iteration_normalizer',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'set_output',\n",
       " 'set_params',\n",
       " 'singular_values_',\n",
       " 'svd_solver',\n",
       " 'tol',\n",
       " 'transform',\n",
       " 'whiten']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "470a3314-2d8d-4337-9f01-28af455ab120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div term 304.4370214406966\n",
      "worst case mag 5.129492386402035e-10\n",
      "div term 304.4370214406966\n",
      "worst case mag 5.129643376733384e-10\n",
      "div term 304.4370214406966\n",
      "worst case mag 5.129641711398847e-10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "np.random.seed(27)\n",
    "\n",
    "class NameBasis(object):\n",
    "    def __init__(self, linear_model):\n",
    "        self.linear_model = linear_model\n",
    "        #       [C,E] [E,1] [C] [C]\n",
    "        # we have A  @  x  + b = y which is -1 for not name and 1 for name\n",
    "        # we want a V s.t.\n",
    "        #       [E,E] [E,1] [E]  [E]\n",
    "        #         V  @  x  + d =  y\n",
    "        # where V is invertible so\n",
    "        #        [E]   [E,E]    [E] [E]\n",
    "        #         x  = V^-1  @  (y - d)\n",
    "        # and\n",
    "        #          [C,E]    [E,1]     [C]\n",
    "        #        V[:C,:]  @   x   +  d[:C] =\n",
    "        #            A                 b\n",
    "        # the simplest way to do this is to set those extra bias terms to zero\n",
    "        # and those extra rows to normally distributed random values\n",
    "        # (with high pr the matrix should be invertible as long as first C aren't linearly dependent)\n",
    "        A = linear_model.coef_\n",
    "        b = linear_model.intercept_\n",
    "        C,E = A.shape\n",
    "        self.E = E\n",
    "        d = np.zeros([E])\n",
    "        d[:C] = b\n",
    "        V = np.random.randn(E,E)\n",
    "        V[:C] = A\n",
    "        # normalize rows to help it be more well behaved\n",
    "        # actually if they are normalized, the input is normalized so output values\n",
    "        # go from -1 to 1\n",
    "        # but that's too big, that means output norm is sqrt(E)\n",
    "        # what we want is norm of result is 1\n",
    "        # each row should be magnitude 1/sqrt(E)\n",
    "        # if input is also size 1/sqrt(E) then dot product gives us\n",
    "        # ((-1,1)*1/sqrt(E)*1/sqrt(E) which is (-1/E,1/E)\n",
    "        # which would give us sqrt(E*E^2) = E^3/2 which is not unit\n",
    "        # we have mag1 mag2 and dot product gives\n",
    "        # mag1*mag2\n",
    "        # and magnitude gives\n",
    "        # sqrt(E*mag1^2*mag2^2) = sqrt(E)*mag1*mag2\n",
    "        # we want this to be 1, so\n",
    "        # 1 = sqrt(E)*mag1*mag2\n",
    "        # assume mag=mag1=mag2\n",
    "        # 1 = sqrt(E)*mag^2\n",
    "        # 1/sqrt(E) = mag^2\n",
    "        # 1/sqrt(sqrt(E)) = mag\n",
    "        # lets double check that\n",
    "        # consider 111111 vector\n",
    "        # when we divide by 1/sqrt(sqrt(E)) we get lots of terms of \n",
    "        # we have two vectors each full of 1/sqrt(sqrt(E)) terms\n",
    "        # dot product will give lots of\n",
    "        # E*(1/sqrt(sqrt(E)))*(1/sqrt(sqrt(E)))\n",
    "        # E*1/sqrt(E)\n",
    "        # The magnitude of that is\n",
    "        # sqrt(E*(E^2/E)) = E\n",
    "        # not what we want\n",
    "        # okay so we have a matrix full of 1/v\n",
    "        # we dot product each row with another vector full of 1/v\n",
    "        # each entry in result is E*1/v^2\n",
    "        # So total magnitude is\n",
    "        # sqrt(E*(E^2/v^4))\n",
    "        # = sqrt(E)*E/v^2\n",
    "        # we want this to be 1\n",
    "        # thus\n",
    "        # 1 = sqrt(E)*E/v^2\n",
    "        # v^2 = sqrt(E)*E\n",
    "        # v = sqrt(sqrt(E)*E)\n",
    "        # lets double check that\n",
    "        # E*1/sqrt(sqrt(E)*E)*1/sqrt(sqrt(E)*E) is each term\n",
    "        # E*1/sqrt(E)*1/E\n",
    "        # 1/sqrt(E) is each term in the result\n",
    "        # sqrt(E*1/E) = sqrt(1) nice!\n",
    "        self.divTerm = float(math.sqrt(math.sqrt(float(E))*E))\n",
    "        print(\"div term\", self.divTerm)\n",
    "        for row in range(C,E):\n",
    "            vrow = V[row]\n",
    "            V[row] = vrow / np.linalg.norm(vrow, ord=2) / self.divTerm\n",
    "        V_inv = np.linalg.inv(V)\n",
    "        \n",
    "        self.d = torch.tensor(d, device=model.cfg.device, dtype=torch.double)\n",
    "        self.V = torch.tensor(V, device=model.cfg.device, dtype=torch.double)\n",
    "        self.V_inv = torch.tensor(V_inv, device=model.cfg.device, dtype=torch.double)\n",
    "        # test to make sure it's invertible\n",
    "        mags = []\n",
    "        for i in range(200):\n",
    "            x = torch.tensor(vX[i] / np.linalg.norm(vX[i], ord=2) / self.divTerm, device=model.cfg.device)\n",
    "            coords = self.map_to_coords(x)\n",
    "            backx = self.map_from_coords(coords)\n",
    "            mags.append(torch.linalg.norm(x-backx, dim=0, ord=2))\n",
    "        print(f\"worst case mag {torch.max(torch.tensor(mags))}\")\n",
    "    \n",
    "    def map_to_coords(self, vec):\n",
    "        vec = vec.double() / torch.linalg.norm(vec, ord=2) / self.divTerm\n",
    "        return ((self.V @ vec.view(self.E, 1))[:,0] + self.d)\n",
    "\n",
    "    def map_from_coords(self, coords):\n",
    "        return (self.V_inv @ (coords - self.d).view(self.E, 1))[:,0].float()        \n",
    "\n",
    "\n",
    "name_bases = [NameBasis(linear_model) for linear_model in linear_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db46432-3422-47fc-9698-78ccba2ddf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                               | 1/20 [00:19<06:17, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|                                                                           | 2/20 [00:39<05:51, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|                                                                       | 3/20 [00:59<05:38, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|                                                                   | 4/20 [01:19<05:21, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|                                                               | 5/20 [01:39<04:57, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|                                                          | 6/20 [01:59<04:39, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|                                                      | 7/20 [02:18<04:15, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|                                                  | 8/20 [02:38<03:55, 19.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|                                              | 9/20 [02:58<03:37, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|                                         | 10/20 [03:18<03:19, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|                                     | 11/20 [03:38<02:59, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|                                 | 12/20 [03:59<02:42, 20.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|                             | 13/20 [04:20<02:23, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|                         | 14/20 [04:41<02:03, 20.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|                    | 15/20 [05:02<01:43, 20.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|                | 16/20 [05:21<01:21, 20.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|            | 17/20 [05:41<01:00, 20.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|        | 18/20 [06:02<00:40, 20.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|    | 19/20 [06:21<00:20, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fb5f8629f60>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dev/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [06:42<00:00, 20.11s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "replace_corrects = []\n",
    "replace_replaces = []\n",
    "pca_sizes = []\n",
    "X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "print(X_proj[:,-1])\n",
    "\n",
    "for n_components in tqdm(list(range(1, 100, 5))):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_proj)\n",
    "    pca_sizes.append(n_components)\n",
    "    replace_correct = []\n",
    "    replace_replace = []\n",
    "    print(f\"layer {layer}\")\n",
    "    name_bases = [0]\n",
    "    for position_1, name_basis in enumerate(name_bases):\n",
    "        num_found = 0\n",
    "        while True:            \n",
    "            data_i = random.choice(list(range(10000)))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i]\n",
    "            corrupted_tokens = data.data[data_i+1]\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            \n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                answer_name_tok,\n",
    "                replace_name_tok,\n",
    "                name_basis\n",
    "            ):\n",
    "                B,L,E = x.size()\n",
    "                for b in range(B):\n",
    "                    vec = x[b,position]\n",
    "                    add_ones = np.concatenate([vec.detach().cpu().numpy(), np.array([1.0])], axis=0).reshape(1,-1)\n",
    "                    pcad = pca.transform(add_ones)\n",
    "                    x[b,position] = torch.tensor(pca.inverse_transform(pcad), device=model.cfg.device).reshape(-1)[:-1]\n",
    "                    '''\n",
    "                    coords = name_basis.map_to_coords(vec/torch.linalg.norm(vec, ord=2))\n",
    "                    C = len(name_tok_to_class)\n",
    "                    sorted = torch.argsort(coords[:C])\n",
    "                    print(coords[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"predict {maxi} {coords[maxi]}\")\n",
    "                    print(f\"answer {name_tok_to_class[answer_name_tok]} replace {name_tok_to_class[replace_name_tok]}\")\n",
    "                    coords[name_tok_to_class[answer_name_tok]] = -0.0692\n",
    "                    coords[name_tok_to_class[replace_name_tok]] = 0.0692\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"now predict {maxi} {coords[maxi]}\")\n",
    "                    patched_vec = name_basis.map_from_coords(coords)\n",
    "                    print(f\"orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    patched_veco = patched_vec / torch.linalg.norm(patched_vec, ord=2) * torch.linalg.norm(vec, ord=2)\n",
    "                    print(f\"now orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    coords2 = name_basis.map_to_coords(patched_vec)\n",
    "                    sorted = torch.argsort(coords2[:C])\n",
    "                    print(\"predict2\", coords2[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords2[:C])\n",
    "                    print(f\"predict2 {maxi} {coords2[maxi]}\")\n",
    "                    '''\n",
    "                    #x[b,position] = patched_veco\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(data_name_positions)):\n",
    "                position = data_name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            hooks = []\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                \n",
    "                hooks.append((\n",
    "                    f'blocks.{layer}.hook_ssm_input', \n",
    "                    partial(replace_hook,\n",
    "                            position=position+1,\n",
    "                            answer_name_tok=answer_tok,\n",
    "                            replace_name_tok=replace_tok,\n",
    "                            name_basis=name_basis\n",
    "                    )\n",
    "                ))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            #logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            #original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            #original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            \n",
    "            logits_modified = model.run_with_hooks(corrupted_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 100:\n",
    "                break\n",
    "        break\n",
    "    replace_corrects.append(replace_correct)\n",
    "    replace_replaces.append(replace_replace)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aae9b467-00ca-41a5-b319-5d67412fd57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca 1 replace min diff -6.385058403015137 max diff 3.271770477294922 avg diff -1.354062795639038\n",
      "pca 6 replace min diff -5.725831985473633 max diff 2.4847850799560547 avg diff -1.5583744049072266\n",
      "pca 11 replace min diff -6.683233261108398 max diff 2.3404159545898438 avg diff -1.9905790090560913\n",
      "pca 16 replace min diff -7.113604545593262 max diff 3.5367918014526367 avg diff -2.205662965774536\n",
      "pca 21 replace min diff -9.534707069396973 max diff 1.856553077697754 avg diff -2.4536325931549072\n",
      "pca 26 replace min diff -8.919142723083496 max diff 1.7314033508300781 avg diff -2.710315704345703\n",
      "pca 31 replace min diff -7.971835136413574 max diff 1.7389650344848633 avg diff -2.910799741744995\n",
      "pca 36 replace min diff -7.82713508605957 max diff 1.1897377967834473 avg diff -2.9427006244659424\n",
      "pca 41 replace min diff -8.441636085510254 max diff 1.600846290588379 avg diff -3.3408656120300293\n",
      "pca 46 replace min diff -9.645776748657227 max diff 1.5369129180908203 avg diff -3.474529504776001\n",
      "pca 51 replace min diff -10.496797561645508 max diff 0.248779296875 avg diff -3.81083083152771\n",
      "pca 56 replace min diff -8.755396842956543 max diff 0.24278831481933594 avg diff -3.885650873184204\n",
      "pca 61 replace min diff -11.150490760803223 max diff 0.4462156295776367 avg diff -4.142153263092041\n",
      "pca 66 replace min diff -9.073711395263672 max diff 0.8152923583984375 avg diff -4.223395824432373\n",
      "pca 71 replace min diff -8.688760757446289 max diff 0.28945446014404297 avg diff -4.340442180633545\n",
      "pca 76 replace min diff -9.15414810180664 max diff -0.8808870315551758 avg diff -4.480126857757568\n",
      "pca 81 replace min diff -9.430322647094727 max diff -0.569371223449707 avg diff -4.623082637786865\n",
      "pca 86 replace min diff -11.85174560546875 max diff -0.02276611328125 avg diff -4.782935619354248\n",
      "pca 91 replace min diff -9.480352401733398 max diff -0.3169670104980469 avg diff -4.726596832275391\n",
      "pca 96 replace min diff -9.863895416259766 max diff -0.45804882049560547 avg diff -5.036709308624268\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "x=%{x}<br>num incorrect=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1,
          6,
          11,
          16,
          21,
          26,
          31,
          36,
          41,
          46,
          51,
          56,
          61,
          66,
          71,
          76,
          81,
          86,
          91,
          96
         ],
         "xaxis": "x",
         "y": [
          46,
          35,
          26,
          25,
          21,
          14,
          10,
          5,
          6,
          5,
          1,
          2,
          1,
          2,
          2,
          0,
          0,
          0,
          0,
          0
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": true,
        "barmode": "relative",
        "font": {
         "color": "black",
         "size": 10
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "projective pca reduction num incorrect / 202"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -1.5,
          98.5
         ],
         "tickmode": "array",
         "ticktext": [
          1,
          6,
          11,
          16,
          21,
          26,
          31,
          36,
          41,
          46,
          51,
          56,
          61,
          66,
          71,
          76,
          81,
          86,
          91,
          96
         ],
         "tickvals": [
          1,
          6,
          11,
          16,
          21,
          26,
          31,
          36,
          41,
          46,
          51,
          56,
          61,
          66,
          71,
          76,
          81,
          86,
          91,
          96
         ],
         "title": {
          "text": "x"
         },
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          48.421052631578945
         ],
         "title": {
          "text": "num incorrect"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"a35b1e48-9602-4f04-9fed-02cafa87a37a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a35b1e48-9602-4f04-9fed-02cafa87a37a\")) {                    Plotly.newPlot(                        \"a35b1e48-9602-4f04-9fed-02cafa87a37a\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}\\u003cbr\\u003enum incorrect=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[1,6,11,16,21,26,31,36,41,46,51,56,61,66,71,76,81,86,91,96],\"xaxis\":\"x\",\"y\":[46,35,26,25,21,14,10,5,6,5,1,2,1,2,2,0,0,0,0,0],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"},\"tickmode\":\"array\",\"tickvals\":[1,6,11,16,21,26,31,36,41,46,51,56,61,66,71,76,81,86,91,96],\"ticktext\":[1,6,11,16,21,26,31,36,41,46,51,56,61,66,71,76,81,86,91,96]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"num incorrect\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"projective pca reduction num incorrect \\u002f 202\"},\"barmode\":\"relative\",\"font\":{\"size\":10,\"color\":\"black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a35b1e48-9602-4f04-9fed-02cafa87a37a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.82138442993164 11.173883438110352\n",
      "12.736701965332031 10.217185974121094\n",
      "8.846115112304688 6.645937442779541\n",
      "7.833235740661621 6.569667816162109\n",
      "11.275167465209961 9.637931823730469\n",
      "11.706157684326172 10.110433578491211\n",
      "10.820472717285156 9.33121109008789\n",
      "9.343393325805664 9.4407377243042\n",
      "7.741237640380859 5.295808792114258\n",
      "11.029853820800781 7.26798152923584\n",
      "9.24068832397461 8.79992389678955\n",
      "12.335310935974121 7.3508076667785645\n",
      "11.4617919921875 10.812494277954102\n",
      "12.249700546264648 9.514029502868652\n",
      "9.796886444091797 9.914495468139648\n",
      "10.353769302368164 8.812589645385742\n",
      "13.758966445922852 9.780296325683594\n",
      "11.305784225463867 10.323810577392578\n",
      "7.346553325653076 5.561267852783203\n",
      "6.7610931396484375 6.760856628417969\n",
      "12.463811874389648 11.240272521972656\n",
      "11.58830738067627 11.424102783203125\n",
      "11.935590744018555 9.477813720703125\n",
      "10.57258415222168 9.6211519241333\n",
      "12.906749725341797 9.574055671691895\n",
      "12.236769676208496 10.673309326171875\n",
      "8.085566520690918 9.532452583312988\n",
      "11.367392539978027 7.331670761108398\n",
      "9.44795036315918 5.439880847930908\n",
      "8.970124244689941 7.604208469390869\n",
      "9.568976402282715 10.046334266662598\n",
      "10.426973342895508 7.972574710845947\n",
      "11.153364181518555 6.23821496963501\n",
      "9.093563079833984 9.273422241210938\n",
      "9.705839157104492 8.230713844299316\n",
      "9.845163345336914 9.030946731567383\n",
      "8.61175537109375 6.784881591796875\n",
      "8.1769437789917 5.850738048553467\n",
      "13.15955924987793 10.660138130187988\n",
      "11.52824592590332 13.080982208251953\n",
      "9.138144493103027 7.357149600982666\n",
      "9.617812156677246 6.641775131225586\n",
      "7.178480625152588 7.275465965270996\n",
      "7.993780136108398 5.953423976898193\n",
      "11.678421020507812 10.713802337646484\n",
      "12.163931846618652 10.626363754272461\n",
      "8.071128845214844 6.695095539093018\n",
      "8.767404556274414 6.991397857666016\n",
      "10.45274829864502 9.172473907470703\n",
      "10.720008850097656 9.83204460144043\n",
      "10.372379302978516 6.889727592468262\n",
      "7.009171009063721 7.680910587310791\n",
      "8.584653854370117 2.1995954513549805\n",
      "6.501134872436523 6.687055587768555\n",
      "10.292490005493164 8.57479476928711\n",
      "10.871880531311035 11.175724983215332\n",
      "10.157279968261719 5.042340278625488\n",
      "8.931731224060059 8.045745849609375\n",
      "7.343886375427246 8.759236335754395\n",
      "9.946905136108398 7.241683006286621\n",
      "8.011834144592285 5.217484474182129\n",
      "7.777530193328857 8.136749267578125\n",
      "7.854931831359863 6.8462324142456055\n",
      "7.600063323974609 5.9740190505981445\n",
      "9.880928993225098 10.607848167419434\n",
      "11.441099166870117 8.816179275512695\n",
      "10.102273941040039 8.818135261535645\n",
      "10.355039596557617 8.35733699798584\n",
      "10.02355670928955 10.525150299072266\n",
      "9.980942726135254 8.55744743347168\n",
      "8.919565200805664 7.377824306488037\n",
      "8.014500617980957 7.8161821365356445\n",
      "8.082802772521973 6.254266262054443\n",
      "11.87661075592041 8.519800186157227\n",
      "10.36467456817627 10.137242317199707\n",
      "11.525394439697266 9.578553199768066\n",
      "11.112127304077148 10.043296813964844\n",
      "9.942113876342773 10.388795852661133\n",
      "10.340627670288086 10.38489818572998\n",
      "11.189665794372559 8.554141998291016\n",
      "10.482337951660156 9.6416015625\n",
      "11.092926025390625 8.462176322937012\n",
      "9.085617065429688 6.455327033996582\n",
      "9.882442474365234 8.481016159057617\n",
      "9.939321517944336 10.563427925109863\n",
      "12.193060874938965 9.030574798583984\n",
      "9.368901252746582 11.42994499206543\n",
      "12.560968399047852 8.981766700744629\n",
      "8.631667137145996 9.08941650390625\n",
      "9.766006469726562 7.052516937255859\n",
      "12.750507354736328 11.585031509399414\n",
      "13.86790657043457 11.32711410522461\n",
      "8.767786979675293 9.437551498413086\n",
      "11.291702270507812 6.035971641540527\n",
      "8.143950462341309 6.657054901123047\n",
      "8.331369400024414 5.593354225158691\n",
      "9.006256103515625 6.433910846710205\n",
      "7.76837158203125 7.088249206542969\n",
      "13.209383964538574 6.946290969848633\n",
      "11.771954536437988 10.52676010131836\n",
      "6.604437828063965 5.945704936981201\n",
      "9.604927062988281 4.239669322967529\n",
      "6.498605728149414 7.74258279800415\n",
      "8.063379287719727 6.335928916931152\n",
      "11.245794296264648 10.385636329650879\n",
      "9.274681091308594 8.268399238586426\n",
      "12.649630546569824 9.217443466186523\n",
      "11.596834182739258 11.266002655029297\n",
      "10.577555656433105 10.347478866577148\n",
      "10.874801635742188 8.240960121154785\n",
      "9.705839157104492 8.230713844299316\n",
      "9.845163345336914 9.030946731567383\n",
      "10.976018905639648 10.999357223510742\n",
      "7.618655204772949 5.923557758331299\n",
      "7.740528583526611 6.883609771728516\n",
      "8.456459045410156 5.746333599090576\n",
      "9.757234573364258 9.329662322998047\n",
      "11.488872528076172 10.028802871704102\n",
      "9.333450317382812 10.927244186401367\n",
      "10.560724258422852 7.579588890075684\n",
      "13.225317001342773 7.90593147277832\n",
      "10.331476211547852 13.603246688842773\n",
      "10.820472717285156 9.33121109008789\n",
      "9.343393325805664 9.4407377243042\n",
      "11.19087028503418 8.692405700683594\n",
      "10.086915016174316 10.87360954284668\n",
      "10.202108383178711 8.780006408691406\n",
      "9.685901641845703 9.203184127807617\n",
      "10.121858596801758 11.52665901184082\n",
      "11.293508529663086 9.64724349975586\n",
      "10.143451690673828 10.562411308288574\n",
      "11.752883911132812 9.691624641418457\n",
      "6.5698041915893555 5.4159440994262695\n",
      "6.250579833984375 5.271914482116699\n",
      "11.442590713500977 7.242542266845703\n",
      "9.511819839477539 10.050323486328125\n",
      "10.38708209991455 11.03580379486084\n",
      "10.666099548339844 7.358905792236328\n",
      "9.636833190917969 5.889793395996094\n",
      "10.958550453186035 8.762382507324219\n",
      "11.237150192260742 9.311643600463867\n",
      "10.727337837219238 8.99577522277832\n",
      "10.913508415222168 9.263092041015625\n",
      "10.930493354797363 10.362013816833496\n",
      "11.06956672668457 7.510549545288086\n",
      "8.053606033325195 10.21324634552002\n",
      "11.883007049560547 8.593852996826172\n",
      "10.630781173706055 9.921819686889648\n",
      "10.55055046081543 11.06204891204834\n",
      "10.363893508911133 8.861485481262207\n",
      "11.81227970123291 11.460952758789062\n",
      "12.305299758911133 9.944406509399414\n",
      "11.917722702026367 12.092464447021484\n",
      "13.397371292114258 11.019512176513672\n",
      "10.808452606201172 11.301603317260742\n",
      "12.303353309631348 9.940918922424316\n",
      "8.465506553649902 8.433185577392578\n",
      "10.081113815307617 8.19450569152832\n",
      "7.7534074783325195 8.943455696105957\n",
      "10.605315208435059 8.789491653442383\n",
      "10.19941520690918 9.749045372009277\n",
      "11.231992721557617 8.155952453613281\n",
      "8.325687408447266 8.213493347167969\n",
      "9.075226783752441 8.483946800231934\n",
      "11.569820404052734 10.559743881225586\n",
      "11.743306159973145 10.061901092529297\n",
      "10.482376098632812 10.617559432983398\n",
      "11.359151840209961 10.052759170532227\n",
      "7.7663164138793945 8.385099411010742\n",
      "9.129294395446777 7.348080158233643\n",
      "10.865220069885254 8.130353927612305\n",
      "8.043354988098145 9.080892562866211\n",
      "9.403135299682617 11.191118240356445\n",
      "12.229394912719727 9.155508995056152\n",
      "5.430807590484619 4.843462944030762\n",
      "5.57808780670166 1.9580473899841309\n",
      "10.483532905578613 9.353864669799805\n",
      "11.181320190429688 11.00922679901123\n",
      "8.289859771728516 7.422601699829102\n",
      "8.618532180786133 7.104608535766602\n",
      "11.890957832336426 8.626033782958984\n",
      "10.324531555175781 10.76175308227539\n",
      "11.185176849365234 9.262042045593262\n",
      "7.4928975105285645 6.53530216217041\n",
      "12.649630546569824 9.217443466186523\n",
      "11.596834182739258 11.266002655029297\n",
      "9.368901252746582 11.42994499206543\n",
      "12.560968399047852 8.981766700744629\n",
      "9.819631576538086 9.461490631103516\n",
      "11.687419891357422 9.635668754577637\n",
      "9.666617393493652 9.291219711303711\n",
      "10.80374813079834 8.969524383544922\n",
      "8.709712028503418 9.432348251342773\n",
      "9.512109756469727 6.584179878234863\n",
      "9.898179054260254 6.0724334716796875\n",
      "7.772026062011719 8.70802116394043\n",
      "9.348716735839844 8.872407913208008\n",
      "8.064765930175781 8.2152099609375\n",
      "10.178813934326172 9.813162803649902\n",
      "9.68673324584961 9.201980590820312\n",
      "12.302922248840332 9.306802749633789\n",
      "11.566715240478516 11.800349235534668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_x = pca_sizes[:len(replace_corrects)]\n",
    "data_y = []\n",
    "for i in range(len(replace_corrects)):\n",
    "    replace_diff = -torch.tensor(replace_corrects[i]) + torch.tensor(replace_replaces[i])\n",
    "    n_correct = torch.sum(replace_diff > 0)\n",
    "    data_y.append(n_correct)\n",
    "    print(f'pca {data_x[i]} replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "\n",
    "data_y = torch.tensor(data_y, device=model.cfg.device)\n",
    "\n",
    "\n",
    "def bar_chart(data, x_labels, y_label, title, font_size=None):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    # it requires a pandas dict with the columns and rows named, annoying\n",
    "    # by default rows and columns are named with ints so we relabel them accordingly\n",
    "    renames = dict([(i, x_labels[i]) for i in range(len(x_labels))])\n",
    "    ps = pd.DataFrame(data.cpu().numpy()).rename(renames, axis='rows').rename({0: y_label}, axis='columns')\n",
    "    fig = px.bar(ps, y=y_label, x=x_labels, title=title)\n",
    "    if not font_size is None:\n",
    "        fig.update_layout(\n",
    "          xaxis = dict(\n",
    "            tickmode='array',\n",
    "            tickvals = x_labels,\n",
    "            ticktext = x_labels, \n",
    "            ),\n",
    "           font=dict(size=font_size, color=\"black\"))\n",
    "        \n",
    "        #fig.update_xaxes(title_font=dict(size=font_size))\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "bar_chart(data_y, x_labels=data_x, y_label='num incorrect', title=f'projective pca reduction num incorrect / {len(replace_replaces[0])}', font_size=10)\n",
    "\n",
    "for i in range(len(replace_corrects[0])):\n",
    "    print(replace_corrects[0][i], replace_replaces[0][i])\n",
    "#patched_diff = -torch.tensor(patched_correct) + torch.tensor(patched_replace)\n",
    "\n",
    "#print(n_correct_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f369477e-4828-477e-b16b-d882309f5184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(len(name_tokens))\n",
    "pca = PCA(n_components=pca_dim)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d78207-1556-4aaf-bffb-b609de24f15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4854c-42c7-4696-a92b-b3401d460bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79a7ebf1-7fc4-473c-9ebc-3a4542f0ca63",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m answer_tok \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcorrect[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     17\u001b[0m template \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdata[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 18\u001b[0m components \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_proj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m grouped_by_answers[answer_tok]\u001b[38;5;241m.\u001b[39mappend((components[component_1], components[component_2]))\n\u001b[1;32m     20\u001b[0m grouped_by_template[template]\u001b[38;5;241m.\u001b[39mappend((components[component_1], components[component_2]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/decomposition/_base.py:145\u001b[0m, in \u001b[0;36m_BasePCA.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    141\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    143\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1049\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:121\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    122\u001b[0m     first_pass_isfinite \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misfinite(xp\u001b[38;5;241m.\u001b[39msum(X))\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:431\u001b[0m, in \u001b[0;36merrstate.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldstate \u001b[38;5;241m=\u001b[39m \u001b[43mseterr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Unspecified:\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldcall \u001b[38;5;241m=\u001b[39m seterrcall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:111\u001b[0m, in \u001b[0;36mseterr\u001b[0;34m(all, divide, over, under, invalid)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mSet how floating-point errors are handled.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m pyvals \u001b[38;5;241m=\u001b[39m umath\u001b[38;5;241m.\u001b[39mgeterrobj()\n\u001b[0;32m--> 111\u001b[0m old \u001b[38;5;241m=\u001b[39m \u001b[43mgeterr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m divide \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     divide \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m old[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivide\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:168\u001b[0m, in \u001b[0;36mgeterr\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgeterr\u001b[39m():\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    Get the current way of handling floating-point errors.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     maskvalue \u001b[38;5;241m=\u001b[39m \u001b[43mumath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeterrobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    169\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[1;32m    170\u001b[0m     res \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name_points = []\n",
    "pca_dim = 90\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "\n",
    "\n",
    "for component_1 in range(0, pca_dim, 2):\n",
    "    component_2 = component_1 + 1\n",
    "    grouped_by_answers = defaultdict(lambda: [])\n",
    "    grouped_by_template = defaultdict(lambda: [])\n",
    "        \n",
    "    for i in range(X.shape[0]):\n",
    "        answer_tok = data.correct[i][0].item()\n",
    "        template = data.data[i][1].item()\n",
    "        components = pca.transform(X_proj[i].reshape(1, -1)).reshape(-1)\n",
    "        grouped_by_answers[answer_tok].append((components[component_1], components[component_2]))\n",
    "        grouped_by_template[template].append((components[component_1], components[component_2]))\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    grouped_by_answers = sorted(list(grouped_by_answers.items()))[:20]\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(grouped_by_answers)))\n",
    "    \n",
    "    for (answer_i, points), c in zip(grouped_by_answers, colors):\n",
    "        x = np.array([point[0] for point in points])\n",
    "        y = np.array([point[1] for point in points])\n",
    "        plt.scatter(x, y, color=c)\n",
    "    plt.title(f'components {component_1} {component_2} colored by name')\n",
    "    plt.savefig(f'{component_1} {component_2} name.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    grouped_by_template = sorted(list(grouped_by_template.items()))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(grouped_by_template)))\n",
    "    \n",
    "    for (answer_i, points), c in zip(grouped_by_template, colors):\n",
    "        x = np.array([point[0] for point in points])\n",
    "        y = np.array([point[1] for point in points])\n",
    "        plt.scatter(x, y, color=c)\n",
    "    plt.title(f'components {component_1} {component_2} colored by template')\n",
    "    plt.savefig(f'{component_1} {component_2} template.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "862073d2-6a9f-410a-bc91-071871ac0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then, [NAME], [NAME] and [NAME] went to the [PLACE]. [NAME] and [NAME] gave a [OBJECT] to\n",
      "Afterwards [NAME], [NAME] and [NAME] went to the [PLACE]. [NAME] and [NAME] gave a [OBJECT] to\n",
      "When [NAME], [NAME] and [NAME] arrived at the [PLACE], [NAME] and [NAME] gave a [OBJECT] to\n",
      "Friends [NAME], [NAME] and [NAME] went to the [PLACE]. [NAME] and [NAME] gave a [OBJECT] to\n"
     ]
    }
   ],
   "source": [
    "for x in ABC_TEMPLATES:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b3da994c-a396-498d-80f4-542563c2580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get positive examples\n",
      "get negative examples\n",
      "shuffle data\n",
      "training erasers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/209 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 1/209 [00:00<02:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1176, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                                  | 2/209 [00:01<01:57,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                                 | 3/209 [00:01<01:54,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                                 | 4/209 [00:02<01:52,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                                 | 5/209 [00:02<01:52,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                                | 6/209 [00:03<01:51,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                                | 7/209 [00:03<01:54,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                               | 8/209 [00:04<01:52,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                               | 9/209 [00:05<01:55,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1300, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                              | 10/209 [00:05<01:55,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1220, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                             | 11/209 [00:06<01:54,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                             | 12/209 [00:06<01:51,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                             | 13/209 [00:07<01:51,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                            | 14/209 [00:07<01:53,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                            | 15/209 [00:08<01:51,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                           | 16/209 [00:09<01:49,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                           | 17/209 [00:09<01:48,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                           | 18/209 [00:10<01:47,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1152, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                          | 19/209 [00:10<01:46,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|                                                                          | 20/209 [00:11<01:45,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|                                                                         | 21/209 [00:11<01:44,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1192, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|                                                                         | 22/209 [00:12<01:48,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1244, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|                                                                         | 23/209 [00:13<01:51,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|                                                                        | 24/209 [00:13<01:48,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|                                                                        | 25/209 [00:14<01:47,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|                                                                       | 26/209 [00:14<01:45,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1220, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|                                                                       | 27/209 [00:15<01:44,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|                                                                       | 28/209 [00:15<01:43,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|                                                                      | 29/209 [00:16<01:42,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|                                                                      | 30/209 [00:17<01:40,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|                                                                     | 31/209 [00:17<01:40,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1080, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|                                                                     | 32/209 [00:18<01:43,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|                                                                     | 33/209 [00:18<01:41,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|                                                                    | 34/209 [00:19<01:40,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|                                                                    | 35/209 [00:19<01:40,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|                                                                    | 36/209 [00:20<01:41,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|                                                                   | 37/209 [00:21<01:41,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1236, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|                                                                   | 38/209 [00:21<01:39,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|                                                                  | 39/209 [00:22<01:38,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1152, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|                                                                  | 40/209 [00:22<01:37,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1240, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|                                                                  | 41/209 [00:23<01:38,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|                                                                 | 42/209 [00:24<01:36,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|                                                                 | 43/209 [00:24<01:35,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|                                                                | 44/209 [00:25<01:35,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1280, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|                                                                | 45/209 [00:25<01:39,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|                                                                | 46/209 [00:26<01:36,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|                                                               | 47/209 [00:27<01:37,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|                                                               | 48/209 [00:27<01:36,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|                                                              | 49/209 [00:28<01:34,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|                                                              | 50/209 [00:28<01:31,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|                                                              | 51/209 [00:29<01:29,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|                                                             | 52/209 [00:29<01:28,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|                                                             | 53/209 [00:30<01:28,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|                                                            | 54/209 [00:30<01:26,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|                                                            | 55/209 [00:31<01:25,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([996, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|                                                            | 56/209 [00:32<01:23,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|                                                           | 57/209 [00:32<01:24,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|                                                           | 58/209 [00:33<01:23,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1292, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|                                                          | 59/209 [00:33<01:24,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|                                                          | 60/209 [00:34<01:23,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1060, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|                                                          | 61/209 [00:34<01:21,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1100, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|                                                         | 62/209 [00:35<01:20,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|                                                         | 63/209 [00:35<01:20,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|                                                         | 64/209 [00:36<01:20,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|                                                        | 65/209 [00:37<01:19,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|                                                        | 66/209 [00:37<01:18,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|                                                       | 67/209 [00:38<01:17,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|                                                       | 68/209 [00:38<01:17,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1244, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|                                                       | 69/209 [00:39<01:17,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|                                                      | 70/209 [00:39<01:16,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1292, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|                                                      | 71/209 [00:40<01:19,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|                                                     | 72/209 [00:41<01:18,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1328, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|                                                     | 73/209 [00:41<01:18,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|                                                     | 74/209 [00:42<01:24,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|                                                    | 75/209 [00:42<01:20,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|                                                    | 76/209 [00:43<01:18,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                   | 77/209 [00:44<01:16,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                   | 78/209 [00:44<01:16,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1176, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|                                                   | 79/209 [00:45<01:15,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|                                                  | 80/209 [00:45<01:13,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|                                                  | 81/209 [00:46<01:13,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|                                                 | 82/209 [00:46<01:11,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|                                                 | 83/209 [00:47<01:10,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|                                                 | 84/209 [00:47<01:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|                                                | 85/209 [00:48<01:09,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|                                                | 86/209 [00:49<01:09,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|                                               | 87/209 [00:49<01:07,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|                                               | 88/209 [00:50<01:08,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|                                               | 89/209 [00:50<01:09,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|                                              | 90/209 [00:51<01:08,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1100, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|                                              | 91/209 [00:51<01:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|                                              | 92/209 [00:52<01:08,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|                                             | 93/209 [00:53<01:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1056, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|                                             | 94/209 [00:53<01:04,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1080, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|                                            | 95/209 [00:54<01:06,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|                                            | 96/209 [00:54<01:05,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|                                            | 97/209 [00:55<01:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|                                           | 98/209 [00:55<01:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|                                           | 99/209 [00:56<01:01,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|                                          | 100/209 [00:57<01:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|                                         | 101/209 [00:57<01:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2212, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|                                         | 102/209 [00:58<01:06,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|                                         | 103/209 [00:58<01:03,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|                                        | 104/209 [00:59<01:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1224, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|                                        | 105/209 [01:00<01:01,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([976, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|                                        | 106/209 [01:00<00:59,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1044, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|                                       | 107/209 [01:01<01:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1064, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|                                       | 108/209 [01:01<01:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|                                      | 109/209 [01:02<01:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1208, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|                                      | 110/209 [01:03<01:01,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1244, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|                                      | 111/209 [01:03<00:59,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|                                     | 112/209 [01:04<00:58,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|                                     | 113/209 [01:04<00:56,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1224, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|                                    | 114/209 [01:05<00:55,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|                                    | 115/209 [01:06<00:54,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|                                    | 116/209 [01:06<00:53,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|                                   | 117/209 [01:07<00:53,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1036, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|                                   | 118/209 [01:07<00:53,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|                                   | 119/209 [01:08<00:53,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1280, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|                                  | 120/209 [01:08<00:52,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|                                  | 121/209 [01:09<00:51,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|                                 | 122/209 [01:10<00:50,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|                                 | 123/209 [01:10<00:49,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|                                 | 124/209 [01:11<00:48,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1060, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|                                | 125/209 [01:11<00:47,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1216, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|                                | 126/209 [01:12<00:47,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|                               | 127/209 [01:13<00:48,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1020, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|                               | 128/209 [01:13<00:46,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|                               | 129/209 [01:14<00:45,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|                              | 130/209 [01:14<00:44,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|                              | 131/209 [01:15<00:43,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1168, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|                             | 132/209 [01:15<00:42,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1108, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|                             | 133/209 [01:16<00:42,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([932, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|                             | 134/209 [01:16<00:40,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1008, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|                            | 135/209 [01:17<00:40,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1084, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|                            | 136/209 [01:17<00:40,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|                            | 137/209 [01:18<00:40,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([980, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|                           | 138/209 [01:19<00:39,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1116, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|                           | 139/209 [01:19<00:38,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|                          | 140/209 [01:20<00:38,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1032, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|                          | 141/209 [01:20<00:37,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1260, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|                          | 142/209 [01:21<00:37,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|                         | 143/209 [01:21<00:38,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|                         | 144/209 [01:22<00:39,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1076, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|                        | 145/209 [01:23<00:39,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|                        | 146/209 [01:23<00:37,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|                        | 147/209 [01:24<00:35,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|                       | 148/209 [01:24<00:34,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|                       | 149/209 [01:25<00:34,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|                      | 150/209 [01:26<00:33,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|                      | 151/209 [01:26<00:33,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|                      | 152/209 [01:27<00:32,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1228, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|                     | 153/209 [01:27<00:31,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1168, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|                     | 154/209 [01:28<00:31,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|                     | 155/209 [01:28<00:31,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1260, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|                    | 156/209 [01:29<00:31,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1008, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|                    | 157/209 [01:30<00:29,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|                   | 158/209 [01:30<00:28,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1092, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|                   | 159/209 [01:31<00:28,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1160, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|                   | 160/209 [01:31<00:27,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|                  | 161/209 [01:32<00:26,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1128, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|                  | 162/209 [01:32<00:26,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|                 | 163/209 [01:33<00:26,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|                 | 164/209 [01:33<00:25,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|                 | 165/209 [01:34<00:24,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|                | 166/209 [01:35<00:25,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1044, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|                | 167/209 [01:35<00:23,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|                | 168/209 [01:36<00:23,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1172, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|               | 169/209 [01:36<00:22,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|               | 170/209 [01:37<00:21,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1052, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|              | 171/209 [01:37<00:21,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1128, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|              | 172/209 [01:38<00:20,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1084, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|              | 173/209 [01:39<00:20,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|             | 174/209 [01:39<00:19,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|             | 175/209 [01:40<00:19,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1060, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|            | 176/209 [01:40<00:18,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1124, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|            | 177/209 [01:41<00:18,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|            | 178/209 [01:41<00:18,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|           | 179/209 [01:42<00:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([960, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|           | 180/209 [01:43<00:16,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|          | 181/209 [01:43<00:15,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1196, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|          | 182/209 [01:44<00:15,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1128, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|          | 183/209 [01:44<00:14,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1168, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|         | 184/209 [01:45<00:14,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|         | 185/209 [01:45<00:13,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1188, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|         | 186/209 [01:46<00:13,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1052, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|        | 187/209 [01:47<00:12,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1148, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|        | 188/209 [01:47<00:12,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|       | 189/209 [01:48<00:11,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|       | 190/209 [01:48<00:10,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1084, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|       | 191/209 [01:49<00:10,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1204, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|      | 192/209 [01:49<00:09,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1028, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|      | 193/209 [01:50<00:08,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|     | 194/209 [01:50<00:08,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1156, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|     | 195/209 [01:51<00:07,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|     | 196/209 [01:52<00:07,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|    | 197/209 [01:52<00:06,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1080, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|    | 198/209 [01:53<00:06,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1164, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|    | 199/209 [01:53<00:05,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|   | 200/209 [01:54<00:05,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1088, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|   | 201/209 [01:55<00:04,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1028, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|  | 202/209 [01:55<00:04,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1132, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|  | 203/209 [01:56<00:03,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1184, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|  | 204/209 [01:56<00:02,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1112, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%| | 205/209 [01:57<00:02,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%| | 206/209 [01:57<00:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1252, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 207/209 [01:58<00:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1188, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 208/209 [01:59<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1036, 2049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 209/209 [01:59<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "from concept_erasure import LeaceEraser\n",
    "from collections import defaultdict\n",
    "X_data_by_name = defaultdict(lambda: [])\n",
    "Y_data_by_name = defaultdict(lambda: [])\n",
    "X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "\n",
    "# gather positive examples\n",
    "print(\"get positive examples\")\n",
    "for i in range(X_proj.shape[0]):\n",
    "    answer_tok = data.correct[i][0].item()\n",
    "    X_data_by_name[answer_tok].append(X_proj[i])\n",
    "    Y_data_by_name[answer_tok].append([1.0,0.0])\n",
    "\n",
    "# gather negative examples\n",
    "print(\"get negative examples\")\n",
    "for answer, X_data in X_data_by_name.items():\n",
    "    num_points = len(X_data)\n",
    "    while len(X_data) < num_points*2:\n",
    "        random_data_i = random.randint(0, X_proj.shape[0]-1)\n",
    "        random_data_answer = data.correct[random_data_i][0].item()\n",
    "        if random_data_answer != answer:\n",
    "            X_data.append(X_proj[random_data_i])\n",
    "            Y_data_by_name[answer].append([0.0, 1.0])\n",
    "\n",
    "# shuffle data\n",
    "print(\"shuffle data\")\n",
    "for answer in list(X_data_by_name.keys()):\n",
    "    inds = list(range(len(X_data_by_name[answer])))\n",
    "    random.shuffle(inds)\n",
    "    X_data_by_name[answer] = [X_data_by_name[answer][i] for i in inds]\n",
    "    Y_data_by_name[answer] = [Y_data_by_name[answer][i] for i in inds]\n",
    "\n",
    "print(\"training erasers\")\n",
    "# train leace\n",
    "name_erasers = {}\n",
    "\n",
    "\n",
    "for answer in tqdm(list(X_data_by_name.keys())):\n",
    "    Xd, Yd = X_data_by_name[answer], Y_data_by_name[answer]\n",
    "    Xd = torch.tensor(Xd, device=model.cfg.device)\n",
    "    Yd = torch.tensor(Yd, device=model.cfg.device)\n",
    "    print(Xd.size())\n",
    "    name_erasers[answer] = LeaceEraser.fit(Xd, Yd)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e8d4940a-afa0-42a5-b71a-fc3878dd24b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 39\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "replace_corrects = []\n",
    "replace_replaces = []\n",
    "original_corrects = []\n",
    "original_replaces = []\n",
    "#pca_sizes = []\n",
    "#X_proj = np.concatenate([X,np.ones((X.shape[0], 1))], axis=1)\n",
    "#print(X_proj[:,-1])\n",
    "\n",
    "# subtract to erase\n",
    "# add to add\n",
    "def apply_eraser(eraser, x):\n",
    "    delta = x - eraser.bias\n",
    "    diff = (delta @ eraser.proj_right.mH) @ eraser.proj_left.mH\n",
    "    return x - diff\n",
    "\n",
    "def invert_eraser(eraser, x):\n",
    "    # (AB)^-1 = B^-1 A^-1\n",
    "    eye = torch.eye(x.size()[0], device=model.cfg.device, dtype=eraser.proj_left.dtype)\n",
    "    \n",
    "    #Inv = torch.linalg.inv(eraser.proj_right.mH @ eraser.proj_left.mH)\n",
    "    #Inv = torch.linalg.pinv(eye-eraser.proj_right.mH @ eraser.proj_left.mH)\n",
    "    # approximation to the inverse\n",
    "    res = eye\n",
    "    prod = eraser.proj_right.mH @ eraser.proj_left.mH\n",
    "    for i in range(40):\n",
    "        res += prod\n",
    "        prod = prod @ eraser.proj_right.mH @ eraser.proj_left.mH\n",
    "    #print(f\"inverse {Inv}\")\n",
    "    bA = (eraser.bias @ eraser.proj_right.mH) @ eraser.proj_left.mH\n",
    "    return (x-bA)@res\n",
    "\n",
    "for _ in range(1):\n",
    "    original_correct = []\n",
    "    original_replace = []\n",
    "    replace_correct = []\n",
    "    replace_replace = []\n",
    "    print(f\"layer {layer}\")\n",
    "    name_bases = [0]\n",
    "    for position_1, name_basis in enumerate(name_bases):\n",
    "        num_found = 0\n",
    "        while True:            \n",
    "            data_i = random.choice(list(range(10000)))\n",
    "            \n",
    "            import random\n",
    "            from functools import partial\n",
    "        \n",
    "            data_i = (data_i // 2)*2\n",
    "            patched_i = data_i + 1\n",
    "            \n",
    "            data_tokens = data.data[data_i]\n",
    "            corrupted_tokens = data.data[data_i+1]\n",
    "            answer_tok = data.correct[data_i][0].item()\n",
    "            answer = model.to_str_tokens(torch.tensor([answer_tok]))[0]\n",
    "            replace_tok = data.correct[patched_i][0].item()\n",
    "            replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "            '''\n",
    "            others = model.to_str_tokens(data.incorrect[data_i])\n",
    "            print(\"prompt\", model.to_str_tokens(data_tokens))\n",
    "            print(\"answer\", answer)\n",
    "            print(\"other names\", others)\n",
    "            replace_name = model.to_str_tokens(answer)[0]\n",
    "            while True:\n",
    "                replace_tok = random.choice(list(name_tokens))\n",
    "                replace_name = model.to_str_tokens(torch.tensor([replace_tok]))[0]\n",
    "                if not replace_name in [answer] + others:\n",
    "                    break\n",
    "            '''\n",
    "            #print(\"got replace name\", repr(replace_name))\n",
    "            #print(\"logits before replace\")\n",
    "            last_token_pos = data.last_token_position[data_i]\n",
    "            \n",
    "            def replace_hook(\n",
    "                x,\n",
    "                hook,\n",
    "                position,\n",
    "                answer_name_tok,\n",
    "                replace_name_tok,\n",
    "            ):\n",
    "                B,L,E = x.size()\n",
    "                for b in range(B):\n",
    "                    veco = torch.concatenate([x[b,position], torch.tensor([1.0], device=model.cfg.device)])\n",
    "                    vec = apply_eraser(name_erasers[answer_name_tok], veco)\n",
    "                    vec2 = invert_eraser(name_erasers[replace_name_tok], vec)\n",
    "                    invert_diff = vec2 - vec\n",
    "                    vec = vec + invert_diff*100\n",
    "                    # we can do vec + diff to get vec2\n",
    "                    # instead we will do vec - diff to do inverse\n",
    "                    #vec = vec2\n",
    "                    \n",
    "                    #print(vec)\n",
    "                    #print(\"done\")\n",
    "                    x[b,position] = vec[:-1]\n",
    "\n",
    "                    #add_ones = np.concatenate([vec.detach().cpu().numpy(), np.array([1.0])], axis=0).reshape(1,-1)\n",
    "                    #pcad = pca.transform(add_ones)\n",
    "                    #x[b,position] = torch.tensor(pca.inverse_transform(pcad), device=model.cfg.device).reshape(-1)[:-1]\n",
    "                    '''\n",
    "                    coords = name_basis.map_to_coords(vec/torch.linalg.norm(vec, ord=2))\n",
    "                    C = len(name_tok_to_class)\n",
    "                    sorted = torch.argsort(coords[:C])\n",
    "                    print(coords[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"predict {maxi} {coords[maxi]}\")\n",
    "                    print(f\"answer {name_tok_to_class[answer_name_tok]} replace {name_tok_to_class[replace_name_tok]}\")\n",
    "                    coords[name_tok_to_class[answer_name_tok]] = -0.0692\n",
    "                    coords[name_tok_to_class[replace_name_tok]] = 0.0692\n",
    "                    maxi = torch.argmax(coords[:C])\n",
    "                    print(f\"now predict {maxi} {coords[maxi]}\")\n",
    "                    patched_vec = name_basis.map_from_coords(coords)\n",
    "                    print(f\"orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    patched_veco = patched_vec / torch.linalg.norm(patched_vec, ord=2) * torch.linalg.norm(vec, ord=2)\n",
    "                    print(f\"now orig norm {torch.linalg.norm(vec, ord=2)} patched norm {torch.linalg.norm(patched_vec, ord=2)}\")\n",
    "                    coords2 = name_basis.map_to_coords(patched_vec)\n",
    "                    sorted = torch.argsort(coords2[:C])\n",
    "                    print(\"predict2\", coords2[sorted][-5:])\n",
    "                    maxi = torch.argmax(coords2[:C])\n",
    "                    print(f\"predict2 {maxi} {coords2[maxi]}\")\n",
    "                    '''\n",
    "                    #x[b,position] = patched_veco\n",
    "                return x\n",
    "            \n",
    "            answer_positions = []\n",
    "            for name_i in range(len(data_name_positions)):\n",
    "                position = data_name_positions[name_i][data_i]\n",
    "                if data_tokens[position].item() == answer_tok:\n",
    "                    answer_positions.append((name_i, position))\n",
    "            \n",
    "            #print(\"answer positions\", answer_positions)\n",
    "            hooks = []\n",
    "            bad = False\n",
    "            for name_i, position in answer_positions:\n",
    "                if not name_i == position_1 or len(answer_positions) > 2:\n",
    "                    bad = True\n",
    "                \n",
    "                hooks.append((\n",
    "                    f'blocks.{layer}.hook_ssm_input', \n",
    "                    partial(replace_hook,\n",
    "                            position=position+1,\n",
    "                            answer_name_tok=answer_tok,\n",
    "                            replace_name_tok=replace_tok,\n",
    "                    )\n",
    "                ))\n",
    "            if bad:\n",
    "                continue\n",
    "            else:\n",
    "                num_found += 1\n",
    "            \n",
    "            logits = model(data_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            original_correct.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            original_replace.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            if num_found % 10 == 0:\n",
    "                print(num_found)\n",
    "            logits_modified = model.run_with_hooks(data_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "            #print(logits_modified.size())\n",
    "            #print(f\"modified answer {repr(answer)} logit {logits_modified[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"modified replace {repr(replace_name)} logit {logits_modified[0,last_token_pos,replace_tok]}\")\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            hooks = []\n",
    "            for name_i, position in answer_positions:\n",
    "                hooks.append((\n",
    "                    f'blocks.{layer}.hook_ssm_input', \n",
    "                    partial(replace_hook,\n",
    "                            position=position+1,\n",
    "                            answer_name_tok=replace_tok,\n",
    "                            replace_name_tok=answer_tok,\n",
    "                    )\n",
    "                ))\n",
    "            \n",
    "            logits = model(corrupted_tokens.view(1,-1), **model_kwargs)\n",
    "            #print(f\"answer {repr(answer)} logit {logits[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"replace {repr(replace_name)} logit {logits[0,last_token_pos,replace_tok]}\")\n",
    "            original_correct.append(logits[0,last_token_pos,replace_tok].item())\n",
    "            original_replace.append(logits[0,last_token_pos,answer_tok].item())\n",
    "            \n",
    "            logits_modified = model.run_with_hooks(corrupted_tokens.view(1, -1), fwd_hooks=hooks, **model_kwargs)\n",
    "\n",
    "            replace_correct.append(logits_modified[0,last_token_pos,replace_tok].item())\n",
    "            replace_replace.append(logits_modified[0,last_token_pos,answer_tok].item())\n",
    "            \n",
    "            \n",
    "            #logits_patched, acts = model.run_with_cache(data.data[patched_i].view(1,-1), names_filter=[hook])\n",
    "            #print(f\"patched answer {repr(answer)} logit {logits_patched[0,last_token_pos,answer_tok]}\")\n",
    "            #print(f\"patched replace {repr(replace_name)} logit {logits_patched[0,last_token_pos,replace_tok]}\")\n",
    "            #patched_correct.append(logits_patched[0,last_token_pos,answer_tok].item())\n",
    "            #patched_replace.append(logits_patched[0,last_token_pos,replace_tok].item())\n",
    "            if num_found > 100:\n",
    "                break\n",
    "        break\n",
    "    original_corrects.append(original_correct)\n",
    "    original_replaces.append(original_replace)\n",
    "    replace_corrects.append(replace_correct)\n",
    "    replace_replaces.append(replace_replace)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1aca3665-2d22-4db2-9cda-852e1f55761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/202\n",
      "replace min diff -68.55792999267578 max diff 69.87189483642578 avg diff -0.19875283539295197\n",
      "h\n",
      "16.470701217651367 9.71561050415039\n",
      "-5.661073684692383 -22.156082153320312\n",
      "h\n",
      "14.580031394958496 9.408432006835938\n",
      "0.48569345474243164 6.747767448425293\n",
      "h\n",
      "14.380048751831055 7.109065055847168\n",
      "-2.442127227783203 -24.21950912475586\n",
      "h\n",
      "16.272052764892578 7.420269966125488\n",
      "-7.698086738586426 62.173805236816406\n",
      "h\n",
      "14.879524230957031 9.761422157287598\n",
      "-3.2463455200195312 25.89336395263672\n",
      "h\n",
      "14.439093589782715 5.619184970855713\n",
      "8.848220825195312 -33.423301696777344\n",
      "h\n",
      "14.669663429260254 8.600264549255371\n",
      "2.081355094909668 -1.9556349515914917\n",
      "h\n",
      "15.520383834838867 7.870769500732422\n",
      "1.4222896099090576 22.22512435913086\n",
      "h\n",
      "17.11648941040039 11.07115650177002\n",
      "-10.067371368408203 -39.855567932128906\n",
      "h\n",
      "14.599285125732422 9.929826736450195\n",
      "-6.593348979949951 -6.830587863922119\n",
      "h\n",
      "16.378326416015625 11.30602741241455\n",
      "5.956884860992432 -38.610435485839844\n",
      "h\n",
      "17.24477195739746 12.21163272857666\n",
      "4.230982780456543 8.75568675994873\n",
      "h\n",
      "17.055301666259766 9.792766571044922\n",
      "-6.7681660652160645 -40.46263122558594\n",
      "h\n",
      "15.095385551452637 8.833169937133789\n",
      "-8.643159866333008 9.353684425354004\n",
      "h\n",
      "17.705638885498047 10.347694396972656\n",
      "-1.1137534379959106 36.980987548828125\n",
      "h\n",
      "17.70909881591797 12.46829891204834\n",
      "4.278864860534668 10.1322021484375\n",
      "h\n",
      "13.674509048461914 2.729785203933716\n",
      "8.848783493041992 14.957258224487305\n",
      "h\n",
      "11.015439987182617 7.332038879394531\n",
      "-0.40244436264038086 6.306756973266602\n",
      "h\n",
      "17.063003540039062 9.478687286376953\n",
      "-0.5124579668045044 -10.10653018951416\n",
      "h\n",
      "17.016000747680664 9.74824333190918\n",
      "-0.053635597229003906 28.03034210205078\n",
      "h\n",
      "14.829706192016602 5.538116931915283\n",
      "0.1917802095413208 50.553794860839844\n",
      "h\n",
      "15.466934204101562 10.313305854797363\n",
      "1.0343191623687744 -2.2826528549194336\n",
      "h\n",
      "12.930335998535156 5.6602678298950195\n",
      "0.40245652198791504 -49.356834411621094\n",
      "h\n",
      "13.753924369812012 6.906387805938721\n",
      "14.573183059692383 40.302452087402344\n",
      "h\n",
      "15.272117614746094 7.513121128082275\n",
      "-1.9908170700073242 25.334665298461914\n",
      "h\n",
      "14.374013900756836 5.310833930969238\n",
      "2.037912368774414 61.625709533691406\n",
      "h\n",
      "13.430246353149414 6.389962196350098\n",
      "-3.8849401473999023 30.17223358154297\n",
      "h\n",
      "12.919710159301758 7.869196891784668\n",
      "-4.0385966300964355 8.03372573852539\n",
      "h\n",
      "17.368846893310547 10.586111068725586\n",
      "-8.072798728942871 5.658577919006348\n",
      "h\n",
      "17.00928497314453 11.611640930175781\n",
      "1.7490825653076172 18.310752868652344\n",
      "h\n",
      "15.7691011428833 6.738853931427002\n",
      "1.6175341606140137 10.121139526367188\n",
      "h\n",
      "14.03289794921875 6.293128967285156\n",
      "-2.97029447555542 -35.81845474243164\n",
      "h\n",
      "14.218904495239258 9.513717651367188\n",
      "5.595700263977051 -18.34531593322754\n",
      "h\n",
      "16.62076187133789 8.895003318786621\n",
      "5.766347885131836 -42.54839324951172\n",
      "h\n",
      "12.203004837036133 6.083037853240967\n",
      "-1.0008347034454346 23.98700714111328\n",
      "h\n",
      "14.704365730285645 7.946584701538086\n",
      "-0.016435742378234863 -14.676387786865234\n",
      "h\n",
      "8.897337913513184 1.077894687652588\n",
      "-3.877026319503784 19.058242797851562\n",
      "h\n",
      "8.121967315673828 -1.0396852493286133\n",
      "-3.933058261871338 47.77484130859375\n",
      "h\n",
      "15.813190460205078 10.41125774383545\n",
      "-4.233362674713135 51.51629638671875\n",
      "h\n",
      "17.074491500854492 8.385383605957031\n",
      "1.612729549407959 9.170707702636719\n",
      "h\n",
      "15.585822105407715 11.576179504394531\n",
      "2.741321325302124 -5.563211441040039\n",
      "h\n",
      "16.00225257873535 8.32889175415039\n",
      "-3.1251511573791504 -39.8695068359375\n",
      "h\n",
      "18.544811248779297 11.8841552734375\n",
      "-2.204787015914917 -15.113668441772461\n",
      "h\n",
      "18.548494338989258 13.399232864379883\n",
      "1.0070135593414307 37.28767776489258\n",
      "h\n",
      "16.36518669128418 10.43846321105957\n",
      "-2.407611608505249 -0.21759843826293945\n",
      "h\n",
      "16.766250610351562 9.270914077758789\n",
      "-3.3712310791015625 30.524829864501953\n",
      "h\n",
      "14.669663429260254 8.600264549255371\n",
      "2.081355094909668 -1.9556349515914917\n",
      "h\n",
      "15.520383834838867 7.870769500732422\n",
      "1.4222896099090576 22.22512435913086\n",
      "h\n",
      "16.39776039123535 7.390601634979248\n",
      "0.17546308040618896 -40.02701187133789\n",
      "h\n",
      "16.6684513092041 10.163793563842773\n",
      "9.735057830810547 -4.866774559020996\n",
      "h\n",
      "14.380048751831055 7.109065055847168\n",
      "-2.442127227783203 -24.21950912475586\n",
      "h\n",
      "16.272052764892578 7.420269966125488\n",
      "-7.698086738586426 62.173805236816406\n",
      "h\n",
      "10.861021041870117 4.524538516998291\n",
      "-0.8411014080047607 32.92559051513672\n",
      "h\n",
      "11.794175148010254 3.1382973194122314\n",
      "6.587797164916992 -3.79280948638916\n",
      "h\n",
      "16.336885452270508 6.245671272277832\n",
      "-9.842906951904297 -47.97581481933594\n",
      "h\n",
      "15.646645545959473 7.008029460906982\n",
      "1.6293400526046753 61.09855651855469\n",
      "h\n",
      "16.299503326416016 9.718326568603516\n",
      "3.4221134185791016 -28.932390213012695\n",
      "h\n",
      "14.449541091918945 11.833253860473633\n",
      "-3.2021055221557617 -35.85157012939453\n",
      "h\n",
      "15.406458854675293 10.657981872558594\n",
      "2.1399261951446533 49.92259979248047\n",
      "h\n",
      "17.072769165039062 11.170125961303711\n",
      "-7.728151798248291 -31.958995819091797\n",
      "h\n",
      "14.30941390991211 7.718364715576172\n",
      "-0.0828852653503418 -27.250425338745117\n",
      "h\n",
      "16.768972396850586 11.284313201904297\n",
      "3.9116079807281494 -54.83154296875\n",
      "h\n",
      "14.224660873413086 6.028111457824707\n",
      "3.5183351039886475 -8.583236694335938\n",
      "h\n",
      "14.157243728637695 4.108088493347168\n",
      "-2.8067798614501953 48.64846420288086\n",
      "h\n",
      "19.83786392211914 12.366390228271484\n",
      "7.711895942687988 0.3670095205307007\n",
      "h\n",
      "18.613697052001953 12.455986022949219\n",
      "-5.930981159210205 30.85239028930664\n",
      "h\n",
      "14.095074653625488 6.3821611404418945\n",
      "9.584667205810547 -30.38941192626953\n",
      "h\n",
      "15.425775527954102 10.400848388671875\n",
      "4.956835746765137 -10.735883712768555\n",
      "h\n",
      "16.855308532714844 9.954970359802246\n",
      "-0.8591716289520264 -7.199571132659912\n",
      "h\n",
      "17.992345809936523 10.363795280456543\n",
      "9.615142822265625 12.433926582336426\n",
      "h\n",
      "11.22191047668457 3.653398275375366\n",
      "1.8061182498931885 -20.239566802978516\n",
      "h\n",
      "9.185664176940918 4.289755821228027\n",
      "0.4170109033584595 -19.251052856445312\n",
      "h\n",
      "16.299503326416016 9.718326568603516\n",
      "3.4221134185791016 -28.932390213012695\n",
      "h\n",
      "14.449541091918945 11.833253860473633\n",
      "-3.2021055221557617 -35.85157012939453\n",
      "h\n",
      "14.052519798278809 9.695889472961426\n",
      "7.987891674041748 -15.997453689575195\n",
      "h\n",
      "14.83008861541748 7.414546489715576\n",
      "-3.505863666534424 -47.1068229675293\n",
      "h\n",
      "16.48956298828125 9.136743545532227\n",
      "-2.1396608352661133 -3.536954402923584\n",
      "h\n",
      "15.77269172668457 9.213828086853027\n",
      "-8.737995147705078 -11.788990020751953\n",
      "h\n",
      "17.51837158203125 9.624862670898438\n",
      "4.503121376037598 -41.50974655151367\n",
      "h\n",
      "16.068586349487305 9.978069305419922\n",
      "1.532455563545227 -15.997509002685547\n",
      "h\n",
      "15.161977767944336 4.8690667152404785\n",
      "2.584624767303467 -13.022727966308594\n",
      "h\n",
      "14.288325309753418 10.116472244262695\n",
      "7.917823314666748 -60.640106201171875\n",
      "h\n",
      "15.050782203674316 10.455619812011719\n",
      "3.980501890182495 9.842601776123047\n",
      "h\n",
      "13.355952262878418 8.135208129882812\n",
      "-3.7414815425872803 12.320381164550781\n",
      "h\n",
      "14.79833984375 10.084672927856445\n",
      "6.437402248382568 55.108848571777344\n",
      "h\n",
      "10.920382499694824 1.7902164459228516\n",
      "-0.6614793539047241 -12.868444442749023\n",
      "h\n",
      "13.344636917114258 7.28670597076416\n",
      "-0.513707160949707 46.30146026611328\n",
      "h\n",
      "16.567476272583008 9.052946090698242\n",
      "2.6877522468566895 20.682714462280273\n",
      "h\n",
      "15.591033935546875 11.579273223876953\n",
      "-6.953457832336426 4.992960453033447\n",
      "h\n",
      "15.871563911437988 8.972944259643555\n",
      "-1.3056917190551758 -16.025474548339844\n",
      "h\n",
      "15.332590103149414 8.09166145324707\n",
      "-1.4696078300476074 9.947774887084961\n",
      "h\n",
      "15.952951431274414 9.328046798706055\n",
      "-8.466363906860352 -33.127723693847656\n",
      "h\n",
      "12.545150756835938 6.543041229248047\n",
      "3.718639850616455 -31.48052406311035\n",
      "h\n",
      "11.745452880859375 4.749141693115234\n",
      "-4.059512615203857 -31.17159652709961\n",
      "h\n",
      "14.710734367370605 7.189019203186035\n",
      "-8.113587379455566 16.371967315673828\n",
      "h\n",
      "15.396932601928711 9.213991165161133\n",
      "-2.7745323181152344 6.283504962921143\n",
      "h\n",
      "15.46364974975586 7.662905693054199\n",
      "-5.817660331726074 -4.512526035308838\n",
      "h\n",
      "15.516579627990723 8.438018798828125\n",
      "7.574199199676514 -40.14968490600586\n",
      "h\n",
      "18.00779914855957 11.00239086151123\n",
      "-3.845308303833008 -25.69446563720703\n",
      "h\n",
      "16.74390411376953 11.326934814453125\n",
      "-5.264564514160156 23.29741859436035\n",
      "h\n",
      "15.607980728149414 8.785783767700195\n",
      "4.279184341430664 21.17559242248535\n",
      "h\n",
      "15.31121826171875 10.23464584350586\n",
      "-1.3506779670715332 35.27305603027344\n",
      "h\n",
      "16.545787811279297 9.748418807983398\n",
      "5.1703362464904785 -14.891695022583008\n",
      "h\n",
      "15.641013145446777 12.105112075805664\n",
      "-4.339848518371582 -2.8296098709106445\n",
      "h\n",
      "17.89249610900879 9.464522361755371\n",
      "2.066053867340088 38.74785232543945\n",
      "h\n",
      "16.218936920166016 9.47114086151123\n",
      "-5.354866027832031 16.037155151367188\n",
      "h\n",
      "14.24139404296875 8.756010055541992\n",
      "4.923202991485596 41.001220703125\n",
      "h\n",
      "14.029823303222656 6.8785505294799805\n",
      "6.097702980041504 43.89731979370117\n",
      "h\n",
      "17.364980697631836 8.91641616821289\n",
      "-0.628294825553894 36.6123161315918\n",
      "h\n",
      "18.27509307861328 12.241517066955566\n",
      "3.087888240814209 -33.56169128417969\n",
      "h\n",
      "14.829706192016602 5.538116931915283\n",
      "0.1917802095413208 50.553794860839844\n",
      "h\n",
      "15.466934204101562 10.313305854797363\n",
      "1.0343191623687744 -2.2826528549194336\n",
      "h\n",
      "16.935216903686523 7.608884811401367\n",
      "-2.2093348503112793 -3.8333492279052734\n",
      "h\n",
      "17.26114273071289 10.614680290222168\n",
      "4.5497636795043945 -34.496795654296875\n",
      "h\n",
      "15.367265701293945 7.916478157043457\n",
      "0.17589432001113892 5.268338203430176\n",
      "h\n",
      "16.1202335357666 7.427145957946777\n",
      "6.865468978881836 32.02280807495117\n",
      "h\n",
      "14.906461715698242 7.238569736480713\n",
      "1.9232205152511597 34.59309768676758\n",
      "h\n",
      "14.982187271118164 10.453558921813965\n",
      "-3.2551188468933105 -41.273555755615234\n",
      "h\n",
      "15.953706741333008 9.514832496643066\n",
      "-11.219736099243164 27.329790115356445\n",
      "h\n",
      "16.191654205322266 11.261881828308105\n",
      "-25.088703155517578 -26.26083755493164\n",
      "h\n",
      "12.981090545654297 4.800163745880127\n",
      "6.47797966003418 -29.343719482421875\n",
      "h\n",
      "12.702577590942383 5.3510541915893555\n",
      "0.045181989669799805 27.955537796020508\n",
      "h\n",
      "18.05076026916504 8.262930870056152\n",
      "-26.727258682250977 -20.908039093017578\n",
      "h\n",
      "13.114811897277832 8.236100196838379\n",
      "6.163795471191406 -10.405448913574219\n",
      "h\n",
      "11.184981346130371 5.477569580078125\n",
      "-0.823401689529419 -37.131561279296875\n",
      "h\n",
      "12.11019515991211 5.487217426300049\n",
      "6.398008823394775 1.1598834991455078\n",
      "h\n",
      "13.631156921386719 5.005945205688477\n",
      "-1.3013010025024414 -35.36598205566406\n",
      "h\n",
      "14.353663444519043 9.097090721130371\n",
      "-4.851175785064697 35.707313537597656\n",
      "h\n",
      "17.855365753173828 8.765284538269043\n",
      "-5.845831871032715 34.547393798828125\n",
      "h\n",
      "14.91015911102295 8.219558715820312\n",
      "-26.652511596679688 -9.593456268310547\n",
      "h\n",
      "13.329482078552246 9.186090469360352\n",
      "-2.7445895671844482 -38.9617805480957\n",
      "h\n",
      "12.575907707214355 3.318831443786621\n",
      "-2.0611305236816406 -0.8795684576034546\n",
      "h\n",
      "15.52709674835205 7.9920525550842285\n",
      "-2.611707925796509 28.657346725463867\n",
      "h\n",
      "15.117034912109375 8.496362686157227\n",
      "0.487715482711792 -22.42041778564453\n",
      "h\n",
      "16.837112426757812 9.816349029541016\n",
      "-7.890166282653809 -30.835987091064453\n",
      "h\n",
      "15.798788070678711 9.763764381408691\n",
      "3.669558525085449 22.46722984313965\n",
      "h\n",
      "16.238201141357422 7.920373439788818\n",
      "-2.11696195602417 36.563568115234375\n",
      "h\n",
      "14.977234840393066 7.65087366104126\n",
      "-13.844106674194336 51.51967239379883\n",
      "h\n",
      "13.773504257202148 8.524214744567871\n",
      "2.0446596145629883 5.833892822265625\n",
      "h\n",
      "13.961038589477539 9.59559440612793\n",
      "-16.38018798828125 -35.64924621582031\n",
      "h\n",
      "13.866863250732422 10.403433799743652\n",
      "0.18948078155517578 -5.849045276641846\n",
      "h\n",
      "16.57666015625 6.441707611083984\n",
      "4.734696388244629 52.837406158447266\n",
      "h\n",
      "14.015767097473145 7.827755928039551\n",
      "-5.012124061584473 -50.24174880981445\n",
      "h\n",
      "14.888607025146484 8.124990463256836\n",
      "-4.5537614822387695 27.047649383544922\n",
      "h\n",
      "13.07066535949707 5.752313613891602\n",
      "-13.06021499633789 7.693819522857666\n",
      "h\n",
      "14.98537826538086 8.10573959350586\n",
      "4.445674419403076 -6.269136428833008\n",
      "h\n",
      "16.95366859436035 10.334005355834961\n",
      "3.146125316619873 -22.511152267456055\n",
      "h\n",
      "17.195240020751953 10.66891098022461\n",
      "-5.892423152923584 0.8991451263427734\n",
      "h\n",
      "17.33126449584961 12.410531044006348\n",
      "-11.9546480178833 -55.83887481689453\n",
      "h\n",
      "16.502975463867188 12.980813026428223\n",
      "0.5605758428573608 -28.651676177978516\n",
      "h\n",
      "14.320621490478516 5.762042045593262\n",
      "-5.752760887145996 -46.874881744384766\n",
      "h\n",
      "12.848661422729492 6.104880332946777\n",
      "-10.425561904907227 -18.884552001953125\n",
      "h\n",
      "16.39776039123535 7.390601634979248\n",
      "0.17546308040618896 -40.02701187133789\n",
      "h\n",
      "16.6684513092041 10.163793563842773\n",
      "9.735057830810547 -4.866774559020996\n",
      "h\n",
      "14.368732452392578 7.548228740692139\n",
      "-4.609913349151611 -36.13181686401367\n",
      "h\n",
      "15.064282417297363 8.308619499206543\n",
      "2.828176498413086 -43.8228874206543\n",
      "h\n",
      "15.272117614746094 7.513121128082275\n",
      "-1.9908170700073242 25.334665298461914\n",
      "h\n",
      "14.374013900756836 5.310833930969238\n",
      "2.037912368774414 61.625709533691406\n",
      "h\n",
      "15.859074592590332 8.208483695983887\n",
      "-5.304727554321289 3.60602068901062\n",
      "h\n",
      "17.013866424560547 8.498764038085938\n",
      "3.4107937812805176 -12.180163383483887\n",
      "h\n",
      "11.89676284790039 7.33900260925293\n",
      "3.0724446773529053 35.774662017822266\n",
      "h\n",
      "14.052923202514648 5.363186359405518\n",
      "-1.5547268390655518 47.63958740234375\n",
      "h\n",
      "19.005756378173828 13.246550559997559\n",
      "1.1653929948806763 6.207075595855713\n",
      "h\n",
      "17.389223098754883 13.453790664672852\n",
      "1.821940302848816 -13.385778427124023\n",
      "h\n",
      "17.68056869506836 5.611257553100586\n",
      "9.42885971069336 9.587654113769531\n",
      "h\n",
      "14.44775104522705 10.439446449279785\n",
      "29.327693939208984 18.844890594482422\n",
      "h\n",
      "11.746161460876465 5.573391914367676\n",
      "-5.846700191497803 -9.517237663269043\n",
      "h\n",
      "11.99139404296875 7.325329780578613\n",
      "-10.146591186523438 -25.697967529296875\n",
      "h\n",
      "16.178407669067383 9.0160551071167\n",
      "6.311351776123047 6.120110034942627\n",
      "h\n",
      "17.384723663330078 8.490104675292969\n",
      "3.763883590698242 -19.53798484802246\n",
      "h\n",
      "14.345429420471191 8.967655181884766\n",
      "-0.42703962326049805 -25.33700180053711\n",
      "h\n",
      "14.806262016296387 4.610994338989258\n",
      "-1.4173917770385742 5.9518938064575195\n",
      "h\n",
      "16.100406646728516 10.995957374572754\n",
      "-1.6567704677581787 10.212364196777344\n",
      "h\n",
      "17.979389190673828 7.976305961608887\n",
      "1.6969459056854248 -45.14743423461914\n",
      "h\n",
      "12.717581748962402 5.667555332183838\n",
      "3.310988187789917 17.849430084228516\n",
      "h\n",
      "13.893537521362305 5.038000583648682\n",
      "-3.183180332183838 -8.53040885925293\n",
      "h\n",
      "15.307296752929688 7.891786575317383\n",
      "5.204636573791504 -19.465051651000977\n",
      "h\n",
      "12.196322441101074 3.679227828979492\n",
      "0.5914669036865234 -50.718353271484375\n",
      "h\n",
      "13.329482078552246 9.186090469360352\n",
      "-2.7445895671844482 -38.9617805480957\n",
      "h\n",
      "12.575907707214355 3.318831443786621\n",
      "-2.0611305236816406 -0.8795684576034546\n",
      "h\n",
      "12.203004837036133 6.083037853240967\n",
      "-1.0008347034454346 23.98700714111328\n",
      "h\n",
      "14.704365730285645 7.946584701538086\n",
      "-0.016435742378234863 -14.676387786865234\n",
      "h\n",
      "15.698116302490234 6.560624122619629\n",
      "4.125256061553955 2.9740285873413086\n",
      "h\n",
      "14.413520812988281 7.559412956237793\n",
      "-18.824169158935547 36.48233413696289\n",
      "h\n",
      "15.054311752319336 7.013485431671143\n",
      "-0.33341383934020996 32.88636016845703\n",
      "h\n",
      "14.400745391845703 8.226999282836914\n",
      "-2.319897174835205 16.9798583984375\n",
      "h\n",
      "16.742595672607422 9.596820831298828\n",
      "-4.120171070098877 -10.617629051208496\n",
      "h\n",
      "14.751602172851562 6.340147018432617\n",
      "12.920976638793945 5.698291778564453\n",
      "h\n",
      "14.489692687988281 5.523256778717041\n",
      "-6.964242935180664 15.203484535217285\n",
      "h\n",
      "14.315783500671387 6.335674285888672\n",
      "7.384576320648193 -5.65513277053833\n",
      "h\n",
      "12.951492309570312 4.968156337738037\n",
      "-0.3871188163757324 15.705499649047852\n",
      "h\n",
      "13.207586288452148 4.612159729003906\n",
      "-23.842777252197266 -11.337262153625488\n",
      "h\n",
      "16.299503326416016 9.718326568603516\n",
      "3.4221134185791016 -28.932390213012695\n",
      "h\n",
      "14.449541091918945 11.833253860473633\n",
      "-3.2021055221557617 -35.85157012939453\n",
      "h\n",
      "15.706313133239746 6.989566326141357\n",
      "4.806384086608887 -6.323780059814453\n",
      "h\n",
      "15.175418853759766 8.616482734680176\n",
      "-1.0566871166229248 -21.671432495117188\n",
      "h\n",
      "15.926142692565918 9.8261137008667\n",
      "2.6988489627838135 15.621175765991211\n",
      "h\n",
      "17.27912712097168 11.191543579101562\n",
      "5.8326616287231445 -13.644901275634766\n",
      "h\n",
      "16.545787811279297 9.748418807983398\n",
      "5.1703362464904785 -14.891695022583008\n",
      "h\n",
      "15.641013145446777 12.105112075805664\n",
      "-4.339848518371582 -2.8296098709106445\n",
      "h\n",
      "15.317859649658203 9.43427848815918\n",
      "0.5738344192504883 15.901336669921875\n",
      "h\n",
      "13.300771713256836 7.8972930908203125\n",
      "0.8151917457580566 -12.686817169189453\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(len(replace_corrects)):\n",
    "    replace_diff = -torch.tensor(replace_corrects[i]) + torch.tensor(replace_replaces[i])\n",
    "    n_correct = torch.sum(replace_diff > 0)\n",
    "    print(f\"{n_correct}/{len(replace_corrects[i])}\")\n",
    "    print(f'replace min diff {torch.min(replace_diff)} max diff {torch.max(replace_diff)} avg diff {torch.mean(replace_diff)}')\n",
    "\n",
    "    for j in range(len(replace_corrects[i])):\n",
    "        print(\"h\")\n",
    "        print(original_corrects[i][j], original_replaces[i][j])\n",
    "        print(replace_corrects[i][j], replace_replaces[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd4e2e-ae43-403d-9410-ad374a7ce622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
